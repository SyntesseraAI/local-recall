---
id: 308a9879-2a2e-48ec-86d1-b9b47a79dc89
subject: Transcript condensing for memory extraction reduces token usage
keywords:
  - transcript
  - condensing
  - token-efficiency
  - memory-extraction
  - haiku-processing
applies_to: 'area:memory-extractor'
occurred_at: '2025-12-01T21:41:32.228Z'
content_hash: 186c2ef7956bfeee
---
## Transcript Condensing Strategy

When extracting memories from transcripts, the full transcript can be very large and costly to process with Claude. The solution implemented is to condense transcripts before sending to Claude for keyword extraction.

### Why Condense

- **Token efficiency**: Large transcripts consume many tokens when processed with Claude Haiku
- **Cost reduction**: Fewer tokens = lower API costs
- **Speed improvement**: Smaller payloads process faster
- **Relevance**: Condensed transcripts focus on key information needed for memory extraction

### How It Works

The transcript condensing process:
1. Takes the full JSONL transcript
2. Extracts key information (user prompts, tool results, major outcomes)
3. Creates a condensed version that preserves important context
4. Sends the condensed version to Claude Haiku for keyword extraction

### Implementation

- Located in `src/core/memory-extractor.ts`
- Part of the MCP server daemon background processing
- Runs asynchronously every 5 minutes
- Helps create efficient, focused memories from session transcripts
