---
id: 79996b49-1e79-4cc0-b015-6b48517652df
subject: >-
  UserPromptSubmit hook uses Orama vector search for both episodic and thinking
  memories
keywords:
  - userpromptsubmit
  - vector search
  - orama
  - ollama embeddings
  - semantic search
  - thinking memories
applies_to: 'file:src/hooks/user-prompt-submit.ts'
occurred_at: '2025-12-21T18:16:18.307Z'
content_hash: 78cc6a92692f9f65
---
## Implementation
The UserPromptSubmit hook performs semantic search on two independent memory types:

### Episodic Memories
- Uses Orama vector store with Ollama embeddings
- Configuration: `episodicEnabled`, `episodicMinSimilarity` (default 0.5), `episodicMaxTokens` (default 1000)
- Returns memories ranked by cosine similarity score

### Thinking Memories
- Uses separate Orama vector store (`orama-thinking-index.json`)
- Configuration: `thinkingEnabled`, `thinkingMinSimilarity` (default 0.5), `thinkingMaxTokens` (default 1000)
- Stores thought+output pairs for reasoning examples

## Execution Flow
1. Parse JSON input with session_id, transcript_path, cwd, prompt
2. Skip internal prompts (containing `[LOCAL_RECALL_INTERNAL]`)
3. Generate embedding for user prompt via Ollama
4. Search both episodic and thinking vector stores (if enabled)
5. Filter by similarity threshold and token budget
6. Combine results and output to stdout

## Potential Issues
- Depends on Ollama running and nomic-embed-text model available
- Vector indexes must exist and be valid JSON
- Token counting must be accurate to respect budget
- Embedding generation can be slow for long prompts
