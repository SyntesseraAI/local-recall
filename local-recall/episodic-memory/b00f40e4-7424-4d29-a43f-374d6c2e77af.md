---
id: b00f40e4-7424-4d29-a43f-374d6c2e77af
subject: Ollama is recommended solution for multi-Claude-instance embedding problem
keywords:
  - ollama
  - embedding
  - daemon
  - api
  - nomic-embed-text
  - multi-process
applies_to: global
occurred_at: '2025-12-21T18:25:17.343Z'
content_hash: b90d1f9da46fb183
---
Ollama provides a single embedding daemon that supports multiple concurrent clients via HTTP API. This solves the ONNX mutex issue because only one process loads the model. Installation: `brew install ollama` (macOS), `curl -fsSL https://ollama.com/install.sh | sh` (Linux), or download from ollama.com (Windows). Pull model: `ollama pull nomic-embed-text`. Server runs on http://localhost:11434 with `/api/embed` endpoint. This allows multiple Claude instances to share one embedding service without concurrency issues.
