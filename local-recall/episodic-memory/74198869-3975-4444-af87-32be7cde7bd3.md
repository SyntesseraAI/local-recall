---
id: 74198869-3975-4444-af87-32be7cde7bd3
subject: Vector embedding support planned for semantic memory search
keywords:
  - embedding
  - vector-store
  - semantic-search
  - fastembed
  - bge-small-en-v1.5
  - memory-search
applies_to: 'area:search'
occurred_at: '2025-12-02T02:36:05.507Z'
content_hash: c5fd356e59647aaa
---
# Vector Embedding and Semantic Search

## Status

Vector embedding support is planned for local-recall to enable semantic search of memories beyond keyword matching.

## Implementation Details

- Uses `fastembed` library with BGE-small-en-v1.5 model (~133MB)
- Model is automatically downloaded to `local_cache/` on first use
- Initial startup may take 30-60 seconds for model download
- Subsequent runs load from cache for faster startup

## Files Being Created

- `src/core/embedding.ts` - Embedding generation logic
- `src/core/vector-store.ts` - Vector storage and retrieval

## Benefits

- Find semantically similar memories even with different keywords
- Improve memory search relevance
- Support more flexible natural language queries

## Troubleshooting

If you see: "Tokenizer file not found at local_cache/fast-bge-small-en-v1.5/tokenizer.json"
- The model cache is corrupted (usually from interrupted download)
- Solution: `rm -rf local_cache/fast-bge-small-en-v1.5*` and re-run
- The model will re-download automatically
