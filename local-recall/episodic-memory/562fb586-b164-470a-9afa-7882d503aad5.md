---
id: 562fb586-b164-470a-9afa-7882d503aad5
subject: Transcript condensing reduces token usage in memory extraction pipeline
keywords:
  - transcript-condensing
  - token-efficiency
  - memory-extraction
  - performance
applies_to: global
occurred_at: '2025-12-02T07:26:15.522Z'
content_hash: fc1f5cd752f41b98
---
The codebase implements transcript condensing as part of the memory extraction pipeline to reduce token usage when sending transcripts to Claude Haiku. This is important for keeping API costs down and improving performance when processing long or verbose transcripts. The condensing happens before the transcript is sent to the model for memory extraction.
