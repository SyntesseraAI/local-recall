---
id: e065434c-7a6c-46b0-a880-df4129374b4a
subject: Memory extraction should filter transcripts to avoid duplicate processing
keywords:
  - transcript-filtering
  - deduplication
  - memory-extraction
  - transcript-collector
  - hash-tracking
applies_to: 'area:transcript-collector'
occurred_at: '2025-12-01T22:32:01.807Z'
content_hash: 68950e1fd083cd96
---
# Transcript Deduplication Strategy

When extracting memories from transcripts, it's important to track which transcripts have already been processed to avoid duplicates.

## Why This Matters

The MCP server processes transcripts periodically (every 5 minutes). Without proper tracking, the same transcript could be processed multiple times, creating duplicate memories.

## Implementation Approach

1. Keep track of processed transcript files using content hashes
2. Only process transcripts that are new or have changed
3. When a transcript is modified, delete and recreate its associated memories
4. Use a tracking file to store hashes of processed transcripts

This is similar to how the daemon already handles detecting changes in transcripts - the same pattern should apply to transcript collection and memory extraction.
