---
id: a074be96-3844-4f6d-8af6-54f309e25264
subject: Embedding model integration using fastembed library
keywords:
  - embeddings
  - vector-store
  - semantic-search
  - fastembed
  - bge-small-en-v1.5
  - cache
  - model
applies_to: 'area:semantic-search'
occurred_at: '2025-12-02T06:31:39.307Z'
content_hash: 9455e492fc4b15c6
---
# Embedding Model Setup

Local Recall uses the `fastembed` library (npm package `@xenova/transformers`) to generate embeddings for semantic search.

## Model Selection

- Model: `BGE-small-en-v1.5`
- Size: ~133MB
- Cache location: `local_cache/` directory
- Auto-downloads on first use
- Subsequent runs load from cache

## First Run Performance

- Initial startup: 30-60 seconds (while downloading model)
- Subsequent runs: Fast (model loaded from cache)
- Download interruptions corrupt cache - solution: delete `local_cache/` and let it re-download

## Implementation Files

- `src/core/embedding.ts` - Embedding generation
- `src/core/vector-store.ts` - Vector storage and similarity search

## Key Takeaway

The embedding model is critical for semantic search functionality. Cache management is important for reliable operation.
