{"action":"add","id":"b1576970-4c65-4d86-bc4f-a8002f49c089","subject":"VectorStore singleton needs reset method for test isolation","keywords":["vector-store","singleton","testing","test-isolation","memory-leaks"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:15:15.466Z","content_hash":"d63df2b378729a3c","content":"The VectorStore uses a singleton pattern with module-level state. Integration tests that use different memory directories need a way to reset this state between tests. Added an internal `_reset()` function for testing that clears the singleton instance, allowing tests to initialize fresh vector stores with different database paths.","timestamp":"2025-12-21T19:27:10.943Z"}
{"action":"add","id":"96270b43-9d19-4a9f-85be-5dc9dda8ef83","subject":"Migrated embedding service from fastembed to Ollama","keywords":["ollama","fastembed","embedding","migration","nomic-embed-text","vector-search"],"applies_to":"global","occurred_at":"2025-12-03T11:46:02.915Z","content_hash":"5493e9917b0a1ac0","content":"# Embedding Service Migration: fastembed → Ollama\n\nReplaced fastembed (ONNX-based BGE-small-en-v1.5) with Ollama HTTP API for embeddings.\n\n## Key Changes\n\n- **Model**: `nomic-embed-text` (768 dimensions) replaces BGE-small-en-v1.5 (384 dimensions)\n- **Architecture**: HTTP API calls to local Ollama server instead of in-process ONNX runtime\n- **Concurrency**: Ollama handles concurrent requests properly - no more mutex errors\n\n## Removed Dependencies\n\n- `fastembed` - ONNX embedding library\n- `proper-lockfile` - Only needed for ONNX mutex workarounds\n- `local_cache/` directory - No longer needed (Ollama manages model storage)\n\n## Configuration\n\n- `OLLAMA_BASE_URL` - Server URL (default: `http://localhost:11434`)\n- `OLLAMA_EMBED_MODEL` - Model name (default: `nomic-embed-text`)\n\n## Migration Required\n\nUsers must rebuild vector indexes after this change due to dimension change (384 → 768):\n\n```bash\nrm local-recall/orama-episodic-index.json\nrm local-recall/orama-thinking-index.json\nollama pull nomic-embed-text\n```","timestamp":"2025-12-21T19:27:10.953Z"}
{"action":"add","id":"491dcc3e-d9a8-4076-93a2-2cfb6114f3b4","subject":"Fix AbortError in user-prompt-submit hook by removing spawn timeout","keywords":["abort error","spawn timeout","child process","user-prompt-submit hook","error handling"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:20:27.934Z","content_hash":"64c5cd6e49128671","content":"The user-prompt-submit hook was throwing an uncaught AbortError when calling Claude for keyword extraction. The root cause was the `timeout` option in the `spawn` call (line 41), which Node.js kills via an AbortError that wasn't being caught.\n\n**Solution**: Removed the `timeout` option from spawn and replaced it with a custom `safeResolve` wrapper that ensures the promise resolves only once. This prevents race conditions and properly handles both normal completion and timeout scenarios.\n\n**Additional fixes**: Removed duplicate `child.on('close', ...)` handlers that could cause multiple resolutions and added an early-exit guard in the close handler.\n\nThis ensures the hook completes gracefully without throwing unhandled promise rejections.","timestamp":"2025-12-21T19:27:10.955Z"}
{"action":"add","id":"9b34589b-2e3b-426e-a307-f40a7ecb80d0","subject":"MCP server runs background daemon processing transcripts every 5 minutes for memory extraction","keywords":["mcp server","daemon","transcript processing","background task"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"eaf2767e9d9cb33f","content":"The MCP server runs a background daemon that syncs transcripts from Claude's cache, processes them using 'claude -p' to extract memories, tracks processed transcripts with content hashes for change detection, and deletes/recreates memories when transcripts change. This runs every 5 minutes. The Stop hook is currently disabled in favor of this async daemon approach.","timestamp":"2025-12-21T19:27:10.957Z"}
{"action":"add","id":"9bfadc9d-136e-40b9-a5d1-398315936548","subject":"Hooks should NOT directly instantiate SearchEngine to avoid loading ONNX in multiple processes","keywords":["hooks","user-prompt-submit","search-engine","embedding","architecture"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"7a7334620e64883c","content":"The user-prompt-submit hook currently loads SearchEngine and ThinkingSearchEngine directly, which triggers ONNX embedding model initialization. This causes mutex errors in concurrent environments. The session-start hook avoids this by only using MemoryManager (file-based operations). Hooks should either use text-based search (no embeddings) or call an HTTP daemon for vector search.","timestamp":"2025-12-21T19:27:10.959Z"}
{"action":"add","id":"39f0f82c-3fd3-48a4-b958-e2a8b9271d17","subject":"Multiple local-recall instances in same folder have concurrent write conflicts","keywords":["concurrency","multi-instance","orama-index","processed-log","file-locking"],"applies_to":"global","occurred_at":"2025-12-21T18:22:39.533Z","content_hash":"196bcc83900a38cc","content":"When multiple Claude Code instances run local-recall on the same codebase folder, they cause concurrent write conflicts:\n\n- `orama-episodic-index.json` and `orama-thinking-index.json`: Multiple processes write without coordination, causing data loss\n- `processed-log.jsonl`: Append operations can interleave, corrupting the log format\n- `thinking-processed-log.jsonl`: Same append issue as episodic version\n\n**Root cause**: No file locking mechanism or process coordination. Each process assumes exclusive access.\n\n**Current workaround**: Hooks are disabled to prevent concurrent writes. Only MCP server daemon writes to memory files.\n\n**Solution needed**: Implement file-based locking (using `proper-lockfile` npm package) or mutex mechanism to coordinate writes across multiple processes.\n\n**Files affected**:\n- `src/core/episodic-jsonl-store.ts` - Appends to processed-log.jsonl\n- `src/core/thinking-jsonl-store.ts` - Appends to thinking-processed-log.jsonl\n- `src/core/vector-store.ts` - Writes index JSON files\n- All hook files that write memory\n\n**Current status**: Session-start and user-prompt-submit hooks disabled in CLAUDE.md to prevent the problem.","timestamp":"2025-12-21T19:27:10.962Z"}
{"action":"add","id":"9d6127b6-7e7b-4df3-8530-0500e7258971","subject":"Memory extraction uses Haiku model with 10 minute timeout and single turn","keywords":["memory-extraction","haiku","timeout","single-turn","json-only"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:29:15.440Z","content_hash":"7c845359ca3134ec","content":"Memory extraction via `claude -p` should use:\n- Model: `haiku` (use `--model haiku` flag)\n- Timeout: 600000ms (10 minutes)\n- Single turn: `--max-turns 1` flag\n- Response format: JSON only (no markdown, no explanation)\n\nThis is configured in the `callClaudeCLI` method in memory-extractor.ts around line 79-84. Haiku is fast and cheap for structured extraction tasks.","timestamp":"2025-12-21T19:27:10.963Z"}
{"action":"add","id":"5c4c843d-4f1b-47db-9f4b-4e6b8008b5a8","subject":"Thinking memories now pair thought blocks with text output for better contextual examples","keywords":["thinking memories","thought extraction","output pairing","transcript parsing","thinking-extractor"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:17:09.782Z","content_hash":"e9a84380c6bcbac5","content":"Thinking memories now combine Claude's internal reasoning (thinking block) with the corresponding text output that follows it. This creates complete thought→output examples that help future sessions understand how Claude reasoned about similar problems.\n\n**Implementation details:**\n- Extracts both ThinkingContent and TextContent from the same AssistantMessageEntry\n- Skips tool-only responses (responses with no text output)\n- Stores in markdown format with sections: `## Thought` and `## Output`\n- Keeps the full output without truncation for complete context\n\nThis is more useful than storing thoughts alone because it provides concrete examples of reasoning paired with the actual output produced.","timestamp":"2025-12-21T19:27:10.967Z"}
{"action":"add","id":"039366e0-4eb9-4630-9ca8-0fd4ae658a97","subject":"nomic-embed-text model has 2048 token context limit","keywords":["ollama","embedding","nomic-embed-text","context-limit","truncation","error-handling"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-20T22:38:28.607Z","content_hash":"37806e2b9514a90a","content":"The `nomic-embed-text` embedding model used for vector search has a hard context limit of 2048 tokens. When inputs exceed this limit, Ollama logs a warning and may experience crashes or EOF errors.\n\nThe solution is to truncate embedding inputs to approximately 6000 characters (~1500 tokens, well under the limit) BEFORE sending to Ollama's API. This prevents context overflow errors and ensures consistent embedding generation.\n\nError signature: `Ollama embed failed: 500 - {\"error\":\"do embedding request: Post ... EOF\"}`","timestamp":"2025-12-21T19:27:10.970Z"}
{"action":"add","id":"47bcaea8-8c2c-49d3-9c39-9b2eea082637","subject":"Synthetic transcript filtering moved to pre-copy stage in transcript collector","keywords":["synthetic transcripts","transcript-collector","syncTranscripts","filtering","optimization"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:22:06.032Z","content_hash":"7f97ff6401fb299a","content":"The transcript collection process now filters synthetic transcripts BEFORE copying them from Claude's cache, rather than copying and then cleaning up. This optimization prevents unnecessary I/O.\n\nPrevious flow:\n1. Copy transcript from cache\n2. Clean up synthetic files\n\nNew flow:\n1. Clean up existing synthetic files\n2. Check `isSyntheticFile()` on source transcript\n3. Skip copying if synthetic (with debug log)\n4. Only copy legitimate transcripts\n\nThis avoids the overhead of copying files that would immediately be removed by cleanup.","timestamp":"2025-12-21T19:27:10.972Z"}
{"action":"add","id":"67a89e8c-291e-47c1-a144-a2586dae853f","subject":"No active memory compaction or cleanup implemented","keywords":["compaction","cleanup","pruning","max-memories","consolidation"],"applies_to":"global","occurred_at":"2025-12-21T19:17:09.190Z","content_hash":"4ee51b673957cf9a","content":"Currently NO memory compaction/cleanup exists. The config has a `maxMemories` option (default 1000) but it's not actively enforced. Memories are only deduplicated at creation time using content hash + timestamp. There is no periodic pruning, merging, or consolidation of memories, which could become an issue as memory store grows over time.","timestamp":"2025-12-21T19:27:10.975Z"}
{"action":"add","id":"05bec31f-5820-4df5-ac1e-c67129ba5895","subject":"MCP server is running from dev-marketplace/local-recall-plugin subdirectory, not project root","keywords":["mcp","server","configuration","dev-marketplace","plugin"],"applies_to":"global","occurred_at":"2025-12-21T18:29:39.576Z","content_hash":"f6d7b38579e8de0f","content":"The MCP server is currently configured and running from:\n- **Location**: `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js`\n- **Config**: `dev-marketplace/local-recall-plugin/.mcp.json`\n- **Process**: Running (verified with pgrep)\n\nThis is a plugin subdirectory structure, not the main project root. The main project root at `/Users/joe/Code/Syntessera/local-recall/` doesn't have a `scripts/` directory yet - indicating that `npm run build` output structure may differ from expected or build artifacts are being placed in the plugin directory.","timestamp":"2025-12-21T19:27:10.978Z"}
{"action":"add","id":"a05d5948-cc89-484f-8c7c-b66578b33e0f","subject":"Configuration supports independent episodic and thinking memory settings with separate thresholds","keywords":["configuration","episodic","thinking","similarity threshold","token budget"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"a0a2b12ee1a4e645","content":"Local Recall allows independent configuration of episodic and thinking memory retrieval. Each has: enabled flag, maxTokens (default 1000), minSimilarity threshold (default 0.5). Configuration via .local-recall.json or env vars. UserPromptSubmit hook filters results by similarity threshold and token budget, then combines both types before output.","timestamp":"2025-12-21T19:27:10.979Z"}
{"action":"add","id":"4f5f0ead-47f0-4328-b8fb-bdeab36cd314","subject":"Project structure and git status for local-recall repository","keywords":["project-structure","git-branch","file-organization","source-layout"],"applies_to":"global","occurred_at":"2025-12-21T18:21:31.415Z","content_hash":"dcd92a0ca44de914","content":"**Current Git Branch**: `claude/create-claude-md-01PPHDFfpxRruDbNfybJi4Y4` (clean working tree, no uncommitted changes)\n\n**Directory Structure**:\n- `src/` - TypeScript source code\n  - `core/` - Memory management, vector stores, search\n  - `hooks/` - Claude Code hook implementations (session-start, user-prompt-submit, stop)\n  - `mcp-server/` - MCP server and tools\n  - `prompts/` - Memory extraction prompts\n  - `utils/` - Utilities (markdown parsing, transcript handling, config, logging)\n- `local-recall/` - Memory storage directory\n  - `episodic-memory/` - Individual episodic memory markdown files\n  - `thinking-memory/` - Thinking memory markdown files\n  - `*.jsonl` - Processed transcripts log\n  - `orama-*-index.json` - Vector indexes (gitignored, auto-generated)\n- `dev-marketplace/local-recall-plugin/` - Claude Code plugin configuration\n  - `config/hooks.json` - Hook configurations\n  - `.mcp.json` - MCP server configuration\n- `dist/` - Compiled JavaScript output (gitignored)\n- Tests in `tests/integration/` and `tests/unit/`","timestamp":"2025-12-21T19:27:10.980Z"}
{"action":"add","id":"b12d830e-2915-4c01-80cf-25f922626df9","subject":"MCP server runs from dev-marketplace/local-recall-plugin subdirectory","keywords":["mcp server","location","plugin","process"],"applies_to":"global","occurred_at":"2025-12-21T18:30:41.521Z","content_hash":"a81b3d4be55a70ed","content":"The MCP server process is running from:\n- Location: `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js`\n- Config: `dev-marketplace/local-recall-plugin/.mcp.json`\n- PID: 4524 (as of last check)\n\nThe main project root at `/Users/joe/Code/Syntessera/local-recall/` doesn't have a built `dist/` or `scripts/` directory yet. The plugin subdirectory is the active MCP server location.","timestamp":"2025-12-21T19:27:10.985Z"}
{"action":"add","id":"6a07ee5f-e3cf-4786-a391-bdf1b2562199","subject":"Transcript collector was copying synthetic transcripts before cleaning them up","keywords":["transcript-collector","synthetic transcripts","syncTranscripts","performance","cleanup","bug fix"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-03T09:48:42.505Z","content_hash":"58ab73263f531dfa","content":"The `syncTranscripts()` method in transcript-collector.ts was inefficiently copying synthetic transcripts from Claude's cache before cleaning them up. The process now checks `isSyntheticFile(transcript.sourcePath)` before copying to avoid unnecessary I/O. The cleanup still runs first to remove any synthetic files that may have slipped through previously, but new/modified transcripts are now filtered before being copied.","timestamp":"2025-12-21T19:27:10.987Z"}
{"action":"add","id":"0448ffe6-0be5-419c-a9d1-5ceb72dfb054","subject":"Fix AbortError in user-prompt-submit hook from spawn timeout","keywords":["user-prompt-submit","spawn","timeout","abort","error-handling","child-process"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:26:12.039Z","content_hash":"2df5868eda9443b5","content":"## Problem\nThe `callClaudeForKeywords` function in user-prompt-submit.ts was throwing unhandled `AbortError` when spawning child processes. The Node.js `spawn` timeout option automatically aborts the process after the timeout, but the abort error wasn't being caught.\n\n## Root Cause\n1. The `spawn` call had a `timeout` option that kills the child process without proper error handling\n2. Duplicate `child.on('close', ...)` event handlers (at lines 60 and 120) could cause race conditions\n3. No safeguard to ensure the promise resolves only once\n\n## Solution\n1. **Remove spawn timeout option** - Node.js built-in timeout throws AbortError which requires specific error handling\n2. **Add safeResolve wrapper** - Implement promise wrapper that ensures single resolution, preventing race conditions\n3. **Remove duplicate close handlers** - Keep only one event listener to prevent multiple resolutions\n4. **Add early-exit guard** - Check if promise already resolved before executing close handler logic\n\n## Implementation Details\nThe fix uses a resolved flag pattern to track promise resolution state and prevents duplicate event handlers from firing.","timestamp":"2025-12-21T19:27:10.989Z"}
{"action":"add","id":"d39b514b-9e94-400f-82a1-913b34893fd5","subject":"Save all thinking blocks even if single-line, but only multiline answers","keywords":["thinking","answers","transcript","memory extraction","single-line","multiline"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:19:48.301Z","content_hash":"857d06a9d94da416","content":"Modified `analyzeForMemories` to save all thinking blocks regardless of length (even single-line), but only save answers/responses if they are multiline (2+ lines of content). This ensures thinking is always captured while filtering out brief single-line responses.","timestamp":"2025-12-21T19:27:10.991Z"}
{"action":"add","id":"d384a99e-86fc-482f-86b5-698af0969b16","subject":"sqlite-vec mutex errors occur with concurrent process loading","keywords":["sqlite-vec","mutex","concurrent","processes","locking","error handling"],"applies_to":"global","occurred_at":"2025-12-21T18:23:08.846Z","content_hash":"2b8c5f07f8457756","content":"The codebase uses sqlite-vec for vector operations. A known issue is 'mutex lock failed: Invalid argument' errors that occur when multiple processes attempt to load sqlite-vec concurrently. This is a cross-process synchronization problem that requires coordination mechanisms like file locking to prevent simultaneous access to the sqlite-vec library during initialization.","timestamp":"2025-12-21T19:27:10.993Z"}
{"action":"add","id":"7583978f-c0aa-4a85-9bac-f7292686d3d4","subject":"Session start loads all memories at once, not incrementally","keywords":["session-start","memory-loading","performance","full-reload"],"applies_to":"global","occurred_at":"2025-12-21T19:19:24.814Z","content_hash":"b381f4dcc908805b","content":"The SessionStart hook performs a full reload of all memories on each session start, not a delta/incremental load. In `src/hooks/session-start.ts`, it creates a fresh MemoryManager instance, calls `listMemories()` to get all memories, then selects the 5 most recent by `occurred_at` for context injection. This means every session incurs the cost of loading the entire memory store, though only the top 5 are actually injected.","timestamp":"2025-12-21T19:27:10.996Z"}
{"action":"add","id":"8d090120-97fe-430e-908e-d6e277e2d0bf","subject":"Local Recall architecture uses Orama vector store with Ollama embeddings for semantic search","keywords":["orama","vector-store","ollama","embeddings","semantic-search","architecture"],"applies_to":"global","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"91a74367c993be99","content":"Local Recall uses Orama (pure JavaScript vector database) for semantic search with Ollama embeddings. The embedding model is `nomic-embed-text` (768 dimensions). Index files are JSON-based and stored at `local-recall/orama-episodic-index.json` and `local-recall/orama-thinking-index.json`. Ollama runs as a background service at `http://localhost:11434` by default.","timestamp":"2025-12-21T19:27:11.001Z"}
{"action":"add","id":"93776029-f204-4d74-8f8d-3dc7cf8c505c","subject":"Thinking memory extraction now has independent processing in MCP daemon","keywords":["thinking extractor","daemon","parallel","separate flags","transcript processing","mcp server"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T18:29:49.579Z","content_hash":"230c2423b5058410","content":"Added thinking memory extraction to the MCP daemon's processing loop. Changes include:\n\n- New imports: `runThinkingExtraction` from `thinking-extractor.js`, `getThinkingVectorStore` from `thinking-vector-store.js`, `ThinkingMemoryManager` from `thinking-memory.js`\n- New flag `isThinkingProcessing` to prevent concurrent thinking extraction runs (separate from episodic `isProcessing` flag)\n- Thinking extraction now runs in parallel daemon loop alongside episodic extraction\n- Each type of memory extraction has its own processing state and can be managed independently\n\nThis prevents the SQLite mutex contention that occurred when both hooks tried to run simultaneously as separate processes.","timestamp":"2025-12-21T19:27:11.010Z"}
{"action":"add","id":"b4295d55-8a57-417a-80d8-c91043a96cf7","subject":"IndexManager and index.json are redundant with SQLite vector store","keywords":["index-manager","redundant","sqlite","vector-store","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T18:17:02.145Z","content_hash":"43fc1a40c4c67f8c","content":"The IndexManager class and index.json file became redundant after migrating to SQLite with vector embeddings. IndexManager was used for keyword lookups and index refreshing, but SQLite + VectorStore now handles both. Removed: src/core/index.ts, src/core/vector-store-disk.ts, and index.test.ts. Updated imports in tools.ts, stop.ts, memory-extractor.ts, and index.ts. This cleanup reduces complexity and file I/O operations.","timestamp":"2025-12-21T19:27:11.014Z"}
{"action":"add","id":"a6206f70-7794-43e8-a2c3-3d2ba75e2929","subject":"Session-start hook loads recent memories from episodic-memory directory","keywords":["session start","episodic memory","memory files","occurred_at","sorting","recency"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T17:42:21.784Z","content_hash":"5e539514acc6c6e1","content":"The session-start hook reads memory files directly from the `local-recall/episodic-memory/` directory, parses their YAML frontmatter, and sorts by `occurred_at` timestamp in descending order to inject the most recent memories into Claude's context on session initialization.","timestamp":"2025-12-21T19:27:11.022Z"}
{"action":"add","id":"faf60405-a9a3-427c-bc98-85ecf79b8f8a","subject":"Transcript condenser optimizes memory extraction by parsing JSONL and extracting minimal content","keywords":["transcript-condenser","memory-extraction","token-optimization","jsonl-parsing","performance"],"applies_to":"global","occurred_at":"2025-12-03T09:49:49.357Z","content_hash":"e5711af2e7882235","content":"# Transcript Condenser Implementation\n\nCreated `src/core/transcript-condenser.ts` to reduce token usage in memory extraction by:\n\n1. **Parsing JSONL transcripts** - Uses typed transcript schema to parse Claude Code session transcripts\n2. **Extracting minimal content** - Only extracts relevant information for each entry type:\n   - User messages: prompt text\n   - Assistant messages: reasoning and key points\n   - Tool operations: tool name and results (skips large outputs)\n   - System events: relevant context only\n3. **Creating condensed format** - Produces structured, concise data for the memory extraction prompt\n\nThis dramatically reduces token usage passed to the extractor while preserving semantic meaning for memory creation.\n\n## Related Files\n- `src/core/memory-extractor.ts` - Updated to use condenser\n- `src/prompts/memory-extraction.ts` - Updated prompt instructions\n- `src/types/transcript-schema.ts` - TypeScript types for JSONL parsing","timestamp":"2025-12-21T19:27:11.029Z"}
{"action":"add","id":"cf848dc7-425b-4227-959f-99e3f507afef","subject":"Content block structure is critical for thinking memory extraction","keywords":["thinking blocks","content blocks","message structure"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:30:41.521Z","content_hash":"5eb7751901124ddc","content":"Content blocks in Claude Code transcripts allow thinking to be extracted separately from text output. A thinking memory needs:\n1. A `ThinkingContentBlock` with the actual thinking text\n2. A `TextContentBlock` with the corresponding response\n\nThis paired structure (thought + output) is what makes thinking memories valuable - they capture the reasoning process alongside the result, helping future sessions understand the decision-making pattern.","timestamp":"2025-12-21T19:27:11.031Z"}
{"action":"add","id":"34c00e81-5736-45bb-b92b-3d0fd49b3e12","subject":"Using Orama directly in hooks is the correct approach for local-recall","keywords":["hooks","orama","search","pure-javascript","no-dependencies","performance"],"applies_to":"global","occurred_at":"2025-12-21T18:28:52.966Z","content_hash":"8f4c7447fead346b","content":"Local-recall's hooks (SessionStart, UserPromptSubmit) should use Orama directly for vector search rather than spawning child processes.\n\n### Why This Works\n1. **Pure JavaScript**: Orama has no native dependencies when used directly (despite sqlite-vec being a backend detail)\n2. **No IPC overhead**: Direct in-process search avoids spawning new processes\n3. **JSON indexes**: Orama indexes are stored as JSON files and can be loaded directly\n4. **Embedding generation**: Hooks can call Ollama HTTP API directly for embeddings\n\n### Architecture\n- Hooks load the Orama index from JSON\n- Call Ollama HTTP API to generate embedding for search query\n- Perform vector search in-process\n- Return results\n\nThis avoids all the complexity of process spawning and mutex issues while keeping hooks efficient.","timestamp":"2025-12-21T19:27:11.041Z"}
{"action":"add","id":"dc40b329-520f-498a-b64e-8571618c02e1","subject":"Synthetic transcript cleanup happens before copying new transcripts","keywords":["transcript-collector","cleanup","synthetic-files","sync-order"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:29:16.937Z","content_hash":"12831aecc1461292","content":"The transcript synchronization process has a two-phase approach: First, `cleanupTranscripts()` removes any existing synthetic files from the local `local-recall/transcripts/` folder. Then, the sync process copies new/modified transcripts from Claude's cache. This ordering ensures that previously copied synthetic files are cleaned up before new ones arrive, but filtering at copy-time prevents unnecessary copies in the first place.","timestamp":"2025-12-21T19:27:11.044Z"}
{"action":"add","id":"4bca2742-e2eb-4f29-ba15-902f8c610071","subject":"Ollama is preferred for embedding inference - standalone daemon with HTTP API for multi-process safety","keywords":["ollama","embedding","daemon","http","installation","alternatives","nomic-embed-text"],"applies_to":"global","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"eae32933ec087a01","content":"Ollama is a standalone embedding server that solves the ONNX concurrency issue. Installation: macOS via `brew install ollama` or from https://ollama.com/download, Linux via shell script at https://ollama.com/install.sh, Windows via installer. Pull embedding model with `ollama pull nomic-embed-text`. Server runs on port 11434. Multiple Claude instances can safely query it via HTTP API without mutex conflicts. This is superior to embedding multiple ONNX instances.","timestamp":"2025-12-21T19:27:11.046Z"}
{"action":"add","id":"51418d28-537d-4a1f-833e-7966c8f276f5","subject":"HTTP daemon architecture prevents concurrent ONNX loading by centralizing model initialization","keywords":["daemon","http","architecture","embedding","concurrency","singleton","onnx"],"applies_to":"global","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"2398684552eaee11","content":"The solution is to run embeddings in a single shared daemon process that all Claude instances communicate with via HTTP. ONNX loads once (no mutex conflict), then multiple processes safely call the HTTP API. Ollama is the recommended approach - it's a standalone embedding server that users can install separately and scales naturally to multiple Claude instances. This avoids the problem of having multiple ONNX instances load concurrently.","timestamp":"2025-12-21T19:27:11.047Z"}
{"action":"add","id":"777205ac-70ef-4c3a-978a-399404c2cefa","subject":"Hooks require absolute paths when Ollama is running locally","keywords":["hooks","ollama","paths","localhost","environment"],"applies_to":"global","occurred_at":"2025-12-21T19:02:46.136Z","content_hash":"cc9379172d1029b8","content":"When running hooks locally with Ollama on localhost, the hooks may work in isolation but fail in production user environments. This suggests hooks might need different environment configurations or path handling depending on whether Ollama is local vs. remote. The issue appears to be related to how hooks are invoked in the Claude Code context versus manual testing.","timestamp":"2025-12-21T19:27:11.048Z"}
{"action":"add","id":"73e965f7-bd35-40c5-8c93-38989dacaee8","subject":"Thinking memory extraction happens in parallel with 20 concurrent workers","keywords":["thinking memory","extraction","parallelization","performance","ollama","embedding"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:02:46.136Z","content_hash":"713c3ff4b13296e5","content":"The thinking memory extractor runs extraction jobs in parallel using 20 concurrent workers. This improves performance when processing multiple thinking blocks from transcripts. The parallel processing is implemented in src/core/thinking-extractor.ts and helps batch embed thinking memories efficiently.","timestamp":"2025-12-21T19:27:11.055Z"}
{"action":"add","id":"d4e30400-fb99-4359-9066-447a6a2ba44e","subject":"VS Code extension hook support differs from Claude Code desktop","keywords":["vs code extension","hook support","claude code","platform differences","hook compatibility"],"applies_to":"global","occurred_at":"2025-12-21T19:02:06.379Z","content_hash":"1f3f109dd9bcb4c3","content":"# VS Code Extension vs Claude Code Desktop Hook Support\n\nThe VS Code extension has different hook support compared to Claude Code desktop:\n- **SessionStart hook**: Works ✓\n- **UserPromptSubmit hook**: Works ✓  \n- **Stop hook**: Does not trigger (or triggers conditionally)\n\nThis suggests the VS Code extension may:\n- Not have full hook event coverage\n- Only support certain hook types\n- Trigger hooks differently than Claude Code desktop\n\nWhen implementing features that depend on hooks, consider this platform difference and provide fallback mechanisms (like using MCP tools directly).","timestamp":"2025-12-21T19:27:11.060Z"}
{"action":"add","id":"907c073e-042a-4995-8c11-bb095a2a7f12","subject":"Memory reprocessing flow: content hash drives memory updates","keywords":["content hash","deduplication","memory extraction","processed-log"],"applies_to":"global","occurred_at":"2025-12-21T19:26:56.234Z","content_hash":"a01f67348306e937","content":"The memory extraction system uses content hashes (SHA-256 prefix) to drive reprocessing. When a transcript is processed:\n\n1. `syncTranscripts()` detects changed files (by mtime and size)\n2. `processTranscript()` computes the content hash of the transcript\n3. If the hash differs from what's in the processed-log, old memories linked to that transcript are deleted\n4. New memories are extracted and created with the new content hash\n5. The processed-log records the hash for future change detection\n\nThis ensures that modified transcripts result in updated memories, while unchanged transcripts are skipped entirely.","timestamp":"2025-12-21T19:27:11.062Z"}
{"action":"add","id":"d573c171-92fd-4b62-b1b6-a4352d989746","subject":"Logger utility writes to recall.log for debugging hook and daemon issues","keywords":["logging","recall.log","debug","file logging"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:16:20.911Z","content_hash":"cec5ad534e86486b","content":"## Purpose\nThe logger utility (src/utils/logger.ts) provides structured logging that writes to `local-recall/recall.log` for debugging.\n\n## Key Features\n- Supports log levels: debug, info, warn, error\n- Can be controlled via `LOCAL_RECALL_LOG_LEVEL` environment variable\n- Outputs both to console (stderr) and to recall.log file\n- Used throughout hooks and daemon for troubleshooting\n\n## Usage in Debugging\nWhen hooks fail, check `local-recall/recall.log` to see detailed execution traces, timing information, and error messages. This file is gitignored and auto-generated.","timestamp":"2025-12-21T19:27:11.065Z"}
{"action":"add","id":"9492397b-98c5-4800-9538-6e05f2003669","subject":"Plugin configuration uses dev-marketplace structure with hooks and MCP server metadata","keywords":["plugin-configuration","hooks.json",".mcp.json","marketplace"],"applies_to":"file:dev-marketplace/local-recall-plugin/","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"99fb4b7931b0d8dd","content":"The plugin uses a dev-marketplace structure with:\n- `config/hooks.json` - Hook definitions and configurations\n- `.mcp.json` - MCP server metadata\nThis allows the plugin to be packaged and distributed through marketplaces.","timestamp":"2025-12-21T19:27:11.073Z"}
{"action":"add","id":"897f15d2-461b-484d-8434-0972571a336e","subject":"Orama migration resolves sqlite-vec mutex contention issues","keywords":["orama","mutex","sqlite-vec","vector-search","migration","hooks","native-extension"],"applies_to":"global","occurred_at":"2025-12-03T11:22:41.598Z","content_hash":"f347e55676719e8a","content":"The migration from SQLite/sqlite-vec to Orama (pure JavaScript vector search) successfully resolved the mutex contention errors that previously occurred when hooks tried to load the native sqlite-vec extension. The hook-daemon architecture no longer needs HTTP communication workaround to avoid concurrent sqlite-vec process locks. This is a significant architectural simplification - hooks can now directly use the vector store without the HTTP fallback pattern.","timestamp":"2025-12-21T19:27:11.079Z"}
{"action":"add","id":"edc6e0f0-d17a-4ca5-970e-5f5827948414","subject":"Memory deduplication uses occurred_at + content_hash instead of mutable timestamps","keywords":["memory","deduplication","idempotency","occurred_at","content_hash","episodic"],"applies_to":"global","occurred_at":"2025-12-21T19:18:18.497Z","content_hash":"861c5713935291b8","content":"Changed memory system from mutable knowledge base to immutable episodic log. Each memory is now idempotent and cannot be updated or deleted (only manually removed by user). Deduplication uses two-part key: `occurred_at` (when event happened in transcript) + `content_hash` (SHA-256 prefix, 16 chars). This prevents duplicate memories from being created when transcripts are reprocessed. Removed `created_at` and `updated_at` fields - only `occurred_at` is tracked. This approach allows memories to be reframed as episodic and supports the full conversation history processing model.","timestamp":"2025-12-21T19:27:11.085Z"}
{"action":"add","id":"308cf066-d6d6-4e0d-b3b6-054436c15de8","subject":"Session-start hook requires npm dependencies to be installed","keywords":["hooks","session-start","dependencies","npm install","testing"],"applies_to":"global","occurred_at":"2025-12-21T18:26:23.982Z","content_hash":"1f445bb1ad5bf039","content":"The session-start hook in `src/hooks/session-start.ts` requires npm dependencies to be installed before it can run. When testing hooks directly, ensure `npm install` has been run first. The hook uses the `rake-pos` package for NLP processing, which is a dev dependency.","timestamp":"2025-12-21T19:27:11.092Z"}
{"action":"add","id":"86503538-252e-4e81-9092-6044045f80a9","subject":"Unified UserPromptSubmit hook replaces separate episodic and thinking hooks","keywords":["hook consolidation","user-prompt-submit","unified","episodic","thinking"],"applies_to":"global","occurred_at":"2025-12-21T19:00:54.454Z","content_hash":"43cde8d156312b06","content":"Merged `src/hooks/user-prompt-submit.ts` and `src/hooks/user-prompt-submit-thinking.ts` into a single unified hook (`src/hooks/user-prompt-submit.ts`) that intelligently calls either episodic memory search, thinking memory search, or both based on environment variable configuration. This simplifies hook setup and allows users to control which memory types are active.","timestamp":"2025-12-21T19:27:11.098Z"}
{"action":"add","id":"f1e818cc-7229-46a7-9529-28da258cb310","subject":"Thinking memory extraction requires multi-line content filtering","keywords":["thinking","memory extraction","filtering","multi-line","content analysis"],"applies_to":"global","occurred_at":"2025-12-21T18:28:38.979Z","content_hash":"69aadcf73d5bdc65","content":"The `analyzeForMemories` function in `src/utils/transcript.ts` only extracts memories from messages with content longer than 2 lines. This filtering:\n\n- Prevents trivial or single-line content from becoming memories\n- Reduces noise in the memory store\n- Is intentional behavior, not a bug\n\nWhen extracting thinking memories, ensure the output text that follows the thinking is multi-line, otherwise it won't be saved as a memory despite having thinking content.","timestamp":"2025-12-21T19:27:11.102Z"}
{"action":"add","id":"38485243-2d6c-4d2f-b7ce-6bdbe67b2c2f","subject":"Episodic memory disabled by default, thinking memory enabled by default","keywords":["episodic memory","thinking memory","default configuration","user preferences"],"applies_to":"global","occurred_at":"2025-12-21T18:29:50.448Z","content_hash":"8f6780dd41df1012","content":"The thinking index implementation revealed that episodic memory should default to OFF and thinking memory should default to ON. This suggests:\n\n1. **Thinking memory is more reliable/useful** - It captures actual reasoning patterns and outputs which appear more actionable than episodic memories\n2. **Episodic memories may have issues** - The user explicitly wanted to disable episodic by default, suggesting quality or relevance concerns\n3. **Independent control is important** - Users need granular control to enable/disable each memory type independently based on their use case\n\nThis design reflects a preference for reasoning examples (thinking) over factual memory (episodic) as the primary memory source.","timestamp":"2025-12-21T19:27:11.111Z"}
{"action":"add","id":"539a94d7-1f5e-4cd7-b74e-fd016f2b64ee","subject":"Data loading into vector store happens through MemoryManager and VectorStore coordination","keywords":["data-loading","initialization","sync","vector-store","memory-manager"],"applies_to":"global","occurred_at":"2025-12-21T19:19:15.418Z","content_hash":"1c743f67667665d1","content":"The vector store initialization process involves:\n\n1. **VectorStore.initialize()**: Called on first access, scans the memory directory, reads all markdown memory files, generates embeddings via Ollama, and populates SQLite with both metadata and vector data.\n\n2. **Subsequent updates**: MemoryManager.createMemory() writes markdown files to disk, then immediately adds to vector store via vectorStore.add(). This ensures the database stays synchronized.\n\n3. **MCP daemon sync**: The background daemon in server.ts:73 calls vectorStore.sync(memories) periodically to handle file system changes and keep the database current.\n\nThis three-layer approach ensures memories are always available for search whether created programmatically, via the file system, or discovered during transcript processing.","timestamp":"2025-12-21T19:27:11.121Z"}
{"action":"add","id":"d3921bac-e567-4dbf-b7f1-9d8d38f1051f","subject":"Memory extractor imports and uses transcript condenser for JSONL processing","keywords":["memory-extractor","transcript-condenser","JSONL-pipeline","token-efficiency"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"7f68e3ffd8db2cbf","content":"Updated `extractMemoriesFromTranscript()` in `memory-extractor.ts` to use the new transcript condenser:\n\n1. Added import for `TranscriptCondenser` and `CondensedTranscript` type\n2. Reads raw JSONL transcript content from file\n3. Calls `condenseTranscript()` to parse and filter the data\n4. Passes condensed data to `buildMemoryExtractionPrompt()` instead of raw content\n5. Maintains all existing memory extraction logic downstream\n\nThis creates a cleaner pipeline: Raw JSONL → Condense → Extract → Create Memories, with token-heavy JSONL processing abstracted away from the prompt generation.","timestamp":"2025-12-21T19:27:11.125Z"}
{"action":"add","id":"d0499898-4d1f-4218-b420-5b3a691399d2","subject":"Memory extraction should use Haiku model with single-turn and JSON-only response","keywords":["haiku","memory-extraction","json-response","model-optimization","cost-reduction"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:23:11.524Z","content_hash":"e5e202f80ce51fd4","content":"Memory extraction was updated to use Claude Haiku instead of default model for cost optimization. Implementation uses `--model haiku --max-turns 1` flags when calling `claude -p`. The memory extraction prompt was updated to require JSON-only output (no markdown, no explanation) to ensure consistent parsing of returned memories. This reduces token usage while ensuring reliable memory extraction.","timestamp":"2025-12-21T19:27:11.130Z"}
{"action":"add","id":"80f32d72-21b7-42e8-81d1-ff99ad5cb1e0","subject":"cleanupTranscripts() method removes invalid and synthetic transcript files","keywords":["cleanup","transcript-validation","file-format","synthetic-removal","maintenance"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-03T09:47:02.103Z","content_hash":"78732f6cbc9ef691","content":"Added `cleanupTranscripts()` method at lines 353-403 that:\n1. Removes files not matching `UUID.jsonl` format (handles `.DS_Store`, malformed names, etc.)\n2. Removes synthetic transcripts by checking for `\"<synthetic>\"` model marker\n3. Returns counts of removed files: `{ invalidFormat: number; synthetic: number }`\n\nThis cleanup runs automatically at the start of `syncTranscripts()` to keep the transcript directory clean. Returns statistics on what was removed.","timestamp":"2025-12-21T19:27:11.131Z"}
{"action":"add","id":"c8a2db0b-236d-4cb3-ba77-e2b4d10f9314","subject":"Enable episodic memory processing via LOCAL_RECALL_EPISODIC_ENABLED environment variable","keywords":["episodic memory","environment variable","mcp server","configuration","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T18:31:41.980Z","content_hash":"0231d48511edf7a4","content":"Episodic memory processing is controlled by the `LOCAL_RECALL_EPISODIC_ENABLED` environment variable in the MCP server configuration. It defaults to `false`. To enable it, add `LOCAL_RECALL_EPISODIC_ENABLED=true` to the `env` section of the MCP server configuration in `.claude/settings.json`. This enables the background daemon to process transcripts and extract episodic memories.","timestamp":"2025-12-21T19:27:11.132Z"}
{"action":"add","id":"8aebd697-b5fb-48b5-9101-d9755b001fe7","subject":"Feature flags for episodic and thinking memory systems","keywords":["configuration","environment variables","episodic memory","thinking memory","feature flags","LOCAL_RECALL_EPISODIC_ENABLED","LOCAL_RECALL_THINKING_ENABLED"],"applies_to":"global","occurred_at":"2025-12-03T09:48:34.346Z","content_hash":"f40fab1f4b24dd27","content":"Added two environment variables to control memory systems:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory search, session-start injection, and extraction\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory search and extraction\n\nImplemented in:\n- `src/core/types.ts:118-119` - Added to config schema\n- `src/utils/config.ts:56-61` - Added env var parsing\n- `src/hooks/user-prompt-submit.ts` - Updated to check episodic flag before searching\n- `src/hooks/user-prompt-submit-thinking.ts` - Updated to check thinking flag before searching\n- `src/hooks/session-start.ts` - Updated to check episodic flag before injecting\n- `src/mcp-server/server.ts` - Updated to check flags for tool availability\n\nThese flags allow users to selectively disable memory extraction and retrieval without removing existing memories, making it easy to switch between episodic-only, thinking-only, or both memory systems.","timestamp":"2025-12-21T19:27:11.134Z"}
{"action":"add","id":"04874730-a8e4-484c-8104-113f263746c7","subject":"Plugin version must be updated in two locations for consistency","keywords":["version","plugin","package.json","plugin.json","synchronization"],"applies_to":"global","occurred_at":"2025-12-13T10:56:31.815Z","content_hash":"4387606c8740675c","content":"The project maintains version consistency across two files that must be kept in sync:\n1. `package.json` - Main package version\n2. `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` - Plugin manifest version\n\nWhen bumping versions, both files must be updated together. The plugin is located in `dev-marketplace/local-recall-plugin/` subdirectory.","timestamp":"2025-12-21T19:27:11.135Z"}
{"action":"add","id":"325d3837-402d-42be-ac12-1400b3cdfd0b","subject":"Duplicate close event handlers cause race conditions in child process management","keywords":["close","event handler","duplicate","race condition","child process"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:27:26.099Z","content_hash":"8db32eac0a8738ba","content":"The user-prompt-submit hook had duplicate `child.on('close', ...)` event listeners registered on the same child process. This can cause multiple resolutions of the promise, race conditions between the timeout and normal completion, and unpredictable behavior. When managing child processes, ensure only one 'close' handler is registered and use a guard variable (e.g., `resolved` flag) to prevent multiple resolutions.","timestamp":"2025-12-21T19:27:11.136Z"}
{"action":"add","id":"6d8f14c5-311c-4dc5-9467-3d6fd38780a0","subject":"Plugin versioning strategy: bump version to force fresh deployment across Claude instances","keywords":["plugin","version","deployment","cache-busting","mcp-server"],"applies_to":"global","occurred_at":"2025-12-21T19:13:11.749Z","content_hash":"6d450d2855173033","content":"When fixing issues with the deployed plugin, bump the version number in both `package.json` and `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` to trigger a fresh deployment. This avoids stale cached versions affecting other Claude instances. The old cached version remains but the new version deploys to a new cache directory, effectively sidelining the old broken version.","timestamp":"2025-12-21T19:27:11.137Z"}
{"action":"add","id":"9582e6bc-de22-4622-88cd-7ada97fb7ec0","subject":"Memory formatting utilities provide consistent display format for different memory types","keywords":["markdown utilities","memory formatting","display formatting","thinking memories","episodic memories"],"applies_to":"file:src/utils/markdown.ts","occurred_at":"2025-12-21T17:22:22.424Z","content_hash":"0d02b4eec1639854","content":"The codebase provides dedicated formatting utilities in `src/utils/markdown.ts` for displaying different memory types:\n\n- `formatEpisodic­MemoryForDisplay(memory: EpisodicMemory)` - Formats episodic memories for injection into context\n- `formatThinkingMemoryForDisplay(memory: ThinkingMemory)` - Formats thinking memories for injection into context\n\nThese utilities handle the presentation layer for memory types, ensuring consistent formatting across different hooks (session-start, user-prompt-submit) and tools. They abstract away the details of converting raw memory objects into human-readable context that gets injected into Claude's prompts.","timestamp":"2025-12-21T19:27:11.138Z"}
{"action":"add","id":"a9e2160d-395a-4896-8caf-7eaf1574d2ba","subject":"Transcript parsing extracts tool invocations and assistant reasoning","keywords":["transcript-parsing","tool-invocations","assistant-reasoning","event-extraction"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"755520e093b937c4","content":"The transcript parser in `src/utils/transcript.ts` (370 lines) extracts structured events from Claude Code session transcripts including:\n- User prompts and requests\n- Assistant text responses and explanations\n- Tool invocations (Read, Edit, Write, Bash, Grep, etc.)\n- Tool results and outcomes\n\nThis parsed transcript structure is used by the Stop hook to identify key moments and reasoning patterns, enabling extraction of meaningful memories about architectural decisions, problem-solving approaches, and code changes. The parser handles multiple tool types and preserves context about what was attempted and why.","timestamp":"2025-12-21T19:27:11.140Z"}
{"action":"add","id":"6e62e564-c266-4db6-8890-79ed61888240","subject":"Skills directory structure for local-recall plugin in dev-marketplace","keywords":["skills","directory","plugin","dev-marketplace","structure"],"applies_to":"file:dev-marketplace/local-recall-plugin/skills/","occurred_at":"2025-12-21T18:31:22.495Z","content_hash":"1d86d67edafe538d","content":"The local-recall plugin stores new skills in `dev-marketplace/local-recall-plugin/skills/` directory. Skills are part of the plugin discoverability mechanism and help users find and invoke local-recall functionality more easily.","timestamp":"2025-12-21T19:27:11.151Z"}
{"action":"add","id":"2a908a29-42ba-40f7-8f66-e175dfb5b198","subject":"Configuration system supports independent episodic and thinking memory feature flags","keywords":["configuration","episodicEnabled","thinkingEnabled","feature flags","config loading"],"applies_to":"global","occurred_at":"2025-12-21T17:22:22.424Z","content_hash":"d053c444862dbf88","content":"The codebase uses a configuration system via `getConfig()` from `src/utils/config.ts` that allows independent control of episodic and thinking memory features.\n\n**Key configuration flags:**\n- `episodicEnabled` - Controls whether episodic memories are retrieved and injected\n- `thinkingEnabled` - Controls whether thinking memories are retrieved and injected\n- Each type can be independently enabled/disabled\n- Loaded via environment variables or `.local-recall.json` configuration file\n\n**Usage pattern:**\nThe session-start hook checks these flags before retrieving respective memory types, allowing users to configure which memory types they want to use in their sessions.","timestamp":"2025-12-21T19:27:11.168Z"}
{"action":"add","id":"c249513d-bf34-4a4e-b50c-9f046de007ec","subject":"Logger API requires single string argument, not multiple parameters","keywords":["logger","api","single-argument","bug-fix","logging"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:17:04.759Z","content_hash":"7dacc349d30503bc","content":"The logger utility in `src/utils/logger.ts` defines its interface to accept a single string argument for messages. When fixing memory extractor logging (line 197), calls like `logger.error('message', error)` would fail because the logger doesn't accept multiple parameters. Correct usage: `logger.error('message: ' + error.message)` or template strings. This is important for any code adding logging to the memory extraction pipeline.","timestamp":"2025-12-21T19:27:11.171Z"}
{"action":"add","id":"e80052f9-9f70-4fea-9aa7-9da9b6a80af5","subject":"IndexManager and index.json are redundant with sqlite-vec vector store","keywords":["index-manager","sqlite-vec","vector-store","refactoring","redundant"],"applies_to":"global","occurred_at":"2025-12-21T19:14:59.526Z","content_hash":"1f3ed9dc9ec22e33","content":"The IndexManager class and index.json file became redundant after migrating to sqlite-vec for vector embeddings. Removed: IndexManager from src/core/index.ts, index_rebuild tool from MCP server, IndexManager imports from hooks and extractors, related test files. Vector store now handles all indexing via sqlite-vec with LIMIT k constraint in JOIN queries. Tests updated to use resetVectorStore() function for proper isolation between test cases.","timestamp":"2025-12-21T19:27:11.177Z"}
{"action":"add","id":"0205ce21-27fd-4aaf-b21d-8f1f7064ad6f","subject":"Local Recall plugin skills architecture and versioning","keywords":["skills","plugin","versioning","mcp tools","discoverability"],"applies_to":"global","occurred_at":"2025-12-21T19:23:20.420Z","content_hash":"6b7decb46337a4ea","content":"The local-recall plugin uses a skills-based architecture for exposing functionality. Version 0.1.3 introduced two new skills: `check-memories` and `proactive-recall`. MCP tool descriptions were enhanced with usage guidance to improve discoverability. Plugin metadata is maintained for better integration with the dev marketplace. Skills are stored in `dev-marketplace/local-recall-plugin/skills/` directory.","timestamp":"2025-12-21T19:27:11.183Z"}
{"action":"add","id":"af07c881-dde2-49c3-9cfc-ffe10d7ce203","subject":"parseTranscriptForMemories() function in transcript.ts extracts memories from raw JSONL","keywords":["parseTranscriptForMemories","JSONL","transcript parsing","memory extraction","transcript.ts"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:27:11.223Z","content_hash":"fb0d3b4b3386ea81","content":"Added `parseTranscriptForMemories(rawContent: string): MemorySuggestion[]` function in transcript.ts that:\n1. Parses raw JSONL content (as read from transcript files)\n2. Filters for user/assistant message entries\n3. Extracts text and thinking from content blocks\n4. Calls analyzeForMemories() to convert messages to memory suggestions\n5. Returns array of MemorySuggestion objects ready to be saved\n\nThis is the main entry point for processing transcripts and centralizes all parsing logic.","timestamp":"2025-12-21T19:27:11.186Z"}
{"action":"add","id":"ae727ae5-6722-419c-830d-efc57938491c","subject":"User requirement: cannot use shared daemon if it prevents running multiple Claude instances simultaneously","keywords":["daemon","architecture","multi-instance","constraint","requirement"],"applies_to":"global","occurred_at":"2025-12-21T18:27:27.411Z","content_hash":"e41d21945b0cbd07","content":"Initial suggestion of a shared daemon per MCP server was rejected because user needs to run multiple Claude instances concurrently. Each Claude instance would still need its own daemon, which brings back the ONNX mutex problem. Ollama solves this by being a single system-level daemon that supports unlimited concurrent clients via HTTP API without needing separate instances.","timestamp":"2025-12-21T19:27:11.193Z"}
{"action":"add","id":"26c64d62-2e55-4ac9-9bb1-e6afae826758","subject":"Three pathways for data to enter SQLite vector store","keywords":["data-loading","sqlite","vector-store","memory-creation","sync"],"applies_to":"global","occurred_at":"2025-12-21T18:26:56.199Z","content_hash":"c296755e76f8284d","content":"Data enters the SQLite vector store through three pathways:\n\n1. **On Memory Creation (immediate)**: `MemoryManager.createMemory()` writes the memory to disk and immediately calls `vectorStore.add(memory)` to generate embedding and insert into database\n\n2. **Startup Sync**: When hooks or tools start, `vectorStore.sync(memories)` is called to ensure the in-memory vector store matches the file-based memories\n\n3. **MCP Server Daemon**: The background daemon processes new/modified transcripts and creates memories, which are then added to the vector store\n\nThe sync operation handles both adding new memories and removing deleted ones.","timestamp":"2025-12-21T19:27:11.199Z"}
{"action":"add","id":"de55a242-6bdb-4e63-bdb1-dbdaeeda8133","subject":"Thinking memories now combine thought + output for better context examples","keywords":["thinking memory","extraction","thought output pairing","context injection","memory format"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:14:45.298Z","content_hash":"a88eb1893583ae62","content":"Thinking memories have been enhanced to capture both Claude's internal reasoning (thought blocks) and the corresponding text response together. This provides concrete examples of 'how I reasoned → what I produced' for future sessions.\n\nImplementation details:\n- Extraction combines thinking blocks with their corresponding text output in a single memory\n- Tool-only responses are skipped (only memories with text output are saved)\n- Memory format uses markdown sections: `## Thought` and `## Output`\n- Subject line is derived from the first sentence of the thinking block\n\nBenefit: Future sessions can see examples of reasoning that led to specific outputs, helping shape how Claude approaches similar problems.","timestamp":"2025-12-21T19:27:11.208Z"}
{"action":"add","id":"7e59302a-f984-4cd6-a609-bc1b6b7908b2","subject":"Fix transcript parsing duplication - stop.ts should use transcript.ts utilities","keywords":["transcript parsing","code duplication","stop.ts","transcript.ts","refactoring"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T18:24:55.963Z","content_hash":"a4003b5c3da9f4b9","content":"The stop.ts hook had duplicate parsing logic that was broken:\n\n1. **Bug**: Checked `c.text` for thinking blocks, but thinking blocks have `c.thinking` property\n2. **Bug**: Never populated the `thinking` field on messages passed to `analyzeForMemories`\n3. **Design issue**: Duplicated parsing logic from transcript.ts\n\nSolution: Exported `parseTranscriptForMemories()` function from transcript.ts that takes raw JSONL content and returns memory suggestions ready to save. This removes all parsing/looping from stop.ts, making it a simple: read file → parse → save memories.\n\nThis also enables reusing the same transcript parsing elsewhere in the codebase.","timestamp":"2025-12-21T19:27:11.213Z"}
{"action":"add","id":"d00437d6-b126-4a42-87ba-08f7813d9d36","subject":"Memory extractor must handle Claude's direct array responses","keywords":["memory-extractor","parseClaudeResponse","schema-validation","claude-response-format","array-wrapping"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:19:41.326Z","content_hash":"737f7ccd5a3d3678","content":"Claude (Haiku) sometimes returns memories as a plain array `[{...}, {...}]` instead of wrapped in an object `{ memories: [...] }`. The parseClaudeResponse method at line 174 needs to detect this case and wrap raw arrays in the expected format before Zod validation. This is a common pattern across different Claude models and API responses.\n\nFix: Added array detection that wraps raw arrays: `if (Array.isArray(parsed)) { parsed = { memories: parsed }; }`","timestamp":"2025-12-21T19:27:11.215Z"}
{"action":"add","id":"117f3008-6cec-4871-b567-96425ad77d30","subject":"Memory files may exist but hooks cannot access or read them properly","keywords":["memory files","file access","permissions","path resolution","hooks","reading memories"],"applies_to":"global","occurred_at":"2025-12-21T18:59:35.657Z","content_hash":"3bf242248af3b9fe","content":"## Potential Issues\n\n1. **Path Resolution**: Hooks may not be resolving the memory directory path correctly\n2. **File Permissions**: Memory files may exist but hooks lack read permissions\n3. **Silent Failures**: Hooks may be catching errors without logging them\n4. **Working Directory**: Hook execution context may have different working directory than expected\n\n## Solutions to Test\n\n- Verify LOCAL_RECALL_DIR environment variable is set correctly\n- Check file permissions on memory files\n- Add detailed logging in hook code to track execution\n- Use absolute paths instead of relative paths when possible\n- Test file access in isolation","timestamp":"2025-12-21T19:27:11.219Z"}
{"action":"add","id":"4c2e709f-cb3d-4497-8650-395abfe496dd","subject":"Use git filter-branch to remove files from unpushed commits","keywords":["git","filter-branch","history rewrite","index-filter","force-with-lease"],"applies_to":"global","occurred_at":"2025-12-21T19:12:57.471Z","content_hash":"5cf662bf87f075c7","content":"When files are accidentally committed but not yet pushed, use `git filter-branch --force --index-filter 'git rm --cached --force -- <file>'` to rewrite history. Set `FILTER_BRANCH_SQUELCH_WARNING=1` to suppress warnings. After rewriting, clean up filter-branch backup refs with `git update-ref -d refs/original/refs/heads/main`. Use `git push --force-with-lease` (safer than `--force`) when pushing rewritten commits to ensure no concurrent pushes are overwritten.","timestamp":"2025-12-21T19:27:11.221Z"}
{"action":"add","id":"ceacf597-aa5e-4efb-b07e-1fe01d611093","subject":"Stop hook changed to process entire transcript history instead of recent messages","keywords":["stop-hook","transcript","processing","transcript-parsing"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:17:28.905Z","content_hash":"b6292a1d27602ef3","content":"# Stop Hook Processing Logic Update\n\n## Previous Behavior\nProcessed only messages within a 30-second time window from the moment the hook fires. This caused the hook to often output \"No recent messages to analyze\" because messages aged out of the window.\n\n## New Behavior\nProcesses the entire transcript history. Deduplication via `occurred_at + content_hash` prevents duplicate memories from being created when the same transcript is processed multiple times.\n\n## Implementation\n- Removed the 30-second time window check\n- Now extracts all transcript messages regardless of age\n- Relies on idempotency mechanism to handle re-processing","timestamp":"2025-12-21T19:27:11.239Z"}
{"action":"add","id":"f0ea3426-f570-4e23-92b3-8ff208968d5b","subject":"Memory files are stored in local-recall/memories/ and indexed with index.json","keywords":["memory-storage","files","index","directory-structure"],"applies_to":"global","occurred_at":"2025-12-21T19:21:30.507Z","content_hash":"b2be7bf802641d37","content":"Memory files are stored in the local-recall/memories/ directory (confirmed 9+ files exist) and are indexed with local-recall/index.json. The directory structure and file organization is critical for memory retrieval operations.","timestamp":"2025-12-21T19:27:11.246Z"}
{"action":"add","id":"9cd34168-ce92-4627-80d9-51d712c750fa","subject":"Project installed as local-recall plugin in Claude Code","keywords":["plugin installation","local-recall plugin","claude code integration","mcp server"],"applies_to":"global","occurred_at":"2025-12-21T19:21:11.638Z","content_hash":"65203ca52a6b2243","content":"# Local Recall Plugin Installation\n\n## Status\nThe local-recall project was successfully installed as a Claude Code plugin using the `/plugin` command. This makes the memory tools available within Claude Code without requiring manual configuration of the MCP server.\n\n## Impact\n- The plugin is now available in Claude Code\n- Claude Code needs to be restarted to load the new plugin\n- This integration enables the memory extraction and retrieval features to work seamlessly within the Claude Code environment","timestamp":"2025-12-21T19:27:11.250Z"}
{"action":"add","id":"47ffdfea-66d5-45df-b075-e21983a003e3","subject":"Transcript analysis extracts thinking blocks and multiline answers separately from transcripts","keywords":["transcript","thinking","analysis","memory-extraction","multiline"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:16:50.918Z","content_hash":"2019c2363872ea3f","content":"When analyzing transcripts for memories:\n- All thinking blocks are saved as memories (even single-line)\n- Only multiline answers are saved (content with 2+ lines)\n- Memory subjects are generated as: first line if multiline text, first sentence (up to `.`) if single-line text\n- This is implemented in `analyzeForMemories()` function which filters answers by `answer.split('\\n').length > 1`","timestamp":"2025-12-21T19:27:11.258Z"}
{"action":"add","id":"a332de7e-8c20-4849-b1de-552d22c4a2cb","subject":"Multiple Claude Code instances each spawn their own MCP server process","keywords":["mcp server","multiple instances","stdio transport","separate projects"],"applies_to":"global","occurred_at":"2025-12-21T18:31:23.288Z","content_hash":"169f35036fe9b599","content":"Each Claude Code instance spawns its own MCP server process when configured. These instances communicate via stdio transport (not shared ports). If instances are in different projects, they should each have separate MCP server configurations in `.claude/settings.json`.","timestamp":"2025-12-21T19:27:11.264Z"}
{"action":"add","id":"04b45921-d168-477d-b5c5-c3a12cd86684","subject":"Memory extraction timeout increased to 10 minutes","keywords":["timeout","memory-extraction","performance","transcript-processing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:23:11.524Z","content_hash":"b5ef353169154147","content":"The `DEFAULT_OPTIONS.timeout` for memory extraction was increased from 2 minutes (120000ms) to 10 minutes (600000ms) to allow sufficient time for processing larger transcripts when extracting memories via claude CLI.","timestamp":"2025-12-21T19:27:11.268Z"}
{"action":"add","id":"8cd86690-fce0-404e-8a0a-f7a6162c8e51","subject":"Ollama embeddings use nomic-embed-text model with 768 dimensions","keywords":["ollama","embeddings","nomic-embed-text","vector-dimensions","model"],"applies_to":"global","occurred_at":"2025-12-21T19:17:41.738Z","content_hash":"10b9bff72899d4d0","content":"Local Recall uses Ollama for generating embeddings with the nomic-embed-text model producing 768-dimensional vectors (~274MB model size). This replaces a previous fastembed integration. When migrating from fastembed (BGE-small-en-v1.5, 384 dimensions), the vector indexes must be rebuilt since the dimension mismatch causes errors. Indexes are auto-regenerated on first run.","timestamp":"2025-12-21T19:27:11.269Z"}
{"action":"add","id":"6dee5498-76b9-4cf3-b275-cec0450fb656","subject":"Memory extraction field name normalization for Claude Haiku responses","keywords":["memory-extractor","field-normalization","haiku-responses","validation","parsing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:16:58.381Z","content_hash":"e43c63c066acf84d","content":"Claude Haiku sometimes returns memory objects with alternative field names. Added normalization in parseClaudeResponse() (lines 179-186) to map:\n- `title` → `subject`\n- `tags` → `keywords`\n- `scope` → `applies_to`\n- `text` → `content`\n\nThis prevents Zod validation failures when Claude uses slightly different field names than expected. The normalization is applied to all parsed memory objects before validation.","timestamp":"2025-12-21T19:27:11.271Z"}
{"action":"add","id":"6cbdf821-eba6-479f-80e9-6022b926841c","subject":"SessionStart hook must use JSON hookSpecificOutput format for plugin context injection","keywords":["hooks","session-start","hookSpecificOutput","plugin","context-injection","JSON-format","fix"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T17:40:53.082Z","content_hash":"92fe77441dcb59c5","content":"**Root Cause:** The session-start hook was using plain `console.log()` statements for output, while plugin hooks require JSON format with `hookSpecificOutput.additionalContext` for Claude to receive the context.\n\n**Symptoms:**\n- Hooks show \"hook success: Success\" in system-reminder\n- No actual memory content appears in Claude's context\n- Transcripts show `\"stdout\":\"\",\"stderr\":\"\"}` for hook responses\n\n**Fix:** Changed session-start.ts to output JSON format:\n```javascript\nconst output = {\n  hookSpecificOutput: {\n    hookEventName: 'SessionStart',\n    additionalContext: contextParts.join('\\n\\n'),\n  },\n};\nconsole.log(JSON.stringify(output));\n```\n\n**Key Insight:** The user-prompt-submit hook already used JSON format correctly. The session-start hook was the only one using plain text output, which doesn't work with plugin-layer hooks.\n\n**Related:** The `:Callback` suffix in hook names indicates plugin-layer hooks which require structured JSON output.","timestamp":"2025-12-21T19:27:11.272Z"}
{"action":"add","id":"ee5e81b5-ecac-449b-b435-ca71d1f081e6","subject":"All 259 tests pass after SessionStart, gitignore, and IndexManager fixes","keywords":["testing","test-suite","integration","unit-tests","passing"],"applies_to":"global","occurred_at":"2025-12-21T19:15:15.466Z","content_hash":"ccc8298898471673","content":"Completed refactoring: removed IndexManager redundancy, fixed SessionStart hook timeout, fixed gitignore creation, and fixed sqlite-vec query syntax. All 259 tests (unit + integration) pass successfully. The codebase is now using pure SQLite vector storage with no redundant index files.","timestamp":"2025-12-21T19:27:11.273Z"}
{"action":"add","id":"fdcc7305-2863-4035-ab57-e7ebd5bdb786","subject":"UserPromptSubmit hook causes mutex error due to direct sqlite-vec loading in Claude Code process","keywords":["mutex error","sqlite-vec","hook","file locking","process isolation","system_error"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:19:08.315Z","content_hash":"9cc87bef4980955a","content":"The UserPromptSubmit hook was throwing 'libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument' when trying to load sqlite-vec directly in the Claude Code hook process.\n\nRoot cause: The hook instantiates SearchEngine and ThinkingSearchEngine which load sqlite-vec (via src/utils/database.ts:152, sqliteVec.load(db)), causing mutex contention in the hook's sandboxed process.\n\nSolution implemented: Added comprehensive PID-based logging to trace process execution and lock acquisition timing to help identify where mutex failures occur. Logging includes:\n- [PID:xxxx] prefix on all messages\n- Lock acquisition attempt counts and elapsed time\n- sqlite-vec load timing with separate vec load vs total time\n- Full stack traces on failure\n\nThis helps distinguish between multiple processes (hook, daemon, MCP server) and debug file lock contention issues.","timestamp":"2025-12-21T19:27:11.273Z"}
{"action":"add","id":"92c9f64e-d8a1-44cc-93d0-5791e4b59b2f","subject":"Session-start hook processes memories with 5-memory limit for context injection","keywords":["session-start","hook","memory-limit","context","occurred_at"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:20:40.036Z","content_hash":"ee10a9bc3cf35842","content":"The session-start hook (src/hooks/session-start.ts) reads memories directly from filesystem without using vector search. It:\n1. Loads episodic memory files from local-recall/episodic-memory/\n2. Sorts by occurred_at timestamp (most recent first)\n3. Returns up to 5 most recent memories for context injection\n4. Uses direct file reading (no Orama dependency) for faster startup\n5. Outputs formatted memory content to stdout for Claude context","timestamp":"2025-12-21T19:27:11.275Z"}
{"action":"add","id":"fa46b66a-c660-49b5-b2ad-d09b4eac0cad","subject":"Memory extraction field name normalization for Claude response handling","keywords":["memory-extractor","field-normalization","claude-response","zod-validation","error-handling"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:19:06.772Z","content_hash":"cd3ed1983c25e9bc","content":"Claude models may return memory objects with alternative field names (e.g., 'description' instead of 'subject', 'tags' instead of 'keywords'). Added field name normalization function at lines 179-186 to map common variations to expected schema fields:\n\n- 'description' → 'subject'\n- 'summary' → 'subject'\n- 'tags' → 'keywords'\n- 'scope' → 'applies_to'\n- 'text' → 'content'\n- 'body' → 'content'\n\nThis normalization is applied to both direct arrays and memories nested in wrapper objects. Prevents Zod validation failures when Claude uses non-standard field names while maintaining backward compatibility with standard format.","timestamp":"2025-12-21T19:27:11.276Z"}
{"action":"add","id":"ffef75b3-f619-45bd-b5bd-e9ea3b64cc95","subject":"Vector store singleton needs reset function for test isolation","keywords":["vector-store","singleton","testing","reset","test-isolation"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:17:30.301Z","content_hash":"80c9b458c98373ba","content":"Added a `resetInstance()` function to reset the vector store singleton between tests. Without this, the singleton state persisted across test cases, causing integration tests to fail due to memories from previous tests remaining in the store. Tests now call `resetInstance()` in their beforeEach/afterEach hooks.","timestamp":"2025-12-21T19:27:11.277Z"}
{"action":"add","id":"955b13b0-cba7-42f4-afe3-8e6713078801","subject":"Local Recall plugin version 0.1.3 released with memory skills and improved tool discoverability","keywords":["version","release","0.1.3","skills","plugin","mcp","discoverability"],"applies_to":"global","occurred_at":"2025-12-21T18:31:22.495Z","content_hash":"5455d61f75000af7","content":"Version 0.1.3 of the local-recall plugin includes:\n- 2 new skills: check-memories and proactive-recall\n- Improved MCP tool descriptions with usage guidance\n- Updated plugin metadata for better discoverability in Claude Code and other MCP clients\n- 8 thinking memory files added to support memory extraction examples\n\nCommit: ff16fae pushed to main branch.","timestamp":"2025-12-21T19:27:11.278Z"}
{"action":"add","id":"10e4dbb6-d809-49ca-bbfa-766333e3d78f","subject":"New configuration variables for episodic and thinking memory token limits and similarity thresholds","keywords":["config","token","similarity","threshold","environment","variables"],"applies_to":"global","occurred_at":"2025-12-21T19:00:40.565Z","content_hash":"335a0ea71a831601","content":"Added new configuration options:\n- `episodicMaxTokens` (env: `LOCAL_RECALL_EPISODIC_MAX_TOKENS`, default: 1000) - Controls maximum tokens for episodic memories in context\n- `episodicMinSimilarity` (env: `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY`, default: 0.8) - Controls minimum similarity threshold for episodic memories (80%)\n- `thinkingMaxTokens` (env: `LOCAL_RECALL_THINKING_MAX_TOKENS`, default: 1000) - Controls maximum tokens for thinking memories in context\n- `thinkingMinSimilarity` (env: `LOCAL_RECALL_THINKING_MIN_SIMILARITY`, default: 0.8) - Controls minimum similarity threshold for thinking memories (80%)\n\nBoth episodic and thinking memory have separate token budgets and similarity thresholds, allowing fine-grained control over how much context is injected for each memory type.","timestamp":"2025-12-21T19:27:11.279Z"}
{"action":"add","id":"2212ccde-9912-4bba-9290-4075e2cc0999","subject":"Use [LOCAL_RECALL_INTERNAL] token prefix to prevent recursive UserPromptSubmit hook execution","keywords":["recursion-guard","user-prompt-submit","hook","internal-token","extraction-process"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:23:40.594Z","content_hash":"e7b7908c39c18337","content":"The UserPromptSubmit hook calls `claude -p` with --strict-mcp-config to extract keywords, which would normally trigger another UserPromptSubmit hook. To prevent this recursive loop, prefix internal prompts with [LOCAL_RECALL_INTERNAL] token and check for it at the start of prompts using startsWith('[LOCAL_RECALL_INTERNAL]'). This allows the hook to skip extraction-related calls while still allowing users to test with extraction prompts manually.","timestamp":"2025-12-21T19:27:11.280Z"}
{"action":"add","id":"effb1a36-1ead-491a-b7e1-d784ff2ce449","subject":"Documentation structure includes new 'Example: How Thinking Memories Appear in Context' section","keywords":["documentation","thinking memory","context injection","example","format"],"applies_to":"file:CLAUDE.md","occurred_at":"2025-12-21T19:14:59.463Z","content_hash":"0d6ef34ba6751d7b","content":"Added comprehensive documentation showing exactly how thinking memories appear in Claude's context when injected by the UserPromptSubmit hook.\n\nThe section demonstrates:\n- The markdown format used for injection\n- Memory metadata (ID, scope, timestamp, similarity score)\n- The combined thought + output structure\n- How multiple thinking memories are presented together\n- Token budget constraints in action\n\nThis helps users understand what information is being provided to Claude and how to interpret it.","timestamp":"2025-12-21T19:27:11.282Z"}
{"action":"add","id":"43edd8f9-d1e2-40d4-acee-0f415d708797","subject":"JSON-only output requirement enforced in memory extraction","keywords":["json output","memory extraction","schema validation","prompt engineering"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:22:59.576Z","content_hash":"14b922043d097e4d","content":"The memory extraction prompt explicitly requires that Claude return ONLY valid JSON with no explanation, markdown formatting, or code blocks (line 120). Combined with `--max-turns 1` in the CLI invocation, this ensures clean, parseable output. The prompt structure in `buildMemoryExtractionPrompt()` makes it clear that the expected return format is a JSON object with a 'memories' array containing memory objects with 'subject', 'keywords', 'applies_to', and 'content' fields.","timestamp":"2025-12-21T19:27:11.283Z"}
{"action":"add","id":"8c196a67-17ea-46eb-b671-cb30885ca734","subject":"Thinking memory formatting includes similarity score in injected context","keywords":["memory formatting","similarity score","display format","markdown output","context injection"],"applies_to":"file:src/utils/markdown.ts","occurred_at":"2025-12-21T19:14:30.494Z","content_hash":"36a3c2e8507e0184","content":"When thinking memories are injected into Claude's context, they're formatted with metadata using `formatThinkingMemoryForDisplay()` function. The formatting includes:\n\n- Memory ID\n- Scope (applies_to field)\n- Occurred timestamp (ISO-8601)\n- Thought section\n- Output section\n- **Similarity score** as percentage (e.g., '85%')\n\nThe similarity score helps Claude understand how relevant the memory is to the current prompt. This contextual metadata makes thinking memories more interpretable and useful for reasoning about which past examples apply to current tasks.","timestamp":"2025-12-21T19:27:11.285Z"}
{"action":"add","id":"34fce0f5-2459-4584-ac40-3171e8b07ef0","subject":"Local Recall plugin architecture uses skills for memory operations","keywords":["plugin","skills","memory","architecture","discoverability"],"applies_to":"global","occurred_at":"2025-12-21T18:30:11.718Z","content_hash":"45121a8146769f39","content":"Local Recall implements a plugin-based architecture in `dev-marketplace/local-recall-plugin/` with reusable skills for memory operations. Two key skills were added: `check-memories` and `proactive-recall`. The plugin system improves tool discoverability through metadata and helps organize memory functionality into modular, reusable components.","timestamp":"2025-12-21T19:27:11.286Z"}
{"action":"add","id":"7a30a6c8-de7c-4510-ae99-e3fde808bbc8","subject":"Stop hook is a deprecated interface - memory extraction now handled by MCP daemon","keywords":["stop hook","deprecated","memory extraction","mcp daemon","transcript processing"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T18:26:23.982Z","content_hash":"ebd21e1a493e2f07","content":"The stop hook in `src/hooks/stop.ts` is currently not being used. According to CLAUDE.md, the Stop hook is disabled and memory extraction is instead handled by the MCP server daemon which processes transcripts asynchronously every 5 minutes. The daemon syncs transcripts from Claude's cache, extracts memories using claude -p, and tracks processed transcripts.","timestamp":"2025-12-21T19:27:11.286Z"}
{"action":"add","id":"499145f8-5c9e-4cdc-a0f3-160c71915196","subject":"Each Claude instance needs isolated MCP server due to daemon architecture constraints","keywords":["mcp","daemon","architecture","multiple instances","port conflicts"],"applies_to":"global","occurred_at":"2025-12-21T19:20:35.399Z","content_hash":"7878d2bea23d4938","content":"User preference: Cannot use a single shared daemon for search because each Claude instance needs its own MCP server. Using an HTTP daemon architecture within the MCP server would mean multiple ONNX instances loading concurrently anyway, recreating the mutex problem.\n\nArchitectural constraint: Multiple running Claude instances cannot share a single daemon port or background process. Each instance requires isolated MCP server configuration.","timestamp":"2025-12-21T19:27:11.287Z"}
{"action":"add","id":"14e6398c-ccb3-44ec-b8b1-71f7212cf676","subject":"Plugin cache MCP server deployment requires bundled dependencies","keywords":["plugin","mcp server","bundling","esbuild","external","dependencies"],"applies_to":"global","occurred_at":"2025-12-21T19:26:25.094Z","content_hash":"b1cfffe86f4d654d","content":"When local-recall is deployed as a Claude plugin, the MCP server must have all dependencies bundled into a single server.js file. The build script previously used `--external:@modelcontextprotocol/sdk` which prevented bundling, causing the plugin cache to fail with missing dependencies.\n\n**Fix applied**: Removed `--external:@modelcontextprotocol/sdk` from the esbuild configuration in package.json's build:scripts command. This ensures the server.js (now ~1.1MB) includes all required dependencies and works standalone in the plugin cache at `/Users/joe/.claude/plugins/cache/local-recall-marketplace/local-recall/0.1.0/scripts/mcp-server/server.js`.","timestamp":"2025-12-21T19:27:11.288Z"}
{"action":"add","id":"ee7dbb99-2518-4a57-ae55-32058d48164a","subject":"Gitignore needs to exclude transcripts and processed-log files","keywords":["gitignore","transcripts","processed-log","local-recall","auto-generated"],"applies_to":"global","occurred_at":"2025-12-21T19:00:14.914Z","content_hash":"33b8ff059ea08451","content":"The `.gitignore` file created in the `local-recall` folder needs to exclude:\n- `transcripts/` - Claude's cached transcripts that shouldn't be version controlled\n- `processed-log.json` - Log file tracking processed transcripts for the daemon\n\nThese are auto-generated files that are maintained by the system and not user-editable. The gitignore template is maintained in two places:\n1. `src/core/index.ts` - generateGitignore() function\n2. `src/core/memory.ts` - gitignore template definition\n\nBoth must be kept in sync when updating the template.","timestamp":"2025-12-21T19:27:11.289Z"}
{"action":"add","id":"9fb55309-3993-438a-bd6f-31323ac85663","subject":"Memory deduplication uses occurred_at timestamp and content_hash to prevent duplicates","keywords":["deduplication","duplicate detection","occurred_at","content_hash","idempotent","memory creation"],"applies_to":"global","occurred_at":"2025-12-21T19:04:31.826Z","content_hash":"e64d35b2dcd60a7c","content":"## Problem\n\nWhen creating memories, especially through automated extraction from transcripts, the same memory could be created multiple times.\n\n## Solution\n\nMemories are deduplicated using two fields:\n\n1. **`occurred_at`** - ISO-8601 timestamp of when the original event occurred\n2. **`content_hash`** - SHA-256 hash prefix (16 characters) of the memory content\n\n## How It Works\n\nWhen creating a new memory, the system:\n1. Calculates the content hash of the memory content\n2. Looks for existing memories with the same `occurred_at` and `content_hash`\n3. Returns the existing memory if found (no duplicate created)\n4. Creates a new memory only if no duplicate exists\n\n## Benefits\n\n- **Idempotent**: Creating the same memory multiple times always returns the same ID\n- **Timestamp-based**: Allows memories of similar content created at different times\n- **Hash-based**: Detects exact content matches even if metadata differs\n- **Stable IDs**: Same event always produces same memory ID\n\n## Code Location\n\n`src/core/memory.ts` - `findDuplicate(occurredAt, contentHash)` and `createMemory()` implement deduplication logic.","timestamp":"2025-12-21T19:27:11.290Z"}
{"action":"add","id":"20115b8f-e027-4169-a8a2-79b3c1e56324","subject":"User prompt hook AbortError caused by unhandled spawn timeout","keywords":["abort error","spawn timeout","user-prompt-submit","async error handling","child process"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:28:08.458Z","content_hash":"e0aa7b1db648e09e","content":"## Problem\nThe user-prompt-submit hook was throwing an unhandled AbortError when calling Claude for keyword extraction. The error originated from Node.js aborting a child process due to the spawn timeout option.\n\n## Root Cause\nThe `callClaudeForKeywords` function in user-prompt-submit.ts had two critical issues:\n1. The `spawn` function was called with a `timeout` option that caused Node.js to abort the child process when exceeded, throwing an AbortError\n2. This abort error wasn't being caught properly in the promise chain\n3. There were duplicate `child.on('close', ...)` event handlers (at lines 60 and 120) causing race conditions\n\n## Solution\n1. Removed the `timeout` option from `spawn` - instead relying on manual timeout logic with proper error handling\n2. Added a `safeResolve` wrapper to ensure the promise only resolves once, preventing race conditions\n3. Removed the duplicate `close` handler to prevent multiple resolution attempts\n4. Added early-exit guard in the close handler to prevent reprocessing\n\n## Impact\nThis fix prevents the AbortError from propagating uncaught and ensures the hook completes gracefully even when Claude process calls timeout or fail.","timestamp":"2025-12-21T19:27:11.291Z"}
{"action":"add","id":"6d6a9169-c48c-49db-90d5-8c582df05b2e","subject":"Hook scripts are built to dev-marketplace/local-recall-plugin/scripts/hooks/ not scripts/","keywords":["hooks","build","output","configuration","dev-marketplace"],"applies_to":"global","occurred_at":"2025-12-21T19:20:51.697Z","content_hash":"0807a5d402a81912","content":"The npm build process outputs compiled hook scripts to `dev-marketplace/local-recall-plugin/scripts/hooks/` rather than to a `scripts/` directory at the project root. This is important for hook configuration - the actual paths must point to the dev-marketplace location, not a root scripts/ folder.","timestamp":"2025-12-21T19:27:11.295Z"}
{"action":"add","id":"73fefc2f-d5b7-4735-a963-cdc425495994","subject":"sqlite-vec requires 'k = ?' parameter in JOIN queries with scope filtering","keywords":["sqlite-vec","sql","vector-search","scope-filter","join"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:17:02.145Z","content_hash":"a82b505a11ddd749","content":"The sqlite-vec extension requires k = ? (limit parameter) in the match clause when using JOIN queries. When scope filtering is applied, sqlite-vec applies the k limit before the JOIN filter, reducing results below the requested limit. Solution: Fetch k * 2 results from sqlite-vec (without scope filter) and filter scopes in JavaScript code afterward. This ensures enough results pass the scope filter.","timestamp":"2025-12-21T19:27:11.300Z"}
{"action":"add","id":"f4a51a77-8bf2-4589-862c-b1f99f590864","subject":"Thinking extractor now groups JSONL entries by message.id to capture complete messages","keywords":["message grouping","jsonl","thinking extractor","parsing","transcript processing"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T09:47:36.366Z","content_hash":"b74947416a68924f","content":"The `parseTranscriptForThinking` function was rewritten to properly handle Claude Code's JSONL format where each content block is a separate line. Key changes:\n\n1. Iterate through all JSONL lines and group by `message.id`\n2. For each message group, collect all `content` entries\n3. Extract thinking blocks where `type === 'thinking'`\n4. Extract corresponding text output where `type === 'text'`\n5. Skip tool-only responses (where no text output follows thinking)\n6. Create thinking memory pairs from thought+output combos\n\nThis ensures complete thinking chains are captured instead of fragmentary single-line extractions.","timestamp":"2025-12-21T19:27:11.305Z"}
{"action":"add","id":"188dc44a-a359-4cb2-b5f0-bdda2232ced0","subject":"Gitignore was updated to remove outdated sqlite references","keywords":["gitignore","sqlite","sqlite-vec","cleanup"],"applies_to":"file:local-recall/.gitignore","occurred_at":"2025-12-21T19:21:45.415Z","content_hash":"e4ad0a4a704b5dfd","content":"Removed outdated sqlite-related references from both `local-recall/.gitignore` and the gitignore generation code in `src/utils/gitignore.ts`. The project no longer uses sqlite-vec or better-sqlite3, only Orama for vector storage.","timestamp":"2025-12-21T19:27:11.312Z"}
{"action":"add","id":"62967ca2-397c-4ca4-a9c9-343425649a5b","subject":"Plugin versioning has two touchpoints: package.json and .claude-plugin/marketplace.json","keywords":["versioning","plugin","package.json","marketplace","distribution"],"applies_to":"global","occurred_at":"2025-12-21T19:10:16.829Z","content_hash":"f24b587070f23fb4","content":"Local Recall maintains version information in two places: (1) `package.json` for npm package distribution and (2) `.claude-plugin/marketplace.json` for Claude Code marketplace distribution. Both must be updated in sync when releasing new versions. The package.json is the primary source of truth, and marketplace.json should mirror it.","timestamp":"2025-12-21T19:27:11.321Z"}
{"action":"add","id":"27424561-42a3-4b4c-accf-19ffcffd28e7","subject":"Documentation updated to reflect SQLite migration and new search behavior","keywords":["documentation","claude.md","sqlite","scoring","vector-store"],"applies_to":"file:CLAUDE.md","occurred_at":"2025-12-21T18:26:56.199Z","content_hash":"aeeb9b2598a90dbc","content":"CLAUDE.md has been updated with:\n\n1. Architecture diagram no longer references Orama indexes\n2. Vector Store section documents SQLite implementation instead of Orama\n3. New \"Scoring and Ranking\" section explains the 2-decimal rounding and recency tiebreaker behavior\n4. Memory directory section removes references to `orama-*-index.json` files\n5. Configuration section and troubleshooting remain largely unchanged\n\nThese updates ensure documentation accurately reflects the current SQLite-based implementation.","timestamp":"2025-12-21T19:27:11.328Z"}
{"action":"add","id":"6967ba41-ed56-41db-b604-59309bdf9596","subject":"Claude Code plugin hooks require proper JSON stdin/stdout communication","keywords":["plugin","hooks","json","stdin","stdout","communication"],"applies_to":"area:local-recall-plugin","occurred_at":"2025-12-21T18:25:24.918Z","content_hash":"e36eacb63a6716ce","content":"Claude Code hook scripts receive JSON data via stdin and must output JSON to stdout for proper integration.\n\n**Input format**: Hooks receive JSON containing:\n- `session_id`: Unique session identifier\n- `transcript_path`: Path to current transcript\n- `cwd`: Current working directory\n- (UserPromptSubmit also includes: `prompt` - the user's prompt text)\n\n**Output format**: Hooks must write valid JSON to stdout for injection into Claude's context. Invalid JSON or non-JSON output will cause hook failures.\n\n**Important**: Ensure proper error handling and JSON.stringify() for all outputs. Test hooks locally to verify stdin/stdout communication before deployment.","timestamp":"2025-12-21T19:27:11.331Z"}
{"action":"add","id":"666bfdd3-c6b1-4053-b8df-5b12ad1ccc0e","subject":"Mutex errors were caused by onnxruntime-node (fastembed dependency), not sqlite","keywords":["mutex","onnxruntime-node","fastembed","native bindings","concurrent processes","locking"],"applies_to":"global","occurred_at":"2025-12-21T19:21:45.415Z","content_hash":"380e62e6f4f19d60","content":"After migrating from sqlite-vec to Orama, mutex errors persisted because the hooks were still loading `fastembed` directly, which depends on `onnxruntime-node`. This native module has the same mutex/locking issues as sqlite-vec when multiple concurrent processes try to load it.\n\nThe original daemon architecture was designed to solve this: a single daemon process would handle all fastembed operations, and hooks would call it via HTTP. This architecture was removed during the Orama migration but the problem with native bindings remains.\n\nSolution implemented: File-based locking using `proper-lockfile` to serialize access to fastembed initialization and embedding operations across concurrent hook processes.","timestamp":"2025-12-21T19:27:11.335Z"}
{"action":"add","id":"5dc09634-c160-461d-92a8-a30d8ed72c19","subject":"Thinking memories should pair thought + output for learning examples","keywords":["thinking memory","extractor","thought output pairing","learning examples","future sessions"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:14:30.494Z","content_hash":"f7933caa3cf000bd","content":"The thinking memory system was enhanced to capture both Claude's reasoning (thought block) and its corresponding output message together. This creates concrete examples of 'how I thought → what I produced' that can be injected into future sessions to help shape Claude's reasoning on similar tasks.\n\nImplementation:\n- Extracts thinking blocks and their associated text output from the same AssistantMessageEntry\n- Skips tool-only responses (only captures responses with text output)\n- Stores as combined markdown: `## Thought\\n\\n{thinking}\\n\\n## Output\\n\\n{output}`\n- Memory subject line taken from first sentence of thinking block\n\nThis pairing is much more valuable than isolated thoughts because it shows the complete thought-to-output flow.","timestamp":"2025-12-21T19:27:11.343Z"}
{"action":"add","id":"37c17b16-a006-4f94-84c1-44e2549cf8b6","subject":"Transcript collection logs indicate MCP server is running and discovering Claude projects","keywords":["transcript collection","logging level","debug vs info","transcript discovery"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:31:23.288Z","content_hash":"8937cc74a3a94628","content":"The transcript collector logs `[transcript]` messages at INFO level when searching for Claude project transcripts and when discovering projects. These logs are only visible if logging is set to appropriate level. Absence of these logs in recall.log typically means either the MCP server isn't running or the code wasn't rebuilt after changes.","timestamp":"2025-12-21T19:27:11.346Z"}
{"action":"add","id":"d60d75cc-8890-4a75-b810-4c3729d4356e","subject":"Thinking blocks in transcripts are streamed as duplicates, not true interleaved thinking","keywords":["thinking","streaming","duplicates","artifacts","transcripts"],"applies_to":"global","occurred_at":"2025-12-21T19:24:36.877Z","content_hash":"8a6a6a5bb6d2d6eb","content":"Analysis of 69,308 transcript entries found that when multiple thinking blocks appear in a single message, they are always duplicates (identical content) caused by streaming artifacts, not true interleaved thinking. No instances of genuine interleaved thinking (different thinking blocks) were found in the codebase. The thinkingParts[] array correctly handles multiple thinking blocks, but deduplication is recommended to prevent redundant content in extracted memories.","timestamp":"2025-12-21T19:27:11.351Z"}
{"action":"add","id":"5591d091-7cf6-4d6b-b911-a559deb2bc62","subject":"Deduplication of thinking blocks prevents memory content from becoming repetitive","keywords":["deduplication","thinking-extractor","set deduplication","streaming duplicates"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:23:30.733Z","content_hash":"36753a6745e91f0f","content":"Added deduplication logic at lines 146-148 of thinking-extractor.ts using Set to filter out duplicate thinking and text parts before joining them. This prevents memories from containing repeated content when streaming artifacts log the same thinking block multiple times. The fix uses `[...new Set(aggregated.thinkingParts)]` and `[...new Set(aggregated.textParts)]` to ensure unique content only.","timestamp":"2025-12-21T19:27:11.354Z"}
{"action":"add","id":"20e90141-e7a4-42c5-bafb-1866768ddf4f","subject":"Embeddings should be stored in JSONL files alongside memory data, not separate in Orama index","keywords":["embeddings","storage","orama","jsonl","vector-search"],"applies_to":"global","occurred_at":"2025-12-21T19:13:46.767Z","content_hash":"cd94c01df914ac6d","content":"The embedding strategy needs clarification: embeddings should be persisted in the JSONL files themselves (as a field in each record) rather than stored only in the separate Orama index JSON file.\n\nThis ensures:\n- Embeddings are preserved when JSONL files are migrated or backed up\n- The JSONL format is self-contained without depending on orama-episodic-index.json\n- Better consistency between file-based storage and in-memory Orama state\n\nCurrent implementation stores embeddings only in Orama's binary index format, making them ephemeral.","timestamp":"2025-12-21T19:27:11.359Z"}
{"action":"add","id":"bf2c9b21-c584-4339-8db6-a7b319b61622","subject":"Simplified hook architecture by removing daemon requirement","keywords":["hooks","architecture","daemon","simplification","http-communication"],"applies_to":"global","occurred_at":"2025-12-03T11:22:58.632Z","content_hash":"ddb322aac029d0d1","content":"# Hook Architecture Simplification\n\n## Before\nHooks communicated with a background daemon via HTTP (localhost:7847) to avoid mutex lock errors from concurrent sqlite-vec loading:\n- SessionStart hook → HTTP request → daemon → vector search\n- UserPromptSubmit hook → HTTP request → daemon → vector search\n- Stop hook → HTTP request → daemon → memory extraction\n\n## After\nHooks now work directly:\n- SessionStart hook → direct memory operations\n- UserPromptSubmit hook → direct vector search via Orama\n- No daemon process required\n- No HTTP communication layer needed\n\n## Benefits\n- Simpler configuration and deployment\n- Fewer moving parts and potential failure points\n- Better integration with Claude Code\n- Reduced complexity for end users","timestamp":"2025-12-21T19:27:11.361Z"}
{"action":"add","id":"682f14e2-b4f1-4748-82c7-ff052a57421c","subject":"Local Recall plugin skills structure and versioning conventions","keywords":["skills","plugin","version","discoverability","mcp-tools"],"applies_to":"global","occurred_at":"2025-12-21T19:23:09.457Z","content_hash":"3f76326c2f21fe11","content":"The local-recall-plugin directory contains skills that are part of the marketplace. When updating skills:\n\n1. Skills are stored in `dev-marketplace/local-recall-plugin/skills/`\n2. Version bumps should be reflected in package.json\n3. MCP tool descriptions should include usage guidance for better discoverability\n4. Plugin metadata in package.json affects how tools appear in the marketplace\n5. Commits that add skills should reference the feature in the commit message\n\nRecent example: Version 0.1.3 added two skills (check-memories, proactive-recall) alongside 8 thinking memory files.","timestamp":"2025-12-21T19:27:11.363Z"}
{"action":"add","id":"d560563e-1141-4ed6-bb76-57c61bda05e3","subject":"Plugin hooks migration from better-sqlite3 to Orama","keywords":["plugin","hooks","better-sqlite3","orama","migration","stale-code","user-prompt-submit"],"applies_to":"area:plugin-hooks","occurred_at":"2025-12-21T18:27:24.119Z","content_hash":"5ea625dd10e6b7a3","content":"The local-recall-plugin had stale hook files that tried to import `better-sqlite3` (a native module that cannot be bundled). The main project switched to Orama (pure JavaScript) for vector search, but the plugin still had old bundled hooks pointing to `user-prompt-submit-thinking.js` which attempted to use better-sqlite3.\n\n**Solution**: Removed the stale `user-prompt-submit-thinking.js` file and updated `dev-marketplace/local-recall-plugin/config/hooks.json` to use the unified `user-prompt-submit.js` hook instead. This hook now handles both episodic and thinking memories using Orama.\n\n**Why this matters**: Native module dependencies cannot be bundled into hook scripts that execute as CLI commands. Orama's pure JavaScript implementation is the correct choice for plugin hooks.","timestamp":"2025-12-21T19:27:11.366Z"}
{"action":"add","id":"9e096b6a-ccea-4377-9083-4c9e72119a19","subject":"Memory system changed to save all messages without filtering","keywords":["transcript","memory extraction","analyzeForMemories","filtering removed","all messages"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:01:42.936Z","content_hash":"b9a7100c66fc570e","content":"The user requested removal of trigger-pattern-based memory filtering. The implementation was simplified to save ALL messages from transcripts without any filtering:\n\n- **Removed**: `USER_TRIGGER_PATTERNS` regex (\"remember this\", \"save this\", \"don't forget\", etc.)\n- **Removed**: `AUTO_DETECT_PATTERNS` heuristics (architecture patterns, bugfix patterns, discovery patterns, convention patterns)\n- **Changed**: `analyzeForMemories()` function now iterates through all messages and saves each one with role prefix (`**user**:` or `**assistant**:`)\n- **Behavior**: Skips only empty messages, captures entire conversation without selective filtering\n\nThis represents a significant shift from a curated/selective memory approach to a comprehensive transcript capture approach.","timestamp":"2025-12-21T19:27:11.368Z"}
{"action":"add","id":"6b48fda9-74c9-422a-9cae-1801c337b5fb","subject":"Claude Haiku returns memory arrays without object wrapper in some cases","keywords":["claude-haiku","api-response","memory-extraction","data-format"],"applies_to":"global","occurred_at":"2025-12-21T19:19:00.855Z","content_hash":"fb4550addde7515d","content":"Discovered that Claude Haiku model sometimes returns memory extraction results as a plain array `[{...}]` instead of wrapping them in an object `{ memories: [...] }`. This is a legitimate response variation that needs to be handled gracefully. The fix detects and normalizes these responses before schema validation to prevent extraction pipeline failures.","timestamp":"2025-12-21T19:27:11.370Z"}
{"action":"add","id":"10d6d1c1-9314-413c-8583-db64cd41a3ab","subject":"Thinking memory extraction class exists but unused in production","keywords":["thinking-extractor","unused-code","production-gap"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:29:45.308Z","content_hash":"9ae35f17a578df49","content":"The `ThinkingExtractor` class was fully implemented (lines 103-310 of `thinking-extractor.ts`) with methods like `extractThinkingFromTranscript()` to parse Claude's thinking blocks and pair them with outputs. However, the `runThinkingExtraction()` function was never being invoked by the MCP server daemon, meaning thinking memories were not being automatically processed from transcripts despite the feature being conceptually complete.","timestamp":"2025-12-21T19:27:11.372Z"}
{"action":"add","id":"83e0ef7c-38eb-4f5c-9cc9-fc5909e98325","subject":"Thinking memories now combine thought blocks with corresponding text output","keywords":["thinking memory","extraction","thought output pairing","claude reasoning"],"applies_to":"global","occurred_at":"2025-12-21T19:14:59.463Z","content_hash":"fb22f47cef527be7","content":"The thinking memory extraction process was updated to capture both Claude's internal reasoning (thinking blocks) and the corresponding text output that follows. This allows future sessions to see examples of \"how I thought → what I produced\" which helps shape Claude's future reasoning.\n\nKey implementation details:\n- Thinking and output are already in the same AssistantMessageEntry in transcripts\n- ThinkingContent and TextContent blocks coexist in the same message\n- Tool-only responses (with no text output) are now skipped\n- Combined format: `## Thought\\n\\n{thinking}\\n\\n## Output\\n\\n{output}`\n\nThis provides concrete examples that are more useful than thinking blocks alone for guiding future reasoning.","timestamp":"2025-12-21T19:27:11.375Z"}
{"action":"add","id":"a56013a9-0cd0-43f1-bd12-d2058ae54c61","subject":"Processed log refactored to append-only JSONL format for performance","keywords":["processed-log","jsonl","append-only","performance","format-migration"],"applies_to":"file:src/core/processed-log.ts","occurred_at":"2025-12-21T18:14:34.568Z","content_hash":"070e94955af46165","content":"The processed log was migrated from JSON array to JSONL (JSON Lines) format. The new implementation:\n- Uses append-only writes for better I/O performance\n- Each entry is a single JSON line with `action: \"add\"` or `action: \"remove\"`\n- `recordProcessed()` appends an \"add\" line, `removeEntry()` appends a \"remove\" line\n- On load, replays all entries to build current state (idempotent reconstruction)\n- Includes a `compact()` method to clean up the file by removing redundant entries\n\nThis design provides better performance and cleaner append semantics than the previous array-based approach.","timestamp":"2025-12-21T19:27:11.378Z"}
{"action":"add","id":"9e642a4d-906f-4437-9c97-6d874ccd0e4f","subject":"UserPromptSubmit hook handles both episodic and thinking memories with independent configuration","keywords":["user-prompt-submit","hook","thinking-memory","episodic-memory","configuration"],"applies_to":"global","occurred_at":"2025-12-21T19:17:41.738Z","content_hash":"f4356872feccd018","content":"The UserPromptSubmit hook unifies both episodic and thinking memory search based on configuration flags. Each memory type has independent settings:\n- episodicEnabled (default: true) + episodicMaxTokens/episodicMinSimilarity\n- thinkingEnabled (default: true) + thinkingMaxTokens/thinkingMinSimilarity\n\nThe hook skips internal prompts containing '[LOCAL_RECALL_INTERNAL]' to avoid recursive memory extraction. Results are filtered by similarity threshold and token budget before combining.","timestamp":"2025-12-21T19:27:11.381Z"}
{"action":"add","id":"b32a60e0-d0f4-4aa2-9c62-066120c00cdc","subject":"Alternative embedding libraries have same ONNX concurrency issues","keywords":["transformers.js","tensorflow.js","embedding-alternative","onnx","mutex"],"applies_to":"global","occurred_at":"2025-12-21T18:24:57.085Z","content_hash":"89d767752b0866ce","content":"Researched alternatives to fastembed including transformers.js and TensorFlow.js. Both use ONNX native runtime, so they have the same mutex issues as fastembed when loaded concurrently. They're not viable solutions for the multi-process hook architecture. Ollama (external daemon) is the only practical solution.","timestamp":"2025-12-21T19:27:11.384Z"}
{"action":"add","id":"fc90528f-5743-4be2-b26e-b3eb964be282","subject":"Mutex errors occur when multiple processes load sqlite-vec concurrently","keywords":["mutex","sqlite-vec","concurrent processes","locking","file-based locking","error handling"],"applies_to":"global","occurred_at":"2025-12-21T19:18:27.194Z","content_hash":"f4ccfe3f1a2f3781","content":"The codebase has identified a critical issue where loading sqlite-vec from multiple processes concurrently can cause 'mutex lock failed: Invalid argument' errors. The solution involves using cross-process file locking to prevent simultaneous sqlite-vec initialization. This is implemented in src/mcp-server/server.ts:230. Tests for mutex/concurrent behavior do not currently exist (no files found matching tests/**/*mutex* or tests/**/*concurrent*), suggesting this is an area needing test coverage.","timestamp":"2025-12-21T19:27:11.387Z"}
{"action":"add","id":"9091854f-c79d-4829-8ebc-3b99b1bd2e09","subject":"Mutex lock error in hooks caused by direct sqlite-vec loading instead of daemon","keywords":["mutex","sqlite-vec","hook","error","libc++abi","locking"],"applies_to":"global","occurred_at":"2025-12-21T18:18:36.755Z","content_hash":"9532f1e731779968","content":"The UserPromptSubmit hook was throwing 'libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument'. This occurs when hooks directly instantiate SearchEngine and ThinkingSearchEngine which attempt to load sqlite-vec. The root cause is that sqlite-vec's native mutex operations fail when called from within the hook subprocess context. Solution: Hooks should use HTTP daemon approach instead of direct database loading to avoid subprocess isolation issues.","timestamp":"2025-12-21T19:27:11.391Z"}
{"action":"add","id":"3ead1799-a950-48fa-b29a-6e369d7c3673","subject":"Thinking memory vector store automatically recreates tables if deleted","keywords":["thinking-vector-store","database","initialization","recovery"],"applies_to":"file:src/core/thinking-vector-store.ts","occurred_at":"2025-12-03T09:47:22.389Z","content_hash":"21bd3849ce71d061","content":"Thinking memory tables are recreated automatically via CreateTable IF NOT EXISTS. If you delete memory.sqlite and the thinking-processed-log.jsonl, the next daemon run will recreate both automatically. ProcessedLog.load() gracefully handles ENOENT errors and starts fresh. This allows resetting thinking memories by simply deleting the processed log and memory files without manual database recreation.","timestamp":"2025-12-21T19:27:11.393Z"}
{"action":"add","id":"90f7f8fa-dbef-4cca-8028-97009adffb71","subject":"onnxruntime-node mutex errors after Orama migration - file lock solution","keywords":["mutex","fastembed","onnxruntime-node","native bindings","concurrent processes","proper-lockfile","embedding lock"],"applies_to":"global","occurred_at":"2025-12-21T19:21:53.918Z","content_hash":"2b64f402d062839c","content":"## Problem\n\nAfter migrating from sqlite-vec to Orama, mutex errors persisted because the hooks were still loading `fastembed` directly. While Orama is pure JavaScript, `fastembed` depends on `onnxruntime-node` which has native bindings that cause mutex lock contention when multiple hook processes load it concurrently.\n\n## Root Cause Analysis\n\n- `onnxruntime-node` (used by fastembed) has the same native mutex issue as sqlite-vec\n- When multiple Claude Code hook processes run in parallel, they all try to load the native module\n- This causes mutex lock contention and crashes\n\n## Solution Implemented\n\nUsed `proper-lockfile` package to serialize access to fastembed/onnxruntime-node:\n\n- Added file-based lock at `/tmp/local-recall-embedding.lock`\n- Lock wraps both initialization and embedding operations\n- Retries up to 10 times with exponential backoff (100ms - 2s)\n- Stale lock timeout: 30 seconds\n- Prevents concurrent native module loading\n\n## Implementation Details\n\nFile: `src/core/embedding.ts`\n- Import: `import lockfile from 'proper-lockfile'`\n- Private method `withEmbeddingLock()` wraps async operations\n- All native module access goes through the lock\n- Logs \"Acquired embedding lock\" and \"Released embedding lock\" messages\n\n## Why This Works\n\nFile locks are OS-level primitives that work across process boundaries - perfect for preventing concurrent access to native modules when hooks run in parallel.","timestamp":"2025-12-21T19:27:11.395Z"}
{"action":"add","id":"d05fee55-a903-4d2f-b13a-bb303d7a2b0d","subject":"Orama index files are gitignored but episodic/thinking memory markdown files are tracked","keywords":["git-tracking","index-files","memory-files","gitignore"],"applies_to":"global","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"31cac8e235c907c5","content":"In the `local-recall/` directory:\n- `orama-episodic-index.json` and `orama-thinking-index.json` are gitignored (auto-generated from memory files)\n- `episodic-memory/*.md` and `thinking-memory/*.md` are version-controlled\n- `.gitignore` file is auto-generated by the system\n- `recall.log` is gitignored (debug log)\n\nThis allows sharing memory content via git while keeping indexes local for performance.","timestamp":"2025-12-21T19:27:11.396Z"}
{"action":"add","id":"47dc6b54-c62b-4ef2-ba3a-4aa5b531a02f","subject":"Transcript collector handles multiple methods of locating Claude project directories","keywords":["transcript","claude-project","directory","location","discovery"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:52.265Z","content_hash":"223a1ef547b9908f","content":"The transcript collector uses `findClaudeProjectDir()` to discover the Claude project directory through multiple strategies:\n1. Check environment variable `CLAUDE_PROJECT_DIR`\n2. Search parent directories for `.claude/` folder containing project settings\n3. Search parent directories for `transcripts/` folder containing transcript files\n\nWhen searching for transcript directories, only files with valid UUID filenames should be considered to avoid matching on other `.jsonl` files that might exist in those folders.","timestamp":"2025-12-21T19:27:11.399Z"}
{"action":"add","id":"9d99c5c5-5d0f-48d0-a37e-45335a50b83e","subject":"Thinking memories store thought+output pairs to show 'how I reasoned → what I produced'","keywords":["thinking-memory","reasoning","extraction","format","thought-output"],"applies_to":"global","occurred_at":"2025-12-21T19:17:41.738Z","content_hash":"993b46630622340a","content":"Thinking memories capture Claude's internal reasoning paired with corresponding text outputs (tool-only responses are skipped). Format includes:\n- Thought: Claude's reasoning block from the transcript\n- Output: The text response that followed the thinking\n\nWhen retrieved, these memories are injected as 'Previous Thoughts' showing concrete examples of similar reasoning patterns. Extraction runs with 20 parallel workers to handle large batches efficiently.","timestamp":"2025-12-21T19:27:11.400Z"}
{"action":"add","id":"b469363c-f1fe-4aba-b5b9-180162ea28b8","subject":"Episodic and thinking memory searches are independent with separate configuration thresholds","keywords":["episodic memory","thinking memory","search","configuration","threshold","min similarity","max tokens"],"applies_to":"global","occurred_at":"2025-12-21T19:04:31.826Z","content_hash":"16bf9be3c8b74f5c","content":"## Architecture\n\nEpisodic and thinking memories are searched independently using separate vector stores and configurations.\n\n## Configuration\n\nEach memory type has independent settings:\n\n**Episodic Memories:**\n- `episodicEnabled` - Enable/disable episodic search\n- `episodicMaxTokens` - Maximum tokens to include (default: 1000)\n- `episodicMinSimilarity` - Minimum similarity threshold (default: 0.5)\n\n**Thinking Memories:**\n- `thinkingEnabled` - Enable/disable thinking search\n- `thinkingMaxTokens` - Maximum tokens to include (default: 1000)\n- `thinkingMinSimilarity` - Minimum similarity threshold (default: 0.5)\n\n## Behavior\n\nThe UserPromptSubmit hook:\n1. Searches episodic memories if `episodicEnabled` and filters by `episodicMinSimilarity`\n2. Searches thinking memories if `thinkingEnabled` and filters by `thinkingMinSimilarity`\n3. Respects separate token budgets for each type\n4. Combines results and injects both types into context\n\n## Benefit\n\nIndependent configuration allows fine-tuning each memory type separately based on quality and relevance needs.\n\n## Code Location\n\n`src/hooks/user-prompt-submit.ts` - Unified hook handles both episodic and thinking memories with separate configurations.","timestamp":"2025-12-21T19:27:11.402Z"}
{"action":"add","id":"aa496df3-255a-474b-a2aa-f693e48f918c","subject":"Claude project discovery uses path-to-dashes naming convention","keywords":["claude projects","transcript discovery","path convention","project folder naming"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:30.211Z","content_hash":"6cf1f9e59463d452","content":"Claude stores projects in ~/.claude/projects with folder names using the full path with slashes replaced by dashes. Example: `/Users/joe/Code/Syntessera/local-recall` becomes `-Users-joe-Code-Syntessera-local-recall`. The TranscriptCollector should prioritize this naming convention when searching for project folders, as it's more reliable than other fallback methods.","timestamp":"2025-12-21T19:27:11.404Z"}
{"action":"add","id":"540c25af-74ed-463c-b90d-fe351d44face","subject":"Plugin hooks were using stale better-sqlite3 dependency that no longer exists","keywords":["plugin","hooks","better-sqlite3","stale code","orama","migration"],"applies_to":"area:plugin","occurred_at":"2025-12-21T18:28:29.693Z","content_hash":"642d73cab0729dae","content":"The dev-marketplace/local-recall-plugin had stale hook files (user-prompt-submit-thinking.js) that tried to import 'better-sqlite3'. This was from an older version before the codebase migrated to Orama (pure JavaScript vector store). The plugin's hooks.json configuration was pointing to these deleted files, causing ERR_MODULE_NOT_FOUND errors when hooks tried to execute.\n\n**Solution:**\n- Deleted the stale user-prompt-submit-thinking.js file\n- Updated hooks.json to point to user-prompt-submit.js (the unified hook that handles both episodic and thinking memories)\n- Rebuilt the plugin scripts to use current dependencies\n\nThe main src/hooks/ files already use Orama correctly, but the plugin needed its hooks.json and bundled scripts to be updated to match.","timestamp":"2025-12-21T19:27:11.405Z"}
{"action":"add","id":"b8740749-c487-4122-b115-39f9f3cd6acc","subject":"Hook-daemon architecture prevents sqlite-vec mutex errors through HTTP communication","keywords":["hook-daemon","http","architecture","sqlite-vec","mutex prevention"],"applies_to":"global","occurred_at":"2025-12-03T11:21:33.144Z","content_hash":"79ec2444217081bd","content":"Hooks are thin clients that communicate with the MCP daemon via HTTP (localhost:7847) to avoid loading the sqlite-vec native extension directly. This prevents \"mutex lock failed\" errors. The daemon owns the database connection and handles all vector store operations, while hooks use fallback file-reading methods when the daemon is unavailable. This is a critical design pattern that prevents concurrent access issues.","timestamp":"2025-12-21T19:27:11.405Z"}
{"action":"add","id":"8645de86-b4bf-4d73-9986-ecbcdcc0c867","subject":"Thinking memory extraction runs in background daemon with same 5-minute interval as episodic","keywords":["daemon","thinking-extraction","episodic-extraction","parallel","processing-interval"],"applies_to":"area:memory-extraction","occurred_at":"2025-12-21T19:24:52.567Z","content_hash":"3fdc9f2d03ed6789","content":"Both episodic and thinking memory extraction now run in the background daemon (`src/mcp-server/server.ts`) on the same 5-minute interval:\n\n- **Episodic extraction**: `runTranscriptProcessing()` with `isProcessing` flag\n- **Thinking extraction**: `runThinkingExtraction()` with `isThinkingProcessing` flag\n- Both calls are made sequentially within the same daemon loop iteration\n- Each has its own processing flag to prevent concurrent runs of the same type\n- They do not block each other - independent processes\n\nThis design avoids the SQLite mutex race condition that occurred when both hooks tried to access the database simultaneously.","timestamp":"2025-12-21T19:27:11.406Z"}
{"action":"add","id":"ab70434b-6495-4b27-8901-60ba39f1be52","subject":"MCP server runs a background daemon that processes transcripts","keywords":["mcp server","daemon","background process","transcript processing","memory extraction"],"applies_to":"global","occurred_at":"2025-12-21T18:31:41.980Z","content_hash":"02989b094f2484a1","content":"The MCP server (src/mcp-server/server.ts) runs a background daemon that processes transcripts every 5 minutes. This daemon handles memory extraction and is controlled by configuration flags like `episodicEnabled`. The daemon is distinct from the hooks which run synchronously during Claude sessions.","timestamp":"2025-12-21T19:27:11.407Z"}
{"action":"add","id":"970b68d1-9b46-4268-b4cf-77c9c6f861ca","subject":"Thinking memories pair Claude's reasoning with its output for pattern learning","keywords":["thinking-memory","thought-output-pairs","reasoning","extraction","format"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"50264ff065eba736","content":"Thinking memories capture thought+output pairs: the `## Thought` section contains Claude's reasoning, and the `## Output` section contains the text response that followed. These are extracted from transcripts and enable future sessions to learn from how Claude reasoned through similar problems. Tool-only responses (no text output) are skipped during extraction. Thinking memories help demonstrate \"how I thought → what I produced\" patterns.","timestamp":"2025-12-21T19:27:11.409Z"}
{"action":"add","id":"0c005c05-933d-4a0d-b95a-c199b96e0955","subject":"UserPromptSubmit hook performs unified semantic search across episodic and thinking memories","keywords":["userpromptsubmit-hook","semantic-search","memory-retrieval","context-injection"],"applies_to":"area:hooks","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"e727ae2a49c14a28","content":"The UserPromptSubmit hook is a unified hook that:\n1. Skips internal prompts containing `[LOCAL_RECALL_INTERNAL]`\n2. Searches both episodic memories (if episodicEnabled) and thinking memories (if thinkingEnabled)\n3. Filters by similarity threshold and token budget\n4. Combines results and injects into Claude's context\n\nConfiguration options:\n- episodicMaxTokens (default: 1000)\n- episodicMinSimilarity (default: 0.5)\n- thinkingMaxTokens (default: 1000)\n- thinkingMinSimilarity (default: 0.5)","timestamp":"2025-12-21T19:27:11.410Z"}
{"action":"add","id":"2517c164-c09d-429b-b940-4f59fc8e1959","subject":"Ollama is the recommended solution for local embeddings with multiple processes","keywords":["ollama","embedding","http-api","multi-process","safe","nomic-embed-text"],"applies_to":"global","occurred_at":"2025-12-21T18:24:57.085Z","content_hash":"49c46d81ea987e65","content":"Ollama (https://ollama.com) is a standalone embedding server that solves the ONNX mutex problem. It runs as a single system-wide service (one ONNX instance), and multiple processes/Claude instances can call it via HTTP API on port 11434. The mutex issue only occurs during ONNX initialization - a shared daemon means ONNX loads once, then many clients use it safely. Installation: `brew install ollama` (macOS), or download from ollama.com. Pull embedding model with `ollama pull nomic-embed-text`. CLAUDE.md already documents Ollama as the embedding service with env vars OLLAMA_BASE_URL and OLLAMA_EMBED_MODEL.","timestamp":"2025-12-21T19:27:11.411Z"}
{"action":"add","id":"2228b07f-6f66-432d-8160-78fffb941cf6","subject":"MCP server daemon runs on startup with specific timing delays","keywords":["mcp server","daemon","startup","initialization","vector sync","transcript processing"],"applies_to":"global","occurred_at":"2025-12-12T10:14:38.028Z","content_hash":"fcd5c4e2bde95ef2","content":"The MCP server daemon in src/mcp-server/server.ts runs background tasks on startup with specific delays:\n\n1. **Vector sync**: Runs 2 seconds after server start, then every 10 minutes (line 169-193)\n2. **Transcript processing**: Runs 5 seconds after server start, then every 5 minutes\n\nThese delays allow the server to fully initialize before processing begins. Each Claude Code instance spawns its own MCP server process via stdio transport.","timestamp":"2025-12-21T19:27:11.412Z"}
{"action":"add","id":"bac9ddc6-1a37-4b05-90d2-7002746a6416","subject":"Orama vector store uses cosine distance with recency tie-breaking for search results","keywords":["orama","vector store","search","scoring","cosine distance","ranking","recency"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"d49d85246017b97c","content":"The Orama vector store returns search results with cosine similarity scores (0.0-1.0 range, rounded to 2 decimals). Results are sorted by score descending, but when scores are equal, more recent memories (by `occurred_at` timestamp) should be ranked first. This recency tie-breaker ensures that in cases of equal relevance, the most recent context takes precedence.","timestamp":"2025-12-21T19:27:11.413Z"}
{"action":"add","id":"10ef4b86-8ca5-4114-99c9-6baa0ae15a21","subject":"MCP Tools documentation updated with new episodic and thinking tools","keywords":["documentation","mcp","tools","api reference"],"applies_to":"file:docs/mcp-server.md","occurred_at":"2025-12-21T19:04:16.673Z","content_hash":"6a78db2ef8f92c73","content":"## Documentation Updates\n\n### File: docs/mcp-server.md\n\nCompletely updated the \"Available Tools\" section to reflect:\n\n#### Episodic Memory Tools (5 tools)\n- `episodic_create` - Create new episodic memory\n- `episodic_get` - Get episodic memory by ID\n- `episodic_search` - Search episodic memories\n\n#### Thinking Memory Tools (2 tools)\n- `thinking_get` - Get thinking memory by ID\n- `thinking_search` - Search thinking memories\n\n#### Removed References\n- Removed `index_rebuild` documentation\n- Removed `memory_list` documentation\n- Removed all `memory_` prefixed tool references\n\n#### Storage Structure\nUpdated to show both memory types:\n- `episodic-memory/` - Individual episodic memory files\n- `thinking-memory/` - Thinking memory files with thought+output pairs","timestamp":"2025-12-21T19:27:11.413Z"}
{"action":"add","id":"4cc4e44f-3eca-48cc-90f0-2a05e971d357","subject":"Memory extraction criteria: save all thinking, but only multiline content","keywords":["memory","extraction","thinking","content","multiline","filter"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:26:21.981Z","content_hash":"14dfe11a460cc714","content":"The `analyzeForMemories()` function implements this filtering logic:\n- **All thinking**: Save all assistant thinking blocks (even single-line) - prefixed with '[Thinking]' in subject\n- **Content**: Only save multiline assistant content (2+ non-empty lines)\n- **User messages**: Never saved\n\nThis is implemented in `src/utils/transcript.ts:294-342` using `message.thinking?.trim()` check and `lines.length >= 2` filter.","timestamp":"2025-12-21T19:27:11.414Z"}
{"action":"add","id":"66acc2a6-ec8f-4254-868c-0e738a4836a7","subject":"Hooks execute but return empty stdout - breaks memory injection for users","keywords":["hooks","empty stdout","SessionStart","UserPromptSubmit","bug","memory injection"],"applies_to":"global","occurred_at":"2025-12-21T18:59:30.332Z","content_hash":"c2e8d4f584714624","content":"## Problem\n\nHooks are executing successfully but returning empty stdout, preventing memory content from being injected into Claude's context during sessions.\n\n## Root Cause\n\nThe hooks are being invoked by Claude Code but not outputting the memory content to stdout. This is likely because:\n1. Memory retrieval logic exists but isn't being called\n2. Output isn't being written to stdout properly\n3. Async operations may not be awaited before process exits\n\n## Impact\n\nUsers configure hooks and see no errors, but memories don't appear in context. This creates a broken user experience where the system appears to work but provides no actual functionality.\n\n## Solution Path\n\nInvestigate:\n1. `src/hooks/session-start.ts` - Check if it's actually retrieving and outputting memories\n2. `src/hooks/user-prompt-submit.ts` - Verify semantic search results are being output\n3. Hook configuration in `.claude/settings.json` - Ensure paths and commands are correct\n4. Add logging to see what's happening in hook execution\n\n## Testing\n\nManually invoke hooks with test input to verify they output memory content to stdout before users set them up.","timestamp":"2025-12-21T19:27:11.415Z"}
{"action":"add","id":"e0f01cfb-d531-4b47-8abc-5110efacfdf7","subject":"Test validation expectations need updating when transcript parsing behavior changes","keywords":["testing","transcript validation","error handling","backward compatibility"],"applies_to":"file:tests/unit/utils/transcript.test.ts","occurred_at":"2025-12-21T18:29:39.576Z","content_hash":"ef04acac0ac24a49","content":"When updating transcript parsing to be more lenient (silently skip invalid messages instead of throwing):\n\n- Old tests expecting `ValidationError` for invalid roles need to be updated\n- New behavior: invalid messages are silently skipped from parsed results\n- Better approach: test that valid messages are retained while invalid ones are filtered out\n- Don't test for thrown errors on invalid input; instead verify they don't appear in parsed output\n\nThis change makes the parser more robust for real-world transcripts that may have edge cases.","timestamp":"2025-12-21T19:27:11.415Z"}
{"action":"add","id":"9c0ee30d-052a-4783-af65-bce936230562","subject":"Memory extraction happens in stop hook via transcript analysis","keywords":["hooks","stop","transcript","memory extraction","claude code"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:01:46.971Z","content_hash":"12910b58ddc316f7","content":"The memory extraction process happens in the stop hook (`src/hooks/stop.ts`) which:\n1. Receives transcript data when a Claude Code session ends\n2. Parses the transcript using utilities from `src/utils/transcript.ts`\n3. Calls `analyzeForMemories()` to extract memories from the transcript\n4. Saves memories to the local-recall system\n\nThe stop hook is triggered by Claude Code at the end of each session and is responsible for persisting conversation insights into the memory system.","timestamp":"2025-12-21T19:27:11.416Z"}
{"action":"add","id":"45bc6bac-a9ae-4db5-a2f4-e066d6881ad5","subject":"Comprehensive test suite for transcript-condenser covers all entry types and edge cases","keywords":["testing","transcript condenser tests","unit tests","edge cases","test coverage"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-21T19:26:56.552Z","content_hash":"dba65dd59f44aa2f","content":"Created `transcript-condenser.test.ts` with extensive test coverage:\n\n**Test categories**:\n1. **Entry type condensing**: Tests for each TranscriptEntry type (user, assistant, system, file-history, queue-operation)\n2. **Content block handling**: Tests for text, tool-use, and tool-result content types\n3. **Edge cases**: Empty content, null values, truncation of long outputs\n4. **Filtering**: Tests for filtering out internal prompts and irrelevant events\n5. **Metadata preservation**: Ensures important metadata is retained in condensed format\n\n**Coverage**: Tests verify that condensing preserves semantic meaning while eliminating noise, ensuring memories extracted from condensed transcripts remain accurate and valuable.\n\nAll tests pass, confirming the condenser works correctly across various transcript scenarios.","timestamp":"2025-12-21T19:27:11.417Z"}
{"action":"add","id":"8c563c94-3761-40ad-9142-c8b59b0b290e","subject":"Configuration uses maxMemories limit with no active pruning","keywords":["config","max-memories","memory-limit","configuration"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T18:20:14.815Z","content_hash":"b212b0f06d32c5da","content":"The configuration system (src/utils/config.ts) defines a `maxMemories` setting (default appears to be around 1000 based on CLAUDE.md). However, this limit is currently NOT actively enforced - there is no automatic pruning or cleanup when the limit is reached. The configuration value exists but is not actively used to constrain memory growth.","timestamp":"2025-12-21T19:27:11.419Z"}
{"action":"add","id":"23df790a-c3a8-4670-b5b8-bad2b2fca0e8","subject":"Transcript collector cleanup strategy prevents synthetic transcript accumulation","keywords":["cleanup","synthetic files","transcript management","local folder","cache sync"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:28:20.994Z","content_hash":"a7b4c5c2e13fe13b","content":"## Two-Layer Synthetic Filtering Strategy\n\nThe transcript collector uses a two-layer approach to prevent synthetic transcripts from accumulating:\n\n1. **Pre-copy filtering**: The new check in `syncTranscripts()` prevents synthetic transcripts from being copied from Claude's cache in the first place\n2. **Fallback cleanup**: `cleanupTranscripts()` still runs to remove any synthetic files that might exist in the local folder from previous runs\n\nThis defensive approach ensures synthetic transcripts never accumulate locally, even if the pre-copy filter somehow fails to catch them.\n\n### Implementation Detail\nThe cleanup runs at the start of every sync cycle, so it acts as a safety net for any synthetic transcripts that slipped through previously or were added manually.","timestamp":"2025-12-21T19:27:11.420Z"}
{"action":"add","id":"66f40282-d50b-4153-8695-4e37cfe0b026","subject":"Memory creation requires transcript parsing and conversation analysis","keywords":["memory extraction","transcript parsing","conversation analysis","stop hook","memory creation"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:02:06.379Z","content_hash":"edb00a23ada4dc2b","content":"# Memory Creation Process\n\nMemories are created by:\n1. Reading the transcript file from the hook input\n2. Parsing conversation events using `src/utils/transcript.ts`\n3. Analyzing user/assistant exchanges for extractable memories\n4. Creating memory files with YAML frontmatter and markdown content\n\nThe Stop hook (`src/hooks/stop.ts`) implements this process at lines 77-108:\n- Validates the prompt contains `[LOCAL_RECALL_INTERNAL]` marker\n- Reads and parses the transcript\n- Calls memory extraction logic\n- Returns created memories\n\nThis process is independent of the vector store - it creates markdown files that are later indexed.","timestamp":"2025-12-21T19:27:11.422Z"}
{"action":"add","id":"1046a8bb-a8fb-4ce9-8ce7-a61aa65c9e86","subject":"Plugin version is managed in two locations that must be kept in sync","keywords":["version bump","plugin version","package.json","plugin.json","sync"],"applies_to":"global","occurred_at":"2025-12-21T18:26:58.164Z","content_hash":"956a73e18c93c990","content":"The plugin version must be updated in two files:\n1. `package.json` - Main package version\n2. `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` - Claude plugin manifest\n\nBoth must be kept in sync when releasing new versions. Latest version: 0.1.2","timestamp":"2025-12-21T19:27:11.422Z"}
{"action":"add","id":"ab2d80c9-73c7-46f3-b3b3-7ddc79a5ff31","subject":"Claude project discovery uses path-to-dashes naming convention in ~/.claude/projects","keywords":["claude projects","path convention","project discovery","transcript location","dashes naming"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:18:58.237Z","content_hash":"08f2bbeaedb3f587","content":"Claude stores projects in ~/.claude/projects using a path-to-dashes naming convention. For example, `/Users/joe/Code/Syntessera/local-recall` becomes `-Users-joe-Code-Syntessera-local-recall`. The `findClaudeProjectDir` function should:\n\n1. Convert the current working directory path to this format (replacing `/` with `-`)\n2. Check for the folder in ~/.claude/projects\n3. Look for transcripts directly in the project folder, NOT in a `transcripts` subfolder\n\nThis is the primary method - fallback scanning should only occur if the main lookup fails. The actual folder structure shows `.jsonl` files are stored directly in the project directory.","timestamp":"2025-12-21T19:27:11.423Z"}
{"action":"add","id":"8ba86f29-6e9f-4c7d-a5d3-bce8d5549b02","subject":"MCP server is running from dev-marketplace plugin subdirectory","keywords":["mcp","server","plugin","configuration","dev-marketplace"],"applies_to":"global","occurred_at":"2025-12-21T19:22:34.972Z","content_hash":"a9e27cdf2f1a148f","content":"The MCP server (PID 4524) is currently running from:\n- Location: `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js`\n- Config: `dev-marketplace/local-recall-plugin/.mcp.json`\n\nThis is a plugin subdirectory structure, not the main project root. The main project root doesn't have a compiled `scripts/` directory yet.","timestamp":"2025-12-21T19:27:11.424Z"}
{"action":"add","id":"96b4908c-80d5-41fe-ab49-03c21534aa88","subject":"Stop hook parses transcripts to extract and store memories automatically","keywords":["hooks","stop-hook","transcript-parsing","memory-extraction"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"ecf9d1a4aa97c62d","content":"The Stop hook executes when a Claude Code session ends. It parses the transcript JSON to extract valuable memories and stores them. The system uses configurable keyword extraction from the transcript content to identify key information for storage.","timestamp":"2025-12-21T19:27:11.425Z"}
{"action":"add","id":"ba713ae5-e4e9-4490-91cc-53a558901af8","subject":".gitignore file ignores Orama indexes and recall.log in local-recall folder","keywords":["gitignore","orama","index","logging","version-control"],"applies_to":"file:src/core/index.ts","occurred_at":"2025-12-21T19:01:06.461Z","content_hash":"e76186a4212c78bc","content":"The `.gitignore` file created in the `local-recall/` directory should contain entries to ignore:\n- `orama-*-index.json` - Auto-generated vector indexes (episodic and thinking)\n- `recall.log` - Debug log file\n\nThese files are auto-generated at runtime and should not be committed to version control. The `.gitignore` is created automatically by `ensureGitignore()` which is called every session start.\n\n**Context**: Memory files themselves (in `local-recall/episodic-memory/` and `local-recall/thinking-memory/`) ARE version-controlled and should not be ignored.","timestamp":"2025-12-21T19:27:11.425Z"}
{"action":"add","id":"0c567112-4b7f-40d5-96ba-8596c764e969","subject":"Filter transcripts to only copy those containing thinking blocks","keywords":["transcript-collector","thinking","haiku","filtering","sync","transcript-sync"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-03T09:47:11.434Z","content_hash":"c413c4f8384f46b2","content":"## Problem\nThe transcript collector was copying all transcripts including Haiku transcripts (which don't contain thinking blocks). This was cluttering the transcript cache with transcripts that don't contribute to thinking memory extraction.\n\n## Solution\nAdded filtering logic to the TranscriptCollector:\n\n1. **New method `hasThinkingBlocks()`** - Checks if a transcript contains thinking blocks by searching for `\"type\":\"thinking\"` in the JSON content. Returns boolean.\n\n2. **Updated `syncTranscripts()`** - Modified to skip copying transcripts that don't contain thinking blocks, logging debug info when skipping.\n\n3. **Updated `cleanupTranscripts()`** - Removes existing transcripts that don't contain thinking blocks from the transcript cache.\n\n## Implementation Details\n- The thinking check looks for content blocks with `type: \"thinking\"` in the transcript JSON structure\n- Both sync and cleanup methods use the same `hasThinkingBlocks()` check for consistency\n- This prevents Haiku-only transcripts (which have no thinking capability) from being copied or retained\n\n## Impact\n- Reduces transcript cache size by excluding haiku transcripts\n- Improves efficiency of thinking memory extraction by only processing relevant transcripts\n- Maintains cleaner transcript history focused on thinking-capable models","timestamp":"2025-12-21T19:27:11.426Z"}
{"action":"add","id":"7a6839c5-77ee-414c-aeef-750e38fc5ded","subject":"MCP servers must be explicitly configured in .claude/settings.json","keywords":["mcp","configuration","settings","github mcp","tools"],"applies_to":"global","occurred_at":"2025-12-21T19:26:45.176Z","content_hash":"3fe7d1c8ee716779","content":"MCP servers are not automatically available to Claude Code. They must be explicitly configured in the project's `.claude/settings.json` file under the `mcpServers` section. Without configuration, MCP tools cannot be accessed even if the server is available on the system.","timestamp":"2025-12-21T19:27:11.427Z"}
{"action":"add","id":"831f317b-69e1-4a88-b213-50ed690a019f","subject":"Episodic memory processing is disabled by default and requires LOCAL_RECALL_EPISODIC_ENABLED environment variable","keywords":["episodic memory","environment variable","configuration","LOCAL_RECALL_EPISODIC_ENABLED","mcp server"],"applies_to":"global","occurred_at":"2025-12-21T18:30:50.594Z","content_hash":"0fc9e6da0a7421dd","content":"Episodic memory processing in the MCP server is controlled by the `LOCAL_RECALL_EPISODIC_ENABLED` environment variable. It defaults to `false` in the configuration. To enable episodic memory processing, add `LOCAL_RECALL_EPISODIC_ENABLED=true` to the `env` section of the MCP server configuration in `.claude/settings.json` or `.claude/settings.local.json`. The config is defined in `src/utils/config.ts` and read by `src/mcp-server/server.ts` which uses it to control the background daemon's `runMemoryExtraction` behavior.","timestamp":"2025-12-21T19:27:11.428Z"}
{"action":"add","id":"489286c3-8b51-48b5-a857-f87a4cd5a039","subject":"Transcript condenser optimizes memory extraction by parsing JSONL and extracting minimal content","keywords":["transcript-condenser","memory-extraction","token-optimization","jsonl-parsing","prompt-building"],"applies_to":"global","occurred_at":"2025-12-21T18:30:38.769Z","content_hash":"0afbc4871c5080c9","content":"Implemented a transcript condenser module (`src/core/transcript-condenser.ts`) that significantly reduces token usage for memory extraction. The condenser:\n\n1. **Parses JSONL transcripts** using TypeScript types defined in `src/types/transcript-schema.ts`\n2. **Extracts only essential content** from each transcript entry:\n   - User messages: subject + key points\n   - Assistant messages: concise explanation\n   - Tool invocations: tool name + brief outcome\n   - Results: only errors/key findings\n3. **Eliminates wasteful content**: full file contents, complete bash outputs, verbose thinking blocks\n4. **Creates condensed structured format** that's passed to the memory extractor\n5. **Significantly reduces token usage** for the extraction prompt\n\nThis is a critical optimization for the memory extraction pipeline, especially when processing large transcripts with extensive file reads, tool outputs, and thinking blocks.","timestamp":"2025-12-21T19:27:11.429Z"}
{"action":"add","id":"59fa6840-be92-4b72-bb6c-9fd21fd93d80","subject":"Thinking memories store thought+output pairs from Claude's reasoning blocks","keywords":["thinking-memory","reasoning","extraction","thought-output-pair","precedent"],"applies_to":"area:thinking-memories","occurred_at":"2025-12-21T18:23:54.705Z","content_hash":"577af6b7fae5b0c2","content":"Thinking memories capture Claude's internal reasoning paired with its text response, providing \"how I thought → what I produced\" precedents:\n\n- Format: Two sections in one markdown file - `## Thought` and `## Output`\n- Extraction: Daemon pulls thinking blocks from transcripts along with corresponding text outputs\n- Tool-only responses are skipped (no thinking block needed)\n- Storage: Each thought+output pair = 1 thinking memory file\n- Retrieval: Semantic search returns relevant thinking memories with similarity scores\n- Injection: Context shows previous thoughts as examples for similar tasks\n- Reset: Delete `thinking-processed-log.jsonl`, `orama-thinking-index.json`, and `thinking-memory/` directory to reprocess","timestamp":"2025-12-21T19:27:11.429Z"}
{"action":"add","id":"64001c89-c1da-49c7-a9ed-24b83c2c37df","subject":"Ollama generates embeddings using nomic-embed-text model","keywords":["ollama","embeddings","nomic-embed-text","768-dimensions"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"047c6aa2c32824f6","content":"Vector embeddings are generated via Ollama with the 'nomic-embed-text' model producing 768-dimensional vectors. Ollama must be installed and running (ollama serve). The OLLAMA_BASE_URL defaults to http://localhost:11434. When migrating from fastembed (384 dimensions), vector indexes must be deleted and rebuilt.","timestamp":"2025-12-21T19:27:11.430Z"}
{"action":"add","id":"82cdf0b8-168c-4ff9-afde-73f80c04aff7","subject":"MCP server daemon runs on startup with automatic intervals","keywords":["mcp server","daemon","startup","intervals","vector sync","transcript processing"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:26:25.094Z","content_hash":"763ea991ba7d8e29","content":"The MCP server daemon automatically starts processing on server startup:\n\n- **Vector sync**: Runs 2 seconds after server start, then repeats every 10 minutes\n- **Transcript processing**: Runs 5 seconds after server start, then repeats every 5 minutes\n\nBoth are triggered via `setTimeout()` initially and `setInterval()` for recurring execution (lines 169-193 in server.ts). This ensures the daemon is active without requiring manual triggering.","timestamp":"2025-12-21T19:27:11.431Z"}
{"action":"add","id":"1c4bc86a-002c-4725-97f7-f490bce3622b","subject":"Plugin configuration in dev-marketplace for local development","keywords":["plugin-configuration","development-setup","hooks-config","mcp-config"],"applies_to":"file:dev-marketplace/local-recall-plugin/config/hooks.json","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"c686b631cfee55b4","content":"The local-recall plugin includes configuration files for development:\n- `dev-marketplace/local-recall-plugin/config/hooks.json` - Defines hook configurations (SessionStart, Stop)\n- `dev-marketplace/local-recall-plugin/.mcp.json` - MCP server configuration\n\nThese files define how the plugin integrates with Claude Code when installed in development mode. The configuration specifies which hooks are active and how the MCP server is exposed, allowing testing of the memory system before distribution.","timestamp":"2025-12-21T19:27:11.431Z"}
{"action":"add","id":"b80874bb-f776-49b6-b719-bb3389ef0c98","subject":"Configuration system uses getConfig() function to access parsed config values","keywords":["config","getConfig","loadConfig","environment variables","configuration parsing"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T19:21:34.993Z","content_hash":"7296359aa72f5378","content":"The local-recall configuration system has two functions:\n\n1. `loadConfig(baseDir)` - Loads and parses configuration from environment variables and `.local-recall.json` file\n2. `getConfig()` - Returns the currently loaded configuration object\n\nHooks and other modules import `getConfig` to access configuration values after the config has been loaded. This pattern is used across multiple files:\n- `src/hooks/user-prompt-submit.ts`\n- `src/hooks/user-prompt-submit-thinking.ts`\n- `src/hooks/session-start.ts`\n- `src/mcp-server/server.ts`\n\nThe config object contains both episodic and thinking memory settings (enabled flags, max tokens, similarity thresholds).","timestamp":"2025-12-21T19:27:11.434Z"}
{"action":"add","id":"e5980567-41ac-4ca3-aca5-cd2525ced470","subject":"Memory storage migrated from markdown to JSONL format for episodic and thinking memories","keywords":["storage-format","jsonl","markdown","migration","episodic-memory","thinking-memory"],"applies_to":"global","occurred_at":"2025-12-21T18:22:39.533Z","content_hash":"a0ab00ee7e4b5e73","content":"Recent migration changed how memories are stored:\n\n**Episodic Memories**: Still stored as individual `.md` files in `local-recall/episodic-memory/` with YAML frontmatter and markdown content.\n\n**Thinking Memories**: Migrated to JSONL format in `thinking-processed-log.jsonl` (not individual files).\n\n**Processed Logs**: Both have JSONL processed logs:\n- `episodic-processed-log.jsonl` - Tracks which transcripts have been processed for episodic extraction\n- `thinking-processed-log.jsonl` - Tracks which transcripts have been processed for thinking extraction\n\n**Key files**:\n- `src/core/episodic-jsonl-store.ts` - Manages episodic processed log\n- `src/core/thinking-jsonl-store.ts` - Manages thinking processed log\n- `src/core/thinking-memory.ts` - CRUD for thinking memories (stored in JSONL)\n\n**Migration details**:\n- Thinking memories are now appended to a single JSONL file rather than individual markdown files\n- Each line is a valid JSON object representing one thinking memory\n- Episodic memories remain as individual markdown files for git version control\n\n**Important**: The thinking memory storage uses append-only JSONL, which means concurrent writes can corrupt the file. This is part of the broader concurrency issue affecting the project.","timestamp":"2025-12-21T19:27:11.435Z"}
{"action":"add","id":"b34ecb27-c3b4-4e18-a093-5277b76c22f7","subject":"Multiple local-recall instances in same folder have concurrent write conflicts","keywords":["concurrency","multi-instance","orama-index","processed-log","file-locking"],"applies_to":"global","occurred_at":"2025-12-21T18:23:54.705Z","content_hash":"c2b183a9c364edfd","content":"When multiple Claude Code instances run local-recall on the same codebase folder, they cause concurrent write conflicts:\n\n- `orama-episodic-index.json` and `orama-thinking-index.json`: Multiple processes write without locking, corrupting JSON\n- `local-recall/thinking-processed-log.jsonl` and `local-recall/episodic-processed-log.jsonl`: Concurrent appends cause corruption\n- `local-recall/thinking-memory/` and `local-recall/episodic-memory/`: File creations race and overwrite\n\nSolution: Implement file-based locking (e.g., `proper-lockfile` or `fs.promises.open` with exclusive flags) before write operations. Need to handle:\n1. Lock acquisition with timeout\n2. Graceful degradation if lock fails\n3. Cleanup of stale locks\n4. Atomic writes to prevent partial file corruption","timestamp":"2025-12-21T19:27:11.436Z"}
{"action":"add","id":"3bcd56da-ae53-4971-acf3-045cc042e4c0","subject":"Memory extraction field name normalization for Claude Haiku responses","keywords":["memory-extractor","claude-haiku","field-normalization","zod-validation","parsing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:19:47.354Z","content_hash":"f1a6ab5587f30417","content":"Claude Haiku sometimes returns memory objects with alternative field names instead of the expected `subject`, `keywords`, `applies_to`, `content`. Added field name normalization in the `parseClaudeResponse` function (lines 179-186) to map common variations:\n\n- `title` → `subject`\n- `summary` → `subject`\n- `description` → `content`\n- `scope` → `applies_to`\n- `tags` → `keywords`\n\nThis normalization happens before Zod validation, preventing validation errors when Claude uses slightly different field naming conventions.","timestamp":"2025-12-21T19:27:11.437Z"}
{"action":"add","id":"b2c1cf39-ae61-4f4a-8a9a-9e8b014bb96a","subject":"MCP tool descriptions should include usage guidance","keywords":["mcp","tools","descriptions","documentation","discoverability"],"applies_to":"area:mcp-server","occurred_at":"2025-12-21T19:24:22.148Z","content_hash":"e89877e719df3437","content":"MCP tool descriptions have been improved to include usage guidance. This makes the tools more discoverable and usable in Claude Code. Tool descriptions should clearly explain what each tool does and provide examples of when to use it, not just technical specifications.","timestamp":"2025-12-21T19:27:11.438Z"}
{"action":"add","id":"5eb5b0d1-54aa-401a-8f63-8637820f0021","subject":"Local Recall uses JSONL format for episodic and thinking memory logs","keywords":["storage format","jsonl","episodic","thinking memory","file format"],"applies_to":"global","occurred_at":"2025-12-21T19:11:52.152Z","content_hash":"074b3e58647bc977","content":"Local Recall stores memories in JSONL (JSON Lines) format with files like `episodic-000001.jsonl` and `thinking-000001.jsonl` in addition to individual markdown files in `episodic-memory/` and `thinking-memory/` directories. The JSONL files appear to use 6-digit padding for sequencing. This format allows for efficient appending of new memories while maintaining backward compatibility with the markdown-based storage system.","timestamp":"2025-12-21T19:27:11.439Z"}
{"action":"add","id":"ea8218a9-7ed2-4ec9-9110-2dc86449f1e8","subject":"JSONL format stores processed transcripts with content hashes for deduplication","keywords":["jsonl","processed-log","content-hash","deduplication","transcript-tracking"],"applies_to":"file:src/core/processed-log.ts","occurred_at":"2025-12-21T18:23:54.705Z","content_hash":"3502497f53cf36db","content":"The processed-log.jsonl files track which transcripts have been processed to enable idempotent memory extraction:\n\n- Each entry: `{\"path\": \"...\", \"contentHash\": \"sha256-prefix\", \"processedAt\": \"iso-timestamp\"}`\n- Content hash is SHA-256 prefix (16 chars) to detect when transcripts change\n- When transcript content changes, old memories are deleted and new ones created\n- Files can have millions of entries, requiring streaming/line-by-line reads\n- JSONL format chosen over SQLite for version-control compatibility and simple line-based appends","timestamp":"2025-12-21T19:27:11.440Z"}
{"action":"add","id":"4b04adb5-b91b-459c-b782-897863cd7f0d","subject":"Thinking memory injection was added to UserPromptSubmit hook","keywords":["thinking memories","previous thoughts","context injection","user prompt submit hook"],"applies_to":"global","occurred_at":"2025-12-21T18:27:35.712Z","content_hash":"83d63a54c30b4224","content":"Thinking memories are injected into Claude's context when a user submits a prompt via a separate thinking memory hook. The injection appears under a heading **\"Local Recall: Previous Thoughts\"** and includes:\n\n- 5 thinking excerpts from previous sessions (configurable)\n- Each excerpt shows: thought + output pair with similarity percentage\n- Similarity scores around 67% were typical in testing\n- Works independently from episodic memories\n- Can be toggled with `LOCAL_RECALL_THINKING_ENABLED` environment variable","timestamp":"2025-12-21T19:27:11.441Z"}
{"action":"add","id":"2e4f8d10-497f-40e2-9b15-4ef01a407bdc","subject":"Thinking memory index achieves 67% similarity in context injection","keywords":["thinking memory","search quality","context injection","similarity threshold","relevance"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-03T09:48:34.346Z","content_hash":"f236320cff45acd5","content":"Observed that thinking memory search was successfully injecting relevant excerpts with 67% similarity threshold. Multiple excerpts about memory list updates and memory-worthy content detection were correctly identified and injected into Claude's context under 'Local Recall: Previous Thoughts' heading.\n\nThis indicates the thinking memory vector search is functioning effectively at capturing conceptually-related thoughts from previous sessions, even though the similarity scores are not extremely high. Consider this baseline when tuning thinking memory similarity thresholds.","timestamp":"2025-12-21T19:27:11.443Z"}
{"action":"add","id":"6aa42c1f-71e0-4316-8cab-57cc0a5ee535","subject":"Hooks check configuration flags to control memory injection and extraction","keywords":["hooks","user-prompt-submit","session-start","configuration checks","conditional logic"],"applies_to":"global","occurred_at":"2025-12-21T19:21:42.416Z","content_hash":"cc8ec04218582fe0","content":"The following hooks were updated to respect the new environment flags:\n\n1. `user-prompt-submit.ts` - Checks `episodicEnabled` before searching/injecting episodic memories\n2. `user-prompt-submit-thinking.ts` - Checks `thinkingEnabled` before searching/injecting thinking memories\n3. `session-start.ts` - Checks `episodicEnabled` before loading recent memories on session initialization\n4. MCP server `server.ts` - Checks both flags before enabling extraction/processing in background daemon\n\nThis allows fine-grained control over which memory systems are active without modifying code.","timestamp":"2025-12-21T19:27:11.444Z"}
{"action":"add","id":"e557c2c4-2809-4e51-a7a5-47eb2a1ff8cf","subject":"Memory extraction prompt and test structure in place","keywords":["memory-extractor","prompts","testing","callClaudeCLI","stripMarkdownCodeBlocks"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:15:07.227Z","content_hash":"fb83d7d598674787","content":"# Memory Extractor Architecture\n\n## Key Components\n\n1. **Memory Extraction Prompt** (`src/prompts/memory-extraction.ts`)\n   - Detailed prompt template for extracting structured memories from transcripts\n   - Outputs JSON with memory objects containing subject, keywords, applies_to, content fields\n\n2. **callClaudeCLI Method** (`src/core/memory-extractor.ts:75-128`)\n   - Invokes Claude via CLI to process transcripts\n   - Handles markdown code block responses with `stripMarkdownCodeBlocks` utility\n   - Previously had no explicit model specification (defaulted to claude-3-5-sonnet)\n\n3. **Test Coverage** (`tests/unit/core/memory-extractor.test.ts`)\n   - 32 unit tests covering various extraction scenarios\n   - Tests verify memory structure, keyword extraction, scope detection\n   - All tests pass with Haiku implementation\n\n## Configuration\n\nMemory extraction is part of the MCP server daemon which processes transcripts asynchronously every 5 minutes. This is a high-frequency operation making model choice (Haiku vs Sonnet) significant for cost and performance.","timestamp":"2025-12-21T19:27:11.445Z"}
{"action":"add","id":"82393716-fd82-4216-a25c-841c20e28879","subject":"SQLite database mutex lock errors from concurrent hook access - both episodic and thinking hooks try to access same database","keywords":["sqlite","mutex","concurrency","thinking-vector-store","race-condition","hooks","user-prompt-submit"],"applies_to":"global","occurred_at":"2025-12-21T19:23:44.640Z","content_hash":"4f812fd46dce5886","content":"Both `user-prompt-submit.js` (episodic) and `user-prompt-submit-thinking.js` (thinking) hooks fire simultaneously and try to access the same SQLite database file. This creates a race condition where concurrent access causes the sqlite-vec native extension's mutex to fail with: `libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument`\n\nRoot cause: Two separate hook processes opening the same `memory.sqlite` file concurrently. The native C++ layer cannot handle this concurrent access pattern.\n\nSolution: Keep hooks read-only and move all write operations to the background daemon which has exclusive control.","timestamp":"2025-12-21T19:27:11.446Z"}
{"action":"add","id":"692ae223-0944-4677-abcb-de13278e3ce4","subject":"Message interleaving pattern (thinking → tool_use → thinking) is across different message IDs","keywords":["message structure","interleaving","tool use","transcript structure"],"applies_to":"global","occurred_at":"2025-12-21T18:29:32.427Z","content_hash":"1a27a92823a681af","content":"Patterns like 'thinking → tool_use → thinking → assistant message' are not interleaved within a single message, but rather separate messages in the transcript stream. Each unique message ID has its own thinking/text parts array. This is important for correctly understanding transcript structure and message boundaries.","timestamp":"2025-12-21T19:27:11.447Z"}
{"action":"add","id":"08c917a9-b172-4250-83c4-9b214b8aba04","subject":"Memory extraction prompt refactored for condensed transcripts","keywords":["memory-extraction prompt","condensed format","prompt engineering"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:30:37.940Z","content_hash":"4875ee66b8f74f75","content":"Updated buildMemoryExtractionPrompt() in src/prompts/memory-extraction.ts to work with condensed transcript data instead of raw JSONL. The prompt now:\n\n1. Receives structured CondensedTranscriptEntry objects instead of raw transcript lines\n2. Has clearer context about what was done (tool invocations, results, decisions)\n3. Focuses extraction on actionable insights from condensed content\n4. Maintains full memory extraction guidelines while working with optimized input\n\nThis change maintains extraction quality while dramatically reducing token consumption per transcript.","timestamp":"2025-12-21T19:27:11.448Z"}
{"action":"add","id":"920100e4-69a6-4c10-b793-cea3e91bb0ff","subject":"Thinking memory injection shows similarity scores and occurrence dates","keywords":["thinking memory","context injection","similarity scores","user experience","previous thoughts"],"applies_to":"global","occurred_at":"2025-12-21T18:27:36.139Z","content_hash":"e3b277f49fcba223","content":"When thinking memories are retrieved during a session, they are injected into context under the heading **\"Local Recall: Previous Thoughts\"** with metadata including:\n\n- The thinking content (what Claude was reasoning about)\n- The output content (what Claude produced)\n- Similarity score (as a percentage, e.g., 67%)\n- Occurrence timestamp\n- Memory ID and scope\n\nThis provides concrete examples of \"how I reasoned → what I produced\" for similar tasks from previous sessions, helping maintain consistency in reasoning patterns across sessions.","timestamp":"2025-12-21T19:27:11.448Z"}
{"action":"add","id":"daed3738-1a76-44ee-92f2-be7dcc2a8f12","subject":"Hooks are the primary integration point between Local Recall and Claude Code","keywords":["hooks","integration","claude code","session-start","user-prompt-submit","stop"],"applies_to":"global","occurred_at":"2025-12-21T19:18:04.336Z","content_hash":"5efdd097a6805651","content":"Local Recall provides three hooks that integrate with Claude Code:\n\n1. **SessionStart Hook** (`src/hooks/session-start.ts`) - Triggered when a Claude Code session begins. Loads the memory index and outputs relevant memories to stdout for context injection.\n\n2. **UserPromptSubmit Hook** (`src/hooks/user-prompt-submit.ts`) - Triggered before Claude processes a user prompt. Searches memory index and injects relevant memories based on semantic similarity.\n\n3. **Stop Hook** (`src/hooks/stop.ts`) - Triggered when a session ends. Parses transcript and extracts new memories to persist for future sessions.\n\nHooks communicate via JSON stdin/stdout and are configured in `.claude/settings.json`.","timestamp":"2025-12-21T19:27:11.450Z"}
{"action":"add","id":"47ab8ed6-2310-4d4b-9b63-512b6ef7493f","subject":"Hook processes in Claude Code run independently and concurrently without shared state","keywords":["hooks","claude-code","processes","concurrent","architecture"],"applies_to":"global","occurred_at":"2025-12-21T18:58:59.192Z","content_hash":"584cf4620bb7ecc9","content":"SessionStart and UserPromptSubmit hooks run as independent shell command processes triggered by Claude Code events. These processes cannot share state and must use stateless approaches (like reading index files) rather than in-memory state or mutexes. This means each hook invocation loads the vector index from disk independently, which Orama supports efficiently.","timestamp":"2025-12-21T19:27:11.452Z"}
{"action":"add","id":"eca22387-4489-4b81-99c3-790175568bc3","subject":"File-based locking pattern for concurrent native module access","keywords":["locking","proper-lockfile","embedding","concurrency","native modules"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T18:27:48.823Z","content_hash":"90a6d70570c6b8fb","content":"Implemented file-based locking using proper-lockfile package to protect both EmbeddingService initialization and embedding operations. This prevents concurrent access to onnxruntime-node which has non-thread-safe native bindings.\n\nImplementation:\n- Lock path: `/tmp/local-recall-embedding.lock`\n- Retries: 10 with exponential backoff\n- Stale lock timeout: 30 seconds\n- Locks both `initialize()` and `embed()` methods\n- Logs 'Acquired embedding lock' and 'Released embedding lock' for debugging","timestamp":"2025-12-21T19:27:11.453Z"}
{"action":"add","id":"6c9e8a32-469d-42fe-b0c1-c2d931fc9957","subject":"Multiple Claude Code instances may use cached or stale MCP server versions","keywords":["multiple instances","mcp server","plugin cache","stale code","timestamp"],"applies_to":"global","occurred_at":"2025-12-21T19:26:25.094Z","content_hash":"8c45b575c4b7f8ec","content":"When multiple Claude Code instances run against different projects:\n\n1. Each instance should have its own MCP server process\n2. If instances are using the plugin marketplace version, they may be cached\n3. Old MCP server processes can continue running after updates, causing duplicate log entries\n4. The plugin cache is stored at `~/.claude/plugins/cache/local-recall-marketplace/local-recall/VERSION/scripts/mcp-server/server.js`\n\n**To update**: Either copy the new server.js to the cache or reinstall the plugin and restart Claude Code instances.","timestamp":"2025-12-21T19:27:11.453Z"}
{"action":"add","id":"8f151486-b4a2-4574-81da-96274eb2c341","subject":"Thinking blocks in transcripts are identified by type field in content","keywords":["thinking-blocks","transcript-structure","json-content","type-field"],"applies_to":"global","occurred_at":"2025-12-03T09:47:11.434Z","content_hash":"0a1527729484be0e","content":"## Discovery\nWhen analyzing transcripts to filter for thinking content, thinking blocks in Claude transcripts are structured as JSON content blocks with a `\"type\":\"thinking\"` field.\n\n## Details\n- Transcripts contain content arrays with multiple blocks\n- Each block is a JSON object with properties including `type`\n- Thinking blocks specifically have `type: \"thinking\"`\n- This is consistent with how the thinking-extractor.ts identifies and processes thinking blocks\n- Non-thinking transcripts (like Haiku models) will have no blocks with `type: \"thinking\"`\n\n## Usage\nThis pattern is used throughout the codebase to:\n- Identify whether a transcript contains thinking\n- Extract thinking blocks from transcripts\n- Filter transcripts during sync and cleanup operations","timestamp":"2025-12-21T19:27:11.454Z"}
{"action":"add","id":"aa90e281-e89c-412e-b164-870a7c44f7dc","subject":"User-prompt-submit hook spawns Claude process to extract keywords from text","keywords":["user-prompt-submit hook","callClaudeForKeywords","keyword extraction","claude subprocess","transcript processing"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:21:11.638Z","content_hash":"5479916e690c6bc9","content":"# Keyword Extraction via Claude Subprocess\n\n## Pattern\nThe user-prompt-submit hook uses a helper function `callClaudeForKeywords` that spawns a separate Claude process to extract keywords from text. This is used in the memory extraction workflow.\n\n## Key Details\n- Function spawns a child process using Node.js `spawn` API\n- Sends a system prompt and text via stdin to the Claude process\n- Receives JSON response with extracted keywords via stdout\n- The function needs robust error handling and timeout management\n- Multiple concurrent spawns can occur, requiring proper process lifecycle management","timestamp":"2025-12-21T19:27:11.454Z"}
{"action":"add","id":"f2967b43-d9a1-4f4f-8485-3e000f76b845","subject":"MCP daemon no longer starts HTTP server, uses pure MCP protocol","keywords":["mcp-server","daemon","http-server","architecture"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"bbae7f5e8911c223","content":"Removed HTTP server startup from the MCP daemon:\n\n- Deleted `startHttpServer()` call from daemon initialization\n- MCP server continues to provide tools via standard MCP protocol\n- Hooks no longer communicate with daemon via HTTP\n- All inter-process communication uses file-based locking at the database level\n\nThe MCP server still processes transcripts asynchronously every 5 minutes using the same VectorStore/ThinkingVectorStore with file-based locking.","timestamp":"2025-12-21T19:27:11.455Z"}
{"action":"add","id":"cfbefc5f-fe7c-497a-a6d0-69e2d47d3d2a","subject":"Internal prompts marked with [LOCAL_RECALL_INTERNAL] skip hook processing","keywords":["hooks","internal-prompts","memory-extraction","skip-detection"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"96c8f70d83125149","content":"The `user-prompt-submit.ts` hook detects and skips internal prompts containing `[LOCAL_RECALL_INTERNAL]` marker. This is intentional - these are prompts sent by the daemon to extract memories from transcripts using `claude -p`. The hook's check is at line ~50: `if (input.prompt?.includes('[LOCAL_RECALL_INTERNAL]'))` returns early. This prevents memory extraction prompts from creating duplicate memories.","timestamp":"2025-12-21T19:27:11.456Z"}
{"action":"add","id":"6178e194-63f8-4d0b-8a6a-0ebcc0284708","subject":"Stop hook processes transcripts and extracts memories for storage","keywords":["hooks","stop","transcript","memory-extraction","processing"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:20:29.762Z","content_hash":"7168d4245126a4e1","content":"The stop hook is responsible for processing Claude's transcript at the end of a session and extracting valuable memories from it. It handles the memory creation workflow that stores lessons learned during the session for future retrieval.","timestamp":"2025-12-21T19:27:11.456Z"}
{"action":"add","id":"2a07c858-0a0d-45e1-bcbd-9c42b6c40eb3","subject":"MemoryManager must ensure .gitignore exists in parent local-recall directory","keywords":["gitignore","memory-manager","initialization","index-manager","file-creation"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:18:14.023Z","content_hash":"8581f2180dfabcb5","content":"The MemoryManager class creates the local-recall/memories/ directory but wasn't ensuring the parent local-recall/.gitignore file existed. This caused .gitignore to only be created when IndexManager ran, not when memory operations occurred.\n\nFix: Add ensureGitignore() method to MemoryManager that:\n1. Stores baseDir as a class property\n2. Calls ensureGitignore() in constructor\n3. Ensures .gitignore exists with proper patterns\n\nThis ensures .gitignore is created early in the memory initialization lifecycle, not dependent on IndexManager being invoked.","timestamp":"2025-12-21T19:27:11.457Z"}
{"action":"add","id":"9e945592-77a3-4765-bbae-ed63fa4875e8","subject":"Hooks executing but returning empty stdout - memory not injected into context","keywords":["hooks","sessionstart","userpromptsubmit","stdout","memory injection","debugging"],"applies_to":"global","occurred_at":"2025-12-21T18:16:52.189Z","content_hash":"73687130908070ad","content":"## Problem Identified\n\nBoth SessionStart and UserPromptSubmit hooks are executing successfully (no errors in logs) but returning completely empty stdout and stderr. This prevents memory content from being injected into Claude's context.\n\n## Hook Execution Status\n\n- **SessionStart hook**: Runs without errors, but produces no output\n- **UserPromptSubmit hook**: Runs without errors, but produces no output\n- **Hook logs**: Show `hook_response: \"\"` (empty string)\n\n## Investigation Steps Taken\n\n1. Verified hooks are configured correctly in `.claude/settings.json`\n2. Checked that compiled hook files exist in `dist/hooks/`\n3. Confirmed Ollama is running and accessible\n4. Verified memory files exist in `local-recall/episodic-memory/`\n5. Tested manual hook execution by running compiled JS files directly\n\n## Next Steps for Resolution\n\n- Add explicit logging to hook entry points (session-start.ts and user-prompt-submit.ts)\n- Verify that hook code is actually executing (not being skipped due to errors)\n- Check if memory file reading and formatting is working correctly\n- Confirm Ollama embedding calls are completing successfully\n- Verify memory search results are being generated and formatted properly\n- Test hook output formatting to ensure it's valid JSON or plain text as expected","timestamp":"2025-12-21T19:27:11.458Z"}
{"action":"add","id":"3ecebf2f-c241-4ab8-ae4a-40743f876a7d","subject":"Comprehensive tests for transcript condenser implementation","keywords":["transcript-condenser tests","test coverage","unit tests"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-21T18:30:37.940Z","content_hash":"6eb987cef43f344d","content":"Created extensive test suite (547 lines) covering:\n\n- **Entry type parsing**: UserEntry, AssistantEntry, ToolEntry, ResultEntry handling\n- **Content extraction**: Selective extraction from each entry type\n- **Edge cases**: Empty content, null values, special characters\n- **Integration**: Full transcript condensation with multiple entry types\n- **Error handling**: Invalid entries and malformed data\n\nAll tests pass with comprehensive coverage of the condenser's functionality, ensuring reliable extraction of condensed transcript data.","timestamp":"2025-12-21T19:27:11.458Z"}
{"action":"add","id":"4718f7a0-5747-438b-9b51-4967f0aa3052","subject":"MCP SDK 1.23.0 breaking changes in Server and StdioServerTransport API","keywords":["mcp-sdk","breaking-changes","server","version-1.23.0","compatibility","stdiotransport"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:23:42.660Z","content_hash":"9bdd11c0633ec7c0","content":"The MCP SDK updated from ^1.0.0 to 1.23.0 with breaking changes:\n\n- `Server` class constructor now requires `options` parameter with `name` field\n- `StdioServerTransport` now takes `stdin` and `stdout` stream objects instead of being auto-initialized\n- Old pattern: `new Server({ ... })` → New pattern: `new Server({ name: '...', ... })`\n- Old pattern: `new StdioServerTransport()` → New pattern: `new StdioServerTransport({ stdin, stdout })`\n\nFix applied in src/mcp-server/server.ts to create transport with proper stream parameters. This ensures MCP server starts correctly with newer SDK versions.","timestamp":"2025-12-21T19:27:11.460Z"}
{"action":"add","id":"e618f90c-9567-4353-8151-741f003c3ca3","subject":"Project version: bumped to 0.1.9 with JSONL storage","keywords":["version","0.1.9","release","jsonl","plugin"],"applies_to":"global","occurred_at":"2025-12-21T19:03:33.302Z","content_hash":"d92f4b6a52d53019","content":"Bumped package.json and plugin.json versions from 0.1.8/0.1.6 to 0.1.9. Changes include: JSONL storage migration with 6-digit padding, pre-computed embeddings, auto-compaction, and proper gitignore configuration. Users should restart Claude Code to load the updated plugin.","timestamp":"2025-12-21T19:27:11.461Z"}
{"action":"add","id":"e4d87f05-7470-47cd-9f8d-c139d36b5719","subject":"Current architecture loads embedding model in hooks - incompatible with multiple Claude instances","keywords":["architecture","hooks","search-engine","vector-store","embedding"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"58d86f52fd6f145c","content":"The `user-prompt-submit.ts` hook directly instantiates `SearchEngine` and `ThinkingSearchEngine`, which trigger embedding model loading via `getVectorStore()` and `getThinkingVectorStore()`. This means each hook execution (each prompt in each Claude instance) attempts to load the ONNX embedding model, creating concurrency conflicts.\n\n**Specific code path**: `user-prompt-submit.ts` → `SearchEngine` → `getVectorStore()` → `embedding.ts` (fastembed/ONNX initialization)\n\nThis design assumes a single Claude instance. With multiple instances, all hooks run concurrently and trigger simultaneous ONNX loads.","timestamp":"2025-12-21T19:27:11.461Z"}
{"action":"add","id":"97b88952-de1c-41d3-8211-c07febe3e1e4","subject":"Memories are stored as markdown files with YAML frontmatter","keywords":["memory-format","markdown","yaml","frontmatter","storage"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"8679c0f9cb33ca94","content":"Each memory is stored as a standalone markdown file with YAML frontmatter containing metadata (id, subject, keywords, applies_to, occurred_at, content_hash). Memory files are version-controlled in git within local-recall/episodic-memory/ and local-recall/thinking-memory/ directories. This design allows memories to be tracked alongside code.","timestamp":"2025-12-21T19:27:11.462Z"}
{"action":"add","id":"e3ed5314-5a1d-42ac-bff8-f41307c92d58","subject":"Recall.log shows Stop hook execution details and memory creation counts","keywords":["recall.log","stop hook","debug log","memory creation","transcript processing"],"applies_to":"file:local-recall/recall.log","occurred_at":"2025-12-21T18:16:21.840Z","content_hash":"a64658a80d7f5b90","content":"The recall.log file (gitignored) contains valuable debug information about hook execution:\n\n- Log entries include timestamps and hook names\n- Stop hook logs show: \"Stop hook fired\", \"Found X potential memories\", \"Created Y new memories\"\n- This file is useful for debugging hook issues and verifying that memory creation is working\n- Located at: `local-recall/recall.log`","timestamp":"2025-12-21T19:27:11.463Z"}
{"action":"add","id":"8474eaba-1b6d-443e-ad4a-fa68d474d0d0","subject":"Settings can be stored in .claude/settings.local.json for local overrides","keywords":["configuration","settings.local.json","local override","mcp configuration"],"applies_to":"global","occurred_at":"2025-12-21T18:30:50.750Z","content_hash":"bfe4174e13bb6e31","content":"Claude Code settings can be stored in `.claude/settings.local.json` for local configuration overrides. This allows different environments or developers to have different settings without modifying the main `.claude/settings.json` file.","timestamp":"2025-12-21T19:27:11.464Z"}
{"action":"add","id":"94838702-929b-46ca-ba88-83e0bc140a39","subject":"Local Recall plugin successfully installed and requires Claude Code restart","keywords":["installation","plugin","local-recall","setup","restart"],"applies_to":"global","occurred_at":"2025-12-21T19:04:56.457Z","content_hash":"9d78c3679895ce51","content":"The local-recall plugin was installed via the /plugin command. After installation, Claude Code needs to be restarted to load the new plugin. This is standard behavior for Claude Code plugin installation.","timestamp":"2025-12-21T19:27:11.464Z"}
{"action":"add","id":"eef99bb9-de3c-43f4-85e9-1245e5b628c9","subject":"Hooks are built to dist/hooks/ directory before being usable","keywords":["hooks","build","compilation","dist"],"applies_to":"global","occurred_at":"2025-12-21T19:20:29.762Z","content_hash":"a9facb72dffe71cb","content":"The hook source files in src/hooks/ must be compiled/built to the dist/hooks/ directory before they can be executed. This is part of the build process that needs to complete before testing or deploying hooks.","timestamp":"2025-12-21T19:27:11.465Z"}
{"action":"add","id":"684bad3a-e801-437b-a08c-c89e5a809b6d","subject":"Transcript files in Claude cache follow UUID.jsonl naming convention","keywords":["transcript","uuid","filename","claude cache","convention","format"],"applies_to":"global","occurred_at":"2025-12-21T18:28:51.693Z","content_hash":"42753f583cc8f082","content":"Claude's transcript cache stores files with UUID-based filenames in JSONL format (e.g., `550e8400-e29b-41d4-a716-446655440000.jsonl`). The local-recall project must validate that transcript filenames match this UUID pattern before processing them, as the directory may contain other `.jsonl` files that are not transcripts.","timestamp":"2025-12-21T19:27:11.466Z"}
{"action":"add","id":"5a03beea-f3b0-4357-bb9c-cf0687c4a8d1","subject":"Stop hook changed to process entire transcript history instead of time window","keywords":["stop hook","transcript","history","time window","memory extraction"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:18:18.497Z","content_hash":"b2a83814e9e3c3fd","content":"Modified stop hook logic to process entire transcript history rather than filtering by 30-second time window. Previous implementation would miss messages older than 30 seconds by the time the stop hook fired. New approach processes all messages in transcript and relies on deduplication (occurred_at + content_hash) to prevent duplicate memory creation when transcripts are reprocessed. This supports the full-history memory model.","timestamp":"2025-12-21T19:27:11.467Z"}
{"action":"add","id":"6551b876-1ef6-4a1a-891c-3f5bfe41fa06","subject":"MCP server concurrency issue with shared codebase folders","keywords":["mcp","concurrency","race condition","index","multiple-instances","stdio"],"applies_to":"global","occurred_at":"2025-12-21T19:16:47.225Z","content_hash":"f2dd1cd92417dee2","content":"When multiple Claude Code instances run on the SAME codebase folder, each spawns its own MCP server process (stdio isolation). However, they all write to the same `orama-episodic-index.json`, `orama-thinking-index.json`, and `processed-log.jsonl` files.\n\n**Problem**: Without file locking or mutex protection, concurrent writes from multiple server instances can:\n- Corrupt index files (partial writes, invalid JSON)\n- Miss processed transcripts (race condition in processed-log checks)\n- Create duplicate memories\n\n**Solution**: Implement file-level locking using `proper-lockfile` npm package:\n1. Acquire lock before reading/writing index and log files\n2. Use atomic file operations (write to temp file, then rename)\n3. Add timeout and stale lock cleanup\n4. Test with multiple concurrent Claude instances on same folder\n\n**Files affected**: `src/core/vector-store.ts`, `src/core/episodic-jsonl-store.ts`, `src/core/thinking-jsonl-store.ts`, `src/core/processed-log.ts`","timestamp":"2025-12-21T19:27:11.468Z"}
{"action":"add","id":"3197f93e-2d0b-4348-86ac-d452c0a4a572","subject":"Memory creation pipeline architecture: Stop hook vs MCP daemon","keywords":["memory creation","stop hook","mcp daemon","transcript processing","architecture"],"applies_to":"global","occurred_at":"2025-12-21T19:03:16.962Z","content_hash":"d7c006b6fda286e8","content":"Local Recall has two paths for creating memories:\n\n1. **Stop Hook Path** (`src/hooks/stop.ts`): Triggered when Claude Code session ends, parses transcript and creates memories immediately. Does NOT work in VS Code extension.\n\n2. **MCP Daemon Path**: Background daemon in MCP server that processes transcripts asynchronously every 5 minutes. Works everywhere because it's a separate process.\n\nThe Stop hook is documented as the primary memory creation mechanism in CLAUDE.md, but the MCP daemon is the reliable fallback that works across all platforms and extensions. Understanding both paths is important for debugging memory creation issues.","timestamp":"2025-12-21T19:27:11.468Z"}
{"action":"add","id":"f30539ce-faec-4b59-ba63-352d63cf86c6","subject":"Hooks now unified - single user-prompt-submit handles episodic and thinking memories","keywords":["hooks","user-prompt-submit","episodic","thinking","unified","configuration"],"applies_to":"area:hooks","occurred_at":"2025-12-21T18:27:24.119Z","content_hash":"4b7b39a55a161272","content":"The UserPromptSubmit hook is now unified and handles both episodic and thinking memory retrieval based on configuration flags:\n\n- `episodicEnabled` / `episodicMaxTokens` / `episodicMinSimilarity` - controls episodic memory injection\n- `thinkingEnabled` / `thinkingMaxTokens` / `thinkingMinSimilarity` - controls thinking memory injection\n\nBoth use Orama for vector search and Ollama for embeddings. The single hook skips internal prompts (those containing `[LOCAL_RECALL_INTERNAL]`) to avoid recursive memory extraction.\n\nThis replaces the previous approach of having separate hooks for each memory type.","timestamp":"2025-12-21T19:27:11.470Z"}
{"action":"add","id":"2ebbda42-9f1e-4125-8f5b-9e84192e34b0","subject":"Proper error handling pattern for spawned child processes with timeouts","keywords":["spawn","error handling","timeout","promise","safe resolve"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:27:26.099Z","content_hash":"f951a14c4c5b29bf","content":"When spawning child processes in Node.js, use Promise.race() with a manual timeout instead of the built-in timeout option. Wrap the promise resolution in a guard function (e.g., `safeResolve`) that only allows the promise to resolve once. This prevents race conditions between timeout expiration and normal process completion. Always ensure error events and abort errors are properly caught with try-catch blocks around await statements.","timestamp":"2025-12-21T19:27:11.470Z"}
{"action":"add","id":"48b9d038-7d0f-4192-b14c-add8000caec0","subject":"Search engine uses vector embeddings from Ollama for semantic similarity matching","keywords":["search","vector-store","ollama","embeddings","semantic-search"],"applies_to":"file:src/core/search.ts","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"b704bc19fa9ed6b8","content":"The search module uses Orama vector store with Ollama embeddings (nomic-embed-text model, 768 dimensions) for semantic search. Results are ranked by cosine similarity score (0.0-1.0) with a recency tie-breaker: when scores are equal, more recent memories (`occurred_at`) rank higher.","timestamp":"2025-12-21T19:27:11.471Z"}
{"action":"add","id":"cfb184c4-61c9-450f-9099-3e880507dd60","subject":"Thinking hook returns 10 items by default, expandable to 25 with high similarity","keywords":["thinking-memories","hook-config","similarity-threshold","result-limits","user-prompt-submit"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-03T09:47:02.103Z","content_hash":"306792982225c753","content":"Modified thinking memory search in user-prompt-submit hook (lines 77-98) to return:\n- Default: 10 items (DEFAULT_LIMIT)\n- Expandable: Up to 25 items if similarity >= 90% (HIGH_SIMILARITY_THRESHOLD)\n\nImplementation fetches up to 25 candidates, then filters to only include items beyond position 10 if their similarity score is 0.90 or higher. This balances context quality (ensuring high-relevance thinking examples) with quantity (providing enough examples for diverse scenarios).","timestamp":"2025-12-21T19:27:11.473Z"}
{"action":"add","id":"2f17596a-bc07-4985-a479-2aff0ab917f6","subject":"Plugin hooks require JSON output format with hookSpecificOutput field for context injection","keywords":["hooks","plugin","json output","sessionstart","context injection","claude code"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:11:52.152Z","content_hash":"859d4d777cf13455","content":"Plugin-layer hooks (SessionStart:Callback, UserPromptSubmit:Callback) require stdout to be in JSON format. The output must contain a `hookSpecificOutput` object with an `additionalContext` field. Plain `console.log()` output is not recognized by the plugin layer and won't inject context into Claude's session. This is different from the hook command format which outputs plain text.","timestamp":"2025-12-21T19:27:11.476Z"}
{"action":"add","id":"2c02b1eb-2d29-4807-b6a3-ff93b1092fbe","subject":"User requires npm-installable solution that supports multiple Claude instances without daemon conflicts","keywords":["requirements","npm","multi-instance","daemon","embedding"],"applies_to":"global","occurred_at":"2025-12-21T18:25:17.343Z","content_hash":"b0638391d4588520","content":"User explicitly does not want a dedicated embedding daemon in the local-recall package, as it would conflict when running multiple Claude instances (each instance would try to start its own daemon). Instead, user prefers embedding solution that is npm-installable and can be shared across instances without port/process conflicts. Ollama (external daemon) works because it's a separate service designed for concurrent clients, unlike an in-process daemon.","timestamp":"2025-12-21T19:27:11.477Z"}
{"action":"add","id":"0554aad4-7f64-4d75-9fe9-cea560b98940","subject":"TypeScript optional chaining pattern for regex capture groups","keywords":["typescript","regex","optional-chaining","capture-groups","type-safety"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-03T09:51:12.210Z","content_hash":"b769d2a3a26e4634","content":"When accessing regex capture groups in TypeScript, use optional chaining (`match?.[1]`) instead of direct indexing (`match[1]`). This handles both the case where the regex doesn't match AND where the capture group doesn't exist. The error TS2532 'Object is possibly undefined' occurs because even if a regex matches, specific capture groups might not if they're in optional parts of the pattern. This pattern safely accesses capture groups: `const captured = codeBlockMatch?.[1]?.trim()`","timestamp":"2025-12-21T19:27:11.478Z"}
{"action":"add","id":"f5b216a4-eee8-4a93-b050-ecd7e81a9a82","subject":"Built hook scripts are generated in dev-marketplace/local-recall-plugin/scripts/hooks/, not scripts/hooks/","keywords":["build","hooks","output-directory","npm","compilation"],"applies_to":"global","occurred_at":"2025-12-21T19:21:30.507Z","content_hash":"57607ce31fb0364e","content":"When running `npm run build`, the compiled hook scripts are placed in dev-marketplace/local-recall-plugin/scripts/hooks/ rather than a local scripts/hooks/ directory. This is likely configured in tsconfig.json or build configuration. The .claude/settings.json should point to these built scripts for hook execution.","timestamp":"2025-12-21T19:27:11.479Z"}
{"action":"add","id":"eaa41780-0440-4fb3-800c-175df62d93fa","subject":"Plugin hooks updated to use Orama instead of better-sqlite3","keywords":["hooks","plugin","orama","better-sqlite3","refactoring","stale-code"],"applies_to":"area:plugin","occurred_at":"2025-12-21T19:21:22.678Z","content_hash":"13d0aba935cfafce","content":"The dev-marketplace/local-recall-plugin had stale hook files that tried to import `better-sqlite3`, a native module that cannot be bundled. The main codebase migrated to Orama (pure JavaScript vector store) but the plugin still referenced old SQLite-based hooks. Fixed by:\n\n1. Deleted stale file: `dev-marketplace/local-recall-plugin/scripts/hooks/user-prompt-submit-thinking.js`\n2. Updated `hooks.json` to point to `user-prompt-submit.js` (which handles both episodic and thinking memories using Orama)\n3. Rebuilt plugin scripts to ensure consistency with main source\n\nThis prevented ERR_MODULE_NOT_FOUND errors when hooks tried to run.","timestamp":"2025-12-21T19:27:11.479Z"}
{"action":"add","id":"89271682-4e1c-4907-936b-ba60d9c7950f","subject":"Thinking memories store thought+output pairs, skipping tool-only responses","keywords":["thinking memories","thought output pairs","claude thinking","extraction logic","response filtering"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:59:50.981Z","content_hash":"85f1bbd629530212","content":"Thinking memories capture Claude's reasoning paired with text output:\n\n1. **Format** - Each thinking memory contains both the thought block and corresponding text output\n2. **Tool-only responses skipped** - Responses containing only tool calls (no text) are not stored\n3. **Semantic pairing** - The thought and output from the same response turn are stored together\n4. **Practical examples** - Provides \"how I reasoned → what I produced\" examples for future sessions\n5. **Retrieval** - Retrieved based on semantic similarity and token budget\n\nThis means thinking memories are only created for responses that produce actual text output, avoiding storage of intermediate reasoning that didn't lead to user-facing text.","timestamp":"2025-12-21T19:27:11.481Z"}
{"action":"add","id":"c093b189-b68c-4128-aa8c-356d02f6d1a4","subject":"Migration must preserve all memory metadata and handle edge cases during transition","keywords":["migration","data preservation","edge cases","backward compatibility"],"applies_to":"global","occurred_at":"2025-12-21T17:34:47.718Z","content_hash":"001c91433e0d1fdb","content":"During the migration from individual markdown files to JSONL format:\n\n1. **Metadata preservation** - All fields must be preserved: id, subject, keywords, applies_to, occurred_at, content_hash, content\n2. **Embedding handling** - Existing embeddings from orama-episodic-index.json and orama-thinking-index.json must be extracted and embedded in JSONL entries\n3. **Deletion record** - After migration, all old markdown files must be deleted and \"delete\" entries may be added to JSONL for historical tracking\n4. **Vector index transition** - Orama indexes should be rebuilt from the JSONL files rather than maintained separately\n5. **Idempotency** - Migration should be safe to run multiple times and detect if already completed","timestamp":"2025-12-21T19:27:11.482Z"}
{"action":"add","id":"e3bd492f-d6b4-4376-9a36-a2fb5dadf4bd","subject":"ONNX runtime causes mutex errors in concurrent hook processes, not sqlite-vec","keywords":["onnx","mutex","concurrency","fastembed","embedding","threading"],"applies_to":"global","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"65eed77902820b39","content":"The mutex errors experienced when running concurrent hooks are caused by ONNX runtime (used by fastembed), not sqlite-vec. The recent migration to Orama fixed SQLite issues, but ONNX runtime has internal mutex conflicts when multiple processes try to load the embedding model simultaneously. The `proper-lockfile` file-based locking mechanism cannot prevent ONNX's system-level mutex issues. Testing with 15 concurrent processes confirmed 15 mutex errors.\n\n**Root cause**: `src/core/embedding.ts` uses fastembed which relies on ONNX native runtime. When `user-prompt-submit.ts` hook instantiates `SearchEngine`/`ThinkingSearchEngine`, each process loads ONNX concurrently, triggering mutex conflicts.\n\n**Why session-start hook is safe**: It only uses `MemoryManager` (file-based, no embeddings) and doesn't load the embedding model.","timestamp":"2025-12-21T19:27:11.483Z"}
{"action":"add","id":"06db870a-6b59-4cab-9c7c-2c949aeddf75","subject":"MCP search tools now return content and support token limits","keywords":["mcp-tools","episodic_search","thinking_search","content-return","max_tokens"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"9faf90e4326ca915","content":"MCP search tools (`episodic_search`, `thinking_search`) now return full memory content in results. Added `max_tokens` parameter to tool schemas (default 2000) to limit total tokens in response. Results include: `id`, `subject`, `content`, `occurred_at`, `similarity_score`, and `tokens_used`. This enables clients to enforce token budgets while accessing full memory content.","timestamp":"2025-12-21T19:27:11.485Z"}
{"action":"add","id":"b6d4675d-a7a4-40a3-a7c4-ea5dafef369a","subject":"MCP SDK v1.23.0 breaking changes affect Server initialization","keywords":["mcp sdk","breaking changes","1.23.0","StdioServerTransport","server initialization"],"applies_to":"global","occurred_at":"2025-12-21T19:03:02.350Z","content_hash":"c0857f6d1e3d9a4a","content":"The @modelcontextprotocol/sdk was upgraded from ^1.0.0 to 1.23.0, introducing breaking changes between v1.0.0 and v1.23.0. The Server and StdioServerTransport usage pattern changed. Need to update src/mcp-server/server.ts to use the new API pattern for proper initialization and transport setup.","timestamp":"2025-12-21T19:27:11.486Z"}
{"action":"add","id":"614d2328-9118-4747-ac77-4fabcaca8958","subject":"Session guarding bug: Memory extraction prompt must include [LOCAL_RECALL_INTERNAL] prefix","keywords":["session-guarding","memory-extraction","internal-prompt","recursion-prevention","hooks"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:23:11.524Z","content_hash":"309f30812562285d","content":"The memory extraction prompt generated by `buildMemoryExtractionPrompt()` was missing the `[LOCAL_RECALL_INTERNAL]` prefix guard. This caused the UserPromptSubmit hook to process memory extraction prompts as regular user prompts, creating recursion loops. The fix: prepend `[LOCAL_RECALL_INTERNAL]` to the start of the memory extraction prompt so the hook at line 161 of `user-prompt-submit.ts` correctly detects and skips it.","timestamp":"2025-12-21T19:27:11.487Z"}
{"action":"add","id":"3a7eea9e-b6c7-48a7-a700-d23f91b9ef21","subject":"MCP server daemon: JSONL-aware syncing and auto-compaction","keywords":["mcp","daemon","sync","compaction","transcript"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:03:33.302Z","content_hash":"384d3b61f6204e86","content":"Updated MCP server daemon's `runVectorSync()` to use `syncWithJsonlStore()` instead of direct file sync. After syncing, checks if JSONL files exceed size threshold and triggers auto-compaction. Auto-compaction runs every 5 minutes if needed, removing deleted entries and creating clean files. Migration runs on startup via `migrate()` function to convert any existing markdown memories to JSONL format.","timestamp":"2025-12-21T19:27:11.487Z"}
{"action":"add","id":"2ff2b918-fd15-44f2-85ad-d6cd3cd5f5c1","subject":"Memory extraction process validates parsed memories with Zod schema","keywords":["memory-extractor","validation","zod","schema","robustness"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:17:53.529Z","content_hash":"8f222ac98a8246ab","content":"The parseClaudeResponse() function uses Zod validation to ensure parsed memories match the expected schema (MemoryData with subject, keywords, applies_to, content fields). Validation failures indicate the parsed structure doesn't match expectations. Before validation, memories should be normalized to ensure field names match the schema, as Claude may return valid memory data using alternative field names. Validation errors should log the actual parsed object structure to aid debugging.","timestamp":"2025-12-21T19:27:11.488Z"}
{"action":"add","id":"258eb759-8db1-4117-911e-560ec1b8a2fb","subject":"TranscriptEntry type schema defines all Claude Code JSONL entry types and their fields","keywords":["transcript schema","jsonl types","entry types","typescript types","transcript format"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T19:26:56.552Z","content_hash":"68c13048cdc5a551","content":"The `transcript-schema.ts` file defines TypeScript interfaces for parsing Claude Code transcript JSONL files:\n\n**Entry types supported**:\n- `UserEntry`: User prompts with optional tags\n- `AssistantEntry`: Claude responses with content blocks\n- `SystemEntry`: System messages and metadata\n- `FileHistorySnapshotEntry`: File state snapshots with git diffs\n- `QueueOperationEntry`: Operation queue events\n\n**Content block types**:\n- `TextContent`: Plain text responses\n- `ToolUseContent`: Tool invocation blocks\n- `ToolResultContent`: Tool execution results\n\n**Key fields**:\n- `type`: Entry type identifier\n- `timestamp`: ISO-8601 timestamp\n- `content`: Entry-specific content\n- `metadata`: Additional contextual data\n\nThese types enable safe parsing of JSONL transcripts for both extraction and condensing operations.","timestamp":"2025-12-21T19:27:11.489Z"}
{"action":"add","id":"35217309-8612-4c8a-92c0-3d25e922b2eb","subject":"Token-based retrieval for thinking memories instead of count-based limiting","keywords":["token limiting","thinking retrieval","context budget","configuration","user-prompt-submit-thinking"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-21T18:17:09.782Z","content_hash":"d2bc3148c3fd2000","content":"Changed thinking memory retrieval from returning a fixed count of memories to accumulating memories until a token budget is reached. This provides more flexible control over context injection.\n\n**Configuration:**\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` (default: 1000) - Maximum tokens to inject per prompt\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` (default: 0.8) - Minimum similarity threshold (80%) for thinking memory retrieval\n\n**Implementation:**\n- Memories are added in similarity score order (highest first)\n- Stops adding when the next memory would exceed the token budget\n- Configurable via environment variables and config file\n\nThis approach allows users to control how much thinking context is injected based on their token budget constraints.","timestamp":"2025-12-21T19:27:11.489Z"}
{"action":"add","id":"f1b0c706-c69b-47b5-8623-6432a26f4ead","subject":"File-based locking approach resolves concurrent native module access in hooks","keywords":["proper-lockfile","concurrency control","file lock","embedding.ts","native modules","serialization"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T18:28:55.282Z","content_hash":"bafc82ed1c6c36dc","content":"Implemented proper-lockfile-based file locking to serialize access to fastembed/onnxruntime-node in `src/core/embedding.ts`. The lock is acquired during both `doInitialize()` and `embed()` operations using `withEmbeddingLock()` wrapper. Lock file location: `/tmp/local-recall-embedding.lock`. This prevents the mutex contention errors that occur when multiple hook processes try to load the native module simultaneously.","timestamp":"2025-12-21T19:27:11.493Z"}
{"action":"add","id":"09805078-3129-4464-961d-bdfaf06148a2","subject":"CLAUDE.md documentation contains outdated SQLite and daemon architecture references","keywords":["documentation","sqlite-vec","daemon","architecture","outdated"],"applies_to":"global","occurred_at":"2025-12-03T11:22:14.365Z","content_hash":"3ee7a78fee0c62bf","content":"The CLAUDE.md project documentation still references the old SQLite+sqlite-vec based vector store architecture and the hook-daemon HTTP communication pattern, even though the codebase has fully migrated to Orama (pure JavaScript vector store).\n\n**Outdated References**:\n- Hook-daemon architecture diagram and HTTP endpoint descriptions\n- References to sqlite-vec native extension and \"mutex lock failed\" issues\n- References to `http-server.ts` (deleted during migration)\n- DaemonClient usage in hooks documentation\n- Description of vector store as SQLite-backed\n\n**Should Be Updated**: Documentation should reflect that Orama eliminated the need for the daemon architecture and native modules.","timestamp":"2025-12-21T19:27:11.494Z"}
{"action":"add","id":"b13165ee-6abb-4b97-b0ab-9a82dfd8355c","subject":"Testing hooks requires npm dependencies to be installed","keywords":["hooks","testing","dependencies","npm install","rake-pos"],"applies_to":"global","occurred_at":"2025-12-21T18:28:17.619Z","content_hash":"c539fe9766038438","content":"When testing the session-start and stop hooks locally, npm dependencies must be installed first. The hooks depend on packages like `rake-pos` for keyword extraction. Run `npm install` before testing hooks to ensure all dependencies are available.","timestamp":"2025-12-21T19:27:11.495Z"}
{"action":"add","id":"975f6325-e891-4295-96b8-f20d66a4271e","subject":"sqlite-vec requires LIMIT k constraint in vector search JOIN queries","keywords":["sqlite-vec","vector-search","sql","limit","join","constraint"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:14:59.526Z","content_hash":"52740159a7b55fc3","content":"The sqlite-vec extension requires `k = ?` in the match clause for JOIN queries to work correctly. When searching with scope filters, must request k+filter_buffer results from sqlite-vec, then filter in JavaScript after retrieval. Cannot apply WHERE scope filter before the k LIMIT in SQL.","timestamp":"2025-12-21T19:27:11.495Z"}
{"action":"add","id":"7a099951-ec70-4694-9396-1f762364a192","subject":"Gitignore function should always update existing files","keywords":["gitignore","auto-generated","sqlite","memory-storage"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:17:55.902Z","content_hash":"0d7ce0d929e4c671","content":"The ensureGitignore() function only created the gitignore file if it didn't exist, so existing files weren't updated with new patterns (like memory.sqlite). Changed to always write the gitignore since it's auto-generated and should reflect current patterns. This ensures new users get correct SQLite exclusions.","timestamp":"2025-12-21T19:27:11.496Z"}
{"action":"add","id":"3b879e7e-6632-4312-bfdf-c91f82b046c9","subject":"Hooks architecture: SessionStart, UserPromptSubmit, and Stop","keywords":["hooks","session-start","user-prompt-submit","stop","claude-code","integration"],"applies_to":"global","occurred_at":"2025-12-21T18:20:14.815Z","content_hash":"35029f163022d710","content":"Local Recall has three main hooks that integrate with Claude Code:\n\n1. **SessionStart Hook** (src/hooks/session-start.ts): Triggered when a Claude Code session begins. Loads the memory index and searches for relevant memories to inject into Claude's context.\n\n2. **UserPromptSubmit Hook** (src/hooks/user-prompt-submit.ts): Triggered when a user submits a prompt. Searches for semantically relevant memories and injects them before Claude processes the prompt.\n\n3. **Stop Hook** (src/hooks/stop.ts): Triggered at the end of a session. Currently disabled - memory extraction is now handled by the MCP server daemon instead.\n\nHooks integrate by reading from local JSON index files (Orama vector store) and outputting memories to stdout, which Claude Code then injects into context.","timestamp":"2025-12-21T19:27:11.496Z"}
{"action":"add","id":"142e9568-0a89-4029-b524-6e52c34bea97","subject":"Transcript collector refactor changed memory collection approach","keywords":["transcript collection","sync pattern","idempotent memories","schema simplification"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:24:15.046Z","content_hash":"efd9b74ee7d5a62c","content":"Recent refactoring changed memory collection from an update-based pattern to an idempotent sync pattern. Memories are now create-only (no updateMemory operation). The schema was simplified by removing the created_at field and using occurred_at for sorting and deduplication. The collector syncs memories from Claude transcripts rather than building them incrementally.","timestamp":"2025-12-21T19:27:11.497Z"}
{"action":"add","id":"7452eac7-0e70-4f7e-a36c-1eeb8b705507","subject":"Cannot use per-instance daemon servers - ONNX mutex conflicts still occur at startup","keywords":["daemon","architecture","concurrency","multiple-instances","onnx"],"applies_to":"global","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"64ba497f8b77041a","content":"The proposed HTTP daemon architecture (embedding server built into MCP server on dynamic ports) doesn't solve the ONNX mutex problem. Running multiple Claude instances still means multiple ONNX runtime initializations happening concurrently, which triggers the same mutex conflicts. The mutex issue is fundamental to ONNX's initialization, not the hook invocation pattern.\n\n**Key insight**: The problem isn't about hooks vs HTTP calls—it's that ONNX runtime can't be safely initialized by multiple concurrent processes. Multiple Claude instances = multiple ONNX initializations = same mutex risk.","timestamp":"2025-12-21T19:27:11.498Z"}
{"action":"add","id":"864335e5-79c3-4e7a-ba70-cfa4187e9807","subject":"Memory extraction tests must properly mock Claude API responses","keywords":["memory-extractor","testing","mocking","mock-claude","unit-tests"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T19:19:00.855Z","content_hash":"be0868a896f54e3d","content":"Created comprehensive test suite for memory-extractor.ts covering: 1) Happy path with valid object response `{ memories: [...] }`, 2) Direct array response `[{...}]` to test the array-wrapping fix, 3) Invalid schema responses that fail validation, 4) Empty/null responses. Tests use `@anthropic-sdk/sdk` mocking. The test file at tests/unit/core/memory-extractor.test.ts includes 6 test cases verifying both valid parsing and edge case handling.","timestamp":"2025-12-21T19:27:11.498Z"}
{"action":"add","id":"ac985ef1-9c2f-4299-adfb-c547e832b7e2","subject":"Memory deduplication prevents duplicates at creation time","keywords":["deduplication","duplicate-prevention","content-hash","occurred-at","memory-manager"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:20:14.815Z","content_hash":"8ce1c6a7260f682a","content":"MemoryManager has a `findDuplicate()` method (lines 52-67) that prevents duplicate memories from being created. Before creating a new memory, it checks if one with the same `occurred_at` timestamp AND `content_hash` already exists. If found, it returns the existing memory instead of creating a new one.\n\nThis is the only deduplication mechanism - there is NO active compaction or cleanup process that consolidates memories over time. Memories accumulate indefinitely (subject to a `maxMemories` config limit).","timestamp":"2025-12-21T19:27:11.499Z"}
{"action":"add","id":"b7d90d48-2bc8-4421-97a9-fd550ec1c4d4","subject":"Vector indexes should be persisted as JSON files that hooks can read independently","keywords":["vector-index","persistence","json","file-based","hook-design"],"applies_to":"global","occurred_at":"2025-12-21T18:58:59.192Z","content_hash":"4637a453a01190aa","content":"Rather than maintaining shared state across hook processes, store vector indexes as JSON files in the local-recall directory. Each hook process independently loads the index from disk when needed. This eliminates concurrency issues and aligns with the stateless hook architecture. Use Orama's persist() method to save indexes to disk after modifications.","timestamp":"2025-12-21T19:27:11.499Z"}
{"action":"add","id":"0a4a53d4-9b2e-4261-ae2e-27867648dda7","subject":"Build and test infrastructure working - npm run build and npm test passing","keywords":["build","testing","typescript","npm scripts","validation"],"applies_to":"global","occurred_at":"2025-12-21T19:14:45.298Z","content_hash":"48941dc52127b0e1","content":"The project build and test suite are functional and passing after the thinking memory enhancements:\n\n- `npm run build` compiles TypeScript successfully\n- `npm test` runs the test suite with all tests passing\n- Changes made to thinking extractor, user-prompt-submit-thinking hook, config, and types did not introduce regressions\n\nThis validates that the token-based retrieval and combined thought+output features are working correctly.","timestamp":"2025-12-21T19:27:11.500Z"}
{"action":"add","id":"a2368938-90ba-4699-89d9-9e474bec9cce","subject":"Memory creation pipeline requires Stop hook or MCP daemon","keywords":["memory creation","stop hook","mcp server","transcript parsing","daemon","async processing"],"applies_to":"global","occurred_at":"2025-12-03T09:51:20.667Z","content_hash":"078f847002336d24","content":"Memories are created through two mechanisms:\n\n1. **Stop Hook** (synchronous): Parses transcript on session end and creates memories immediately via `src/hooks/stop.ts`\n2. **MCP Daemon** (asynchronous): Background process that syncs transcripts from Claude cache and processes them every 5 minutes\n\nThe MCP daemon is more reliable across different Claude Code environments since it doesn't depend on hook support. It handles transcript detection via content hashing and processes using `claude -p` for extraction.","timestamp":"2025-12-21T19:27:11.500Z"}
{"action":"add","id":"db02bc43-d233-47c8-b252-c3b7cda680e7","subject":"Memory extraction handles Zod validation errors with detailed logging","keywords":["memory-extractor","zod","validation","error-handling","debugging"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:19:06.772Z","content_hash":"5067a813db9b9fec","content":"When Zod validation fails in memory extraction, the error handler at lines 226-230 logs detailed validation error information. The error object contains an 'issues' array with field-level validation failures. This helps identify which specific fields failed validation and why.\n\nDuring debugging, check:\n1. Exact field names returned by Claude vs schema expectations\n2. Whether values are null/undefined vs wrong type\n3. Whether fields are missing entirely vs present with wrong values\n\nField normalization was added before Zod validation to handle common naming discrepancies from Claude's responses.","timestamp":"2025-12-21T19:27:11.501Z"}
{"action":"add","id":"c2715120-e418-4879-a4d7-35f442a1b3e4","subject":"ONNX runtime causes mutex errors in concurrent hook execution, not sqlite-vec","keywords":["mutex","onnx","fastembed","concurrency","embedding","error","hook"],"applies_to":"global","occurred_at":"2025-12-21T19:19:42.881Z","content_hash":"67dc40ec65e3adfd","content":"The mutex errors occurring during concurrent hook execution are caused by ONNX runtime (used by fastembed embedding library), not sqlite-vec. When multiple Claude instances or concurrent processes try to load the ONNX embedding model simultaneously, they encounter system-level mutex conflicts. The proper-lockfile mechanism doesn't prevent ONNX's internal mutex issues. This was confirmed through testing with 15 concurrent processes, all producing mutex errors.","timestamp":"2025-12-21T19:27:11.501Z"}
{"action":"add","id":"0662ae82-c412-49d6-b063-53765186ce1f","subject":"Session-start hook requires npm dependencies including rake-pos for keyword extraction","keywords":["hooks","dependencies","session-start","rake-pos","installation"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:21:19.454Z","content_hash":"1fa9d642e96a323a","content":"The session-start hook needs npm dependencies to be installed before it can run. The rake-pos package is required for keyword extraction functionality. Make sure to run `npm install` before testing hooks.","timestamp":"2025-12-21T19:27:11.502Z"}
{"action":"add","id":"9026734a-9f82-4141-9e74-8efd129927c7","subject":"Transcript sync checks both mtime and size for change detection","keywords":["transcript collector","sync","change detection","mtime","file size"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:27:03.117Z","content_hash":"bbff27fa2da598dd","content":"The syncTranscripts() method now checks both modification time (mtime) AND file size to detect if a transcript has changed since last sync. This is more reliable than mtime alone because:\n- mtime can be preserved when copying files\n- Size check provides additional confirmation that content actually changed\n- ProcessTranscript() uses content hash as final validation before reprocessing\n\nFlow: mtime+size check → skip if unchanged → processTranscript() computes hash → delete old memories if hash changed → create new memories","timestamp":"2025-12-21T19:27:11.502Z"}
{"action":"add","id":"9cb85187-7d20-4e0c-a695-990638d9e02c","subject":"UserPromptSubmit hook skips internal prompts with [LOCAL_RECALL_INTERNAL]","keywords":["hooks","internal-prompts","filtering","memory-extraction"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"eb5c9222bf091bf6","content":"The UserPromptSubmit hook filters out prompts containing '[LOCAL_RECALL_INTERNAL]' marker. This marker is used for internal memory extraction prompts that shouldn't trigger recursive memory searches, preventing feedback loops and unnecessary processing.","timestamp":"2025-12-21T19:27:11.502Z"}
{"action":"add","id":"fd9448cb-4aba-492c-9144-c2c5bdfad5a0","subject":"Thinking extraction requires backward compatibility with test format","keywords":["transcript parsing","backward compatibility","thinking messages","test format"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:23:27.035Z","content_hash":"e4c5390c4fe4ae3a","content":"The transcript parser must support both formats:\n1. **Real Claude Code format** - `content` as array of blocks with `type` field\n2. **Test format** - Messages with `role` and `content` as string (used in existing tests)\n\nThe `parseMessage` function tries the real format first (looking for `type` field), then falls back to the test format (looking for `role` field). This ensures backward compatibility while supporting the new thinking block extraction.\n\nThinking is extracted from content blocks during parsing and stored in the normalized `TranscriptMessage.thinking` field.","timestamp":"2025-12-21T19:27:11.503Z"}
{"action":"add","id":"eed12d6d-1617-4416-973e-e7c18314d390","subject":"CLAUDE.md documentation contains outdated sqlite/mutex references after Orama migration","keywords":["documentation","claude.md","outdated","sqlite-vec","mutex","needs update"],"applies_to":"global","occurred_at":"2025-12-21T18:28:55.282Z","content_hash":"a968a6f6e1a8103b","content":"CLAUDE.md still references sqlite-vec and mutex lock issues from the pre-Orama architecture. Should be updated to reflect that: (1) the main codebase now uses pure-JavaScript Orama with no mutex issues in the core library, (2) mutex contention only occurs in hook processes due to fastembed's onnxruntime-node dependency, (3) the daemon HTTP architecture mentioned in diagrams was removed during migration.","timestamp":"2025-12-21T19:27:11.504Z"}
{"action":"add","id":"28836be5-2cef-4fd9-b1a8-866649a6f9de","subject":"Mutex lock errors occur when multiple processes load sqlite-vec concurrently","keywords":["mutex","sqlite-vec","concurrent","lock","cross-process","error handling"],"applies_to":"global","occurred_at":"2025-12-21T18:21:13.843Z","content_hash":"ef56b3745ac7a34f","content":"The codebase has identified a known issue where 'mutex lock failed: Invalid argument' errors occur when multiple processes attempt to load sqlite-vec simultaneously. This is a cross-process synchronization problem. The solution involves implementing cross-process file locking to prevent sqlite-vec mutex errors. See src/mcp-server/server.ts:230 for context.","timestamp":"2025-12-21T19:27:11.504Z"}
{"action":"add","id":"1db7d4e2-51fd-4668-bf73-dc9da0b06285","subject":"Version synchronization in Claude Code plugins requires updating three files","keywords":["versioning","plugin","package.json","claude-plugin","marketplace","distribution"],"applies_to":"global","occurred_at":"2025-12-20T22:38:28.607Z","content_hash":"58681f10c1d5bb79","content":"Claude Code plugins have multiple version references that must be kept in sync:\n\n1. `package.json` - The npm package version\n2. `.claude-plugin/plugin.json` - Claude Code plugin manifest\n3. `.claude-plugin/marketplace.json` - Marketplace distribution metadata\n\nWhen bumping versions, all three files must be updated together. Missing any of these can cause version mismatches and prevent proper marketplace detection of updates. Use grep to find all `0.X.X` references before committing version bumps.","timestamp":"2025-12-21T19:27:11.505Z"}
{"action":"add","id":"280e2ae6-a73f-42ca-8be6-93f05d51cf6c","subject":"Transcript parsing must support both new and legacy message formats","keywords":["backward compatibility","transcript parsing","role vs type"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:30:41.521Z","content_hash":"f7a510435fc3c9b1","content":"The transcript parser must handle both:\n1. New format: `message.type` field with content as array of blocks\n2. Legacy format: `message.role` field with content as string\n\nThe `extractThinkingAndContent` helper normalizes both formats into:\n- `thinking`: string (extracted from thinking blocks or root thinking field)\n- `content`: string (extracted from text blocks or root content field)\n\nThis allows the rest of the pipeline (analyzeForMemories, thinking extraction) to work with a consistent format.","timestamp":"2025-12-21T19:27:11.506Z"}
{"action":"add","id":"d48aa65f-1252-4695-a837-f40beab96a16","subject":"Duplicate event listeners can cause unexpected behavior in Node.js child processes","keywords":["event listeners","child process","duplicate handlers","close event","error handling"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:20:27.934Z","content_hash":"2a5d9dbf877656ef","content":"The user-prompt-submit hook had duplicate `child.on('close', ...)` handlers registered on the same child process. This can cause:\n- Multiple callback executions\n- Race conditions in promise resolution\n- Difficult-to-debug behavior\n\n**Resolution**: Consolidated all event handling into a single `close` handler with proper guards to ensure callbacks execute only once.","timestamp":"2025-12-21T19:27:11.506Z"}
{"action":"add","id":"45d1fa25-9669-4a57-b921-0ba99e48e8eb","subject":"Internal prompts should use [LOCAL_RECALL_INTERNAL] token prefix for testing and recursion control","keywords":["internal token","extraction process","testing","recursion prevention"],"applies_to":"global","occurred_at":"2025-12-21T18:25:22.045Z","content_hash":"a905be6d1d248e31","content":"All internal Local Recall prompts (like keyword extraction) should prefix the prompt with [LOCAL_RECALL_INTERNAL] token. This allows the recursion guard to detect internal prompts without relying on prompt content matching, making it easier to test with similar prompts and providing more reliable prevention of hook recursion.","timestamp":"2025-12-21T19:27:11.506Z"}
{"action":"add","id":"0845fa4a-a941-48e1-be97-b6719c05aaf4","subject":"Synthetic transcript detection and filtering strategy in transcript sync process","keywords":["synthetic","filtering","transcript sync","cleanup","cache","optimization"],"applies_to":"area:transcript-collection","occurred_at":"2025-12-21T19:22:16.212Z","content_hash":"85f362d3ecf955ab","content":"The transcript collection process uses a two-stage synthetic filtering approach:\n1. **Pre-copy filtering**: Check `isSyntheticFile()` before copying transcripts from Claude's cache to avoid unnecessary I/O\n2. **Cleanup pass**: Run `cleanupTranscripts()` to remove any synthetic files that may have been copied previously\n\nThis dual approach handles edge cases while optimizing the common case of filtering synthetic transcripts early in the sync process.","timestamp":"2025-12-21T19:27:11.507Z"}
{"action":"add","id":"db7d1065-f4c2-4d31-ad10-8cb7ad5e558f","subject":"Removed update/delete operations from memory MCP tools - memories are append-only","keywords":["mcp","tools","api","immutable"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T19:17:28.905Z","content_hash":"15d19d7e88b79048","content":"# MCP Memory Tools Refactor\n\nRemoved `memory_update` and `memory_delete` tool definitions from MCP server.\n\n## Changes\n\n- Removed the entire tool definition for memory_update\n- Removed the entire tool definition for memory_delete\n- Kept only: `memory_create`, `memory_get`, `memory_list`, `memory_search`\n\nMemories are now append-only. Users must manually delete files from the filesystem if they need to remove memories. This enforces the immutable episodic log design.","timestamp":"2025-12-21T19:27:11.508Z"}
{"action":"add","id":"c56305ec-5003-49e8-9777-47b5230848fe","subject":"Documentation was out of sync with actual codebase structure","keywords":["documentation","architecture","outdated","discrepancies","claude.md"],"applies_to":"global","occurred_at":"2025-12-03T09:51:05.046Z","content_hash":"9a4dbe6df17cb4a7","content":"The CLAUDE.md and docs/ files had multiple inconsistencies with the actual codebase:\n\n**Removed non-existent items:**\n- `.claude-plugin/` directory\n- `hooks.json` configuration file\n- `.mcp.json` configuration file\n- `scripts/` folder references\n- Non-existent utils: `summarize.ts`, `gitignore.ts`, `config.ts`\n\n**Fixed path references:**\n- Build output goes to `dist/` not `scripts/`\n- Corrected all references from `scripts/hooks/` to `dist/hooks/`\n- Corrected all references from `scripts/mcp-server/` to `dist/mcp-server/`\n\n**Added missing documented files:**\n- `src/core/transcript-collector.ts`\n- `src/core/transcript-condenser.ts`\n- `src/core/memory-extractor.ts`\n- `src/core/processed-log.ts`\n- `src/core/thinking-*.ts` files (multiple thinking-related modules)\n- `src/prompts/` folder\n- `src/types/` folder\n\n**Documentation files updated:**\n- `CLAUDE.md` - Fixed architecture tree and removed plugin structure section\n- `docs/architecture.md` - Updated component descriptions to match actual code\n- `docs/hooks.md` - Clarified hook configuration and flows\n- `docs/mcp-server.md` - Updated server startup and configuration sections","timestamp":"2025-12-21T19:27:11.508Z"}
{"action":"add","id":"b74c72b4-bac0-48c8-882b-bb0ce8520c8d","subject":"IDE inline suggestions are separate from code comments","keywords":["github-copilot","ide","suggestions","comments","editor"],"applies_to":"global","occurred_at":"2025-12-21T18:31:36.092Z","content_hash":"3ecde462100c8e16","content":"IDE inline suggestions (like GitHub Copilot suggestions in the editor) are not visible in file contents read via tools. These are editor-level features that don't appear in the actual source code. To access suggestion context, integration with GitHub's MCP server or GitHub API would be required.","timestamp":"2025-12-21T19:27:11.509Z"}
{"action":"add","id":"9798012f-918e-4113-b268-dbe28359440e","subject":"Thinking memory extraction was not running in daemon - only episodic extraction was active","keywords":["thinking memory extraction","daemon","mcp server","transcript processing","parallel execution"],"applies_to":"global","occurred_at":"2025-12-21T18:29:49.579Z","content_hash":"160e227e5be5cbbc","content":"The MCP server daemon in `src/mcp-server/server.ts` was only calling `runTranscriptProcessing()` from memory-extractor.js to handle episodic memory extraction. The thinking extractor (`ThinkingExtractor` class in `src/core/thinking-extractor.ts`) existed but was never invoked by the daemon. This meant thinking memories were never being automatically extracted from transcripts like episodic memories were.\n\nThinking memory extraction has now been added to run in parallel with episodic extraction using separate processing flags (`isThinkingProcessing` and `isProcessing`) to prevent concurrent access issues.","timestamp":"2025-12-21T19:27:11.509Z"}
{"action":"add","id":"72a61194-6daf-4f98-b097-82b9658462d9","subject":"Mutex lock failures occur when multiple processes load sqlite-vec concurrently","keywords":["mutex","sqlite-vec","concurrent","process","locking","error"],"applies_to":"global","occurred_at":"2025-12-21T18:21:04.841Z","content_hash":"f35ebd4203aa3ba6","content":"# Mutex Lock Error with sqlite-vec\n\nThe codebase has a known issue where multiple processes loading sqlite-vec can trigger \"mutex lock failed: Invalid argument\" errors. This occurs during concurrent access to the sqlite-vec library.\n\n## Context\n- Located in src/mcp-server/server.ts:230\n- Cross-process file locking is being used as a mitigation strategy\n- Mutex errors happen specifically when multiple processes try to load sqlite-vec simultaneously\n\n## Solution Applied\n- Cross-process file locking prevents sqlite-vec mutex errors\n- This suggests using file-based locks to serialize access to sqlite-vec across different processes\n\n## Testing Note\n- No existing tests found for mutex behavior (grep for 'mutex' and 'concurrent' returned no test files)\n- Tests for concurrent access patterns should be added to prevent regressions","timestamp":"2025-12-21T19:27:11.510Z"}
{"action":"add","id":"70db6bb7-6fb6-4199-99d5-0be1551433a7","subject":"Memory extraction and processing happens in MCP server, controlled by feature flags","keywords":["mcp server","memory extraction","background daemon","feature flags"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T18:27:35.712Z","content_hash":"c84223a4fcd4b65a","content":"The MCP server handles memory extraction and processing with the ability to disable either memory type:\n\n- Episodic extraction can be disabled with `LOCAL_RECALL_EPISODIC_ENABLED`\n- Thinking extraction can be disabled with `LOCAL_RECALL_THINKING_ENABLED`\n- The background daemon respects these flags to avoid processing disabled memory types\n- This allows users to opt-in/out of different memory systems without deleting existing memories","timestamp":"2025-12-21T19:27:11.511Z"}
{"action":"add","id":"d4847b04-0e9b-42bd-a736-233b497a2f5e","subject":"Thinking memory files are stored in plugin structure","keywords":["thinking","memory","files","plugin","8 files"],"applies_to":"file:dev-marketplace/local-recall-plugin/","occurred_at":"2025-12-21T18:30:11.718Z","content_hash":"0541c27f18796e03","content":"8 thinking memory files were added to the plugin during this session. These files capture Claude's reasoning patterns and outputs, helping future AI assistants understand how to approach similar tasks. The thinking memory storage is integrated into the plugin's skill structure.","timestamp":"2025-12-21T19:27:11.511Z"}
{"action":"add","id":"f78d009b-9f79-4f9c-845f-1612c4a43e28","subject":"Session-start hook is safe from ONNX mutex issues","keywords":["session-start","hook","memory-manager","file-based","safe"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:26:49.611Z","content_hash":"a433aaa9b2221b1b","content":"The session-start hook only uses MemoryManager (file-based, no embeddings) to load the 5 most recent memories. It doesn't instantiate any embedding models or vector stores, so it's not affected by ONNX mutex issues and can safely run in multiple concurrent Claude instances.","timestamp":"2025-12-21T19:27:11.511Z"}
{"action":"add","id":"2189898b-b584-472e-85a6-d5ef44a24e60","subject":"Version bumping forces plugin cache refresh in Claude marketplace","keywords":["version","plugin","cache","deployment","marketplace"],"applies_to":"global","occurred_at":"2025-12-12T10:19:41.481Z","content_hash":"a4270ab5260f72f0","content":"Bumping the version number in both package.json and .claude-plugin/plugin.json (e.g., 0.1.0 → 0.1.1) forces Claude to download a fresh copy of the plugin instead of using cached files. This is useful when the bundled server.js has been updated but users still have an old cached version. Users must uninstall/reinstall the plugin after a version bump to get the new deployment.","timestamp":"2025-12-21T19:27:11.512Z"}
{"action":"add","id":"70877504-b70f-4561-9d88-42bb48f7642a","subject":"Build script outputs to local-recall-plugin not dev-marketplace","keywords":["build","script","package.json","output","plugin-scripts"],"applies_to":"file:package.json","occurred_at":"2025-12-21T19:04:06.127Z","content_hash":"78e1037fe1a3252f","content":"The `build:scripts` npm script in package.json was updated to output built files to `local-recall-plugin/scripts/` instead of the old `dev-marketplace/local-recall-plugin/scripts/` path. This reflects the restructuring to the standard marketplace plugin layout.","timestamp":"2025-12-21T19:27:11.513Z"}
{"action":"add","id":"545fe9fd-0aa7-46c9-b0b2-903d09b3cb2d","subject":"Plugin cache MCP server needs bundled dependencies, not external imports","keywords":["plugin cache","bundling","esbuild","external dependencies","mcp sdk","deployment"],"applies_to":"file:package.json","occurred_at":"2025-12-21T18:31:23.288Z","content_hash":"9277338141d27f33","content":"The plugin deployment system caches MCP servers at `~/.claude/plugins/cache/` without including `node_modules`. The build script was using `--external:@modelcontextprotocol/sdk` which prevented bundling the MCP SDK into the server.js file.\n\nFix: Remove `--external:@modelcontextprotocol/sdk` from the esbuild configuration so that dependencies are bundled into a self-contained server.js (~1.1MB instead of 704KB).\n\nThis applies to the build script for dev-marketplace plugin deployment.","timestamp":"2025-12-21T19:27:11.514Z"}
{"action":"add","id":"2ce95ba7-83cb-4922-a0ca-510ccce49cb1","subject":"Memory types enabled by default in configuration","keywords":["episodicEnabled","thinkingEnabled","default configuration","memory types","types.ts"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:20:43.672Z","content_hash":"71f8eb8ba597f93a","content":"Both `episodicEnabled` and `thinkingEnabled` are set to `true` by default in `src/core/types.ts` lines 118-121. This means both episodic and thinking memories are active without requiring additional configuration changes.","timestamp":"2025-12-21T19:27:11.514Z"}
{"action":"add","id":"d0dc7dd3-7859-465e-9ad3-7b173e512feb","subject":"Claude project directories use path-to-dashes naming convention in ~/.claude/projects","keywords":["claude projects","project discovery","path convention","transcript location"],"applies_to":"global","occurred_at":"2025-12-21T19:19:53.624Z","content_hash":"92039a2d1fb6c954","content":"Claude stores projects in ~/.claude/projects using the full path with slashes replaced by dashes.\n\nExample: `/Users/joe/Code/Syntessera/local-recall` → `-Users-joe-Code-Syntessera-local-recall`\n\nTranscripts are stored directly in the project folder as `.jsonl` files, NOT in a `transcripts` subfolder.\n\nFix applied in `src/core/transcript-collector.ts`:\n- Prioritize searching ~/.claude/projects for directories matching the path-to-dashes pattern\n- Look for .jsonl files directly in the project directory\n- Use path conversion: `cwd.replace(/\\//g, '-')` to match Claude's naming scheme","timestamp":"2025-12-21T19:27:11.515Z"}
{"action":"add","id":"7b19a54b-07a1-417e-8cf5-4dd31a3ee261","subject":"Episodic memory is now enabled by default with unified hook architecture","keywords":["episodic","memory","enabled","default","hook","configuration"],"applies_to":"global","occurred_at":"2025-12-21T19:00:40.565Z","content_hash":"aa738d7ca654ebf0","content":"Changed episodic memory default from `false` to `true` in the configuration. This means episodic memories will be retrieved and injected by default unless explicitly disabled via `LOCAL_RECALL_EPISODIC_ENABLED=false` environment variable.","timestamp":"2025-12-21T19:27:11.516Z"}
{"action":"add","id":"82ea8226-96d3-4ab8-b93e-2b2f3501a8d0","subject":"Search results ranked by cosine similarity with recency tie-breaking","keywords":["search","scoring","cosine-similarity","tie-breaking","recency","ranking"],"applies_to":"file:src/core/search.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"fb3c2b1ed749d95a","content":"Search results use cosine distance similarity scoring (0.0 to 1.0 range, rounded to 2 decimals). Results are sorted by score descending. When scores are equal (tie), more recent memories (higher `occurred_at` timestamp) are ranked first. This ensures both relevance and freshness in memory retrieval.","timestamp":"2025-12-21T19:27:11.518Z"}
{"action":"add","id":"90b799ad-657e-4056-9864-7919176aa261","subject":"Plugin MCP server must have dependencies bundled due to no node_modules in deployment","keywords":["plugin","bundling","mcp-server","esbuild","dependencies"],"applies_to":"file:dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json","occurred_at":"2025-12-21T19:13:11.749Z","content_hash":"31638ce49cb15903","content":"The MCP server (scripts/mcp-server/server.js) must be bundled with all dependencies using esbuild without the `--external` flag. The plugin deployment does not include node_modules, so all required packages must be statically bundled into the server.js file. Previously, using `--external` caused the server to fail with missing dependencies when run in other Claude instances.","timestamp":"2025-12-21T19:27:11.519Z"}
{"action":"add","id":"2038d3cd-08b2-4fec-ab79-d8d6c5647976","subject":"MCP server daemon runs on startup with staggered initialization delays","keywords":["mcp","daemon","startup","initialization","timing"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:26:32.435Z","content_hash":"350afaa781d751e0","content":"The MCP server daemon runs on startup with staggered delays:\n- Vector sync: 2 seconds after server start (then every 10 minutes)\n- Transcript processing: 5 seconds after server start (then every 5 minutes)\n\nThis is implemented via setTimeout at lines 169-193 in server.ts. The delays allow the server to fully initialize before starting background tasks.","timestamp":"2025-12-21T19:27:11.519Z"}
{"action":"add","id":"b9cced40-ed25-47fd-ae49-572257fafdee","subject":"UserPromptSubmit hook mutex error caused by direct sqlite-vec loading in hook process","keywords":["mutex error","sqlite-vec","hook","libc++abi","file locking","concurrent access"],"applies_to":"global","occurred_at":"2025-12-21T19:16:20.911Z","content_hash":"1d912d52a836120d","content":"## Problem\nThe UserPromptSubmit hook was failing with: `libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument`\n\n## Root Cause\nThe hook was directly instantiating `SearchEngine` and `ThinkingSearchEngine` which load sqlite-vec (a C++ native module). When multiple hooks run concurrently, sqlite-vec's internal mutex fails because it's not designed for concurrent access from different processes.\n\n## Solution\nThe proper approach is to use HTTP daemon communication instead of direct database loading in hooks. Hooks should:\n1. Contact the MCP daemon via HTTP\n2. Let the daemon handle all database access\n3. Not load sqlite-vec or other native modules directly\n\n## Files Affected\n- src/hooks/user-prompt-submit.ts (needs refactor to use HTTP daemon)\n- src/utils/database.ts (file locking exists but insufficient for concurrent C++ module access)\n- src/core/vector-store.ts (uses sqlite-vec)\n\n## Logging Improvements Made\nAdded comprehensive logging to help diagnose similar issues:\n- PID logging `[PID:xxxx]` on all log entries to track which process is running\n- Lock acquisition timing and attempt counts\n- sqlite-vec load timing with separate measurements\n- Full stack traces on failures","timestamp":"2025-12-21T19:27:11.519Z"}
{"action":"add","id":"094b005e-3a73-4fb9-8685-abf9719dc488","subject":"Orama uses sqlite-vec backend which requires careful process isolation","keywords":["orama","sqlite-vec","vector-store","child-process","native-module","threading"],"applies_to":"global","occurred_at":"2025-12-21T18:28:52.966Z","content_hash":"85b6c5396dd9a8b4","content":"Orama (the vector store library used in local-recall) internally uses sqlite-vec as its backend. sqlite-vec is a native C++ module that manages its own mutexes for thread safety.\n\n### Implications\n1. **Process Isolation**: Orama indexes cannot be safely passed between parent and child processes\n2. **Threading Issues**: Multiple processes trying to access the same Orama instance will cause mutex conflicts\n3. **State Corruption**: Child processes inherit parent memory state, including partially-initialized sqlite-vec, which can corrupt the mutex\n\n### Best Practices\n- Initialize Orama in the process that will use it, not in a parent process\n- If using child_process.execFile(), ensure the child process independently initializes what it needs\n- Don't try to share Orama instances across process boundaries via serialization","timestamp":"2025-12-21T19:27:11.520Z"}
{"action":"add","id":"438836ac-26bc-4147-a486-26ffc24daaba","subject":"local_cache/ directory must be in .gitignore to prevent accidental commits","keywords":["gitignore","local_cache","cache","build output","exclusion"],"applies_to":"global","occurred_at":"2025-12-21T18:16:09.042Z","content_hash":"8abad5acbd817721","content":"The `local_cache/` directory contains temporary cache files (likely from Ollama or other build processes) that should never be committed to git. It must be explicitly listed in `.gitignore`. Files from this directory were previously committed to git history but have been removed using `git filter-branch`.","timestamp":"2025-12-21T19:27:11.520Z"}
{"action":"add","id":"0305f213-0a5e-40fc-9444-2a613d08360b","subject":"Stop hook redesigned to process entire transcript history","keywords":["stop-hook","transcript-processing","memory-extraction"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T18:22:28.112Z","content_hash":"4c9407aa4e1b74d6","content":"Removed 30-second time window filter that was preventing memory extraction. Now:\n\n- Processes entire transcript history instead of only recent messages\n- Allows duplicate detection via `occurred_at` + `content_hash` to skip re-extracting\n- Sends extracted memories to MCP server for creation\n\nOld design filtered messages older than 30 seconds, causing most content to be ignored by the time the hook fired.","timestamp":"2025-12-21T19:27:11.521Z"}
{"action":"add","id":"7c0f061d-9c74-4765-8136-c538dc073338","subject":"Folder renamed from 'memories' to 'episodic-memory' throughout codebase","keywords":["folder naming","episodic-memory","directory structure","refactoring"],"applies_to":"global","occurred_at":"2025-12-21T18:31:46.868Z","content_hash":"f81edcf947d64883","content":"The memory storage folder was renamed from 'memories' to 'episodic-memory' to better clarify its purpose. This change was applied across:\n\n- `src/core/memory.ts:34` - Updated folder path definition\n- `src/core/index.ts:30` - Updated folder path definition\n- `tests/unit/core/memory.test.ts:54` - Updated test expectations\n- Documentation files (CLAUDE.md, docs/mcp-server.md, docs/architecture.md)\n\nThe renaming distinguishes episodic memories from thinking memories, which are stored in the `thinking-memory` folder. Both folders are tracked in git.","timestamp":"2025-12-21T19:27:11.522Z"}
{"action":"add","id":"84b7de30-e8c5-4b96-a14e-bc6d29c86eb6","subject":"onnxruntime-node native mutex issue with fastembed in concurrent hook processes","keywords":["mutex","fastembed","onnxruntime-node","native bindings","concurrency","embedding","hook process"],"applies_to":"global","occurred_at":"2025-12-21T18:28:55.282Z","content_hash":"04f20297391e80fc","content":"After migrating from sqlite-vec to Orama, mutex errors persisted because fastembed (used for embeddings) depends on onnxruntime-node, which has native bindings that cause the same mutex contention issues as sqlite-vec when loaded by multiple concurrent hook processes. The solution is to serialize access using proper-lockfile with a file-based lock at `/tmp/local-recall-embedding.lock` with 10 retries and 30-second stale timeout, protecting both initialization and embedding operations.","timestamp":"2025-12-21T19:27:11.523Z"}
{"action":"add","id":"a8e84056-642d-4cf5-b66a-6382947b298f","subject":"Environment variables for controlling episodic and thinking memory systems","keywords":["environment variables","configuration","episodic memory","thinking memory","LOCAL_RECALL_EPISODIC_ENABLED","LOCAL_RECALL_THINKING_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:21:42.416Z","content_hash":"78bc3a53db7a9e66","content":"Added two environment variables to control memory systems:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory search, session-start retrieval, and extraction/processing\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory search and extraction/processing\n\nThese flags were added to:\n- `src/core/types.ts` - Config interface (lines 118-119)\n- `src/utils/config.ts` - Environment variable parsing (lines 56-61)\n- All hooks and MCP server were updated to check these flags before enabling/disabling features","timestamp":"2025-12-21T19:27:11.523Z"}
{"action":"add","id":"8bf28d71-1255-4f56-a270-df908216fd3f","subject":"User-prompt-submit hook consolidated from two separate hooks into one unified hook","keywords":["hook","user-prompt-submit","unified","episodic","thinking","consolidated"],"applies_to":"global","occurred_at":"2025-12-21T19:00:40.565Z","content_hash":"6d326443796bc523","content":"The two separate hooks (`user-prompt-submit.ts` and `user-prompt-submit-thinking.ts`) have been merged into a single `user-prompt-submit.ts` hook. This hook now handles both episodic and thinking memory retrieval based on configuration flags. The old `user-prompt-submit-thinking.ts` file has been deleted. This simplifies the hook architecture and allows users to enable/disable episodic and thinking memory independently.","timestamp":"2025-12-21T19:27:11.524Z"}
{"action":"add","id":"3ca6fc79-58bd-4c62-8f67-640f31e3836e","subject":"Vector search scoring: rounds to 2 decimals, uses recency as tie-breaker","keywords":["vector-search","scoring","similarity","recency","sorting","tie-breaking"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:24:20.066Z","content_hash":"99f2fde10cfb7419","content":"Vector search results use **cosine distance similarity scoring** with the following behavior:\n\n- **Score calculation**: `Math.round((1 - row.distance / 2) * 100) / 100` converts distance to similarity\n- **Score range**: 0.0 (no match) to 1.0 (identical), rounded to 2 decimal places (e.g., 0.65)\n- **Primary sort**: Results sorted by similarity score (descending) - highest scores first\n- **Tie-breaker**: When scores are equal, results are secondary sorted by `occurred_at` (descending) - more recent memories ranked first\n\nThis ensures cleaner score reporting and prioritizes recent relevant memories when similarity scores are equivalent.","timestamp":"2025-12-21T19:27:11.524Z"}
{"action":"add","id":"54abfb05-a084-4f25-99f7-35d35ebfff24","subject":"Thinking memories extracted from same AssistantMessageEntry containing both thinking and text blocks","keywords":["transcript structure","assistant message","thinking content","text content","extraction source"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:14:45.298Z","content_hash":"b0cc5417faa11c85","content":"The transcript structure stores thinking and output together in the same `AssistantMessageEntry`:\n\n- `ThinkingContent` blocks contain Claude's internal reasoning\n- `TextContent` blocks contain the visible output\n- `ToolUseContent` blocks contain tool calls\n\nThis means thinking and output don't require looking at the 'next' message - they're already paired in the same entry. This is why combining them into a single memory makes sense: they're already associated in the transcript data structure.\n\nFile: `src/types/transcript-schema.ts` defines the structure.","timestamp":"2025-12-21T19:27:11.525Z"}
{"action":"add","id":"5df59591-1a3c-4165-884e-c85692a7d9d2","subject":"Local Recall architecture uses Orama for vector search instead of previous embeddings approach","keywords":["orama","vector search","embeddings","architecture","search implementation"],"applies_to":"global","occurred_at":"2025-12-21T19:17:45.599Z","content_hash":"9d0b3086d8471497","content":"Local Recall has transitioned to using Orama (pure JavaScript vector database) for semantic search instead of previous embedding approaches. This is a key architectural decision that affects how memories are indexed and retrieved. Orama provides vector storage and similarity search with no native dependencies, making it ideal for Claude Code hooks which need to run in isolated processes.","timestamp":"2025-12-21T19:27:11.526Z"}
{"action":"add","id":"05ce931a-e9f3-4e10-86ba-da3451122308","subject":"Changed memory extraction to save all messages without filtering or trigger patterns","keywords":["memory extraction","transcript analysis","message filtering","trigger patterns removed","all messages saved"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-03T09:50:51.143Z","content_hash":"f72bafbd6b42fb51","content":"The `analyzeForMemories()` function in `src/utils/transcript.ts` was refactored to remove all filtering logic:\n\n## Changes Made\n\n1. **Removed** `USER_TRIGGER_PATTERNS` - previously matched phrases like \"remember this\", \"save this for later\", \"don't forget\", etc.\n\n2. **Removed** `AUTO_DETECT_PATTERNS` - previously detected patterns like architecture decisions, bugfixes, discoveries, and conventions\n\n3. **Simplified behavior** - now saves every message from the transcript:\n   - Skips only empty messages\n   - Formats each message with role prefix (`**user**:` or `**assistant**:`)\n   - No semantic filtering or heuristic-based selection\n\nThis change means all conversation content is now preserved in memory rather than using selective filtering based on trigger phrases or auto-detected patterns.","timestamp":"2025-12-21T19:27:11.526Z"}
{"action":"add","id":"e098330b-51e6-4aee-b2c0-a281236d1cc0","subject":"UUID filename validation required for transcript files","keywords":["transcript","uuid","validation","filename","collector","filtering"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:21:01.282Z","content_hash":"53c76763d80a2420","content":"Transcript files in the transcripts folder must have UUID filenames (format: `550e8400-e29b-41d4-a716-446655440000.jsonl`). Non-UUID `.jsonl` files should not be processed or copied. Implemented UUID validation via `UUID_REGEX` pattern and `isUuidFilename()` helper function. Applied validation in three locations:\n1. `findClaudeProjectDir()` - when discovering Claude project directories and checking for transcript files\n2. `listSourceTranscripts()` - when listing source transcripts from Claude's cache\n3. `listLocalTranscripts()` - when listing locally stored transcripts\n\nThis prevents false positives from miscellaneous `.jsonl` files that may exist in the transcripts directory.","timestamp":"2025-12-21T19:27:11.527Z"}
{"action":"add","id":"06986c70-37b7-4e6d-9f88-3d7f97ca7792","subject":"Memory index location is local-recall/index.json","keywords":["memory index","file location","data structure","vector index"],"applies_to":"global","occurred_at":"2025-12-21T18:26:34.189Z","content_hash":"be76fe92800d5d02","content":"The project's memory index is stored at `local-recall/index.json`. Memory files themselves are stored in the `local-recall/memories/` directory. These files are version-controlled in git as part of the project's persistent memory layer.","timestamp":"2025-12-21T19:27:11.527Z"}
{"action":"add","id":"4ba1450c-c1a7-49f2-b69d-b7ff921e9525","subject":"Gitignore patterns removed sqlite references after migration to Orama","keywords":["gitignore","sqlite","cleanup","documentation accuracy"],"applies_to":"file:local-recall/.gitignore","occurred_at":"2025-12-21T19:22:44.635Z","content_hash":"32f9089786e31ff4","content":"Removed outdated sqlite references from `.gitignore` and `src/utils/gitignore.ts` after complete migration from sqlite-vec to Orama. The patterns were misleading since the project no longer uses any SQLite dependencies in package.json.","timestamp":"2025-12-21T19:27:11.528Z"}
{"action":"add","id":"f4019f9a-7178-42af-b389-e150b101f190","subject":"Vector index is automatically generated and should not be checked into git","keywords":["vector index","orama","index file","gitignore","generated"],"applies_to":"global","occurred_at":"2025-12-21T18:27:35.568Z","content_hash":"638b39d8109ffb0a","content":"The file `local-recall/orama-episodic-index.json` is a generated vector index file that should be gitignored. It's created automatically when memories are added to the vector store. Similarly, `local-recall/orama-thinking-index.json` is the thinking memory index. These are not manually edited and are regenerated as needed.","timestamp":"2025-12-21T19:27:11.528Z"}
{"action":"add","id":"e8802895-dba5-400a-b6e2-7d2a0ce6e11c","subject":"Need to add mutex error tests for sqlite-vec concurrent access","keywords":["testing","mutex","sqlite-vec","concurrency","test coverage","concurrent processes"],"applies_to":"area:testing","occurred_at":"2025-12-21T19:18:27.194Z","content_hash":"69d73ef69730a921","content":"The project lacks test coverage for mutex and concurrency scenarios with sqlite-vec. This is a gap since the codebase implements cross-process file locking in src/mcp-server/server.ts to prevent mutex errors during concurrent access. Tests should cover: (1) multiple processes initializing sqlite-vec simultaneously, (2) file locking mechanism correctness, (3) error recovery when mutex locks fail.","timestamp":"2025-12-21T19:27:11.529Z"}
{"action":"add","id":"2c4a8bb1-e846-4cdb-b243-09b9d973cc50","subject":"Memory deduplication uses content_hash SHA-256 prefix and occurred_at timestamp","keywords":["memory","deduplication","content hash","occurred_at","duplicate detection"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"5abcf24edf3172c3","content":"The memory manager deduplicates memories using a combination of:\n1. `occurred_at` timestamp - when the original event occurred\n2. `content_hash` - SHA-256 prefix (16 characters) of the memory content\n\nThe `findDuplicate()` function checks both fields to identify if a memory already exists before creating a new one. This prevents duplicate memories from being created when the same concept is re-discovered in different sessions.","timestamp":"2025-12-21T19:27:11.529Z"}
{"action":"add","id":"13a804c6-1ec1-4a8f-8634-441503ed9f7e","subject":"Hook configuration and availability across Claude Code environments","keywords":["hooks","hook support","session start","user prompt submit","stop hook","environment differences"],"applies_to":"global","occurred_at":"2025-12-03T09:51:20.667Z","content_hash":"317986482e637be7","content":"Different Claude Code environments have varying hook support:\n\n- **SessionStart**: Fires reliably in VS Code extension\n- **UserPromptSubmit**: Fires reliably in VS Code extension  \n- **Stop**: Does NOT fire in VS Code extension (or fires rarely)\n\nHooks are configured in `dev-marketplace/local-recall-plugin/config/hooks.json`. When designing features that depend on hooks, the MCP daemon is a more reliable fallback mechanism for environments with limited hook support.","timestamp":"2025-12-21T19:27:11.530Z"}
{"action":"add","id":"a338f844-75c6-46d4-ba54-a5120f3488c8","subject":"Vector embedding approach uses BGE-small-en-v1.5 model with 384 dimensions","keywords":["vector","embedding","bge-small-en-v1.5","fastembed","384-dimensions","asymmetric"],"applies_to":"area:vector-store","occurred_at":"2025-12-03T09:50:05.007Z","content_hash":"a195f8317756dae7","content":"Local Recall uses the BGE-small-en-v1.5 embedding model via the fastembed library for semantic search. The model produces 384-dimensional embeddings and uses asymmetric embedding - passages (memories) are embedded differently than queries using passageEmbed() for documents and queryEmbed() for search queries. This asymmetric approach optimizes for the different use cases of indexing documents vs searching them.","timestamp":"2025-12-21T19:27:11.530Z"}
{"action":"add","id":"f5aa1ffb-d850-413e-94f9-b913840a5ca5","subject":"TranscriptMessage type now includes optional thinking field for storing Claude's reasoning","keywords":["types","thinking","transcript-message","schema"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:16:50.918Z","content_hash":"174d4b3b0de1c6dd","content":"Added `thinking?: string` optional field to `TranscriptMessage` interface at line 118 to support storing Claude's thinking blocks separately from answers. This allows transcript validation and analysis to distinguish between thinking content and response content.","timestamp":"2025-12-21T19:27:11.531Z"}
{"action":"add","id":"381a06e7-9f97-4a39-a088-2ae68e6037fc","subject":"Mutex errors occur when multiple processes load sqlite-vec concurrently","keywords":["mutex","sqlite-vec","concurrent","locking","error handling"],"applies_to":"global","occurred_at":"2025-12-21T19:17:36.210Z","content_hash":"8c98a7f5402c397c","content":"The codebase has a known issue where concurrent process loading of sqlite-vec can cause \"mutex lock failed: Invalid argument\" errors. This is mentioned in src/mcp-server/server.ts:230 with a comment about using cross-process file locking to prevent these errors. The issue occurs when multiple processes try to load the sqlite-vec library simultaneously, which suggests the MCP server needs to implement proper file locking mechanisms when initializing the vector store.","timestamp":"2025-12-21T19:27:11.531Z"}
{"action":"add","id":"fedd0e95-903e-4e29-953a-483aaaeae6ea","subject":"All three Local Recall hooks are functional and working together","keywords":["hooks","sessionstart","userpromptsubmit","stop hook","integration"],"applies_to":"global","occurred_at":"2025-12-21T18:16:21.840Z","content_hash":"750d274a137e7cc1","content":"The Local Recall system has three hooks that work together:\n\n1. **SessionStart** - Loads 5 most recent episodic memories at session start (verified: 8 memories loaded)\n2. **UserPromptSubmit** - Searches and injects relevant episodic and thinking memories before Claude processes prompts\n3. **Stop** - Fires at session end, processes the transcript, and creates new memories automatically (verified in recall.log)\n\nThis creates a complete cycle: memories loaded → memories searched → new memories created. The system is fully operational and requires no additional fixes.","timestamp":"2025-12-21T19:27:11.531Z"}
{"action":"add","id":"af4eaf44-0d96-4e41-821e-00ab8c245cf9","subject":"Thinking memory extraction must run in daemon, not in user-prompt-submit hook","keywords":["thinking-extraction","daemon","concurrency","sqlite-mutex","hook-crash"],"applies_to":"global","occurred_at":"2025-12-21T19:24:52.567Z","content_hash":"46233fec8bbb7b7b","content":"## Problem\n\nWhen both episodic and thinking user-prompt-submit hooks fire simultaneously, they create a race condition:\n- `user-prompt-submit.js` opens `memory.sqlite` via VectorStore\n- `user-prompt-submit-thinking.js` opens `memory.sqlite` via ThinkingVectorStore\n- sqlite-vec extension's native mutex fails under concurrent access\n- Results in: `libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument`\n\n## Solution\n\nThinking memory extraction is now handled by the background daemon (`src/mcp-server/server.ts`) in parallel with episodic memory extraction:\n- Both use separate processing flags: `isProcessing` (episodic) and `isThinkingProcessing` (thinking)\n- Both run every 5 minutes on the daemon's interval\n- No longer running in hooks, eliminating concurrent SQLite access\n- The thinking hook (`user-prompt-submit-thinking.js`) was causing the crash and should be removed from hook configuration\n\n## Implementation Details\n\n`src/mcp-server/server.ts` additions:\n- Import `runThinkingExtraction` from thinking-extractor.js\n- Import `getThinkingVectorStore` and `ThinkingMemoryManager` from thinking modules\n- Add `isThinkingProcessing` flag (lines ~40)\n- Add `runThinkingExtraction()` call in daemon loop (lines ~110)\n- Similar processing pattern to episodic: check flag, run extraction, update flag","timestamp":"2025-12-21T19:27:11.532Z"}
{"action":"add","id":"e0818d86-a99e-4a9d-84e1-285f4c7f8790","subject":"Logger warn method accepts single argument only","keywords":["logger","api-constraint","logging","error-handling"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T18:14:34.568Z","content_hash":"93df7607b92d9c99","content":"The logger utility's `warn()` method in `src/utils/logger.ts` only accepts a single argument (the message). When refactoring error handling, ensure you don't pass multiple arguments to warn() - if you need to log multiple values, either stringify them together or use separate log calls.","timestamp":"2025-12-21T19:27:11.532Z"}
{"action":"add","id":"62505f2f-b02e-4091-9322-717fbefdae4e","subject":"Session start loads all memories and returns 5 most recent, not a delta","keywords":["session-start","memory-loading","hook","full-reload"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:20:08.847Z","content_hash":"95b15a2feec1a58e","content":"# Session Start Memory Loading\n\nThe SessionStart hook performs a **full reload** of all memories, not a delta:\n\n**Process**:\n1. Creates a fresh `MemoryManager` instance\n2. Calls `listMemories()` to load all memories from disk\n3. Sorts by `occurred_at` descending (newest first)\n4. Takes the 5 most recent memories\n5. Returns them as context to inject into Claude's session\n\n**Key Points**:\n- Not incremental - always loads all memories then filters to top 5\n- Each session starts fresh with the most recent context\n- No tracking of what was shown in previous sessions\n- Simple and reliable, no complex delta logic needed","timestamp":"2025-12-21T19:27:11.533Z"}
{"action":"add","id":"5fba50d4-f1e3-4b93-81c5-49b5d93a0181","subject":"TranscriptMessage now includes optional thinking field","keywords":["types","transcript","thinking","message","schema"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:16:05.970Z","content_hash":"076468abd7e5b7e7","content":"Added optional `thinking?: string` field to TranscriptMessage interface (line 118) to support separate storage of Claude's thinking blocks. This allows transcript validation and analysis to handle thinking content independently from response content.","timestamp":"2025-12-21T19:27:11.534Z"}
{"action":"add","id":"616a75e0-ab11-4688-b97c-8da6307ff2a1","subject":"ONNX runtime mutex errors prevent concurrent embedding model loading in hooks","keywords":["mutex","onnx","concurrency","embeddings","fastembed","locking"],"applies_to":"global","occurred_at":"2025-12-21T19:20:35.399Z","content_hash":"e48d514f2ca55c11","content":"The mutex errors encountered were from ONNX runtime (fastembed backend), not sqlite-vec. When multiple Claude instances run simultaneously, their hooks all try to load the ONNX embedding model concurrently, triggering system-level mutex conflicts. The `proper-lockfile` file-based locking cannot prevent ONNX's internal mutex issues.\n\nTested with 3 batches of concurrent processes and confirmed 15 mutex errors from 15 concurrent processes.\n\nRoot cause: `user-prompt-submit.ts` hook directly instantiates SearchEngine which loads the embedding model. File-based locking is insufficient for ONNX runtime's native mutex protection.\n\n**Solution**: Use Ollama as a shared embedding daemon. One process loads ONNX once, multiple clients call via HTTP API. This prevents the concurrent initialization that causes mutex conflicts.","timestamp":"2025-12-21T19:27:11.534Z"}
{"action":"add","id":"df7f9e04-2632-43b1-adb9-ede1840e7b28","subject":"Memory extraction should use [LOCAL_RECALL_INTERNAL] token prefix for internal prompts","keywords":["internal token","extraction prompts","testing friendly","recursion prevention"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:19:12.033Z","content_hash":"669f1eb2e8d5a28e","content":"Use [LOCAL_RECALL_INTERNAL] as a prefix token at the start of internal/system prompts (like keyword extraction) rather than checking the content. This makes the system more testable - users can test with prompts containing 'Extract keywords...' without triggering the recursion guard. The hook checks startsWith('[LOCAL_RECALL_INTERNAL]') to identify internal calls.","timestamp":"2025-12-21T19:27:11.534Z"}
{"action":"add","id":"5a4a7f1c-326a-4de8-8e49-582a6cbb8e7e","subject":"Test suite for transcript-condenser covers entry type parsing and content extraction with edge cases","keywords":["testing","transcript-condenser","unit-tests","vitest","edge-cases"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-03T09:49:49.357Z","content_hash":"581af3ee8a9c200e","content":"# Transcript Condenser Tests\n\nComprehensive test suite in `tests/unit/core/transcript-condenser.test.ts` validates:\n\n## Test Coverage\n- Parsing each JSONL entry type (user, assistant, system, etc.)\n- Extracting minimal but sufficient content from each type\n- Handling edge cases:\n  - Empty content blocks\n  - Missing optional fields\n  - Large outputs (verified they're truncated)\n  - Thinking blocks with multiple entries\n  - Tool operations with various result types\n\n## Test Patterns\nUses Vitest for unit testing with fixtures for different transcript scenarios. All tests pass successfully.\n\n## Integration\nTests ensure the condenser produces valid input for the memory extraction subprocess.","timestamp":"2025-12-21T19:27:11.535Z"}
{"action":"add","id":"4245f153-6e6b-48bb-8c51-6d069eedc570","subject":"Improved error handling in UserPromptSubmit hook with stack traces and timing","keywords":["hook","error handling","logging","user-prompt-submit","stack trace"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:18:36.755Z","content_hash":"7ffd2c3a4c692726","content":"Enhanced the UserPromptSubmit hook with better error handling and logging:\n- Wraps main function in try-catch with comprehensive error logging\n- Logs timing for episodic and thinking memory searches separately\n- Includes stack traces for debugging\n- Tracks token usage and memory counts\n- Better error context helps identify where failures occur in the search pipeline","timestamp":"2025-12-21T19:27:11.535Z"}
{"action":"add","id":"8759ede8-ac73-4857-8881-447461a5e385","subject":"Mutex errors caused by onnxruntime-node native bindings in fastembed, not sqlite-vec","keywords":["mutex","fastembed","onnxruntime-node","native bindings","concurrent processes","hook architecture"],"applies_to":"global","occurred_at":"2025-12-21T19:22:44.635Z","content_hash":"291550299e9a4151","content":"After migrating to Orama (pure JavaScript vector store), mutex errors were still occurring. Root cause investigation revealed that `fastembed` depends on `onnxruntime-node`, which has native bindings that create the same mutex contention issues as the previous `sqlite-vec` implementation when multiple hook processes load it concurrently. The issue occurs both during initialization and during embedding inference operations.\n\nThis is a fundamental problem with loading native modules from multiple CLI hook processes - only one process can hold the mutex lock at a time, causing other processes to fail.","timestamp":"2025-12-21T19:27:11.537Z"}
{"action":"add","id":"c94e0033-b781-467b-a442-a5e37606a99e","subject":"Agent memories require multi-line content to be saved","keywords":["memory filtering","agent messages","multi-line","single-line","memory storage"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:13:49.919Z","content_hash":"05ac33f4d838a549","content":"Tool invocation and agent memories (assistant messages marked as internal) must have at least 2 non-empty lines to be saved. Single-line messages are filtered out. This prevents storing trivial or incomplete agent responses.","timestamp":"2025-12-21T19:27:11.537Z"}
{"action":"add","id":"90e1242b-57ff-4dd3-a43d-67f440facbb2","subject":"Build process compiles TypeScript and runs additional build scripts","keywords":["build","typescript","npm","tsc","build-scripts"],"applies_to":"global","occurred_at":"2025-12-03T09:51:12.210Z","content_hash":"b4c3b447418c3d9a","content":"The local-recall project uses `npm run build` which runs `tsc && npm run build:scripts`. The TypeScript compiler (`tsc`) must pass without errors before the build scripts execute. This is a sequential pipeline where TypeScript compilation is the first gate - any type errors will prevent the build scripts from running.","timestamp":"2025-12-21T19:27:11.538Z"}
{"action":"add","id":"732c324e-1b1a-4547-b494-e6ace8a40123","subject":"Three pathways for data to enter the SQLite vector store: on-creation, on-sync, and background daemon","keywords":["data-flow","vector-store","sync","daemon","embedding"],"applies_to":"global","occurred_at":"2025-12-21T19:20:08.847Z","content_hash":"4212cea966869a87","content":"# Vector Store Data Loading Pathways\n\nThere are three ways data flows into the SQLite vector store:\n\n**1. On Memory Creation (Immediate)**\n- Location: `src/core/memory.ts:107-113`\n- When `MemoryManager.createMemory()` is called:\n  - Memory written to disk as markdown file\n  - `vectorStore.add(memory)` called immediately\n  - Embedding generated via Ollama\n  - Record inserted into SQLite\n\n**2. Vector Store Sync (Periodic)**\n- Location: `src/mcp-server/server.ts:73`\n- Called during daemon runs\n- `vectorStore.sync(memories)` reconciles file-based memories with vector store\n- Adds missing memories, removes deleted ones\n- Ensures consistency between disk and database\n\n**3. Background Daemon (Every 5 minutes)**\n- Location: `src/mcp-server/server.ts` daemon loop\n- Processes transcripts from Claude cache\n- Creates new memory files\n- Triggers sync to populate vector store\n\nEach pathway ensures embeddings are generated and stored atomically.","timestamp":"2025-12-21T19:27:11.538Z"}
{"action":"add","id":"d6047e1d-9f17-420a-869d-d07e0439a39a","subject":"Session-start hook simplified to use file-based MemoryManager","keywords":["hooks","session-start","memory-manager","file-based"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"84211962fde3e6de","content":"Simplified the session-start hook to only use the file-based MemoryManager:\n\n- Removed HTTP daemon calls and DaemonClient\n- Now directly calls `listMemories()` to get recent memories without semantic search\n- No vector store operations needed for this hook (just returns most recent)\n- Returns memories from episodic or thinking stores based on configuration\n- Falls back gracefully if memory retrieval fails\n\nThis is safe because the hook only needs recency ranking (already provided by filesystem timestamps), not semantic search.","timestamp":"2025-12-21T19:27:11.540Z"}
{"action":"add","id":"e8e905b3-c0f5-4f94-a6e2-8a4c89074bac","subject":"Testing infrastructure runs successfully with npm test","keywords":["testing","jest","npm","test-suite","build"],"applies_to":"global","occurred_at":"2025-12-21T18:27:59.719Z","content_hash":"ab0f64e909c90dae","content":"The project includes a working test suite that can be executed with `npm test`. The build process completes successfully with `npm run build` and produces output without errors. All tests pass after the transcript-collector UUID validation changes were implemented, indicating the modifications don't break existing functionality.","timestamp":"2025-12-21T19:27:11.540Z"}
{"action":"add","id":"f66ede80-5877-4b29-a632-c0e450310822","subject":"Claude transcripts stored in ~/.claude/projects/<sanitized-path>/transcripts/","keywords":["claude-projects","transcript-storage","path-sanitization","home-directory"],"applies_to":"global","occurred_at":"2025-12-12T10:04:58.695Z","content_hash":"5dd4ed22fadfffe0","content":"Claude Code stores project transcripts in a specific location:\n\n- **Base directory**: `~/.claude/projects/`\n- **Project folder**: Sanitized version of the working directory path (slashes replaced with dashes)\n- **Example**: Project at `/Users/joe/projects/my-app` stores transcripts in `~/.claude/projects/-Users-joe-projects-my-app/transcripts/`\n\nThe transcript collector uses this path to locate and sync transcripts from Claude's cache into the local-recall memory system.","timestamp":"2025-12-21T19:27:11.541Z"}
{"action":"add","id":"ef9ed755-fdeb-4a78-afc3-6a3f8d48c23f","subject":"Memory deduplication uses occurred_at timestamp and content hash","keywords":["deduplication","memory-creation","content-hash","idempotency","duplicate-detection"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"3019d891f68e4afd","content":"When creating a memory, the system checks for duplicates using `findDuplicate(occurredAt, contentHash)` which compares the timestamp and 16-character SHA-256 content hash prefix. If a matching duplicate exists, the existing memory ID is returned instead of creating a new file. This ensures idempotency: calling create multiple times with the same data returns the same memory ID.","timestamp":"2025-12-21T19:27:11.542Z"}
{"action":"add","id":"2465bc21-253b-4425-8b50-c8c7da8e6206","subject":"Test coverage added for memory extractor parseClaudeResponse","keywords":["tests","memory-extractor","unit-tests","vitest","parseClaudeResponse"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T19:18:46.281Z","content_hash":"dbc464300819f591","content":"Created comprehensive unit test file (tests/unit/core/memory-extractor.test.ts) with 6 test cases covering: array format handling, nested object format, error handling for invalid Zod schema, and edge cases. All 220 tests pass in the project.","timestamp":"2025-12-21T19:27:11.543Z"}
{"action":"add","id":"5b8dceaf-24bc-4147-a6c1-4d85b6cae1ae","subject":"Configuration changes required updates across multiple hook and server files","keywords":["configuration","hooks","server","refactoring","consistent implementation"],"applies_to":"global","occurred_at":"2025-12-21T18:29:50.448Z","content_hash":"00273ae730b95b70","content":"When adding the episodic/thinking enabled flags, the following files all needed to be updated consistently:\n\n1. `src/core/types.ts` - Config interface schema\n2. `src/utils/config.ts` - Environment variable parsing\n3. `src/hooks/user-prompt-submit.ts` - Episodic memory search\n4. `src/hooks/user-prompt-submit-thinking.ts` - Thinking memory search  \n5. `src/hooks/session-start.ts` - Session startup memory injection\n6. `src/mcp-server/server.ts` - Server-side extraction and tools\n\nAll files needed the same pattern: import `getConfig`, check the appropriate enabled flag before processing memories. This suggests configuration changes should be tracked broadly across the codebase to ensure consistency.","timestamp":"2025-12-21T19:27:11.544Z"}
{"action":"add","id":"f1122ce4-d58f-47cd-9443-7f6799acb501","subject":"Transcript dataset contains 39,879 files with 12,594 synthetic and 27,285 real transcripts","keywords":["transcripts","synthetic","counting","validation","dataset","claude-opus"],"applies_to":"global","occurred_at":"2025-12-03T09:47:02.103Z","content_hash":"cb014236375ef573","content":"The local-recall/transcripts directory contains 39,879 total JSONL transcript files. Of these, 12,594 are synthetic files (generated during memory extraction tests) and 27,285 are real transcripts from actual Claude sessions. Only 51 transcripts (out of ~40k) contain thinking blocks, totaling 1,101 thinking block instances.\n\nSynthetic files can be identified by the presence of `\"<synthetic>\"` in the model field. Real transcripts use models like `claude-opus-4-5-20251101`. Files with thinking blocks also contain `thinkingMetadata` with fields like `{\"level\":\"high\",\"disabled\":false,\"triggers\":[]}` and thinking block objects with `{\"type\":\"thinking\",\"thinking\":\"...\",\"signature\":\"...\"}`.","timestamp":"2025-12-21T19:27:11.545Z"}
{"action":"add","id":"e6402cd0-0404-4254-a66e-6179fbd9ad13","subject":"MCP server is running from dev-marketplace plugin subdirectory","keywords":["mcp server","plugin architecture","dev-marketplace","process running"],"applies_to":"global","occurred_at":"2025-12-21T19:23:27.035Z","content_hash":"21c4c61811c0d816","content":"The MCP server is currently running as a background process (PID 4524) from `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js`, not from the main project root. The main project root doesn't have a `scripts/` directory yet - it appears the build output or plugin structure diverges from the core local-recall project.\n\nThe MCP configuration is at `dev-marketplace/local-recall-plugin/.mcp.json` rather than the project root. This suggests local-recall is being developed as a plugin within a larger marketplace/platform structure.","timestamp":"2025-12-21T19:27:11.546Z"}
{"action":"add","id":"44d94925-ed54-494c-ad62-22364d2e2cc1","subject":"Thinking memory extraction was not running in the daemon - now added","keywords":["thinking memory","daemon","extraction","parallel processing","mcp server"],"applies_to":"global","occurred_at":"2025-12-03T09:49:02.141Z","content_hash":"c0c28c857bafca77","content":"The thinking memory extraction was implemented but never actually called by the MCP server daemon. Previously, only episodic memory extraction ran via `runTranscriptProcessing()` from `memory-extractor.js`. Thinking memory extraction via `runThinkingExtraction()` from `thinking-extractor.ts` was never invoked. This has been fixed by adding thinking extraction to run in parallel with episodic extraction in the daemon loop, with separate processing flags to prevent concurrent runs: `isEpisodicProcessing` and `isThinkingProcessing`.","timestamp":"2025-12-21T19:27:11.546Z"}
{"action":"add","id":"74cf1443-bfdd-4bfa-8ae2-a353b01d5646","subject":"Over 400 new episodic and thinking memories created recently","keywords":["episodic-memory","thinking-memory","batch-creation","memory-extraction"],"applies_to":"global","occurred_at":"2025-12-21T18:24:32.614Z","content_hash":"d6022b249eddb84c","content":"# Recent Memory Creation Spike\n\nThe git status shows 400+ new memory files (untracked) across both episodic and thinking memory directories:\n\n**Episodic memories**: Approximately 200+ new files in `local-recall/episodic-memory/`\n**Thinking memories**: Approximately 200+ new files in `local-recall/thinking-memory/`\n\nThese represent newly extracted memories that haven't been staged yet. This suggests:\n1. Recent transcript processing has been extracting memories at scale\n2. The memory extraction system (transcript-collector, memory-extractor) is working actively\n3. These memories are ready to be added to the git repository once reviewed\n\nThe volume indicates the system is creating meaningful, extractable memories from Claude Code sessions.","timestamp":"2025-12-21T19:27:11.547Z"}
{"action":"add","id":"4db6c6c9-d052-40bf-bf0c-d9e021c816b1","subject":"Transcript collector logging strategy for debugging missing transcripts","keywords":["transcript-collector","logging","debug","claude-projects","info-level"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-12T10:04:58.695Z","content_hash":"a7f10227f7da9fcc","content":"When transcript collection fails in new repos, the issue is often visibility. The transcript collector already had debug-level logging, but those aren't shown by default. Added INFO-level logging at key points:\n\n1. **Search initiation** - Log the search start and project path being searched\n2. **Directory existence checks** - Log whether ~/.claude/projects exists\n3. **Path construction** - Log the expected folder name (sanitized project path)\n4. **Results** - Log how many transcripts were found (or 0 if none)\n5. **Sync summary** - Log detailed summary of what was copied/updated\n\nThis makes troubleshooting missing transcripts much easier since users can see the exact paths being searched in `local-recall/recall.log`.","timestamp":"2025-12-21T19:27:11.548Z"}
{"action":"add","id":"2962446c-ccb0-4009-8482-d53b3262feb4","subject":"UserPromptSubmit hook returns JSON but requires .claude/settings.json configuration","keywords":["hooks","userpromptsubmit","configuration","json","claude","settings"],"applies_to":"global","occurred_at":"2025-12-21T19:20:51.697Z","content_hash":"cd8010fd22165966","content":"The UserPromptSubmit hook in src/hooks/user-prompt-submit.ts correctly returns JSON output via `console.log(JSON.stringify(output))` with structure `{ hookSpecificOutput: { hookEventName, additionalContext } }`. However, the hook won't fire unless it's properly configured in `.claude/settings.json`. Without this configuration file, the hook is never invoked even though the code is correct.","timestamp":"2025-12-21T19:27:11.549Z"}
{"action":"add","id":"b13b1c04-5bd7-4957-8272-04fa50bdcf0e","subject":"Transcript collection logging uses INFO level, not DEBUG","keywords":["transcript","logging","discovery","debug level","log verification"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:31:15.659Z","content_hash":"c2e0c010dafa977e","content":"Transcript discovery logs (searching for Claude projects, finding transcript directories) use INFO-level logging, not DEBUG. This helps distinguish transcript collection activity in recall.log. When upgrading the MCP server, ensure you rebuild with `npm run build` to get the latest logging changes, otherwise old cached versions may show different log messages.","timestamp":"2025-12-21T19:27:11.549Z"}
{"action":"add","id":"1427d584-8cdf-447c-997b-aa00754c35dd","subject":"thinking.jsonl is a leftover artifact from incomplete migration, should be deleted","keywords":["cleanup","migration","thinking.jsonl","artifact","old-format"],"applies_to":"global","occurred_at":"2025-12-21T19:13:46.767Z","content_hash":"e618e4ecfc8ce1af","content":"The file `thinking.jsonl` (2.8MB, 2121 lines) is a leftover from the first storage migration (Markdown → single JSONL). This predates the current multi-file format migration.\n\nFile status:\n- `thinking.jsonl` - OLD single-file format (should be deleted)\n- `thinking-000001.jsonl` - NEW multi-file format (155 lines, 191KB)\n\nThe old file should be removed as it's redundant with the new multi-file approach.","timestamp":"2025-12-21T19:27:11.550Z"}
{"action":"add","id":"ae4ad79c-f9f5-4804-8ecd-ffd885209121","subject":"Gitignore management should always write, not just create missing files","keywords":["gitignore","auto-generated","sqlite","memory","file-system"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:17:02.145Z","content_hash":"f9cc4b38919bb146","content":"The ensureGitignore() function only created gitignore if it didn't exist, meaning existing files weren't updated with new patterns. Since the gitignore is auto-generated, it should always be written to ensure new patterns (like memory.sqlite) are properly ignored. This ensures consistency across new user setups.","timestamp":"2025-12-21T19:27:11.551Z"}
{"action":"add","id":"a0ea002b-db52-4f6e-bc54-b0b7dec6b838","subject":"Thinking memory hook returns 10 items default, up to 25 if similarity > 90%","keywords":["thinking hook","similarity threshold","result limit","high similarity"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-21T18:15:46.377Z","content_hash":"cbb1f90a3ea47821","content":"Modified the thinking memory hook (lines 77-98) to use tiered result filtering:\n- Fetches up to 25 candidate results from vector search\n- Returns first 10 items by default (DEFAULT_LIMIT = 10)\n- Includes items 11-25 only if their similarity score >= 0.90 (HIGH_SIMILARITY_THRESHOLD)\n\nThis provides a good baseline of diverse thinking examples while allowing highly relevant high-similarity items to expand the context window when appropriate.","timestamp":"2025-12-21T19:27:11.552Z"}
{"action":"add","id":"6911b86b-4314-4298-ac54-58d9af3b22c6","subject":"MCP server bundling requires dependencies included in compiled output","keywords":["mcp-server","esbuild","bundling","external dependencies"],"applies_to":"file:dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json","occurred_at":"2025-12-12T10:19:41.481Z","content_hash":"141a5daccddb1fa1","content":"The MCP server (server.js) must be compiled with all dependencies bundled into a single file since the plugin environment doesn't include node_modules. The build script should NOT use esbuild's `--external` flag for the MCP server build. The compiled server.js should be ~1.1MB when properly bundled with all dependencies.","timestamp":"2025-12-21T19:27:11.553Z"}
{"action":"add","id":"158f2e78-3898-4c6d-bb50-abc5017e78e3","subject":"Episodic memory disabled by default in configuration","keywords":["episodic memory","default configuration","disabled","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:18:46.418Z","content_hash":"1ab48d6c49b8fcfd","content":"Changed the default value of `episodicEnabled` from `true` to `false` in the configuration schema. This means episodic memory retrieval is now disabled by default unless explicitly enabled via `LOCAL_RECALL_EPISODIC_ENABLED=true` environment variable or `\"episodicEnabled\": true` in `.local-recall.json` config file.\n\nModified files:\n- `src/core/types.ts:118` - schema default in Zod schema\n- `CLAUDE.md` - configuration table documentation\n\nUsers must explicitly opt-in to episodic memory retrieval.","timestamp":"2025-12-21T19:27:11.554Z"}
{"action":"add","id":"504fb0b5-379f-461d-be94-8b652f8268f2","subject":"Version synchronization across multiple plugin manifest files","keywords":["version","package.json","plugin.json","marketplace.json","sync"],"applies_to":"global","occurred_at":"2025-12-21T19:00:39.886Z","content_hash":"26bf3347eeea9f8f","content":"Local Recall has version references in three places that must stay in sync:\n1. `package.json` - npm package version\n2. `.claude-plugin/plugin.json` - Claude plugin manifest\n3. `.claude-plugin/marketplace.json` - marketplace distribution manifest\n\nWhen bumping versions, ALL three files must be updated together. Missing any causes version mismatches between the distributed package and marketplace metadata.","timestamp":"2025-12-21T19:27:11.555Z"}
{"action":"add","id":"d6d39d7a-e35e-4855-9c9e-89a830d14483","subject":"Memory deduplication uses occurred_at timestamp and content_hash for duplicate detection","keywords":["deduplication","duplicate detection","content hash","occurred_at"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"aa0d48568ab760c4","content":"The findDuplicate() function checks for existing memories using occurred_at timestamp and SHA-256 content_hash prefix (16 chars) to identify duplicate memories. This allows idempotent memory creation operations where creating the same memory twice returns the existing memory rather than duplicating it.","timestamp":"2025-12-21T19:27:11.556Z"}
{"action":"add","id":"a66dfd7f-d830-47bc-aaa9-fa0900eb1a36","subject":"Only save assistant messages, not user messages, in transcript memory extraction","keywords":["transcript","memory extraction","user messages","assistant messages","filtering"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:13:49.919Z","content_hash":"2c3b93606814e375","content":"When extracting memories from transcripts, only process assistant messages. User messages should be skipped entirely. This keeps memories focused on Claude's outputs and reasoning rather than user inputs.","timestamp":"2025-12-21T19:27:11.556Z"}
{"action":"add","id":"f38a2265-7643-497c-b366-839f99f2c27f","subject":"Thinking memories should capture all thinking but only multiline answers","keywords":["thinking","memory extraction","transcript analysis","multiline"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:18:43.074Z","content_hash":"72ac02ee14be7fb3","content":"When analyzing transcripts for memories, the system should:\n- Save ALL thinking content (even single-line), without any prefix modification\n- Save ONLY multiline answers (content with 2+ lines)\n- Use `generateSubject()` to extract the first line for multi-line text, or first sentence for single-line text\n\nThis creates an asymmetric memory pattern: all internal reasoning is captured, but only more substantial responses are saved as separate memories.","timestamp":"2025-12-21T19:27:11.557Z"}
{"action":"add","id":"33227aa3-c422-4110-a531-3e7e852a8499","subject":"UUID filename validation required for transcript files","keywords":["transcript","uuid","filename","validation","transcript-collector"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:54.287Z","content_hash":"e233c4c844d66267","content":"Transcript files in Claude's transcript folders must have UUID filenames (e.g., `550e8400-e29b-41d4-a716-446655440000.jsonl`). Non-UUID files should not be processed or copied. Added UUID_REGEX pattern and isUuidFilename() helper function to validate filenames before processing. This is validated in three places:\n1. findClaudeProjectDir() - when discovering transcript directories\n2. listSourceTranscripts() - when collecting transcripts from source\n3. listLocalTranscripts() - when listing local processed transcripts\n\nThis prevents accidental processing of non-transcript files that might exist in the transcripts folder.","timestamp":"2025-12-21T19:27:11.558Z"}
{"action":"add","id":"d11f2aa9-6556-4d61-9e78-5c599af4aa26","subject":"Episodic and thinking memory vectors need separate index files and processing pipelines","keywords":["episodic-memory","thinking-memory","vector-store","orama","index","separate","independent"],"applies_to":"area:vector-store","occurred_at":"2025-12-21T19:02:32.602Z","content_hash":"b1098f4786fdae5f","content":"Local Recall maintains separate vector indexes for episodic and thinking memories:\n- `orama-episodic-index.json` - Vector index for episodic memories\n- `orama-thinking-index.json` - Vector index for thinking memories\n\nThese indexes are built and maintained independently. Each memory type has its own:\n- Vector store instance (episodic vs thinking)\n- Search implementation\n- Processing pipeline (transcript extraction for episodic, thinking block extraction for thinking)\n- Configuration thresholds (episodicMinSimilarity vs thinkingMinSimilarity)\n\nThis separation allows independent configuration and retrieval of each memory type.","timestamp":"2025-12-21T19:27:11.558Z"}
{"action":"add","id":"a480f0e4-2bc4-4a3c-a9aa-bafefc707d2e","subject":"Local-recall .gitignore should track the file itself in git","keywords":["gitignore","version-control","local-recall","git-tracking"],"applies_to":"global","occurred_at":"2025-12-21T18:17:18.600Z","content_hash":"fde99ad3ebe68cee","content":"The `local-recall/.gitignore` file itself is version-controlled and tracked in git (unlike the index files it specifies). The file should be added to git commits so that all developers get the same gitignore configuration.\n\nCurrent .gitignore pattern: Ignores index files (`orama-*-index.json`), processed logs (`*-processed-log.jsonl`), and debug logs (`recall.log`).","timestamp":"2025-12-21T19:27:11.559Z"}
{"action":"add","id":"018cbc91-4a5d-4161-a17f-3223b00b3e47","subject":"Commit 91d7734: Major refactor replacing SQLite with Orama","keywords":["commit","refactor","114-files","orama","architecture"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"a7d880fe1b5e4aab","content":"Significant architectural refactoring in commit 91d7734: 114 files changed (+3,120 / -1,843 lines). Replaced SQLite + sqlite-vec with Orama vector search. Removed daemon architecture. Added 11 episodic memories and ~70 thinking memories. Simplified hooks to work directly without HTTP communication.","timestamp":"2025-12-21T19:27:11.569Z"}
{"action":"add","id":"2e62e305-83a4-48fa-8f01-08dba5df177f","subject":"File-based locking mechanism prevents sqlite-vec concurrent loading crashes","keywords":["sqlite-vec","mutex","file-lock","concurrency","database","hook"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T19:14:44.781Z","content_hash":"8b2855ba8a9d46b5","content":"The `sqlite-vec.load(db)` function crashes with a C++ runtime mutex error when called concurrently from multiple hook processes. This cannot be caught in JavaScript.\n\nImplemented file-based locking in `loadDatabase()` to prevent concurrent sqlite-vec initialization:\n1. Creates a lock file (`<db-path>.lock`) before loading sqlite-vec\n2. Waits with exponential backoff if lock exists (checks every 10ms, max 1000 iterations)\n3. Removes lock file after initialization\n4. Detects and removes stale locks (older than 30 seconds)\n\nThis serializes sqlite-vec loading across concurrent hook invocations while remaining non-blocking for normal database operations.","timestamp":"2025-12-21T19:27:11.570Z"}
{"action":"add","id":"f458c3dd-088f-4829-999c-24e3fe431f69","subject":"Config utility updated to parse new episodic and thinking memory environment variables","keywords":["config","utils","environment-variables","parsing"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-03T09:50:15.512Z","content_hash":"9b75b698f449663f","content":"Updated `src/utils/config.ts` to parse the new environment variables for episodic memory configuration:\n- `LOCAL_RECALL_EPISODIC_MAX_TOKENS`\n- `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY`\n\nThese are now parsed and validated alongside existing thinking memory configuration variables.","timestamp":"2025-12-21T19:27:11.571Z"}
{"action":"add","id":"6644b279-a0cd-45c6-a654-541fea0c03b3","subject":"Local Recall project has working core infrastructure with memory CRUD, indexing, hooks, and MCP server","keywords":["local-recall","architecture","project-status","infrastructure","implemented"],"applies_to":"global","occurred_at":"2025-12-21T18:21:41.992Z","content_hash":"aac9ee4a64c524fd","content":"Local Recall has successfully implemented the core infrastructure:\n\n- **Memory Management**: Complete CRUD operations in `src/core/memory.ts`\n- **Indexing**: Index management system in `src/core/index.ts` using Fuse.js for fuzzy search\n- **Hooks**: Two Claude Code hooks are complete:\n  - `session-start` hook loads relevant memories at session start\n  - `stop` hook auto-extracts memories from transcripts\n- **MCP Server**: Fully implemented with 6 exposed tools\n- **Keyword Extraction**: Working system for extracting searchable keywords\n- **Search**: Complete fuzzy search implementation in `src/core/search.ts`\n\nThe foundation is stable and ready for enhancement. Next priorities are higher-level features like CLI, deduplication, memory decay, or smart retrieval.","timestamp":"2025-12-21T19:27:11.572Z"}
{"action":"add","id":"a9008978-6d15-45b4-9057-4856d4db0066","subject":"User preference: reject daemon architecture for embedding service","keywords":["daemon","embedding","architecture","multi-instance","claude"],"applies_to":"global","occurred_at":"2025-12-21T18:24:57.085Z","content_hash":"7e91db6ec03e12a1","content":"User explicitly rejected a shared embedding daemon approach (either external HTTP server or built into MCP server) because it would prevent running multiple Claude instances simultaneously. The requirement is: embeddings must work with multiple concurrent Claude instances without conflicts.","timestamp":"2025-12-21T19:27:11.573Z"}
{"action":"add","id":"14a362eb-4191-4e60-9187-23404a179000","subject":"Transcript parsing needs backward compatibility for test format","keywords":["transcript","parsing","backward-compatibility","testing","role-field"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:28:33.686Z","content_hash":"b51195c5ade5ef44","content":"When updating transcript parsing to handle actual Claude Code format (with content blocks), maintain backward compatibility with existing test format that uses `role: \"assistant\"|\"user\"` instead of `type: \"message\"|\"user_message\"`.\n\nThe parser should gracefully handle both formats:\n1. Modern format: `type` field with `content` as array of blocks\n2. Legacy test format: `role` field with `content` as string or already-extracted thinking\n\nThis prevents breaking existing tests while supporting the real transcript format.","timestamp":"2025-12-21T19:27:11.573Z"}
{"action":"add","id":"9f2dec6f-fa57-4393-b6b2-d888e1a29cbd","subject":"Memory system defaults: episodic off by default, thinking on by default","keywords":["default configuration","episodic memory disabled","thinking memory enabled","initialization"],"applies_to":"global","occurred_at":"2025-12-21T19:21:42.416Z","content_hash":"f8207159e521e495","content":"Design decision: Episodic memories default to OFF while thinking memories default to ON. This reflects that thinking memories are more consistently useful for future sessions, while episodic memories require more careful curation. Users can enable episodic memories via `LOCAL_RECALL_EPISODIC_ENABLED=true` environment variable.","timestamp":"2025-12-21T19:27:11.574Z"}
{"action":"add","id":"525ecbd7-6014-457d-907e-c94539ba0645","subject":"SessionStart hook now loads recent memories directly without vector store","keywords":["sessionstart","performance","optimization","recent-memories"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:15:38.757Z","content_hash":"bd58d8d4d427f734","content":"Changed SessionStart hook to load the 5 most recent memories by reading files directly and sorting by occurred_at timestamp, rather than initializing the vector store. This avoids the overhead of loading the embedding model (133MB download + initialization) on every session start. The hook now completes in milliseconds instead of timing out.","timestamp":"2025-12-21T19:27:11.574Z"}
{"action":"add","id":"48044a37-1314-4f41-a80a-8e69a2d728d5","subject":"Stop hook performs keyword extraction on transcripts for memory creation","keywords":["stop-hook","keywords","rake-pos","transcript","memory-extraction"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:20:40.036Z","content_hash":"c5c3914ce78c51fc","content":"The stop hook (src/hooks/stop.ts) processes transcripts to extract memories. It uses the rake-pos library for keyword extraction (RAKE algorithm with POS tagging). The hook:\n1. Reads transcript from path provided in hook input\n2. Parses transcript content\n3. Extracts keywords using RAKE + POS tagging\n4. Creates memory records with these keywords\n5. Requires npm dependencies to be installed (rake-pos not available without npm install)","timestamp":"2025-12-21T19:27:11.575Z"}
{"action":"add","id":"7a63e551-da61-497e-ad6b-28fd306bd8c9","subject":"Architecture: Thinking memories and episodic memories operate independently with separate hooks","keywords":["architecture","hooks","thinking memories","episodic memories","user-prompt-submit"],"applies_to":"global","occurred_at":"2025-12-21T18:17:09.782Z","content_hash":"2fa384143b623f8c","content":"The local-recall system has two independent memory systems that can be configured separately:\n\n**Episodic Memories** (`user-prompt-submit.ts` hook):\n- Store facts and contextual information\n- Default similarity threshold: 0.5\n- Default token budget: 1000\n- Configuration: `episodicEnabled`, `episodicMaxTokens`, `episodicMinSimilarity`\n\n**Thinking Memories** (`user-prompt-submit-thinking.ts` hook):\n- Store thought→output examples\n- Default similarity threshold: 0.8 (higher bar for relevance)\n- Default token budget: 1000\n- Configuration: `thinkingEnabled`, `thinkingMaxTokens`, `thinkingMinSimilarity`\n\nBoth can be enabled/disabled independently and have separate vector stores with different Orama indexes.","timestamp":"2025-12-21T19:27:11.575Z"}
{"action":"add","id":"6ab16d4a-2162-4ebb-b9b5-29eaf19c2fad","subject":"Memory extraction must handle thinking blocks from content arrays correctly","keywords":["thinking blocks","content blocks","extraction","transcript","memory"],"applies_to":"global","occurred_at":"2025-12-21T18:27:11.223Z","content_hash":"a39fbb90a8250afa","content":"When extracting memories from transcripts:\n- Thinking blocks are objects with `type: 'thinking'` and `thinking` property (not `text`)\n- Content blocks array may contain multiple types: text blocks and thinking blocks\n- Use `extractThinkingFromBlocks()` to get thinking content\n- Use `extractTextFromBlocks()` to get text content\n- Both all thinking content (even single-line) and multiline content get saved as memories\n- Single-line content is filtered out (only multiline is saved)","timestamp":"2025-12-21T19:27:11.577Z"}
{"action":"add","id":"e5724017-3479-4c63-87ff-20afdaabf391","subject":"Storage format migration: JSONL files should live in episodic-memory/ and thinking-memory/ folders, not root","keywords":["migration","jsonl","storage","folder-structure","episodic","thinking"],"applies_to":"global","occurred_at":"2025-12-21T19:13:46.767Z","content_hash":"b82c91df19c79b02","content":"The project is undergoing a storage migration from individual markdown files to JSONL format. The expected final state is:\n\n- JSONL files should be stored IN the episodic-memory/ and thinking-memory/ folders (not in local-recall/ root)\n- Example: `local-recall/episodic-memory/episodic-000001.jsonl` instead of `local-recall/episodic-000001.jsonl`\n- All *.md files should be deleted after migration\n- The JSONL files should contain embedding vectors alongside the memory data (not stored separately in Orama index)\n\nCurrent state has JSONL files in root directory with minimal entries, and markdown files still exist across 779 episodic and 2132 thinking memory files.","timestamp":"2025-12-21T19:27:11.577Z"}
{"action":"add","id":"1225a822-091d-415c-aa04-43aa161bc7bd","subject":"Transcript types pre-calculated in TypeScript schema","keywords":["transcript-schema","JSONL types","Claude Code transcript format","type safety"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T18:30:37.940Z","content_hash":"8bd5d655b4f0c99c","content":"Created comprehensive TypeScript types for Claude Code transcript JSONL format in src/types/transcript-schema.ts (433 lines). Includes:\n\n- **Entry types**: User, Assistant, System, FileHistorySnapshot, QueueOperation\n- **Content blocks**: TextContent, ThinkingContent, ToolUseContent, ToolResultContent, ImageContent\n- **Tool definitions**: FileTools (Read, Edit, Write, Glob, Grep), ShellTools (Bash, BashOutput), MCP tools\n- **Complete metadata**: timestamps, message IDs, session info\n\nThese types enable type-safe parsing of transcripts and form the basis for selective content extraction in the condenser.","timestamp":"2025-12-21T19:27:11.578Z"}
{"action":"add","id":"ca99731f-6283-45ce-bf43-c3d483b0272c","subject":"MCP server configuration location and structure","keywords":["mcp server","settings","configuration",".claude/settings.local.json","environment variables"],"applies_to":"global","occurred_at":"2025-12-21T18:31:41.980Z","content_hash":"7e0e0b90a7e1234e","content":"MCP server configuration is defined in `.claude/settings.local.json`. Environment variables are passed via the `env` object in the MCP server configuration. Key environment variables include `LOCAL_RECALL_DIR` for the memory directory path and feature flags like `LOCAL_RECALL_EPISODIC_ENABLED`.","timestamp":"2025-12-21T19:27:11.579Z"}
{"action":"add","id":"b803f1c8-b531-4d85-b8fd-e65b32511fdd","subject":"JSONL storage format for episodic and thinking memories with 6-digit padding","keywords":["jsonl","storage","episodic-memory","thinking-memory","serialization","padding"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"53686a9cdee571d9","content":"Memories are stored in JSONL format (JSON Lines) with filenames using 6-digit zero-padded sequential numbering: `episodic-000001.jsonl`, `episodic-000002.jsonl`, etc. This replaces individual markdown files and provides better I/O performance for batch operations. The format enables efficient streaming and processing of large memory collections. See `src/core/episodic-jsonl-store.ts` and `src/core/thinking-jsonl-store.ts` for implementation.","timestamp":"2025-12-21T19:27:11.579Z"}
{"action":"add","id":"693dfe14-4dba-426b-93f1-4b0f4dec90de","subject":"Memory reprocessing flow uses content hash for deduplication","keywords":["content hash","deduplication","memory extraction","reprocessing","processed-log"],"applies_to":"global","occurred_at":"2025-12-21T18:31:46.868Z","content_hash":"20eda06df0069da0","content":"The memory extraction system uses a content hash-based approach for handling transcript changes:\n\n1. `transcript-collector.ts` detects changes by comparing file size and mtime\n2. `memory-extractor.ts` computes the actual content hash and processes the transcript\n3. `processed-log.ts` tracks processed transcripts by their content hash\n4. When a transcript's content changes (detected via hash), old memories associated with that transcript are deleted before creating new ones\n\nThis ensures that reprocessing a transcript doesn't create duplicate memories - old ones are cleaned up first based on the content hash comparison.","timestamp":"2025-12-21T19:27:11.580Z"}
{"action":"add","id":"1ed884fb-0be8-46c7-ad6a-077167c2011c","subject":"Memory extraction prompt starts with [LOCAL_RECALL_INTERNAL] prefix for hook filtering","keywords":["memory extraction","prompt prefix","hook filtering","local recall internal"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-03T09:48:52.171Z","content_hash":"ae4af993508c2f3f","content":"The `buildMemoryExtractionPrompt` function was updated to prepend `[LOCAL_RECALL_INTERNAL]` to the memory extraction prompt (line 62-63). This prefix signals to the UserPromptSubmit hook (at `src/hooks/user-prompt-submit.ts:161`) that the prompt is internal and should skip processing, preventing the MCP daemon from triggering memory extraction recursion when calling `claude -p`.","timestamp":"2025-12-21T19:27:11.581Z"}
{"action":"add","id":"7e427241-b195-4e96-af3c-d3fdc3f6a7ed","subject":"Memory vector index uses cosine distance scoring for similarity","keywords":["vector store","orama","cosine distance","similarity score","embeddings"],"applies_to":"global","occurred_at":"2025-12-21T18:28:17.619Z","content_hash":"b8c357ed92f14504","content":"The Orama vector store uses cosine distance for similarity scoring with results ranging from 0.0 (no match) to 1.0 (identical). Scores are rounded to 2 decimal places. When scores are equal, results use recency tie-breaking based on the `occurred_at` field to rank newer memories first.","timestamp":"2025-12-21T19:27:11.582Z"}
{"action":"add","id":"0ee65a35-8377-43c6-871b-8add709b6b46","subject":"Multiple Claude instances cannot safely share a single daemon process","keywords":["daemon","architecture","multi-instance","claude","design-pattern"],"applies_to":"global","occurred_at":"2025-12-21T18:26:49.611Z","content_hash":"0a6f39e9e1fc58c6","content":"A local HTTP daemon approach (embedding server built into MCP server) won't work for multiple Claude instances because each instance would still create its own daemon process, leading to multiple ONNX loads and the same mutex issues.\n\nThe fundamental requirement: multiple Claude instances running simultaneously need either (1) a true shared singleton daemon like Ollama that runs outside of Claude, or (2) pure-JavaScript libraries that don't have ONNX concurrency limitations.","timestamp":"2025-12-21T19:27:11.582Z"}
{"action":"add","id":"2be9547f-9a6e-4ffa-afc1-2dffd598c7ef","subject":"Stop hook is disabled; memory extraction handled by MCP daemon","keywords":["stop-hook","memory-extraction","mcp-daemon","transcript-processing","background-processing"],"applies_to":"global","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"81416325cd65eb4f","content":"The Stop hook is currently disabled because memory extraction moved to the MCP server daemon. The daemon processes transcripts asynchronously every 5 minutes (configurable via `indexRefreshInterval`). This approach avoids blocking the Claude Code UI and allows processing of long transcripts. The daemon uses `claude -p` to extract memories from transcripts and tracks processed transcripts with content hashes for change detection.","timestamp":"2025-12-21T19:27:11.586Z"}
{"action":"add","id":"6fedac24-ebbd-49c0-acd0-f803395da446","subject":"Transcript message type needs optional thinking field for capturing Claude's reasoning separately","keywords":["transcript","types","thinking","message","typescript"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:18:08.509Z","content_hash":"633536f909be2d04","content":"Added optional `thinking?: string` field to `TranscriptMessage` type to capture Claude's internal reasoning blocks separately from the final response. This allows the memory system to store all thinking (even single-line) while only saving multiline answers.","timestamp":"2025-12-21T19:27:11.586Z"}
{"action":"add","id":"e7ece1e2-9198-4de0-94b3-1f2573b9babb","subject":"Local Recall has three main hooks: SessionStart, UserPromptSubmit, and Stop","keywords":["hooks","session-start","user-prompt-submit","stop","claude code integration","context injection"],"applies_to":"global","occurred_at":"2025-12-21T18:21:53.570Z","content_hash":"3bca80e6ef5816ee","content":"Local Recall integrates with Claude Code through three hooks:\n\n1. **SessionStart Hook** (`src/hooks/session-start.ts`)\n   - Triggered when a Claude Code session begins\n   - Loads memory index from `local-recall/index.json`\n   - Searches for relevant memories based on context (files, areas)\n   - Outputs memories to stdout for injection into Claude's context\n   - Shows index statistics\n\n2. **UserPromptSubmit Hook** (`src/hooks/user-prompt-submit.ts`)\n   - Triggered when user submits a prompt before Claude processes it\n   - Performs semantic search on memories relevant to the prompt\n   - Filters results and injects into context\n\n3. **Stop Hook** (`src/hooks/stop.ts`)\n   - Handles session cleanup and memory processing\n   - Can trigger memory extraction from transcripts\n\nAll hooks work with the vector-backed memory system to provide context-aware information injection.","timestamp":"2025-12-21T19:27:11.587Z"}
{"action":"add","id":"77dc218a-fa01-445e-8f33-65e3d4871354","subject":"Memory deduplication uses content hash and timestamp to prevent duplicates","keywords":["deduplication","content-hash","occurred-at","duplicate-detection"],"applies_to":"global","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"b498c244fc5388f0","content":"The memory system prevents duplicate memories using a two-factor approach:\n\n1. **Content hash**: SHA-256 hash (16-char prefix) of the memory content\n2. **Timestamp**: `occurred_at` ISO-8601 timestamp of when the event occurred\n\nBefore creating a new memory, the system checks if a memory with the same `occurred_at` and `content_hash` already exists. If found, it returns the existing memory ID instead of creating a duplicate.\n\nThis approach allows identical memories from different sessions while preventing true duplicates.","timestamp":"2025-12-21T19:27:11.587Z"}
{"action":"add","id":"e241b8cf-ecfa-43dc-8086-ed8bdfc58e34","subject":"Logger.warn() method takes only one argument","keywords":["logger","warn","api","method-signature"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:11:11.958Z","content_hash":"c356b53e551cd499","content":"The `logger.warn()` method in `src/utils/logger.ts` accepts only a single argument (the message). When updating code that uses the logger, ensure warn calls don't pass multiple arguments - use string interpolation instead.","timestamp":"2025-12-21T19:27:11.588Z"}
{"action":"add","id":"3c3e2055-d400-48dd-b86c-521a5c555f4e","subject":"Plugin deployment uses versioned cache directory at ~/.claude/plugins/cache/","keywords":["plugin","deployment","cache","version","mcp-server","path"],"applies_to":"global","occurred_at":"2025-12-21T19:13:11.749Z","content_hash":"43fc580bfcb58b87","content":"The local-recall plugin deploys to `~/.claude/plugins/cache/local-recall-marketplace/local-recall/{version}/` where `{version}` is the version number in plugin.json. Other Claude instances that install the plugin will use this cached deployment. The build script must bundle all dependencies into the MCP server (no `--external` flag) since node_modules are not shipped with the plugin. Version bumps force fresh deployments and invalidate old cached versions.","timestamp":"2025-12-21T19:27:11.588Z"}
{"action":"add","id":"636c4805-7490-4ec2-ba36-a5c2f5994686","subject":"MCP tools renamed with episodic_ prefix and thinking tools added","keywords":["mcp","tools","episodic","thinking","refactoring"],"applies_to":"global","occurred_at":"2025-12-21T19:04:16.673Z","content_hash":"74d3f960ec60999a","content":"## MCP Tool Changes\n\nThe MCP server tools were refactored to improve clarity and add thinking memory support:\n\n### Removed Tools\n- `index_rebuild` - Removed to prevent excessive LLM power\n- `memory_list` - Removed to limit LLM capabilities\n\n### Renamed Tools\nAll episodic memory tools now use the `episodic_` prefix:\n- `episodic_create` - Create episodic memories\n- `episodic_get` - Retrieve specific episodic memory by ID\n- `episodic_search` - Semantic search of episodic memories\n\n### New Thinking Memory Tools\nAdded parallel tools for thinking memories:\n- `thinking_get` - Retrieve specific thinking memory by ID\n- `thinking_search` - Semantic search of thinking memories\n\n**Location**: `src/mcp-server/tools.ts`\n\nThis change clearly delineates memory types and prevents the LLM from having access to potentially dangerous operations like index rebuilding or listing all memories.","timestamp":"2025-12-21T19:27:11.589Z"}
{"action":"add","id":"8288de05-16e9-4879-a07b-70593b48cb2b","subject":"Memory extractor uses 10 concurrent workers for transcript processing","keywords":["concurrency","memory-extractor","parallel","workers","performance"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:14:34.568Z","content_hash":"ccb7450c83a5051e","content":"The memory extractor in `src/core/memory-extractor.ts:39` uses a `concurrency: 10` setting to control how many transcript processing tasks run in parallel. This can be increased to higher values (e.g., 20) for faster processing when needed, depending on system resources and transcript volume.","timestamp":"2025-12-21T19:27:11.589Z"}
{"action":"add","id":"542a5c38-a7f6-4db3-94cb-9be68e859548","subject":"Local Recall project has core CRUD operations and MCP server fully implemented","keywords":["local-recall","architecture","implementation-status","core-components","mcp-server"],"applies_to":"global","occurred_at":"2025-12-21T18:23:32.479Z","content_hash":"287ad69db0894804","content":"The Local Recall memory system has the following components completed:\n- Core memory CRUD operations (memory.ts)\n- Index management for semantic search\n- Fuzzy search implementation using Fuse.js\n- MCP Server with 6 exposed tools\n- Session-start hook for loading relevant memories\n- Stop hook for automatic memory extraction from transcripts\n- Keyword extraction utilities\n\nThese are the foundational components. Future work can focus on CLI tools, memory deduplication, or live testing.","timestamp":"2025-12-21T19:27:11.590Z"}
{"action":"add","id":"afb2b1eb-6388-429c-8344-c107b2fe5e75","subject":"MCP server exposes memory tools for Claude Code and Claude Desktop integration","keywords":["mcp-server","tools","integration","claude-code","claude-desktop"],"applies_to":"global","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"9c5b4862907cc3da","content":"The MCP server provides tool interfaces for memory operations. Configuration varies depending on installation context:\n- As npm package: uses `./node_modules/local-recall/dist/` paths\n- From project directory: uses local `./dist/` paths\nBoth require `LOCAL_RECALL_DIR` environment variable to locate memory storage.","timestamp":"2025-12-21T19:27:11.591Z"}
{"action":"add","id":"97cc0b0d-caf0-486c-ae44-048e0591e5ec","subject":"JSONL storage format migration with episodic and thinking memory memories","keywords":["jsonl","storage","episodic-memory","thinking-memory","migration","multi-file"],"applies_to":"global","occurred_at":"2025-12-21T19:23:42.660Z","content_hash":"961d9f9b9fca5192","content":"Local Recall uses JSONL (JSON Lines) format for storing memories with multi-file support:\n\n- Episodic memories stored in `local-recall/episodic-000001.jsonl`, `episodic-000002.jsonl`, etc.\n- Thinking memories stored in `local-recall/thinking-000001.jsonl`, `thinking-000002.jsonl`, etc.\n- Files use 6-digit zero-padded numbering for proper sorting\n- Each line is a complete JSON object representing one memory\n- Allows better scalability than individual markdown files\n- Migration involved converting from individual markdown files to JSONL format\n- Recent commits: feat: Migrate memory storage to JSONL format with multi-file support (445109d)","timestamp":"2025-12-21T19:27:11.591Z"}
{"action":"add","id":"31a184e8-abcf-4963-897c-b934dc3e9b52","subject":"Recursion guard using [LOCAL_RECALL_INTERNAL] token prevents infinite hook loops","keywords":["recursion prevention","hook guard","internal prompts","user prompt submit"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:26:30.211Z","content_hash":"613fb1f7a5e235b1","content":"The UserPromptSubmit hook can recursively fire when calling `claude -p` for memory extraction. Prevent this by: 1) Prefixing internal extraction prompts with `[LOCAL_RECALL_INTERNAL]` token, 2) Checking `prompt.startsWith('[LOCAL_RECALL_INTERNAL]')` to skip processing, 3) Using `--strict-mcp-config` flag to disable MCP servers during extraction subprocess. This token-based approach is better than content-based checks because it allows testing with extraction-related prompts without triggering the guard.","timestamp":"2025-12-21T19:27:11.592Z"}
{"action":"add","id":"c47ca81f-4dab-4906-b803-eed185d76185","subject":"Background daemon in MCP server processes transcripts every 5 minutes for memory extraction","keywords":["daemon","mcp server","transcript processing","memory extraction","background job"],"applies_to":"area:mcp-server","occurred_at":"2025-12-03T09:49:57.517Z","content_hash":"e0a1aec150eaeb2b","content":"The MCP server (`src/mcp-server/server.ts`) runs a background daemon that automatically processes transcripts every 5 minutes when `episodicEnabled` is true. This daemon extracts memories from transcripts using the `MemoryExtractor` class (`src/core/memory-extractor.ts`). The daemon is not a separate process but runs as part of the MCP server lifecycle.","timestamp":"2025-12-21T19:27:11.593Z"}
{"action":"add","id":"886da0ee-b63f-481e-9637-db2eadb702fd","subject":"Remove thinking user-prompt-submit hook after daemon integration","keywords":["hook-configuration","user-prompt-submit-thinking","deprecated","daemon"],"applies_to":"global","occurred_at":"2025-12-21T19:24:52.567Z","content_hash":"f74c793a5c45b70b","content":"After adding thinking memory extraction to the daemon:\n\n1. The `user-prompt-submit-thinking.js` hook is no longer needed and should be removed from `.claude/settings.json`\n2. Only keep the episodic `user-prompt-submit.js` hook for searching memories\n3. The thinking hook was causing mutex lock failures due to concurrent SQLite access\n4. All extraction now happens reliably in the daemon background process","timestamp":"2025-12-21T19:27:11.593Z"}
{"action":"add","id":"9be38505-d4fa-4ab3-9317-3f1cb8a38305","subject":"Memory types enabled by default in configuration","keywords":["episodicEnabled","thinkingEnabled","default configuration","types.ts","memory types"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:27:36.265Z","content_hash":"bff990f9707cbc6d","content":"Both `episodicEnabled` and `thinkingEnabled` are set to `true` by default in `src/core/types.ts` lines 118-121. This means both episodic and thinking memories are active for users without requiring explicit configuration.","timestamp":"2025-12-21T19:27:11.593Z"}
{"action":"add","id":"5441c333-bd97-4631-aed3-4f3039b243cf","subject":"Logging strategy for database operations includes PID tracking and operation timing","keywords":["logging","database","pid","timing","debug","file-locking"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T19:16:09.210Z","content_hash":"3019ecdf2ae4adb8","content":"Enhanced logging in database.ts now includes:\n- `[PID:xxxx]` prefix on all log entries to identify the process\n- Lock acquisition logging showing attempt count and elapsed time\n- Separate timing for sqlite-vec load vs total database initialization time\n- Full stack traces on failure for easier debugging\n\nThis is especially important for the hook system where multiple processes access the same database concurrently.","timestamp":"2025-12-21T19:27:11.594Z"}
{"action":"add","id":"27de3a91-75ba-47e4-b02f-16ae39af6369","subject":"Thinking memory similarity threshold uses decimal notation (0.0-1.0)","keywords":["thinking memory","similarity","threshold","configuration","0.8"],"applies_to":"global","occurred_at":"2025-12-21T19:14:59.463Z","content_hash":"bba8ad59c3a76749","content":"The thinking memory minimum similarity threshold is configured using decimal notation (0.0 to 1.0) where 0.8 = 80% similarity.\n\nConfiguration:\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` (env var, default: 0.8)\n- Used in search filtering to only include memories above the threshold\n- Different from episodic memories which may use different notation\n- Stored as a number in the config schema, not a percentage string","timestamp":"2025-12-21T19:27:11.594Z"}
{"action":"add","id":"da3a0bb7-4a61-458b-9246-da128951a4f9","subject":"SQLite mutex lock failure when both episodic and thinking hooks run simultaneously","keywords":["sqlite","mutex","concurrent access","race condition","hooks","thinking hook","episodic hook"],"applies_to":"global","occurred_at":"2025-12-21T18:29:49.579Z","content_hash":"6a5422b063562b63","content":"Both `user-prompt-submit.js` and `user-prompt-submit-thinking.js` hooks run as separate processes and try to access the same `memory.sqlite` file simultaneously. When both hooks fire on user prompt submit, they create a race condition where both try to initialize/lock the same SQLite database. The `sqlite-vec` extension's native mutex handling fails under concurrent access, throwing `std::__1::system_error: mutex lock failed: Invalid argument`.\n\nThe solution is to move thinking memory extraction to the MCP daemon where it can be serialized and run sequentially with episodic extraction (or with its own timing), rather than having it run as a concurrent hook process.","timestamp":"2025-12-21T19:27:11.594Z"}
{"action":"add","id":"4cf66de3-5ff2-4498-8f8b-e9fcd22beb8e","subject":"Hook execution is stable after Orama migration","keywords":["hooks","testing","stability","orama","user-prompt-submit"],"applies_to":"global","occurred_at":"2025-12-21T19:01:52.332Z","content_hash":"0b1d0da169cc739a","content":"Verified through testing that hooks (UserPromptSubmit and SessionStart) execute cleanly without errors after the Orama migration. The hooks complete successfully without mutex or concurrency issues. This confirms the migration was successful and the hook architecture is now more robust.","timestamp":"2025-12-21T19:27:11.595Z"}
{"action":"add","id":"4d25720d-c824-4710-8122-96b41e87b625","subject":"Memory deduplication strategy - occurrence time and content hash","keywords":["deduplication","memory-manager","findDuplicate","content-hash","occurred-at"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:17:09.190Z","content_hash":"4f360531207d6bf5","content":"MemoryManager prevents duplicates using `findDuplicate(occurredAt, contentHash)` (line 52-67). Before creating a memory, it checks if one with the same timestamp AND content hash already exists. If found, returns existing memory instead of creating new one.\n\nThis is the ONLY deduplication/compaction mechanism - there is no periodic cleanup, pruning, or consolidation of old memories. The `maxMemories` config option exists (default 1000) but is not enforced in the current implementation.","timestamp":"2025-12-21T19:27:11.595Z"}
{"action":"add","id":"5f5adabc-dcdc-4c87-964e-6e30e2871f60","subject":"Nomic-embed-text model has 2048 token context limit","keywords":["ollama","nomic-embed-text","embedding","context limit","truncation","2048 tokens"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T19:00:26.631Z","content_hash":"84758c0a366d4815","content":"The `nomic-embed-text` embedding model used for vector search has a **2048 token context limit** (trained on max 2048 tokens). When input text exceeds this, Ollama's subprocess panics with EOF errors and internal routing failures.\n\nThe fix is to truncate input text to ~6000 characters (~1500 tokens, leaving safety margin) before sending to Ollama's `/api/embeddings` endpoint. This prevents model context overflow while maintaining semantic quality of embeddings.\n\nError pattern: \"requested context size too large for model num_ctx=8192 n_ctx_train=2048\"","timestamp":"2025-12-21T19:27:11.596Z"}
{"action":"add","id":"af1a4a64-737f-485d-bf9d-8794c5ca01f7","subject":"Ollama is the recommended solution for multi-instance Claude support","keywords":["ollama","embedding","daemon","multi-instance","nomic-embed-text","http","api"],"applies_to":"global","occurred_at":"2025-12-21T18:26:49.611Z","content_hash":"bc6fc8aba4c44909","content":"Ollama provides a shared embedding server that eliminates ONNX mutex issues by centralizing the model loading. Multiple Claude instances can call the same Ollama daemon via HTTP API instead of each loading their own ONNX runtime.\n\nOllama advantages:\n- Single model instance shared across all processes\n- HTTP API (no native dependencies in hooks)\n- Runs as a background service\n- Supports the nomic-embed-text model (768 dimensions, ~274MB)\n- Easy installation via package managers (brew on macOS, apt on Linux)\n- Auto-starts as a service on macOS\n\nSetup:\n1. Install: `brew install ollama` (macOS) or download from ollama.com\n2. Pull model: `ollama pull nomic-embed-text`\n3. Runs on port 11434 by default\n\nHooks would call Ollama's HTTP embedding endpoint instead of loading fastembed directly, preventing concurrent ONNX initialization issues.","timestamp":"2025-12-21T19:27:11.596Z"}
{"action":"add","id":"1fbc05a1-f995-4b91-96d0-c3823729bb91","subject":"MCP server distribution requires git-tracked scripts for Claude Code plugins","keywords":["mcp-server","plugin","distribution","github","git-tracked","local-recall-plugin","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T18:23:00.278Z","content_hash":"778000e39e00df20","content":"Claude Code fetches plugins from GitHub repositories. The MCP server startup failure was caused by `local-recall-plugin/scripts/` being in .gitignore, so the plugin couldn't find the compiled hook scripts when Claude Code attempted to load it.\n\n**Solution**: Remove the scripts directory from .gitignore so that the compiled hooks are available when the plugin is distributed via GitHub.\n\n**Affected files**:\n- `local-recall-plugin/.gitignore` - needs to whitelist `scripts/` directory\n- `local-recall-plugin/scripts/` - must be git-tracked for plugin distribution\n\n**Why this matters**: When distributing Claude Code plugins via NPM/GitHub, all runtime dependencies must be version-controlled. The plugin's hooks need to be available when Claude Code loads the plugin from the repository.","timestamp":"2025-12-21T19:27:11.597Z"}
{"action":"add","id":"adcc7a9b-7595-4d6e-93da-62d7f85044e8","subject":"Memory extraction field name normalization handles Claude model variations","keywords":["memory-extractor","field-normalization","zod-validation","claude-haiku","error-handling"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:21:17.810Z","content_hash":"0af0316f4d9b2823","content":"Claude Haiku sometimes returns memory objects with alternative field names instead of the expected `subject`, `keywords`, `applies_to`, and `content` fields. Added field name normalization in parseClaudeResponse (lines 179-186) that maps common variations:\n\n- `subject` ← `summary` | `title` | `subject`\n- `keywords` ← `tags` | `keywords`\n- `applies_to` ← `scope` | `applies_to`\n- `content` ← `description` | `body` | `content`\n\nThis normalization is applied to each memory object before Zod validation, preventing validation failures when Claude uses slightly different field names. The fix handles both direct array responses and wrapped responses (e.g., `{memories: [...]}`)","timestamp":"2025-12-21T19:27:11.597Z"}
{"action":"add","id":"f37f30e0-dcbf-4a1c-bc71-9b7a63bcf5fa","subject":"Simplified text summarization by removing ts-textrank dependency and using line/sentence-based approach","keywords":["summarize","textrank","dependency","simplification","text-processing"],"applies_to":"file:src/utils/summarize.ts","occurred_at":"2025-12-21T18:18:08.509Z","content_hash":"8099d0e7f7ea7a86","content":"Removed `ts-textrank` npm package and replaced with simple logic:\n- For multi-line text: take the first line\n- For single-line text: take up to first `.` or all text if no period\n\nThis eliminates external dependency while maintaining useful subject extraction. Applied to both `generateSubject` in summarize.ts and transcript.ts.","timestamp":"2025-12-21T19:27:11.598Z"}
{"action":"add","id":"0dcc4f99-8952-4f01-b753-46915d9bc183","subject":"Build and test pipeline validates transcript optimization","keywords":["npm build","test suite","integration validation"],"applies_to":"global","occurred_at":"2025-12-21T18:30:37.940Z","content_hash":"b35f5fb9a7260dd3","content":"The implementation was validated through:\n\n1. **TypeScript compilation**: Full project build passes (npm run build)\n2. **Unit test suite**: All 100+ tests pass, including new transcript-condenser tests\n3. **Prompt tests updated**: Memory extraction prompt tests updated to validate condensed format handling\n4. **No regressions**: Existing functionality preserved while adding optimization\n\nThe changes integrate seamlessly with the existing memory extraction pipeline without breaking existing functionality.","timestamp":"2025-12-21T19:27:11.599Z"}
{"action":"add","id":"17c30548-65e1-4ee0-b900-005bffb6bec7","subject":"Transcript utility parses Claude Code JSON transcripts into structured events","keywords":["transcript-parsing","json-parsing","events","utilities"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"b0cd8fa8a3efd585","content":"The transcript utility converts Claude Code's JSON transcript format into structured events that can be analyzed for memory extraction. This enables the system to programmatically identify key information from conversations that should be preserved.","timestamp":"2025-12-21T19:27:11.600Z"}
{"action":"add","id":"949bc9e1-8c62-4771-87f2-a2781a5adff1","subject":"SessionStart hook timeout issue - avoid initializing vector store in hooks","keywords":["session-start","hook","timeout","vector-store","embedding","performance"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:17:02.145Z","content_hash":"25d744e022d84042","content":"The SessionStart hook was timing out (30s limit) because it initialized the vector store, which downloads a 133MB embedding model on first use. Fixed by loading the 5 most recent memories directly from files without vector store initialization. Vector store is now lazily initialized by MCP server or user-prompt-submit hook instead. This prevents slow startup for new sessions.","timestamp":"2025-12-21T19:27:11.600Z"}
{"action":"add","id":"755ebef1-1430-490d-902a-3ffaa91189b1","subject":"Raw transcript entries use type field instead of role for message type","keywords":["transcript format","raw format","type vs role","message structure"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:24:55.963Z","content_hash":"555d14193165846b","content":"Transcript format has two variants:\n\n1. **Raw format** (from Claude Code): Uses `type` field (not `role`), e.g. `{\"type\": \"user\" | \"assistant\", \"timestamp\": \"...\", \"message\": {\"content\": ...}}`\n2. **Legacy format**: Uses `role` field, e.g. `{\"role\": \"user\" | \"assistant\", \"content\": \"...\", \"timestamp\": \"...\"}`\n\nThe parsing logic handles both for backwards compatibility. The raw format supports content blocks (array of `{type, text}` or `{type, thinking}` objects), while legacy format has flat string content.","timestamp":"2025-12-21T19:27:11.601Z"}
{"action":"add","id":"33260ce6-8699-4030-9687-263fdfde6202","subject":"Package.json build scripts updated to remove deleted thinking hook references","keywords":["build","package.json","scripts","cleanup"],"applies_to":"file:package.json","occurred_at":"2025-12-03T09:50:15.512Z","content_hash":"f636023ee95b4ffc","content":"Removed references to the deleted `user-prompt-submit-thinking.ts` hook from package.json build scripts after the consolidation of episodic and thinking hooks into a single unified hook.\n\nUpdated the `hooks:user-prompt-submit` npm script to point only to the new consolidated hook.","timestamp":"2025-12-21T19:27:11.601Z"}
{"action":"add","id":"5391edb6-6daa-4415-8d6b-e1e979252cf1","subject":"Comprehensive logging added to database.ts for debugging lock contention","keywords":["logging","database","lock","debugging","pid","timing"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T18:18:36.755Z","content_hash":"0eadbdc45f5ca858","content":"Added detailed logging to track database lock contention issues:\n- Every log entry includes `[PID:xxxx]` to identify which process is running\n- Lock acquisition attempts log attempt count and elapsed time\n- sqlite-vec load operation logs separate timing for vec load vs total time\n- Full stack traces are captured on lock failures\n- Timing information helps identify which operations are slow or blocked","timestamp":"2025-12-21T19:27:11.602Z"}
{"action":"add","id":"2abb76bd-3163-48c3-ab06-7326e54362f9","subject":"VectorStore and ThinkingVectorStore must wrap all database operations with file locks","keywords":["vector-store","database-operations","locking","search","sync"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"1cc829fe4c5bcbda","content":"All database operations in VectorStore must use `withDbMutex(this.dbPath, ...)` to prevent concurrent access:\n\n- `initialize()` - loads index or creates new one\n- `add()` - inserts embeddings\n- `remove()` - deletes embeddings\n- `search()` - vector similarity search\n- `sync()` - reconciles file-based memories with store\n- `persist()` - saves index to JSON\n\nSame pattern applies to ThinkingVectorStore. The dbPath is stored as instance variable during construction via `getOrCreateDatabase()`.","timestamp":"2025-12-21T19:27:11.602Z"}
{"action":"add","id":"8d8ee6ef-b8c3-4c14-b83b-417d21b4b299","subject":"ONNX runtime mutex errors occur with concurrent hook execution, not sqlite-vec","keywords":["onnx","mutex","concurrent","fastembed","embedding","threading"],"applies_to":"global","occurred_at":"2025-12-21T18:25:17.343Z","content_hash":"156643e9aed11216","content":"The mutex errors during concurrent hook execution are caused by ONNX runtime (used by fastembed), not sqlite-vec. When multiple Claude instances run hooks concurrently, they attempt to load the ONNX embedding model simultaneously, triggering system-level mutex conflicts. This happens even with proper-lockfile preventing file-based races, because ONNX has internal threading issues. The Orama migration successfully eliminated sqlite-vec issues, but the embedding model loading remains the bottleneck for concurrent hooks.","timestamp":"2025-12-21T19:27:11.603Z"}
{"action":"add","id":"74e7d192-d071-4dc6-9d85-a833db5ac672","subject":"Schema changes to memory frontmatter: added occurred_at and content_hash, removed updated_at","keywords":["schema","frontmatter","types","memory-format"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:17:28.905Z","content_hash":"beab61402ff9b653","content":"# Memory Frontmatter Schema Update\n\n## Fields Added\n- `occurred_at`: ISO-8601 timestamp of when the event/conversation happened (source timestamp)\n- `content_hash`: SHA-256 hash prefix (16 chars) of memory content for deduplication\n\n## Fields Removed\n- `updated_at`: No longer needed for immutable memories\n- `timeWindow`: Configuration field removed (no longer using time-window-based filtering)\n\n## Updated Types\n- `CreateMemoryInput`: Now includes `occurred_at` parameter\n- Removed `UpdateMemoryInput` type entirely\n- Memory schema reflects immutable, append-only design","timestamp":"2025-12-21T19:27:11.605Z"}
{"action":"add","id":"e7b31652-a9df-4697-9426-910a10d4d7b1","subject":"TranscriptMessage type now includes optional thinking field","keywords":["types","transcript schema","message structure"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:18:43.074Z","content_hash":"2c72f2774ea70578","content":"Added optional `thinking?: string` field to the `TranscriptMessage` interface (line 118). This allows the transcript parser to capture Claude's internal reasoning separately from the response content.\n\nValidation in `src/utils/transcript.ts` has been updated to accept and validate this optional field.","timestamp":"2025-12-21T19:27:11.605Z"}
{"action":"add","id":"58f2ff71-522e-4f79-9fe1-f37cc9c6401b","subject":"Session guarding implementation for memory extraction prompts","keywords":["session guarding","LOCAL_RECALL_INTERNAL","memory extraction","prefix guard","recursion prevention"],"applies_to":"global","occurred_at":"2025-12-21T19:23:52.480Z","content_hash":"ead4922eb65bbc57","content":"The UserPromptSubmit hook filters internal prompts by checking for the `[LOCAL_RECALL_INTERNAL]` prefix to prevent recursive processing. The memory extraction prompt from `buildMemoryExtractionPrompt()` in `src/prompts/memory-extraction.ts` must include this prefix (e.g., `[LOCAL_RECALL_INTERNAL] You are analyzing a Claude Code session transcript...`) so that when the MCP daemon calls `claude -p` for memory extraction, the hook detects it and skips processing. Without this prefix, the memory extraction prompt itself gets processed by the hook, causing infinite recursion.","timestamp":"2025-12-21T19:27:11.606Z"}
{"action":"add","id":"79bbb680-f697-4b4d-9bb1-f763a5eed23c","subject":"Configuration supports separate settings for episodic and thinking memories","keywords":["configuration","episodic memory","thinking memory","similarity threshold","token budget"],"applies_to":"global","occurred_at":"2025-12-21T19:17:45.599Z","content_hash":"c5799c219dae2994","content":"The system supports independent configuration for episodic and thinking memories through environment variables or .local-recall.json file. Each memory type has configurable: enabled status, max tokens to inject per prompt, and minimum similarity threshold (0.0-1.0). Default thresholds are 0.5 and default max tokens are 1000 for both types.","timestamp":"2025-12-21T19:27:11.607Z"}
{"action":"add","id":"16717a58-b101-494b-b3c2-7fe9892b0dd8","subject":"Thinking memory injection achieved 67% similarity in initial test with 5 excerpts","keywords":["thinking memory","search quality","similarity score","context injection","previous thoughts"],"applies_to":"global","occurred_at":"2025-12-21T19:22:32.316Z","content_hash":"25bd0c068a3694f8","content":"Initial testing of thinking memory context injection showed 5 thinking excerpts retrieved with 67% similarity scores. These included memories about:\n- Searching for memories and listing all to find related content\n- Updating memory_list response to show correct fields\n- Improving logic for what content is \"memory worthy\"\n- Checking memories when there don't seem to be any\n- Searching functionality (truncated in transcript)\n\nAll excerpts had identical 67% similarity, suggesting either uniform relevance to the query or potential tuning needed for the similarity threshold. This indicates the thinking memory system is functional for capturing and retrieving reasoning patterns from previous sessions.","timestamp":"2025-12-21T19:27:11.608Z"}
{"action":"add","id":"a4845d38-086e-4dc5-ab3c-cc0db9e0eaa2","subject":"SessionStart hook successfully executes and returns memories in proper JSON format","keywords":["sessionstart","hook","json","memory","working"],"applies_to":"global","occurred_at":"2025-12-21T19:21:30.507Z","content_hash":"a844129b20372398","content":"The SessionStart hook is working correctly - it fires when Claude Code sessions begin and returns JSON output with hookSpecificOutput structure containing the hook event name and additional context (memories). Log entries show successful execution with memory results being injected into the session context.","timestamp":"2025-12-21T19:27:11.609Z"}
{"action":"add","id":"d88a193a-b6d3-497c-81b0-cd44bcffd8a9","subject":"Ollama provides the ideal solution for local embeddings across multiple Claude instances","keywords":["ollama","embeddings","http api","shared daemon","multiprocess safe"],"applies_to":"global","occurred_at":"2025-12-21T19:20:35.399Z","content_hash":"2fc3ed6011ec4ce3","content":"Ollama is an npm-installable embedding server that:\n- Runs as a single daemon on port 11434\n- Loads the embedding model once into memory\n- Serves HTTP requests from multiple clients simultaneously\n- Prevents ONNX mutex issues because only one process initializes the model\n- Supports multiple Claude instances calling the same HTTP endpoint\n- Model: `nomic-embed-text` (768 dimensions, ~274MB)\n\nInstallation: `brew install ollama` (macOS), then `ollama pull nomic-embed-text` and `ollama serve`.\n\nThis solves the concurrent initialization problem while maintaining support for multiple simultaneous Claude instances.","timestamp":"2025-12-21T19:27:11.609Z"}
{"action":"add","id":"fb0200ff-b4f6-439c-b10b-2bb6bc43afc3","subject":"SessionStart hook updated to retrieve both episodic and thinking memories","keywords":["session-start","hook","thinking-memories","episodic-memories","context-injection","session-continuity"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-08T12:40:12.042Z","content_hash":"ebff927a526e5247","content":"Updated the SessionStart hook to retrieve both episodic and thinking memories for session context:\n\n**Changes:**\n- Now loads the 5 most recent episodic memories AND 5 most recent thinking memories (based on `occurred_at`)\n- Respects both `episodicEnabled` and `thinkingEnabled` config flags\n- Outputs separate sections: \"# Local Recall: Recent Memories\" and \"# Local Recall: Recent Thoughts\"\n- Memory stats show totals for both memory types\n\n**Purpose:**\nThis allows sessions to continue with fuller context from previous work, including both factual memories (episodic) and reasoning patterns (thinking).\n\n**Imports added:**\n- `ThinkingMemoryManager` from `../core/thinking-memory.js`\n- `formatThinkingMemoryForDisplay` from `../utils/markdown.js`\n- Types: `Memory`, `ThinkingMemory`","timestamp":"2025-12-21T19:27:11.610Z"}
{"action":"add","id":"6e28a49d-a6a3-4c3c-a4ff-2bbcf38e6c00","subject":"Thinking extractor needed to parse streaming transcripts by message ID grouping","keywords":["thinking-extractor","message-id","streaming","jsonl","parsing","transcript"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:14:44.781Z","content_hash":"0c9c27799314ad02","content":"Claude Code streams assistant responses as separate JSONL lines where each content block (thinking, text, tool_use) has its own line but shares the same `message.id`. The thinking extractor was failing because it expected thinking and text content in the same array.\n\nFixed by modifying `parseTranscriptForThinking` to:\n1. Parse all JSONL lines into an array\n2. Create a Map grouping entries by `message.id`\n3. For each message, collect thinking blocks and text content separately\n4. Only create thinking memories when BOTH thinking and text exist for the same message\n\nThis allows proper pairing of thoughts with their corresponding outputs across multiple JSONL lines.","timestamp":"2025-12-21T19:27:11.611Z"}
{"action":"add","id":"580ff51b-c191-465b-bf84-dd052a7f91f5","subject":"Thinking memory files are version-controlled artifacts","keywords":["thinking-memory","version-controlled","artifacts","git"],"applies_to":"file:local-recall/thinking-memory/","occurred_at":"2025-12-21T19:24:22.148Z","content_hash":"753cd0d377a6953f","content":"Thinking memory files (*.md) are stored in `local-recall/thinking-memory/` and are version-controlled in git. They capture 'thought → output' pairs from previous sessions and are committed to the repository. These files help future sessions learn from past reasoning patterns.","timestamp":"2025-12-21T19:27:11.613Z"}
{"action":"add","id":"595767ff-22bb-4a13-a0a4-697db0dcee93","subject":"Episodic memory disabled by default in configuration","keywords":["episodic memory","default disabled","configuration","env vars","types.ts"],"applies_to":"global","occurred_at":"2025-12-21T18:23:22.834Z","content_hash":"93d01f7ff10746aa","content":"Changed the default value of `episodicEnabled` from `true` to `false` in the config schema.\n\nThis was updated in two places:\n- `src/core/types.ts:118` - The Zod schema definition\n- `CLAUDE.md` - Documentation table\n\nUsers can now enable episodic memory retrieval by explicitly setting `LOCAL_RECALL_EPISODIC_ENABLED=true` (environment variable) or `\"episodicEnabled\": true` in `.local-recall.json` config file.\n\nThis represents a shift to opt-in behavior for episodic memory rather than opt-out.","timestamp":"2025-12-21T19:27:11.613Z"}
{"action":"add","id":"94850fcf-eb94-4922-928a-0553d8548fd1","subject":"GitHub MCP server not configured in local environment","keywords":["github","mcp","integration","configuration","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T18:31:36.092Z","content_hash":"7c65d90e517b46cc","content":"The local-recall project does not currently have a GitHub MCP server configured. To access GitHub features like PR comments or suggestions, a GitHub MCP server would need to be installed and configured in `.claude/settings.json` with appropriate credentials and endpoints.","timestamp":"2025-12-21T19:27:11.614Z"}
{"action":"add","id":"9d2acc67-6e8a-43b6-9b60-df3854589c8d","subject":"Memory extractor integrates transcript condenser for efficient processing","keywords":["memory extractor","transcript condenser","integration","efficiency"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:25:23.828Z","content_hash":"dd4c2703ece17c6b","content":"Modified `src/core/memory-extractor.ts` to integrate the transcript condenser:\n\n1. Reads raw transcript JSONL from file\n2. Passes it through `condenseTranscript()` from transcript-condenser module\n3. Sends condensed data to memory extraction prompt\n4. Processes extracted memories\n\nThe integration is minimal and transparent - the extractor receives structured, pre-filtered data that reduces token usage while maintaining the ability to create meaningful memories from session transcripts.","timestamp":"2025-12-21T19:27:11.614Z"}
{"action":"add","id":"a3ac14bb-134c-4bdb-940f-6cc8343c5dd8","subject":"Memory extractor must handle both array and object response formats from Claude","keywords":["memory-extractor","parseClaudeResponse","claude-response-format","error-handling","haiku"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:19:00.855Z","content_hash":"e5759a9b0d868240","content":"The `parseClaudeResponse` method in memory-extractor.ts was failing when Claude returned memories as a plain array `[{...}]` instead of the expected object format `{ memories: [...] }`. Added array detection at line 174-177 that checks if the parsed JSON is an array and wraps it in the expected format before Zod validation. This handles the case where Claude (especially Haiku) returns the data directly without the wrapper object. This fix prevents 'Expected object, received array' validation errors.","timestamp":"2025-12-21T19:27:11.615Z"}
{"action":"add","id":"c2bfcb98-7733-43a9-932b-5caa5fc5ed4e","subject":"Configuration schema defaults are defined in src/core/types.ts using Zod","keywords":["configuration","types.ts","zod schema","defaults","env vars"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:23:22.834Z","content_hash":"500e018d5d19a85b","content":"The configuration schema uses Zod for validation and default value definition. The `episodicEnabled` default is set using `.default(true/false)` on line 118 of `src/core/types.ts`.\n\nWhen making configuration changes, both the schema default AND the documentation in CLAUDE.md should be updated together to keep them in sync.","timestamp":"2025-12-21T19:27:11.615Z"}
{"action":"add","id":"979377cd-575c-47f5-86d2-a637273a3c86","subject":"Local Recall is a markdown-based memory system for AI coding assistants with vector search","keywords":["architecture","local-recall","memory-system","vector-search","markdown"],"applies_to":"global","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"d9e71e4241462ba7","content":"Local Recall is a persistent memory layer that enables Claude Code and other AI tools to store and retrieve contextual information across sessions. All memories are stored locally in markdown files with YAML frontmatter, making them version-controllable. The system uses semantic vector search via Ollama embeddings for intelligent memory retrieval.","timestamp":"2025-12-21T19:27:11.616Z"}
{"action":"add","id":"4b879931-e9f2-4f09-b949-8d5aebcbca17","subject":"Haiku model response format behavior in memory extraction","keywords":["claude-haiku","response-format","memory-extraction","json-parsing"],"applies_to":"global","occurred_at":"2025-12-21T19:18:46.281Z","content_hash":"e681fe9c73636054","content":"Claude Haiku sometimes returns JSON arrays directly without wrapping in an object, while other models may consistently wrap responses. The memory extractor needs to handle both formats gracefully. This is a model-specific behavior to account for in prompt design and response parsing.","timestamp":"2025-12-21T19:27:11.617Z"}
{"action":"add","id":"13ebc959-2148-4a0b-8f3b-5f3efb0352c4","subject":"Token-based retrieval for thinking memories with configurable limits","keywords":["thinking memory retrieval","token budget","similarity threshold","configuration","memory injection"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:14:45.298Z","content_hash":"0e4c4ca1fdcfec9f","content":"Thinking memories are now retrieved using a token-based budget system instead of a fixed count. This allows better control over memory injection size.\n\nConfiguration:\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` (env var, default: 1000) - max tokens of thinking memories to inject\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` (env var, default: 0.8) - minimum similarity threshold (0.0-1.0)\n\nRetrieval logic in `src/hooks/user-prompt-submit-thinking.ts`:\n- Searches thinking memories by semantic similarity\n- Filters by minimum similarity threshold\n- Accumulates memories in order until token budget is exceeded\n- Formats with thought + output sections\n\nThis replaces the previous count-based approach and provides more fine-grained control.","timestamp":"2025-12-21T19:27:11.618Z"}
{"action":"add","id":"2c79392e-7a04-45cf-bf9f-c220dd00dbb8","subject":"Hook logging should be verbose for debugging subprocess issues","keywords":["hook","subprocess","logging","debug","context"],"applies_to":"global","occurred_at":"2025-12-21T18:18:36.755Z","content_hash":"0d28ed24e57e8b9a","content":"When debugging hook issues, verbose logging is essential because hooks run in subprocess context where normal debugging is difficult. The improved logging now includes: process IDs, timing information, lock state, and full stack traces. This helps identify subprocess-specific issues like mutex failures that don't occur in normal execution.","timestamp":"2025-12-21T19:27:11.618Z"}
{"action":"add","id":"0c3dd196-f262-4818-af6e-02da3196e00a","subject":"Single-line assistant content should not be saved as memories","keywords":["memory filtering","single-line content","multiline","transcript analysis"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:19:37.035Z","content_hash":"bb5183238f549518","content":"The analyzeForMemories() function filters assistant messages: all thinking is saved (even single-line), but content/answers are ONLY saved if they have 2+ lines (split by newline). Single-line content is filtered out as not memory-worthy. This prevents trivial responses from polluting the memory store.","timestamp":"2025-12-21T19:27:11.619Z"}
{"action":"add","id":"372cd7c1-170a-4211-b0a3-7d631bbd2ff5","subject":"Thinking extraction successfully processes 616 memories from 59 transcripts","keywords":["thinking-memory","extraction","batch-processing","verification","transcript"],"applies_to":"global","occurred_at":"2025-12-21T19:14:44.781Z","content_hash":"58946cef90e16859","content":"After fixes, the thinking extractor successfully processed 59 transcripts and created 616 thinking memories. Each memory contains:\n- Unique ID (UUID)\n- Subject from first sentence of thinking block\n- Frontmatter with metadata (keywords, applies_to, occurred_at, content_hash)\n- Two sections: `## Thought` (Claude's reasoning) and `## Output` (the response text)\n\nMemories are stored in `local-recall/thinking-memory/` with proper formatting for semantic search via Orama vector store.","timestamp":"2025-12-21T19:27:11.619Z"}
{"action":"add","id":"7f2eefdd-a48f-4262-9bef-54b8536bf85f","subject":"Documentation updates for embedding model setup and troubleshooting","keywords":["documentation","embedding model","setup instructions","troubleshooting","fastembed","deployment"],"applies_to":"global","occurred_at":"2025-12-21T19:26:39.326Z","content_hash":"6a999e96b2786b27","content":"## Updates Made\nAdded comprehensive documentation to help users avoid embedding model issues:\n\n### CLAUDE.md Updates\n1. Added \"Embedding Model\" section under Development explaining:\n   - Uses fastembed with BGE-small-en-v1.5 model (384 dimensions)\n   - Model automatically downloads to `local_cache/` on first use\n   - First initialization may be slow due to model download\n\n2. Added \"Troubleshooting\" section with:\n   - \"Tokenizer file not found\" error and solution (clear cache)\n   - Explanation of corrupted/incomplete model downloads\n   - Steps to verify model files are present\n\n### docs/architecture.md Updates\n1. Updated architecture diagram to show Vector Store and Embedding Service components\n2. Added detailed documentation for VectorStore component including search implementation\n3. Added documentation for EmbeddingService component\n4. Updated storage layer section to mention vector indexes\n\n### .gitignore Updates\nAdded `local_cache/` to .gitignore to prevent committing auto-generated model cache files.\n\n## Why This Matters\nFuture developers/users encountering slow first startup or embedding errors will find clear guidance on what's expected and how to resolve issues.","timestamp":"2025-12-21T19:27:11.620Z"}
{"action":"add","id":"dc4dcc38-4e62-4602-97ee-0abe800be8e4","subject":"Memory extraction must handle both thinking and multiline content correctly","keywords":["thinking blocks","memory extraction","single-line content","transcript analysis"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:24:55.963Z","content_hash":"4f029798abca2840","content":"The `analyzeForMemories()` function has specific rules for what gets saved as memories:\n\n1. **Thinking**: Save ALL thinking content (even single-line), prefixed with \"[Thinking]\"\n2. **Content/Answers**: Only save MULTILINE content - single-line responses are dropped\n3. **User messages**: Never save user messages, only assistant messages\n\nThis filtering happens in `analyzeForMemories()` (lines 294-342) which checks `lines.length >= 2` for content. The `parseTranscriptForMemories()` function calls this after parsing raw JSONL, ensuring consistent behavior.","timestamp":"2025-12-21T19:27:11.620Z"}
{"action":"add","id":"31ce771c-e838-42ae-a15d-eceb6605afc1","subject":"Thinking extractor handles multiple thinking blocks per message correctly","keywords":["thinking blocks","multiple","aggregation","message streaming","thinking-extractor"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T17:29:39.364Z","content_hash":"d9c93e025bd9deb9","content":"The thinking extractor is designed to handle multiple thinking blocks within a single Claude message. The `AggregatedMessage` interface uses `thinkingParts: string[]` (an array) to accumulate multiple thinking blocks from a single message ID. The extraction logic pushes each thinking block found to this array via `aggregated.thinkingParts.push(thinkingContent)`. This supports Claude's behavior of potentially generating multiple interleaved thinking blocks within a single response.","timestamp":"2025-12-21T19:27:11.621Z"}
{"action":"add","id":"636a8750-715c-4b51-a5f4-92208da0139e","subject":"Pre-computed embeddings and auto-compaction integrated into memory system","keywords":["embeddings","pre-computed","compaction","lazy-loading","index-refresh","performance"],"applies_to":"global","occurred_at":"2025-12-21T18:28:54.683Z","content_hash":"23c0384a2008ec15","content":"Added pre-computed embeddings to memory files to improve performance and enable background index compaction.\n\n**Pre-computed Embeddings**:\n- Vector embeddings are now computed once when memories are created\n- Stored in memory metadata to avoid re-computing on every search\n- Reduces Ollama calls during search operations\n- Embeddings are lazy-loaded only when needed for vector store\n\n**Auto-compaction Feature**:\n- Memory indexes are automatically compacted in the background\n- Removes deleted memories from the index efficiently\n- Runs on configurable interval (default 5 minutes via `indexRefreshInterval`)\n- Prevents index from growing unbounded with deleted entries\n\n**Benefits**:\n- Faster searches (no re-embedding needed)\n- Smaller index files over time\n- Background processes don't block main operations\n- Improved memory efficiency as the system scales\n\n**Configuration**:\n- `indexRefreshInterval` - How often to compact indexes (seconds)\n- Default configured for optimal balance between responsiveness and compaction frequency","timestamp":"2025-12-21T19:27:11.622Z"}
{"action":"add","id":"aaaa439a-7617-4da4-9522-4c48ce261589","subject":"New transcript schema types define all Claude Code JSONL entry structures","keywords":["transcript schema","jsonl","types","typescript","claude code"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T19:25:23.828Z","content_hash":"c859cadfa43e9609","content":"Created comprehensive TypeScript types in `src/types/transcript-schema.ts` that define all entry types in Claude Code transcript JSONL files:\n\n- **UserEntry**: user queries with timestamp\n- **AssistantEntry**: Claude responses with content blocks (text, code, thinking)\n- **SystemEntry**: system messages\n- **FileHistorySnapshot**: file state snapshots with hashes\n- **QueueOperation**: tool invocations with input/output\n\nThese types enable typed parsing of JSONL transcripts without manually handling unstructured data. The schema provides the foundation for the transcript condenser to efficiently extract relevant content.","timestamp":"2025-12-21T19:27:11.622Z"}
{"action":"add","id":"28ce5719-fd75-4336-a92b-5bf077b1d63b","subject":"Memory files use applies_to scope for filtering","keywords":["scope","applies_to","global","file-scoped","area-scoped"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"410d497fdd3f9950","content":"Memory scope is defined via applies_to field with three options: 'global' (entire codebase), 'file:<path>' (specific file), or 'area:<name>' (component/area). This allows memories to be filtered by relevance to the current context when memories are retrieved.","timestamp":"2025-12-21T19:27:11.622Z"}
{"action":"add","id":"cc5f9842-8b94-4c50-be54-87634c43a21f","subject":"Plugin hooks were using stale better-sqlite3 dependency that no longer exists","keywords":["plugin","hooks","better-sqlite3","stale-code","dev-marketplace","user-prompt-submit-thinking"],"applies_to":"area:plugin-development","occurred_at":"2025-12-21T19:21:32.710Z","content_hash":"73a0f1341c3e1a4b","content":"The dev-marketplace/local-recall-plugin had a stale `user-prompt-submit-thinking.js` hook that attempted to import `better-sqlite3`, which is no longer used in the project. The main codebase migrated from SQLite to Orama (pure JavaScript vector store) for embeddings and search.\n\nThe plugin's `config/hooks.json` was pointing to this deleted file, causing 'Cannot find package better-sqlite3' errors when the hook executed.\n\nFix: Remove the stale hook file and update hooks.json to point to `user-prompt-submit.js` which now handles both episodic and thinking memory searches using Orama.","timestamp":"2025-12-21T19:27:11.623Z"}
{"action":"add","id":"2e3b7301-657c-4bc0-9bcd-39c5352679e3","subject":"UserPromptSubmit hook filters internal memories using [LOCAL_RECALL_INTERNAL] marker","keywords":["hooks","user prompt submit","internal prompts","memory extraction","filtering","claude prompts"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:59:50.981Z","content_hash":"dd547e0173cfe484","content":"The UserPromptSubmit hook implementation skips processing internal prompts that contain the `[LOCAL_RECALL_INTERNAL]` marker. This is important for:\n\n1. **Preventing noise** - Memory extraction prompts sent internally to Claude should not create additional memories\n2. **Clean audit trail** - Only user-initiated prompts contribute to the memory system\n3. **Avoiding circular memory creation** - If memory extraction itself created memories about memory extraction, it would cause feedback loops\n\nWhen sending internal prompts for memory extraction, always include the `[LOCAL_RECALL_INTERNAL]` marker to prevent the UserPromptSubmit hook from processing them as user memories.","timestamp":"2025-12-21T19:27:11.624Z"}
{"action":"add","id":"9707e97b-1337-4ab6-bff6-82a1ba34b621","subject":"sqlite-vec mutex errors caused by C++ pthread mutexes in multi-process access","keywords":["sqlite-vec","mutex","threading","native-bindings","error-resolution"],"applies_to":"global","occurred_at":"2025-12-21T18:58:59.192Z","content_hash":"7ee1982231eeb313","content":"The 'mutex lock failed: Invalid argument' errors were caused by sqlite-vec using internal C++ pthread mutexes that fail when multiple processes load the extension simultaneously. The mutex error occurs at the native code level when the extension's .so/.dylib file is loaded by concurrent processes. Solution: Use only Orama (pure JavaScript) for vector operations instead of sqlite-vec. This avoids all native threading issues since Orama has no native dependencies and can safely run in multiple hook processes.","timestamp":"2025-12-21T19:27:11.624Z"}
{"action":"add","id":"96bd538d-4ccf-4c46-902a-48f515fdb700","subject":"Disable MCP servers during internal extraction subprocess with --strict-mcp-config","keywords":["mcp-server","claude-command","strict-mcp-config","extraction","subprocess"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:23:40.594Z","content_hash":"4978fb59113ae79c","content":"When calling `claude -p` for keyword extraction, pass --strict-mcp-config parameter to prevent MCP servers from loading in that subprocess. This adds an additional layer of protection against recursive hook execution and ensures the extraction process runs cleanly without interference from MCP tools.","timestamp":"2025-12-21T19:27:11.625Z"}
{"action":"add","id":"a6b6b0e1-b605-4874-b301-95ddfae0e00b","subject":"Session start loads all memories, not deltas - full reload on each session","keywords":["session-start","memory-loading","hook","full-reload","initialization"],"applies_to":"global","occurred_at":"2025-12-21T18:24:38.922Z","content_hash":"2f61d2a5996b4002","content":"On session start, the system performs a **full reload** of memories, not a delta/incremental load. The SessionStart hook in `src/hooks/session-start.ts` creates a fresh MemoryManager instance and loads all memories from disk, then selects the 5 most recent ones (sorted by `occurred_at` descending) for injection into the session context.\n\nThis design is intentional - each session starts with a clean slate and loads the most recent memories, ensuring fresh context without carrying stale session state between sessions.","timestamp":"2025-12-21T19:27:11.626Z"}
{"action":"add","id":"8bf2ed6d-7b0e-4625-bc16-fc52c29c78a1","subject":"Configuration defaults are defined in src/core/types.ts using Zod schema","keywords":["configuration","defaults","zod","schema","types.ts"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:19:26.883Z","content_hash":"b3d4665c3e87ed25","content":"The configuration system uses Zod for schema validation and default values. All configuration defaults are defined in `src/core/types.ts` using the `.default()` method on Zod fields. When making configuration changes, both the schema defaults in `src/core/types.ts` AND the documentation in `CLAUDE.md` must be updated to remain in sync.","timestamp":"2025-12-21T19:27:11.627Z"}
{"action":"add","id":"77e6ff6d-5ced-4709-9439-b4385fd47bad","subject":"Plugin hooks require JSON output format with hookSpecificOutput field","keywords":["hooks","plugin","output format","json","sessionstart","claude code"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:15:33.474Z","content_hash":"58927c42c00c8fb4","content":"Plugin-layer hooks (SessionStart:Callback, UserPromptSubmit:Callback) require stdout to be in JSON format with a `hookSpecificOutput` object containing `additionalContext` field. Plain `console.log()` output won't work - the hook output must follow the plugin hook response schema with `hookSpecificOutput.additionalContext` for injecting context into Claude's session.","timestamp":"2025-12-21T19:27:11.628Z"}
{"action":"add","id":"88f4fd06-583a-45f4-a508-b8b34fc3b1e5","subject":"Vector search scoring uses cosine distance with recency tie-breaker","keywords":["scoring","cosine-distance","similarity","ranking","tie-breaker","recency"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"3cef4ff1968bcc76","content":"Search result scoring from Orama vector store:\n- Score range: 0.0 (no match) to 1.0 (identical match)\n- Uses cosine distance similarity\n- Scores rounded to 2 decimal places (e.g., 0.65)\n- Results sorted by score descending\n- **Recency tie-breaker**: When scores are equal, more recent memories (higher `occurred_at`) are ranked first\n\nThis ensures that functionally similar memories are presented in chronological order when similarity is equivalent.","timestamp":"2025-12-21T19:27:11.629Z"}
{"action":"add","id":"6a7d92e8-e58b-4af6-897f-8386573d25df","subject":"Transcript collector architecture and lifecycle in local-recall","keywords":["transcript-collector","claude-cache","transcript-processing","architecture"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:20:50.505Z","content_hash":"9450b28c46fbf83b","content":"The TranscriptCollector class manages transcript files from two sources:\n\n1. **Source transcripts** - Located in Claude's project cache at `~/.claude/projects/<project>/transcripts/`\n2. **Local transcripts** - Stored in the local-recall project folder\n\n**Key methods:**\n- `findClaudeProjectDir()` - Locates the Claude project directory by matching against the current working directory\n- `listSourceTranscripts()` - Lists transcripts from Claude's cache (source of truth)\n- `listLocalTranscripts()` - Lists transcripts already processed locally\n- `copyTranscripts()` - Copies new transcripts from Claude's cache to local storage\n\nTranscripts are JSONL format files. The collector identifies them by UUID filename pattern to distinguish real transcripts from other files in the directory.","timestamp":"2025-12-21T19:27:11.630Z"}
{"action":"add","id":"f1816a05-9bee-480c-8a6f-058914f2db55","subject":"SessionStart hook reads 5 most recent memories; UserPromptSubmit searches semantically","keywords":["session-start-hook","user-prompt-submit-hook","memory-injection","semantic-search"],"applies_to":"global","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"2cd8f387b026b8df","content":"Two hook strategies:\n1. **SessionStart**: Reads last 5 memories directly from files (no embedding cost), sorted by `occurred_at`. Provides recent context without search overhead.\n2. **UserPromptSubmit**: Performs semantic search on both episodic and thinking memories using embeddings. Each memory type has independent config: `episodicEnabled`, `episodicMaxTokens`, `episodicMinSimilarity` (and thinking equivalents). Searches respect similarity threshold (default 0.5) and token budget.","timestamp":"2025-12-21T19:27:11.630Z"}
{"action":"add","id":"9332463c-ab97-4cd1-9520-a529152e812e","subject":"Transcript condenser optimizes memory extraction by parsing JSONL and extracting minimal content","keywords":["transcript condenser","memory extraction","jsonl parsing","token optimization","performance"],"applies_to":"global","occurred_at":"2025-12-21T19:26:56.552Z","content_hash":"c2458b6730c52ef1","content":"Created `src/core/transcript-condenser.ts` to optimize memory extraction by:\n\n1. **Parsing JSONL transcripts**: Uses typed `TranscriptEntry` types to parse raw JSONL content\n2. **Selective content extraction**: Extracts only relevant data from each entry type:\n   - User messages: Full text\n   - Assistant responses: Relevant portions only\n   - Tool invocations: Tool name and key results\n   - File operations: Only important edits/writes\n3. **Condensed format**: Creates structured `CondensedEvent` objects with minimal data\n4. **Token reduction**: Significantly reduces tokens passed to Claude for memory creation by excluding:\n   - Full file contents\n   - Complete bash outputs\n   - Irrelevant tool metadata\n   - Internal thinking blocks\n\nThe condenser is integrated into `memory-extractor.ts` to parse transcripts before passing to the prompt, reducing token usage and improving extraction speed.","timestamp":"2025-12-21T19:27:11.631Z"}
{"action":"add","id":"3cc0bfb9-7d7c-4a72-b4f7-7b98a7d98225","subject":"Index files and logs should be gitignored, but .gitignore itself is version-controlled","keywords":["gitignore","version-control","index-files","logs"],"applies_to":"global","occurred_at":"2025-12-21T19:15:59.803Z","content_hash":"0370ba483982b41d","content":"The local-recall/.gitignore file itself must be tracked in git (it was previously deleted and needed to be restored). This file excludes:\n- orama-*-index.json (generated vector indexes)\n- recall.log (debug logs)\n- *.jsonl.lock (JSONL lock files)\n\nThe .gitignore is created by MemoryManager.ensureGitignore() and should always exist in the repository.","timestamp":"2025-12-21T19:27:11.631Z"}
{"action":"add","id":"8b552f9b-87f5-470a-993a-a1d2d06e4472","subject":"Vector store initialization requires sqlite-vec extension for similarity search","keywords":["sqlite-vec","extension","initialization","vector-store","setup"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-03T09:47:48.632Z","content_hash":"8e99cf0d1b960dbe","content":"The vector store uses SQLite's `sqlite-vec` extension for efficient vector similarity search. During initialization via `vectorStore.initialize()`, the extension must be loaded before creating the embedding tables. The store maintains two main tables:\n\n- `memories`: Stores memory metadata (id, subject, keywords, applies_to, occurred_at, content_hash, content)\n- `memory_embeddings`: Stores embeddings and their vector similarity indices\n\nEmbeddings are generated using the BGE-small-en-v1.5 model, which is cached in `local_cache/` after first download.","timestamp":"2025-12-21T19:27:11.632Z"}
{"action":"add","id":"76d93ffb-fbcc-48a1-97ab-5f4db900d1a7","subject":"Ollama embedding model changed from BGE-small-en-v1.5 (384 dims) to nomic-embed-text (768 dims)","keywords":["ollama","embeddings","vector store","migration","model dimensions","orama index"],"applies_to":"global","occurred_at":"2025-12-21T18:59:50.981Z","content_hash":"a9fb18f7575bec9b","content":"Local Recall migrated embedding models:\n\n**Previous:** BGE-small-en-v1.5 (384 dimensions)\n**Current:** nomic-embed-text (768 dimensions)\n\nThis change requires:\n1. **Rebuilding vector indexes** - Old Orama indexes must be deleted (they're gitignored and auto-regenerated)\n2. **Migration procedure** - Delete orama-episodic-index.json and orama-thinking-index.json to trigger rebuild\n3. **Larger index files** - 768 dimensions means bigger JSON index files on disk\n4. **Better semantic understanding** - Nomic model provides superior embedding quality for similarity search\n\nThis is documented in the troubleshooting section for users migrating from older versions.","timestamp":"2025-12-21T19:27:11.633Z"}
{"action":"add","id":"f483a325-ac16-4ef4-945d-19c9e72a2821","subject":"MCP server daemon processes transcripts asynchronously every 5 minutes","keywords":["mcp server","daemon","transcript processing","background","schedule","memory extraction"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"156ccf4bfe62e8fd","content":"The MCP server runs a background daemon that:\n1. Syncs transcripts from Claude's cache (`~/.claude/projects/<project>/transcripts/`)\n2. Processes transcripts using `claude -p` to extract memories asynchronously\n3. Tracks processed transcripts with content hashes for change detection\n4. Deletes and recreates memories when transcripts change\n5. Runs on a 5-minute interval\n\nThis background processing allows memory extraction without blocking the main hook execution path.","timestamp":"2025-12-21T19:27:11.633Z"}
{"action":"add","id":"ef7285aa-8ec8-4130-a5b0-798172c9dafb","subject":"Thinking memories are experimental feature with separate extraction pipeline","keywords":["thinking memories","experimental","extraction","thought output","daemon","async processing"],"applies_to":"global","occurred_at":"2025-12-21T17:42:21.784Z","content_hash":"bb62ceb217a3ef4b","content":"Thinking memories capture Claude's internal reasoning paired with outputs. They are extracted asynchronously by the MCP daemon from transcripts (20 parallel workers), separate from episodic memories. Stored as markdown with 'Thought' and 'Output' sections. Can be disabled/reset by deleting `thinking-processed-log.jsonl` and `orama-thinking-index.json` to reprocess from scratch.","timestamp":"2025-12-21T19:27:11.634Z"}
{"action":"add","id":"89ee6d5d-fba0-41bc-9a4e-d70be57deab1","subject":"MCP server startup issues after SDK upgrade require SDK documentation review","keywords":["mcp server","startup","sdk upgrade","debugging","initialization"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:03:02.350Z","content_hash":"1875dbd1df58f2fd","content":"When encountering MCP server startup failures after SDK version upgrades, check the @modelcontextprotocol/sdk release notes and examples for breaking changes in Server and StdioServerTransport initialization. The SDK provides example implementations in their GitHub repository that show the correct current pattern.","timestamp":"2025-12-21T19:27:11.635Z"}
{"action":"add","id":"4790627d-c6ca-4949-8fcf-ea8b864d8775","subject":"Memory extraction timeout set to 10 minutes","keywords":["timeout","memory extraction","DEFAULT_OPTIONS","600000ms"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:23:52.480Z","content_hash":"b88a630caec05234","content":"The `DEFAULT_OPTIONS` in memory-extractor.ts line 40 sets the timeout to 600000ms (10 minutes) for memory extraction operations via the Claude CLI. This allows sufficient time for processing large transcripts without premature timeout failures.","timestamp":"2025-12-21T19:27:11.635Z"}
{"action":"add","id":"b7c447fd-719a-4539-8089-36680dbbb9fd","subject":"analyzeForMemories only saves multi-line content to avoid noise","keywords":["memory extraction","analysis","content filtering","single-line"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:22:34.972Z","content_hash":"8abfdbb81e141dc7","content":"The `analyzeForMemories` function deliberately filters out single-line messages from being saved as memories. This is by design to reduce noise in the memory system - single-line responses (like 'Got it' or 'Done') aren't valuable memories.\n\nTests should be written with multi-line content to properly test memory extraction functionality.","timestamp":"2025-12-21T19:27:11.636Z"}
{"action":"add","id":"cb81e113-e598-4502-81ba-a84cbc75de46","subject":"Memory deduplication uses occurred_at and content_hash","keywords":["deduplication","idempotent","content-hash","occurred-at"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"cb4d2b01d0c0aa83","content":"Memory creation is idempotent: before creating a new memory, findDuplicate() checks for existing memories with the same occurred_at timestamp and content_hash (SHA-256 prefix). If a duplicate exists, the existing memory is returned instead of creating a new one. This prevents accumulation of redundant memories.","timestamp":"2025-12-21T19:27:11.640Z"}
{"action":"add","id":"a33b170d-f28d-472a-884c-3108bdcad301","subject":"Database locking mechanism prevents concurrent sqlite-vec loading errors","keywords":["database","sqlite-vec","mutex","file locking","concurrent access","socket opening"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T19:15:00.052Z","content_hash":"642dddbb01a054a7","content":"The sqlite-vec C++ extension throws 'socket already open' errors when loaded concurrently from multiple processes. This happens when hooks run in parallel during the UserPromptSubmit phase.\n\nImplemented file-based locking in `src/utils/database.ts`:\n- `acquireDatabaseLock()`: Creates a lock file before loading sqlite-vec\n- `releaseDatabaseLock()`: Removes the lock file after loading\n- Timeout of 5 seconds per lock attempt\n- Automatic stale lock detection (older than 3 seconds)\n- Graceful fallback when lock acquisition fails\n\nThis prevents concurrent socket initialization while maintaining error resilience.","timestamp":"2025-12-21T19:27:11.641Z"}
{"action":"add","id":"eb7b5463-4a92-4dee-b81b-c306df286f0e","subject":"Transcript utilities parse messages and extract memory candidates","keywords":["transcript parsing","message parsing","memory extraction","analyzeForMemories"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:10:34.378Z","content_hash":"8a9988da6d74eb1d","content":"The `analyzeForMemories()` function in transcript.ts:\n1. Parses transcript messages to identify speaker and content\n2. Filters to only assistant messages (skips user messages)\n3. Checks for multi-line content (minimum 2 non-empty lines)\n4. Returns message content for memory creation\n5. Role prefixes are removed from stored content to keep memories clean","timestamp":"2025-12-21T19:27:11.642Z"}
{"action":"add","id":"bb06123a-8e2a-429e-819a-f35ca267c983","subject":"Architecture: transcript.ts should export parsing utilities, stop.ts only calls them","keywords":["architecture","separation of concerns","parsing","hooks"],"applies_to":"global","occurred_at":"2025-12-21T18:27:11.223Z","content_hash":"d17ca50d64e2c014","content":"Clean architecture pattern: Keep parsing logic in utility modules (transcript.ts), hooks (stop.ts) should only handle I/O and orchestration.\n\nstop.ts responsibilities:\n1. Read input from stdin (session_id, transcript_path, cwd)\n2. Load configuration\n3. Read transcript file\n4. Call parseTranscriptForMemories() to get suggestions\n5. Loop through and save each memory using MemoryManager\n\nThis makes utilities reusable and testable separately from hook infrastructure.","timestamp":"2025-12-21T19:27:11.642Z"}
{"action":"add","id":"45d73177-be5a-4107-a95f-e1ae963d5dc0","subject":"Hook error handling should include detailed timing and stack traces for debugging","keywords":["hooks","error handling","timing","stack traces","user-prompt-submit"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:16:09.210Z","content_hash":"61f53811800923df","content":"The UserPromptSubmit hook was improved to include:\n- Operation timing for SearchEngine and ThinkingSearchEngine instantiation\n- Full stack traces when errors occur\n- Clear logging at each step (initialization, search, combining results)\n- Detailed error messages that capture the full context\n\nThis makes it much easier to identify whether errors are in initialization, search execution, or result combination.","timestamp":"2025-12-21T19:27:11.643Z"}
{"action":"add","id":"5077aae0-5df6-4464-bfd5-93805414e282","subject":"Documentation accuracy audit completed - CLAUDE.md and docs/ required updates","keywords":["documentation","architecture","CLAUDE.md","accuracy","audit","discrepancies"],"applies_to":"global","occurred_at":"2025-12-21T18:58:34.079Z","content_hash":"50afacf2fd0ec1f2","content":"## Documentation Inconsistencies Found\n\nAudit revealed several outdated references in CLAUDE.md and docs/:\n\n### CLAUDE.md Issues\n- Architecture tree showed fictional `scripts/` folder instead of actual `dist/` build output\n- Referenced non-existent `.claude-plugin/`, `hooks.json`, `.mcp.json` files\n- Listed missing utils: `summarize.ts`, `gitignore.ts`, `config.ts`\n- Missing core modules: `transcript-collector.ts`, `transcript-condenser.ts`, `memory-extractor.ts`, `processed-log.ts`\n- No mention of `prompts/`, `types/` directories\n\n### docs/ Updates Applied\n- **architecture.md**: Replaced \"Index Manager\" with \"Transcript Condenser\", updated storage/search/creation sections\n- **hooks.md**: Updated configuration examples, flow diagrams, environment variables\n- **mcp-server.md**: Updated server startup, storage structure, client integration, configuration sections\n\n## Resolution\nAll path references updated from `scripts/` to `dist/`, plugin structure removed, actual file structure now accurately reflected.\n\n## Important Note\nDocumentation files should be reviewed periodically as code evolves to prevent future drift between docs and implementation.","timestamp":"2025-12-21T19:27:11.643Z"}
{"action":"add","id":"9dbfd63a-0888-4ffe-94bc-1385be1921f4","subject":"Memory creation is idempotent via findDuplicate check","keywords":["memory","createMemory","idempotent","duplicate detection"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:18:18.497Z","content_hash":"520d0384b8ba22d5","content":"Implemented `findDuplicate(occurredAt, contentHash)` method to check for existing memories before creation. The `createMemory()` function now: 1) Computes content hash, 2) Checks for duplicate with same occurred_at + content_hash, 3) Returns existing memory if found, 4) Creates new memory if not found. This ensures safe reprocessing of transcripts without creating duplicate memories.","timestamp":"2025-12-21T19:27:11.644Z"}
{"action":"add","id":"71deaec7-6267-4230-a461-056398082895","subject":"New configuration options for thinking memory token limits and similarity thresholds","keywords":["configuration","thinking-memory","env-vars","token-limits"],"applies_to":"global","occurred_at":"2025-12-03T09:47:22.389Z","content_hash":"f570a9a64726b079","content":"Added new configuration options:\n- LOCAL_RECALL_THINKING_MAX_TOKENS: Maximum tokens of thinking memories to inject (default: 1000)\n- LOCAL_RECALL_THINKING_MIN_SIMILARITY: Minimum similarity threshold 0.0-1.0 (default: 0.8)\n- LOCAL_RECALL_EPISODIC_MAX_TOKENS: Maximum tokens of episodic memories to inject (default: 1000)\n- LOCAL_RECALL_EPISODIC_MIN_SIMILARITY: Minimum similarity threshold for episodic (default: 0.8)\nBoth memory types now use token-based retrieval with configurable similarity filtering.","timestamp":"2025-12-21T19:27:11.644Z"}
{"action":"add","id":"ea4f4dd4-a76c-4f08-9985-f15b73991769","subject":"Fallback mechanisms in transcript discovery when primary path fails","keywords":["transcript-collector","discovery","fallback","directory-scanning"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-12T10:04:58.695Z","content_hash":"f266046eada079b3","content":"The transcript collector implements multiple fallback strategies when the standard path doesn't work:\n\n1. **Primary**: Use the expected path with sanitized project name\n2. **Fallback 1**: Scan all directories in ~/.claude/projects/ and check for projects matching the cwd\n3. **Fallback 2**: Look for directories ending with specific patterns to match the project\n\nThis defensive approach ensures transcripts are found even if Claude's naming scheme changes or in unusual project structures. All fallback attempts are now logged at INFO level for visibility.","timestamp":"2025-12-21T19:27:11.645Z"}
{"action":"add","id":"4d5e3106-cb5a-4c3a-a5f1-c8e60e3f93b2","subject":"Default log level changed to 'error' to minimize log noise","keywords":["logging","log level","default","error","noise reduction"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-13T14:09:24.515Z","content_hash":"73d203da6cc88343","content":"The default log level in `getMinLogLevel()` function was changed from 'info' to 'error' to minimize log noise in production. Users can still override this by setting the `LOCAL_RECALL_LOG_LEVEL` environment variable to 'debug', 'info', or 'warn' as needed.","timestamp":"2025-12-21T19:27:11.645Z"}
{"action":"add","id":"cf977dc8-8429-4227-996a-afccbcf30042","subject":"Enable episodic memory processing via LOCAL_RECALL_EPISODIC_ENABLED environment variable","keywords":["episodic memory","environment variable","LOCAL_RECALL_EPISODIC_ENABLED","mcp server configuration","memory processing"],"applies_to":"global","occurred_at":"2025-12-03T09:49:57.517Z","content_hash":"60eb7fb2678ce1a8","content":"Episodic memory processing is controlled by the `LOCAL_RECALL_EPISODIC_ENABLED` environment variable in the MCP server configuration. It defaults to `false` and must be explicitly enabled by adding `\"LOCAL_RECALL_EPISODIC_ENABLED\": \"true\"` to the `env` section of the local-recall MCP server configuration in `.claude/settings.json` or `.claude/settings.local.json`. The config is read in `src/utils/config.ts` and used in `src/mcp-server/server.ts` to control whether the background daemon processes transcripts for memory extraction.","timestamp":"2025-12-21T19:27:11.647Z"}
{"action":"add","id":"944485f1-5661-4ca2-a1ee-f275dcf45a7f","subject":"Processed log refactored to JSONL append-only format","keywords":["processed-log","jsonl","append-only","file-format","architecture"],"applies_to":"file:src/core/processed-log.ts","occurred_at":"2025-12-21T18:14:47.343Z","content_hash":"3cc406d1e9daba2d","content":"The processed log was refactored from JSON to JSONL (JSON Lines) format for better performance and cleaner append-only operations. Each line is a single JSON object with an `action` field ('add' or 'remove'). On load, the file is replayed to build the current state. A `compact()` method is available to clean up the file when needed. This makes the log append-only, faster to write, and easier to process incrementally.","timestamp":"2025-12-21T19:27:11.647Z"}
{"action":"add","id":"d99ae4b1-3eec-4395-9413-110605a1c8ee","subject":"sqlite-vec loading sequence and file locking mechanism","keywords":["sqlite-vec","native extension","file locking","database initialization","mutex"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-03T10:22:44.117Z","content_hash":"fe7db80f4efb4515","content":"The sqlite-vec extension is loaded in database.ts around line 152 via `sqliteVec.load(db)`. A file locking mechanism exists in the initializeDatabase function to prevent concurrent loading. The lock file is stored at `{memoryDir}/.db.lock`. Lock acquisition includes retry logic with timing and PID logging. However, the mutex error still occurs when multiple processes attempt to load sqlite-vec, suggesting the file lock alone is insufficient for concurrent hook processes.","timestamp":"2025-12-21T19:27:11.648Z"}
{"action":"add","id":"67e8d701-10cd-42e8-a380-e20efa064ff7","subject":"Episodic memories are semantic-searchable records with file/area scope","keywords":["episodic-memory","scope","applies_to","subject","keywords"],"applies_to":"area:episodic-memories","occurred_at":"2025-12-21T18:23:54.705Z","content_hash":"979d8359d33ab2b5","content":"Episodic memories document decisions, fixes, and conventions:\n\n- YAML frontmatter metadata: `id`, `subject`, `keywords`, `applies_to`, `occurred_at`, `content_hash`\n- Scope options: `global` (codebase-wide), `file:<path>` (specific file), `area:<name>` (component)\n- Keywords are lowercase and specific for better search matching\n- Subject is brief one-line description (max ~200 chars)\n- Content uses markdown for readability\n- Each memory is atomic - one concept per file\n- Deduplication: Uses `occurred_at` timestamp + `content_hash` to detect duplicates","timestamp":"2025-12-21T19:27:11.650Z"}
{"action":"add","id":"d1754db1-cbad-4238-b808-3704c5b9a971","subject":"Transcript collector needs INFO-level logging for debugging new repository setup","keywords":["transcript-collector","logging","debug","new-repo","transcripts","visibility"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:02:53.332Z","content_hash":"09c17269cb6e5ac6","content":"When setting up local-recall in a new repository, the transcript collector's debug-level logging doesn't show by default. Added INFO-level logging to make the search process visible:\n\n1. Log when starting the search with the project path\n2. Show whether the Claude projects directory exists\n3. Report the expected folder pattern (-path-to-your-project)\n4. Show transcript search results (found count or not found)\n5. Report sync summary with counts of added/removed/skipped transcripts\n\nThis helps users understand what's happening during initial setup and troubleshoot if transcripts aren't being copied over.","timestamp":"2025-12-21T19:27:11.651Z"}
{"action":"add","id":"e67c7e32-412d-490d-a416-317300c20ca4","subject":"Thinking extractor captures all thinking blocks without content filtering","keywords":["thinking","extractor","filter","blocks","content","no-filtering"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T09:48:06.256Z","content_hash":"51b0efd25fac5cc5","content":"The thinking extractor (lines 41-46) captures **every** thinking block from assistant messages without applying any content-based filtering. It simply extracts all `type: 'thinking'` blocks and joins them.\n\n**Current behavior**: All thinking is stored as-is, which may include low-value reasoning or repetitive thoughts.\n\n**Consideration for future**: If filtering is needed in the future, it would need to be added to the extraction logic, not at search time.","timestamp":"2025-12-21T19:27:11.652Z"}
{"action":"add","id":"6f8547f8-8ae0-49cc-832b-53f3b5b5bbf0","subject":"Claude Code streams thinking and text as separate JSONL lines with same message.id","keywords":["thinking extraction","jsonl parsing","message grouping","transcript format","thinking memories"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T09:47:36.366Z","content_hash":"4779ba7c1306a98c","content":"Claude Code streams assistant responses as separate JSONL lines - each content block (thinking, text, tool_use) gets its own line but they share the same `message.id`. The thinking extractor was expecting them in the same content array. Fixed by:\n\n1. Parsing all JSONL lines from transcript\n2. Grouping entries by `message.id` using a Map\n3. Aggregating thinking and text content from entries with the same message ID\n4. Creating thinking memory pairs from the grouped content\n\nLines 89-159 in thinking-extractor.ts now correctly groups by message ID before extracting thinking blocks.","timestamp":"2025-12-21T19:27:11.653Z"}
{"action":"add","id":"1c74bf5d-c703-4251-8e71-ea0f619b36e7","subject":"Memory extraction prompt tests updated to verify condensed transcript handling","keywords":["memory-extraction-tests","prompt-tests","condensed-format"],"applies_to":"file:tests/unit/prompts/memory-extraction.test.ts","occurred_at":"2025-12-21T18:30:38.769Z","content_hash":"0c12a61c39627123","content":"Updated existing memory extraction prompt tests to:\n\n1. **Verify condensed transcript format** is properly recognized\n2. **Ensure guidelines are present** in the prompt\n3. **Validate memory extraction criteria** are clear\n4. **Check examples** are included\n\nThe tests confirm that the updated prompt builder correctly handles the new condensed transcript format while maintaining all essential extraction guidance. This ensures memory quality doesn't degrade despite reduced token usage.","timestamp":"2025-12-21T19:27:11.654Z"}
{"action":"add","id":"fec5ec79-3acc-4b27-83eb-42873808323f","subject":"Hook configuration for local-recall must be in .claude/settings.json for UserPromptSubmit to fire","keywords":["hooks","configuration","userpromptsubmit","claude-code","settings"],"applies_to":"global","occurred_at":"2025-12-21T19:21:30.507Z","content_hash":"2239ff31d85f2f8c","content":"The SessionStart hook fires automatically when configured, but UserPromptSubmit hook requires explicit configuration in .claude/settings.json. Without this configuration file, UserPromptSubmit won't fire even though the hook code exists and returns proper JSON output with `hookSpecificOutput` structure. The hook code is built to dev-marketplace/local-recall-plugin/scripts/hooks/ by npm run build.\n\nHook configuration needs:\n- SessionStart: Loads recent memories from files\n- UserPromptSubmit: Searches memories and returns JSON context\n- Stop: Analyzes transcripts for memory extraction","timestamp":"2025-12-21T19:27:11.654Z"}
{"action":"add","id":"7f3ef31a-50e0-48e6-97c7-37cccf348bba","subject":"Session-start hook leverages IndexManager for automatic .gitignore management","keywords":["session-start","hook","gitignore","workflow"],"applies_to":"global","occurred_at":"2025-12-21T19:00:53.999Z","content_hash":"c8e64ac5577d59e0","content":"The session-start hook doesn't need explicit .gitignore creation logic because IndexManager handles it automatically. When the hook calls `searchEngine.getRelevantForSession()` during session initialization, it triggers `indexManager.getIndex()` which ensures the .gitignore file exists. This is a clean separation of concerns where the index manager owns responsibility for maintaining the directory structure and configuration files needed for the memory system to function.","timestamp":"2025-12-21T19:27:11.655Z"}
{"action":"add","id":"c857d8ef-16f4-4453-8c72-80f730bcfb45","subject":"Refactored vector search from SQLite+sqlite-vec to Orama","keywords":["refactor","orama","vector-search","sqlite-vec","pure-javascript"],"applies_to":"global","occurred_at":"2025-12-03T11:22:58.632Z","content_hash":"a2e74d7f3d78b080","content":"# Vector Search Architecture Refactoring\n\nThe project replaced the SQLite + sqlite-vec architecture with Orama, a pure JavaScript search engine.\n\n## Key Changes\n\n### Motivation\n- sqlite-vec requires native extensions that cause mutex lock errors when multiple processes load them concurrently\n- Orama is pure JavaScript, eliminating these concurrency issues\n\n### What Was Removed\n- `src/core/database.ts` - Database utility module\n- `src/mcp-server/http-server.ts` - HTTP communication layer\n- `src/utils/daemon-client.ts` - Daemon HTTP client\n- Hook-daemon architecture that used HTTP to avoid concurrent sqlite-vec loading\n\n### What Changed\n- Hooks now work directly without needing to communicate with a daemon via HTTP\n- Memory search and retrieval operations simplified\n- Vector embeddings still use fastembed, but storage/search now uses Orama\n\n### Migration Impact\n- 114 files changed (+3,120 / -1,843 lines)\n- Eliminates the complex HTTP communication pattern between hooks and daemon\n- Simpler deployment and configuration\n- Better compatibility with Claude Code's hook system","timestamp":"2025-12-21T19:27:11.655Z"}
{"action":"add","id":"53dc807b-2fb9-4986-b747-057cb7b70866","subject":"Plugin version is synchronized across multiple files","keywords":["version","plugin.json","package.json","version bump","deployment"],"applies_to":"global","occurred_at":"2025-12-21T19:20:43.672Z","content_hash":"76d331724c3e7038","content":"The project version must be updated in two places to keep them synchronized:\n1. `package.json` - Main package version\n2. `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` - Plugin manifest version\n\nWhen bumping versions (e.g., 0.1.1 → 0.1.2), both files must be updated together. After version changes, run `npm run build` to ensure the compiled distribution is up-to-date before committing.","timestamp":"2025-12-21T19:27:11.656Z"}
{"action":"add","id":"cd14d3fc-44f0-4049-a362-b8e0ce3c9e9d","subject":"Hook testing process: verify build artifacts, check memory state, then test hooks","keywords":["hooks","testing","workflow","session-start","stop-hook","dist"],"applies_to":"global","occurred_at":"2025-12-21T19:20:40.036Z","content_hash":"402a6ca58319d77e","content":"Established testing workflow for hooks:\n1. Verify hooks are compiled in dist/hooks/ (results of `npm run build`)\n2. Check existing memory files in local-recall/episodic-memory/ to understand baseline state\n3. Check memory index (orama-episodic-index.json) to confirm vector store state\n4. Test session-start hook by simulating hook input with session_id, transcript_path, and cwd\n5. Test stop hook similarly\n\nHooks expect JSON input via stdin with standard hook parameters and output results to stdout.","timestamp":"2025-12-21T19:27:11.657Z"}
{"action":"add","id":"0b58af6c-1294-464c-9127-7047983f5802","subject":"UUID validation added to transcript filename processing in TranscriptCollector","keywords":["transcript-collector","uuid-validation","filename-validation","transcript-files"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:20:50.505Z","content_hash":"1f0a29401262be88","content":"Added UUID filename validation to ensure only proper transcript files (with UUID filenames like `550e8400-e29b-41d4-a716-446655440000.jsonl`) are processed or copied from Claude's cache. This prevents accidental processing of unrelated `.jsonl` files.\n\n**Implementation details:**\n- Added `UUID_REGEX` pattern: `/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i`\n- Added `isUuidFilename()` helper function to validate filenames\n- Updated three locations in `findClaudeProjectDir()` method\n- Updated `listSourceTranscripts()` method to filter by UUID\n- Updated `listLocalTranscripts()` method to filter by UUID\n\n**Why this matters:** Claude's transcript directory may contain other `.jsonl` files that aren't transcripts, so UUID validation prevents false positives and ensures data integrity.","timestamp":"2025-12-21T19:27:11.658Z"}
{"action":"add","id":"912f19f3-21ae-4828-a66d-4dd0ed038bd7","subject":"User prompt submit hook unifies episodic and thinking memory searches","keywords":["user-prompt-submit","semantic-search","episodic-memory","thinking-memory","unified-search","configuration"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"84b2bb62e12a238b","content":"The UserPromptSubmit hook performs unified semantic search across both episodic and thinking memory types. It respects independent configuration for each memory type (max tokens and minimum similarity threshold). Results from both stores are combined, deduplicated by ID, and ranked by similarity score. The hook skips internal prompts (marked with `[LOCAL_RECALL_INTERNAL]`) to avoid processing metadata queries.","timestamp":"2025-12-21T19:27:11.659Z"}
{"action":"add","id":"0be5d6cc-1c3d-47d9-a28d-23bc6399abd8","subject":"Transcript collector filters transcripts to only copy those containing thinking blocks","keywords":["transcript-collector","thinking blocks","sync","filtering","haiku transcripts","performance"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:12:31.304Z","content_hash":"57ce7249d22f8057","content":"The transcript collector has been updated to filter transcripts during sync. Only transcripts containing thinking blocks (type: 'thinking' in content) are copied to the local recall directory. This excludes Haiku model transcripts which don't generate thinking blocks, reducing unnecessary storage and processing overhead.\n\nImplementation details:\n- `hasThinkingBlocks()` method checks for thinking content blocks in transcript JSON\n- `syncTranscripts()` skips copying transcripts without thinking blocks\n- `cleanupTranscripts()` removes existing transcripts that lack thinking blocks\n- This is a storage optimization while maintaining thinking memory extraction capability","timestamp":"2025-12-21T19:27:11.661Z"}
{"action":"add","id":"7bf81f8c-b206-4f86-b67c-5c45d98201f2","subject":"Session-start hook now retrieves both episodic and thinking memories","keywords":["session-start","hook","memory-retrieval","episodic","thinking","context-injection"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:58:21.298Z","content_hash":"ff279c35df929fe2","content":"The session-start hook has been updated to retrieve and inject both episodic and thinking memories when a Claude Code session begins, instead of just episodic memories. This allows sessions to continue with richer context including both factual memories and previous reasoning patterns.\n\n### Implementation Details\n- Retrieves the 5 most recent episodic memories (sorted by `occurred_at`, newest first) when `episodicEnabled` is true\n- Retrieves the 5 most recent thinking memories (sorted by `occurred_at`, newest first) when `thinkingEnabled` is true\n- Uses the `formatMemoryForDisplay()` function for episodic memories and `formatThinkingMemoryForDisplay()` for thinking memories\n- Both memory types are output to stdout for injection into Claude's context\n- Configuration flags control whether each memory type is included\n\n### Memory Scope\nBoth episodic and thinking memories are retrieved using memory managers that read directly from the file system, providing immediate context without requiring the MCP server.","timestamp":"2025-12-21T19:27:11.662Z"}
{"action":"add","id":"5c753c1e-0157-498a-998c-8836b10d6612","subject":"Transcript parser should be backward-compatible with both old and new formats","keywords":["transcript","parsing","backward compatibility","content blocks","role"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:22:34.972Z","content_hash":"f00407dd701159ef","content":"The transcript parser needs to support both:\n\n1. **Old format** - `content` as string, `thinking` at root, `role` field\n2. **New format** - `content` as array of blocks, `type` field, thinking in content blocks\n\nThe parser should try parsing as new format first, then fall back to old format if it fails. This ensures compatibility with existing test data while handling real Claude Code transcripts correctly.","timestamp":"2025-12-21T19:27:11.664Z"}
{"action":"add","id":"ac2bab35-8848-463f-924b-4f0d93a59a4c","subject":"CLAUDE.md documentation updated for unified hook and new configuration","keywords":["documentation","CLAUDE.md","hook setup","configuration","env vars"],"applies_to":"global","occurred_at":"2025-12-21T19:00:54.454Z","content_hash":"2b549ef21a47bed0","content":"Updated CLAUDE.md to reflect the consolidation of episodic and thinking hooks into a single UserPromptSubmit hook, and documented all new configuration options. The documentation now clearly shows:\n- Only one UserPromptSubmit hook needs to be configured\n- New env vars for token budgets and similarity thresholds\n- Default values (1000 tokens, 80% similarity for both memory types)\n- How the unified hook intelligently activates based on configuration","timestamp":"2025-12-21T19:27:11.665Z"}
{"action":"add","id":"aefc8ed1-cbb7-439c-955c-0e904ee1931c","subject":"Removed HTTP server architecture in favor of direct file-based locking","keywords":["http-server","daemon-client","architecture","refactoring"],"applies_to":"global","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"e1fe368694412a74","content":"Simplified the architecture by removing the HTTP server approach:\n\n**Deleted:**\n- `src/utils/daemon-client.ts` - No longer needed\n- `src/mcp-server/http-server.ts` - No longer needed\n\n**Modified:**\n- Hooks now directly instantiate VectorStore/ThinkingVectorStore with file-based locking\n- MCP server no longer starts HTTP server (removed from daemon startup)\n- Hooks use the same imports as they would in the daemon: `SearchEngine`, `ThinkingSearchEngine`\n\nThis eliminates the complexity of inter-process HTTP communication while maintaining safety through file-based locking.","timestamp":"2025-12-21T19:27:11.665Z"}
{"action":"add","id":"4366422e-1c4a-4277-8f4e-1e918da5be32","subject":"Gitignore utility removed sqlite references during cleanup","keywords":["gitignore","sqlite","cleanup","gitignore.ts","removed references"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:28:55.282Z","content_hash":"3c2bea035b8d1cae","content":"Updated `src/utils/gitignore.ts` to remove sqlite-related patterns that were lingering from the previous sqlite-vec architecture. The gitignore template is auto-generated by the memory system and should only contain patterns for Orama index files and runtime artifacts, not obsolete sqlite references.","timestamp":"2025-12-21T19:27:11.666Z"}
{"action":"add","id":"61e35ac0-50d2-473c-9e59-1b8ba3fd2309","subject":"ESLint and gitignore patterns updated for new structure","keywords":["eslint","gitignore","configuration","pattern","dev-marketplace","local-recall-plugin"],"applies_to":"global","occurred_at":"2025-12-21T19:04:06.127Z","content_hash":"8f602fc8dc61ec3c","content":"Configuration files were updated to reflect the new plugin structure:\n\n- `eslint.config.js`: Ignore patterns updated from `dev-marketplace/**` to `local-recall-plugin/**`\n- `.gitignore`: Plugin build output patterns updated to reference `local-recall-plugin/scripts/` instead of the old nested path\n- `README.md`: Installation instructions updated to reflect the new root-level `local-recall-plugin/` location","timestamp":"2025-12-21T19:27:11.667Z"}
{"action":"add","id":"bdf17a45-3a18-488a-bcaa-e202d8d83351","subject":"MCP server running from dev-marketplace/local-recall-plugin subdirectory","keywords":["mcp server","configuration","location","plugin","dev-marketplace"],"applies_to":"global","occurred_at":"2025-12-21T19:22:24.167Z","content_hash":"e4594ae225ccb449","content":"The MCP server is currently running from `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js` with config at `dev-marketplace/local-recall-plugin/.mcp.json`. The main project root does not yet have a compiled `scripts/` directory - this suggests the plugin directory is a separate development setup.","timestamp":"2025-12-21T19:27:11.668Z"}
{"action":"add","id":"5b5d6645-78bc-47ed-a7a5-04cf2f981220","subject":"Hook configuration in dev marketplace plugin setup","keywords":["hooks.json","plugin configuration","hook events",".claude-plugin"],"applies_to":"file:dev-marketplace/local-recall-plugin/config/hooks.json","occurred_at":"2025-12-21T19:03:16.962Z","content_hash":"ad2783d88a972070","content":"The local-recall plugin defines hooks in `dev-marketplace/local-recall-plugin/config/hooks.json`. The hook configuration includes SessionStart and UserPromptSubmit hooks which are working in VS Code extension, but the Stop hook is missing or not supported.\n\nVS Code extension hook support appears to be more limited than the Claude Code CLI tool, affecting the memory creation pipeline.","timestamp":"2025-12-21T19:27:11.685Z"}
{"action":"add","id":"011b3e84-097b-4126-bb41-9cc319c71f3e","subject":"Environment variables added to control episodic and thinking memory systems","keywords":["environment variables","configuration","episodic memory","thinking memory","feature flags","LOCAL_RECALL_EPISODIC_ENABLED","LOCAL_RECALL_THINKING_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:21:34.993Z","content_hash":"f447577f32168aa6","content":"Added two environment variables to toggle memory systems independently:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory search, session-start injection, and extraction/processing\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory search and extraction/processing\n\nThese are parsed in `src/utils/config.ts` and stored in the config schema (`src/core/types.ts`). The flags are checked in multiple places:\n- Hooks: `src/hooks/user-prompt-submit.ts`, `src/hooks/user-prompt-submit-thinking.ts`, `src/hooks/session-start.ts`\n- MCP server: `src/mcp-server/server.ts` (controls which extraction/processing tasks run in the daemon)\n\nThis allows users to completely disable either memory system without removing code, useful for debugging or reducing overhead.","timestamp":"2025-12-21T19:27:11.690Z"}
{"action":"add","id":"20f447e3-4adc-4633-ab06-02cf9dbd0006","subject":"Transcript files stored directly in Claude project directory, not in transcripts subfolder","keywords":["transcript location","claude projects","file structure","transcript discovery"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:19:12.033Z","content_hash":"42f6b3649d50fba6","content":"Claude stores transcript .jsonl files directly in ~/.claude/projects/<project-name>/ directory, not in a transcripts/ subfolder. The listSourceTranscripts method should look for *.jsonl files directly in the project directory. This was discovered when debugging why the transcript collector found 230 transcripts after fixing the path lookup logic.","timestamp":"2025-12-21T19:27:11.701Z"}
{"action":"add","id":"00350bb8-3c61-40ac-9693-db4ff2e1de3e","subject":"Ollama provides single shared embedding daemon for multiple Claude instances","keywords":["ollama","embedding","daemon","http-api","local","architecture"],"applies_to":"global","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"766d7fadf905f7c5","content":"Ollama is an npm-installable embedding server that avoids ONNX concurrency issues by running as a single daemon process. Installation is simple:\n\n**macOS**: `brew install ollama` or download from https://ollama.com/download\n**Linux**: `curl -fsSL https://ollama.com/install.sh | sh`\n**Windows**: Download installer from https://ollama.com/download\n\n**Setup**: Pull embedding model: `ollama pull nomic-embed-text`, then start: `ollama serve` (runs on port 11434)\n\n**Why this solves the problem**: One Ollama daemon handles all embedding requests via HTTP API, regardless of how many Claude instances run. The ONNX model loads once in the daemon process, not once per Claude instance. Multiple clients can safely query the already-loaded model without mutex conflicts.","timestamp":"2025-12-21T19:27:11.702Z"}
{"action":"add","id":"a853e21c-a8f6-4daf-8c87-8b1a69f2e4e0","subject":"Unified UserPromptSubmit hook handles both episodic and thinking memories","keywords":["hooks","user-prompt-submit","episodic","thinking","unified","architecture"],"applies_to":"global","occurred_at":"2025-12-21T18:28:29.693Z","content_hash":"ec50fb86c48908dd","content":"The UserPromptSubmit hook in src/hooks/user-prompt-submit.ts is now a unified hook that handles both episodic and thinking memory searches based on configuration. It:\n\n1. Skips internal prompts containing [LOCAL_RECALL_INTERNAL]\n2. Conditionally searches episodic memories if episodicEnabled\n3. Conditionally searches thinking memories if thinkingEnabled\n4. Filters results by similarity threshold and token budget\n5. Combines results from both types before outputting\n\nThis replaces the older approach of having separate hooks for each memory type. The plugin configuration should point to this single unified hook, not to deleted specialized hooks.","timestamp":"2025-12-21T19:27:11.705Z"}
{"action":"add","id":"a0c75a5c-76bf-4202-80fb-d486cbf09fba","subject":"Plugin config uses CLAUDE_PLUGIN_ROOT environment variable for relative paths","keywords":["plugin","config","mcp","environment variable","CLAUDE_PLUGIN_ROOT"],"applies_to":"global","occurred_at":"2025-12-21T18:15:57.311Z","content_hash":"c9c7d2500ad2270b","content":"The `.mcp.json` plugin configuration uses `${CLAUDE_PLUGIN_ROOT}/scripts/mcp-server/server.js` to reference the bundled server script. This variable is resolved at plugin runtime to point to the actual deployed plugin cache directory, allowing the same config to work across different installation locations.","timestamp":"2025-12-21T19:27:11.722Z"}
{"action":"add","id":"089c19a1-3832-4a7c-860f-ff0b776a4daa","subject":"Orama vector index is JSON-based, requires manual rebuilding on schema changes","keywords":["orama","vector index","json","index files","rebuild"],"applies_to":"global","occurred_at":"2025-12-21T19:14:23.787Z","content_hash":"262094cb5bacc69f","content":"## Index Storage\nOrama uses pure JavaScript vector storage with JSON-based index files:\n- Files: `local-recall/orama-episodic-index.json` and `local-recall/orama-thinking-index.json`\n- These are large JSON files containing the vector embeddings and index structure\n- Stored as .json (not .dat or binary format)\n\n## Index Rebuilding\nWhen index files become corrupted or need to be reset:\n1. Delete the JSON index files\n2. System will automatically rebuild them from markdown memory files on next run\n3. May be slow first time as embeddings are regenerated via Ollama\n\n## Important for Debugging\n- Check if index JSON files are valid (can be very large)\n- Index files are gitignored and should not be committed\n- Orama requires Ollama running for embedding generation during index rebuild","timestamp":"2025-12-21T19:27:11.723Z"}
{"action":"add","id":"84ede2b1-664d-4828-af32-946282e84e2e","subject":"Current hooks architecture uses Orama for pure JavaScript vector search","keywords":["hooks","vector-search","orama","pure-javascript","architecture"],"applies_to":"area:hooks","occurred_at":"2025-12-21T19:21:22.678Z","content_hash":"b2a0606b036a85d1","content":"The project's hook system now uses Orama (pure JavaScript) for vector search instead of native modules like better-sqlite3. This enables hooks to run directly in Claude Code processes without binary dependencies or process isolation issues. The main hooks (`user-prompt-submit.js`, `session-start.js`) use:\n\n- Orama for semantic search (works in Node.js processes)\n- Ollama for embeddings (external service call)\n- JSON index files for persistence\n\nThis architecture is important to maintain when updating or creating new hooks - avoid native dependencies.","timestamp":"2025-12-21T19:27:11.724Z"}
{"action":"add","id":"7f1f45a3-76cc-48e1-ac1a-63d095508548","subject":"Removed update and delete MCP tools - memories are write-once","keywords":["mcp","tools","memory_update","memory_delete","immutable"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T19:18:18.497Z","content_hash":"e678313644d0ec5a","content":"Removed `memory_update` and `memory_delete` MCP tools. Memory system is now write-once with no update/delete operations. Only manual user intervention (directly deleting files) can remove memories. This reflects the episodic memory model where memories are immutable records of past events.","timestamp":"2025-12-21T19:27:11.724Z"}
{"action":"add","id":"0ac5f0a9-dd08-48eb-8709-e40d22f8b9e4","subject":"Memory extractor handles multiple Claude response wrapper formats","keywords":["memory-extractor","json-parsing","claude-response","wrapper-formats","fallback-logic"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:19:47.354Z","content_hash":"1da7d09b10a9ffd5","content":"The `parseClaudeResponse` function in memory-extractor.ts handles multiple JSON wrapper formats that Claude might return:\n\n1. Direct array: `[{memory1}, {memory2}]`\n2. `memories` wrapper: `{memories: [{...}, {...}]}`\n3. `results` wrapper: `{results: [{...}]}`\n4. Fallback: Extract JSON object from response text using regex\n\nEach format is tried in sequence with the wrapper checks before attempting the fallback regex extraction. Field normalization is applied to all parsed objects regardless of source format.","timestamp":"2025-12-21T19:27:11.725Z"}
{"action":"add","id":"e557254d-cb10-4fc4-8787-5d9966385b5b","subject":"Finding valid thinking blocks in Claude transcripts requires careful file selection","keywords":["transcript discovery","thinking blocks","claude cache","file location"],"applies_to":"global","occurred_at":"2025-12-03T17:29:39.364Z","content_hash":"078d7102b5a5d805","content":"Claude transcripts with thinking blocks are located in both `~/.claude/projects/*/transcripts/` and locally synced copies in the project directory. Not all transcripts contain thinking blocks - inspection via `grep '\"type\":\"thinking\"'` is needed to find valid examples. The most recent session transcripts may be in `~/.claude/projects/` while processed/synced copies are in the local-recall project folder.","timestamp":"2025-12-21T19:27:11.725Z"}
{"action":"add","id":"ce4f5d3e-5427-4d8b-a7c5-3144b776e29f","subject":"Transcript condenser reduces token usage for memory extraction","keywords":["transcript-condenser","token optimization","memory extraction","JSONL parsing","performance"],"applies_to":"global","occurred_at":"2025-12-21T18:30:37.940Z","content_hash":"76c75275e40577ba","content":"Implemented a transcript condenser (src/core/transcript-condenser.ts) that parses raw JSONL transcript entries and extracts only essential content for memory creation. This reduces token usage significantly by:\n\n1. **Selective content extraction**: Only extracts relevant parts from each transcript entry type\n2. **Structured condensation**: Creates condensed, structured format for the extractor prompt\n3. **Entry type handling**: Processes different entry types (User, Assistant, Tool, Result) with appropriate content filtering\n4. **Batch processing**: Handles multiple transcript lines efficiently\n\nThe condenser is integrated into memory-extractor.ts and is called before building the memory extraction prompt, replacing the previous approach of passing raw JSONL content to Claude.","timestamp":"2025-12-21T19:27:11.726Z"}
{"action":"add","id":"9a05834d-bdae-436f-a2d9-6d191be2ba20","subject":"User-prompt-submit hook now directly uses vector stores with file-based locking","keywords":["hooks","user-prompt-submit","episodic","thinking","direct-access"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"9203595cd445bec7","content":"Updated the hook to instantiate SearchEngine and ThinkingSearchEngine directly instead of making HTTP calls:\n\n- Creates instances of SearchEngine and ThinkingSearchEngine locally\n- Both engines initialize VectorStore/ThinkingVectorStore with file-based locking\n- Runs episodic and thinking searches sequentially (not in parallel)\n- All database operations are protected by cross-process file locks\n- Falls back gracefully if vector store initialization fails (returns empty results)\n\nThe sequential execution and file-based locking ensure no mutex conflicts occur.","timestamp":"2025-12-21T19:27:11.727Z"}
{"action":"add","id":"b5d17c9a-1c0f-43d3-86c0-58a1a1ab8371","subject":"Mutex lock failed error caused by concurrent sqlite-vec loading across processes","keywords":["sqlite-vec","mutex","concurrency","threading","error","pthread","EINVAL"],"applies_to":"global","occurred_at":"2025-12-21T18:28:52.966Z","content_hash":"be94ba3699fdccdb","content":"The 'mutex lock failed: Invalid argument' error occurs when multiple processes try to load sqlite-vec simultaneously. The error is a C++ pthread_mutex_lock() returning EINVAL, which happens when a thread attempts to lock a mutex that was destroyed or already locked in an invalid state.\n\n### Root Cause\nWhen the parent process creates a child process (via execFile), the child inherits a copy of the parent's memory, including any partially-initialized sqlite-vec state. If the parent had begun loading sqlite-vec but hadn't fully initialized it, the child gets an invalid/corrupted mutex that causes pthread_mutex_lock() to fail with EINVAL.\n\n### Solution\nAvoid loading sqlite-vec in the parent process before spawning children. Instead:\n1. Load sqlite-vec only in the child process after execFile returns\n2. Or use a different approach that doesn't require sqlite-vec in the parent\n3. Ensure proper initialization order and process isolation\n\n### Technical Details\n- Error message: 'mutex lock failed: Invalid argument (os error 22)'\n- Occurs with native modules that use mutexes (sqlite-vec, Orama integration)\n- Most common when using child_process.execFile() to spawn TypeScript/Node.js subprocesses","timestamp":"2025-12-21T19:27:11.727Z"}
{"action":"add","id":"41c984d7-60c4-486b-96bd-d5869529303d","subject":"Timeout configuration for memory extraction increased to 10 minutes","keywords":["timeout","memory extraction","performance","claude cli"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:29:11.578Z","content_hash":"924d167bfbde3f6a","content":"The `DEFAULT_OPTIONS` in `memory-extractor.ts` sets timeout to 10 minutes (600000ms). This was increased from 2 minutes to accommodate Haiku processing of longer transcripts. The timeout applies to the entire `claude -p` execution which includes prompt sending, processing, and JSON response.","timestamp":"2025-12-21T19:27:11.728Z"}
{"action":"add","id":"556bfed0-4414-4da7-a025-af02762e8cde","subject":"SessionStart hook loads 5 most recent memories directly from files without search","keywords":["sessionstart-hook","recent-memories","context-loading"],"applies_to":"area:hooks","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"107c8d7093289508","content":"The SessionStart hook is triggered when a Claude Code session begins and:\n1. Reads the 5 most recent memories directly from files (sorted by `occurred_at`)\n2. Outputs memory content to stdout\n3. Gets injected into Claude's context at session start\n\nThis provides quick context awareness without needing semantic search, using recent memories as high-signal starting point.","timestamp":"2025-12-21T19:27:11.728Z"}
{"action":"add","id":"b5b5eb3f-48d8-48e3-822b-ac6b1be154c2","subject":"Memory extraction prompt updated to work with condensed structured transcript data","keywords":["memory extraction","prompt","structured data","guidelines"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:25:46.514Z","content_hash":"7480cfc32040572f","content":"The memory extraction prompt was updated to work with condensed transcript data:\n\n1. **Receives structured entries** instead of raw JSONL\n2. **Works with parsed content** - User prompts, assistant responses, and tool operations\n3. **Maintains extraction guidelines** - Memory metadata (subject, keywords, scope, applies_to)\n4. **Handles tool context** - Understands tool invocations and their purposes\n5. **Produces consistent output** - JSON format with id, subject, keywords, applies_to, occurred_at, content_hash, and content\n\nThe prompt guides Claude to extract meaningful memories from the structured transcript without needing to parse raw JSONL or deal with verbose output.","timestamp":"2025-12-21T19:27:11.729Z"}
{"action":"add","id":"7cd2012e-27e8-4aa2-8445-c20a94070723","subject":"Transcript collector now filters synthetic transcripts before copying from cache","keywords":["transcript-collector","synthetic-transcripts","sync-process","filtering","performance"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:29:16.937Z","content_hash":"600d98e7c933c07a","content":"The `syncTranscripts()` method in transcript-collector.ts was updated to check if source transcripts are synthetic BEFORE copying them from Claude's cache. This prevents unnecessary I/O overhead from copying files that would just be deleted during cleanup. The flow is: 1) cleanupTranscripts() removes existing synthetic files, 2) For each new/modified transcript, checks isSyntheticFile() before copying, 3) Skips with debug log if synthetic. This optimization reduces disk I/O when syncing transcripts.","timestamp":"2025-12-21T19:27:11.730Z"}
{"action":"add","id":"6cb72169-5387-4f17-ac5f-58a833d92a79","subject":"Local Recall plugin successfully installed and ready for use","keywords":["installation","plugin","local-recall","setup"],"applies_to":"global","occurred_at":"2025-12-21T18:16:03.803Z","content_hash":"d2f711904b562f79","content":"The local-recall plugin has been installed successfully. Users need to restart Claude Code to load the new plugin after installation. The installation command uses the `/plugin` command to add local-recall to the project.","timestamp":"2025-12-21T19:27:11.731Z"}
{"action":"add","id":"efc043ec-3c77-49f1-8118-7ebed8c3edb0","subject":"Thinking memory retrieval now uses token-based limits instead of count-based limits","keywords":["thinking memory","retrieval","token limit","configurable","budget"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-21T19:14:59.463Z","content_hash":"18d47f636b0a415c","content":"Changed thinking memory retrieval from a fixed count (10 memories) to a token-based budget system that's configurable via environment variables.\n\nConfiguration:\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` (env var, default: 1000) - Maximum tokens of thinking memories to inject per prompt\n- Added to config schema in `src/core/types.ts` and loaded in `src/utils/config.ts`\n- Memories are added until hitting the token budget\n- Also respects similarity threshold (default 80%, or 0.8)\n\nThis approach is more precise than count-based limiting because it ensures consistent context window usage regardless of memory size.","timestamp":"2025-12-21T19:27:11.732Z"}
{"action":"add","id":"4f530315-07e2-49b8-8620-b48d9817c6df","subject":"Local Recall plugin successfully installed and ready for use","keywords":["local-recall","plugin","installation","setup","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T19:14:22.773Z","content_hash":"1277e12154b2a46f","content":"The local-recall plugin has been installed successfully via the `/plugin` command. The plugin is now ready to be used after restarting Claude Code. This enables memory persistence across sessions for the project.","timestamp":"2025-12-21T19:27:11.732Z"}
{"action":"add","id":"1702d396-bdf2-4a9f-97b4-e1da53b7d345","subject":"Memories use duplicate prevention via content hash and timestamp, but no compaction/pruning exists","keywords":["deduplication","duplicate prevention","content-hash","occurred-at","memory management","no compaction"],"applies_to":"global","occurred_at":"2025-12-21T18:21:53.570Z","content_hash":"8ff36a0fe282cba8","content":"Memory management in Local Recall includes **duplicate prevention** but not compaction:\n\n**Deduplication (Implemented):**\n- `MemoryManager.findDuplicate()` prevents duplicate memory creation\n- Checks if memory with same `occurred_at` timestamp AND `content_hash` already exists\n- If duplicate found, returns existing memory instead of creating new one\n- Helps prevent redundant memories from being stored\n\n**Compaction/Pruning (Does NOT exist):**\n- No automatic cleanup or consolidation of memories\n- No oldest-memory deletion based on `maxMemories` limit\n- `maxMemories` config option exists but is not enforced\n- Memories accumulate indefinitely once created\n- No merging or summarization of related memories\n\nThis means memory directory can grow unbounded unless manually managed.","timestamp":"2025-12-21T19:27:11.732Z"}
{"action":"add","id":"c753afbe-cf4c-42b0-be7d-4727d9519c15","subject":"Memory schema includes occurred_at for tracking when events happened, enabling proper episodic ordering","keywords":["schema","memory","occurred_at","timestamp","episodic"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:20:12.298Z","content_hash":"ecdf3a48e01c3bf8","content":"# Memory Schema: occurred_at Field\n\n## Purpose\n`occurred_at` (ISO-8601 timestamp) marks when the original conversation/event occurred, not when the memory was created.\n\n## Usage\n1. **Deduplication**: Part of dedup key (occurred_at + content_hash)\n2. **Ordering**: Memories sorted by occurred_at descending (most recent first)\n3. **Tie-breaking**: When search scores are equal, recency wins\n4. **Episodic context**: Preserves chronological order of learning\n\n## In CreateMemoryInput\n- `occurred_at` is required and comes from the transcript entry timestamp\n- Separate from `created_at` which is auto-generated when memory file is written\n\n## Contrast with created_at\n- `created_at`: When the memory file was written (auto-generated)\n- `occurred_at`: When the event/learning occurred in the conversation\n\nThis distinction is crucial for episodic memory - the \"when did I learn this\" vs \"when did I process it\" are different timestamps.","timestamp":"2025-12-21T19:27:11.733Z"}
{"action":"add","id":"e276c7ae-f06f-49e1-b841-61ae57626943","subject":"Git workflow for pushing plugin and memory updates","keywords":["git","commit","push","workflow","plugin-updates"],"applies_to":"global","occurred_at":"2025-12-21T19:23:09.457Z","content_hash":"4aa83022d4f03041","content":"When committing plugin and memory updates:\n\n1. Use `git status` to identify all modified files in the plugin directory\n2. Stage changes with `git add dev-marketplace/local-recall-plugin/...`\n3. Create descriptive commits that list the specific changes:\n   - Version bumps\n   - New skills added\n   - Tool description improvements\n   - Metadata updates\n   - New memory files\n4. Push to main branch with `git push`\n\nThe process ensures all plugin changes and associated memory files are tracked together in version control.","timestamp":"2025-12-21T19:27:11.734Z"}
{"action":"add","id":"f4d06209-6941-467f-9726-6e95c8edabaa","subject":"Transcript synthetic file detection should occur before copying, not after","keywords":["performance","synthetic transcripts","file handling","transcript sync"],"applies_to":"global","occurred_at":"2025-12-21T19:23:07.179Z","content_hash":"40f9fea1e815cee4","content":"When syncing transcripts from Claude's cache, synthetic transcripts should be filtered **before** copying to the local transcript directory, not after. This avoids unnecessary I/O operations where files are copied only to be cleaned up on the next pass.\n\nThe pattern: check source → skip if synthetic → only copy genuine transcripts → then cleanup any remaining synthetic files as a safety measure.","timestamp":"2025-12-21T19:27:11.734Z"}
{"action":"add","id":"e3856857-8553-48e2-9129-97096cedfe4c","subject":"ensureGitignore() creates base local-recall directory if it doesn't exist","keywords":["gitignore","directory","mkdir","initialization"],"applies_to":"file:src/core/index.ts","occurred_at":"2025-12-21T19:01:06.461Z","content_hash":"cecce50bd300681f","content":"The `ensureGitignore()` method was updated to create the base `local-recall` directory using `fs.mkdirSync()` if it doesn't already exist. This ensures the method works on fresh projects where the local-recall folder hasn't been initialized yet.\n\n**Location**: `src/core/index.ts`, line 210\n\n**Purpose**: Handles the case where a session starts on a project with no local-recall directory at all.","timestamp":"2025-12-21T19:27:11.735Z"}
{"action":"add","id":"04a80d26-d5aa-4921-b78d-c8e87af763ea","subject":"Memory extractor must use default model (Sonnet), not Haiku","keywords":["memory-extractor","model","claude-cli","sonnet","haiku"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:22:56.476Z","content_hash":"12c5979be06be29b","content":"The memory extractor in `callClaudeCLI` should use Claude's default model (Sonnet), not Haiku. Only the keyword extraction logic in `user-prompt-submit.ts:37` should use Haiku for performance. This ensures memory extraction uses sufficient model capability.","timestamp":"2025-12-21T19:27:11.735Z"}
{"action":"add","id":"32a8539a-c43e-4c06-87f2-a6e467c77db8","subject":"Orama migration removed daemon HTTP server architecture","keywords":["orama","migration","architecture","http-server","daemon","removed"],"applies_to":"global","occurred_at":"2025-12-21T18:28:55.282Z","content_hash":"2f1b19d43c9ddcd2","content":"During the migration from sqlite-vec/fastembed to pure-JavaScript Orama, the HTTP daemon server (`src/mcp-server/http-server.ts`) was removed. This daemon architecture was designed to serialize access to native modules by having hooks call HTTP endpoints instead of loading native modules directly. The daemon approach would be ideal but was deleted during the refactor, necessitating the file-lock workaround instead.","timestamp":"2025-12-21T19:27:11.736Z"}
{"action":"add","id":"ed7dde37-b98e-4fda-8ff1-32bd38ead8cb","subject":"Token-based limiting for thinking memory retrieval with configurable budget","keywords":["token limiting","retrieval budget","thinking memories","configuration","similarity threshold"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-21T19:14:30.494Z","content_hash":"f626940250eb5acf","content":"Thinking memory retrieval was changed from count-based (fixed number of memories) to token-based limiting. This provides better control over context injection.\n\nNew configuration options:\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` (default: 1000) - Maximum tokens to inject\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` (default: 0.8) - Minimum similarity threshold (0.0-1.0, default is 80%)\n\nAlgorithm:\n1. Search vector store with query embedding\n2. Filter results by minimum similarity threshold\n3. Add memories in order until token budget is exceeded\n4. Inject formatted memories into context\n\nConfiguration is managed in `src/utils/config.ts` and schema defined in `src/core/types.ts`.","timestamp":"2025-12-21T19:27:11.736Z"}
{"action":"add","id":"649d8795-80e9-4c63-b92f-11337f500983","subject":"Thinking memories successfully created from transcripts with proper format","keywords":["thinking","memory","extraction","transcript","success"],"applies_to":"global","occurred_at":"2025-12-21T18:16:42.322Z","content_hash":"28f0e6a272263f6a","content":"After fixing the extractor, thinking memory extraction successfully processes transcripts. Creates memories with both `## Thought` and `## Output` sections. Each thinking memory represents a thought-output pair from Claude's reasoning. Test extraction created 616 thinking memories from 59 transcripts without errors.","timestamp":"2025-12-21T19:27:11.736Z"}
{"action":"add","id":"3b05956f-32f8-4edb-aea8-0d8976ccc412","subject":"Transcript types schema provides JSONL structure for Claude Code cache transcripts","keywords":["transcript-schema","jsonl","types","claude-code","transcript-structure"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T18:30:38.769Z","content_hash":"c527e815c3951f80","content":"Created comprehensive TypeScript types for parsing Claude Code transcript JSONL files. The schema includes:\n\n**Entry types:**\n- `UserEntry`: User messages\n- `AssistantEntry`: Claude responses with content blocks\n- `SystemEntry`: System messages\n- `FileHistorySnapshot`: File change history\n- `QueueOperation`: Tool/agent invocations\n\n**Content block types:**\n- `TextBlock`: Plain text\n- `ThinkingBlock`: Internal reasoning\n- `ToolUseBlock`: Tool invocations\n- `ToolResultBlock`: Tool results\n\n**Key properties:**\n- Each entry has `timestamp` and `type` for sequencing\n- `content` is an array of content blocks\n- Metadata includes session info, turn count, and model info\n\nThis schema is essential for the transcript condenser to properly parse and extract relevant content.","timestamp":"2025-12-21T19:27:11.737Z"}
{"action":"add","id":"a976224e-dde8-4e98-8a7e-eba837f480fd","subject":"Memory extraction prompt tests updated for condensed transcript format","keywords":["memory-extraction-tests","test-updates","condensed-format-validation"],"applies_to":"file:tests/unit/prompts/memory-extraction.test.ts","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"9e1adf7ed051798f","content":"Updated existing tests in `memory-extraction.test.ts` to work with the new condensed transcript format:\n\n1. Modified test data to match `CondensedTranscript` structure\n2. Updated assertions to validate proper handling of condensed events\n3. Ensured prompt generation works correctly with pre-parsed data\n4. Maintained backward compatibility with existing memory extraction logic\n\nTests validate that the new condensed format provides sufficient context for quality memory extraction while reducing token overhead.","timestamp":"2025-12-21T19:27:11.737Z"}
{"action":"add","id":"eb15beac-1d47-46d1-a890-d8cded3c1ce9","subject":"Claude project discovery uses path-to-dashes naming convention","keywords":["claude projects","transcript discovery","path conversion","project folder naming"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:24:15.046Z","content_hash":"d48aed1419c128eb","content":"Claude stores projects in ~/.claude/projects/ using a path-to-dashes naming convention. For example, /Users/joe/Code/Syntessera/local-recall becomes -Users-joe-Code-Syntessera-local-recall. The code must convert the current working directory path by replacing forward slashes with dashes and prepending a dash, then search ~/.claude/projects/ for matching folders. Transcripts are stored directly in the project folder (not in a transcripts subfolder).","timestamp":"2025-12-21T19:27:11.738Z"}
{"action":"add","id":"e2a7e4a8-ef3e-477f-ad4a-c224f498382e","subject":"ProcessedLog refactored to JSONL format with append-only operations","keywords":["processed-log","jsonl","append-only","performance","architecture"],"applies_to":"file:src/core/processed-log.ts","occurred_at":"2025-12-21T19:11:11.958Z","content_hash":"a1b1a225b356f445","content":"The ProcessedLog implementation was migrated from JSON to JSONL format for cleaner, faster, and append-only operations:\n\n- Each entry is a single JSON line with `action: \"add\"` or `action: \"remove\"`\n- `recordProcessed()` appends an \"add\" entry\n- `removeEntry()` appends a \"remove\" entry\n- On load, the file is replayed to reconstruct current state\n- Added `compact()` method to defragment the file when needed\n\nBenefits: No need for pretty-printing, append-only means no rewrites, faster I/O, simpler to reason about state transitions.","timestamp":"2025-12-21T19:27:11.739Z"}
{"action":"add","id":"8a75d99e-7b4a-4096-b63c-100e6838aeab","subject":"Logging configuration supports environment variable override","keywords":["logging","environment variable","LOCAL_RECALL_LOG_LEVEL","configuration"],"applies_to":"global","occurred_at":"2025-12-13T14:09:24.515Z","content_hash":"3219d810bab2636e","content":"The logging system respects the `LOCAL_RECALL_LOG_LEVEL` environment variable, allowing users to override the default log level at runtime. Valid values are 'debug', 'info', 'warn', and 'error'.","timestamp":"2025-12-21T19:27:11.740Z"}
{"action":"add","id":"aaa180ae-9fcb-4423-9435-b828a0351378","subject":"Removed sqlite references from gitignore patterns","keywords":["gitignore","cleanup","sqlite","documentation"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:27:48.823Z","content_hash":"01d064643984226a","content":"Updated gitignore generation to remove outdated sqlite-vec and better-sqlite3 references that were leftover from the pre-Orama migration. These patterns were confusing since the codebase no longer uses SQLite-based vector storage.","timestamp":"2025-12-21T19:27:11.740Z"}
{"action":"add","id":"5d95231c-144e-41cd-8cef-8a5f1f3b0a18","subject":"Logger utility requires single string arguments, not multiple args","keywords":["logger","logging","debug","error","api"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:16:58.381Z","content_hash":"7265582a22f05ebb","content":"The logger utility in src/utils/logger.ts expects single string arguments via string interpolation, not multiple arguments like console.log(). When calling logger.debug() or logger.error(), concatenate messages into a single string rather than passing multiple arguments.","timestamp":"2025-12-21T19:27:11.742Z"}
{"action":"add","id":"ba11af73-e75f-4540-9544-bae9a3a2dfd6","subject":"Orama migration resolves mutex contention issues from sqlite-vec","keywords":["orama","mutex","sqlite-vec","migration","hooks","pure javascript"],"applies_to":"global","occurred_at":"2025-12-21T19:01:54.815Z","content_hash":"bca792bfcfbe50a1","content":"The migration from sqlite-vec to Orama (pure JavaScript vector store) has successfully resolved mutex contention issues that were occurring in hooks. Orama is pure JavaScript with no native dependencies, eliminating the process isolation and mutex problems that sqlite-vec had when running in hook processes. Hooks now complete cleanly without mutex errors.","timestamp":"2025-12-21T19:27:11.742Z"}
{"action":"add","id":"996ad0f8-e25e-4404-a620-6d585211a6b7","subject":"Orama pure JavaScript architecture eliminates HTTP server need","keywords":["orama","architecture","vector-store","pure-javascript","no-http-server"],"applies_to":"global","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"3386e8ddac080172","content":"The codebase migrated from an HTTP server architecture to using Orama directly for vector search. Orama is a pure JavaScript library with no native dependencies or mutex issues, so hooks can call it directly without needing a separate daemon HTTP server. The old `http-server.ts` mentioned in docs doesn't exist - Orama handles all vector operations in-process within hooks and MCP server.","timestamp":"2025-12-21T19:27:11.743Z"}
{"action":"add","id":"d1294304-b2ff-4162-b5b1-86efa77e2615","subject":"File-based locking mechanism for cross-process database safety","keywords":["file-lock","database","synchronization","cross-process","stale-lock"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"49197f5656d2e0e4","content":"Implemented `withDbMutex(dbPath, operation)` function that:\n\n1. Creates a lock file next to the database (`{dbPath}.lock`)\n2. Acquires lock with timeout (5 second retries with exponential backoff)\n3. Detects stale locks (>10 seconds old) and removes them\n4. Executes the operation with lock held\n5. Releases lock in finally block\n\nThis ensures that all sqlite-vec operations are serialized across processes, preventing mutex corruption. Lock files are cleaned up automatically.","timestamp":"2025-12-21T19:27:11.744Z"}
{"action":"add","id":"faa7ec6f-1097-44ca-9c15-c1efba9b2548","subject":"Synthetic transcript handling in transcript collector","keywords":["synthetic transcripts","transcript-collector","copyTranscript","filtering","i/o optimization"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:28:20.994Z","content_hash":"62b9b8415ef223e2","content":"## Synthetic Transcript Filtering\n\nThe transcript collector's `syncTranscripts()` method now filters synthetic transcripts BEFORE copying them from Claude's cache, rather than after. This optimization prevents unnecessary I/O operations.\n\n### Flow\n1. `cleanupTranscripts()` runs first - removes any existing synthetic files from `local-recall/transcripts/`\n2. Lists source transcripts from Claude's cache\n3. For each new/modified transcript, checks `isSyntheticFile(transcript.sourcePath)` BEFORE copying\n4. Skips copying with debug log if the transcript is synthetic\n\n### Why This Matters\nPreviously, synthetic transcripts could be copied into the local folder and then deleted on the next cleanup run. Now they're filtered at the source, avoiding wasted I/O operations.\n\n### Related Code\n- `isSyntheticFile()` - Determines if a transcript is synthetic\n- `cleanupTranscripts()` - Removes synthetic files that might have slipped through\n- `copyTranscript()` - The actual copy operation, now guarded by synthetic check","timestamp":"2025-12-21T19:27:11.746Z"}
{"action":"add","id":"b092f7c1-8037-4091-b5e0-64cefcbda0b6","subject":"Test mocking structure for Claude CLI invocation in memory extractor tests","keywords":["memory-extractor","testing","mocking","spawn","child-process"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T19:22:56.476Z","content_hash":"ff9871f38cab91de","content":"When testing `callClaudeCLI`, mock the entire child process: both `spawn()` for the claude command and `spawn()` for the stdin cat command. Properly simulate stdout/stderr/exit events on mock child processes. The test structure mirrors the internal pipe-based message passing used when sending large prompts via stdin.","timestamp":"2025-12-21T19:27:11.747Z"}
{"action":"add","id":"ffe0bf22-97c9-42ed-bf05-a4824b568297","subject":"Transcript sync now checks both mtime and file size for changes","keywords":["transcript sync","file size","change detection","transcript-collector"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:26:56.234Z","content_hash":"1e63db7f295c6bb9","content":"Updated the `syncTranscripts()` method to detect changes by checking both file modification time (mtime) AND file size. This ensures that even if a transcript file is quickly rewritten with slightly different content, the system will detect and reprocess it rather than skipping it due to recent mtime.\n\nPreviously, the system relied only on mtime for change detection, which could miss changes if the new file had an older timestamp. The processed-log system handles the actual reprocessing by comparing content hashes - if the hash changed, old memories are deleted and new ones are created.","timestamp":"2025-12-21T19:27:11.747Z"}
{"action":"add","id":"a4ee0c48-ddfe-4046-ae93-5a3d94b652cc","subject":"MCP tools simplified: removed update and delete operations","keywords":["mcp-server","tools","memory-api"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T18:22:28.112Z","content_hash":"d63746c5d6ce70b9","content":"Removed `memory_update` and `memory_delete` MCP tools. Available tools now:\n\n- `memory_create`: Create idempotent memories (returns existing if duplicate)\n- `memory_get`: Retrieve specific memory by ID\n- `memory_search`: Semantic search\n- `memory_list`: List all memories\n\nMemory management is now read-only for agents; only users can manually delete.","timestamp":"2025-12-21T19:27:11.748Z"}
{"action":"add","id":"3b0b5f96-cf54-483d-9382-612e42a6306d","subject":"user-prompt-submit hook directly loads embedding model, causing concurrency issues","keywords":["user-prompt-submit","hook","embedding","search engine","concurrency"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:19:42.881Z","content_hash":"ebca6b854f54b755","content":"The user-prompt-submit hook directly instantiates SearchEngine and ThinkingSearchEngine, which both load the embedding model via getVectorStore and getThinkingVectorStore. This direct model loading in each hook execution causes ONNX mutex conflicts when multiple Claude instances run simultaneously. In contrast, session-start hook only uses MemoryManager (file-based, no embeddings) and is safe.","timestamp":"2025-12-21T19:27:11.749Z"}
{"action":"add","id":"756da8f8-6db0-4840-b41f-6822c0cad2d7","subject":"Local Recall uses Orama (pure JavaScript) instead of SQLite for vector search","keywords":["orama","vector-search","sqlite","migration","architecture"],"applies_to":"global","occurred_at":"2025-12-03T11:22:02.028Z","content_hash":"63133b9042e0651a","content":"The project has migrated from using SQLite with the sqlite-vec extension to Orama, a pure JavaScript vector search library. This change allows:\n\n1. **Bundling**: Hooks can be bundled without native dependencies\n2. **Distribution**: Plugin hooks work without requiring native module compilation\n3. **Simplicity**: No need for the HTTP daemon architecture that was used to avoid mutex lock errors from concurrent sqlite-vec access\n\nOrama handles both episodic and thinking memory searches through the same interface. Old code referencing sqlite-vec, http-server.ts, or daemon-client.ts is stale and should be removed.","timestamp":"2025-12-21T19:27:11.750Z"}
{"action":"add","id":"89041d45-d3d8-4a29-beb4-b124ca889de2","subject":"SessionStart hook performs full reload of all memories, not delta","keywords":["session-start","hook","memory-loading","full-reload","initialization"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-03T09:47:48.632Z","content_hash":"fc49d7ca5d97d251","content":"On session startup, the SessionStart hook performs a **full reload** of all memories rather than a delta sync. The implementation in `src/hooks/session-start.ts:57-63` creates a fresh `MemoryManager` instance, loads all memories via `listMemories()`, and then selects the 5 most recent memories sorted by `occurred_at` timestamp. This is a full reload approach, not incremental.","timestamp":"2025-12-21T19:27:11.750Z"}
{"action":"add","id":"617b2fbe-492e-4493-b4ba-dd3472365396","subject":"Memory extraction uses Claude Haiku with single-turn JSON output","keywords":["memory extraction","haiku model","json output","single turn","claude cli"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:30:03.315Z","content_hash":"5bf2a47aadfd0c19","content":"Memory extraction invokes Claude CLI with specific constraints:\n- Model: `claude-haiku-4-5` (for cost and speed)\n- Flags: `--max-turns 1` (single response only, no back-and-forth)\n- Output: JSON-only format (no explanatory text)\n- Timeout: 600000ms (10 minutes) to allow sufficient processing time\n\nThe prompt in `memory-extraction.ts` explicitly instructs Claude to return ONLY valid JSON with no additional explanation or markdown formatting.","timestamp":"2025-12-21T19:27:11.751Z"}
{"action":"add","id":"69ec1320-69f2-4a3f-8afd-045a434da9a1","subject":"Extensive thinking memory file deletions indicate cleanup or reset operation","keywords":["thinking-memory","cleanup","deletion","reset","batch-operation"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T18:24:32.614Z","content_hash":"cd5b830b65e9f3ad","content":"# Thinking Memory Cleanup Operation\n\nApproximately 80+ thinking memory files were deleted in a batch operation. This includes IDs like:\n- 012c7ece-33ff-4266-9cda-93d65ae88e3d.md\n- 02f089cd-9b80-43c5-b45a-fcd6559d860c.md\n- And many others...\n\nThis could indicate either:\n1. A reset of the thinking memory system as part of the JSONL migration\n2. A cleanup of obsolete or duplicate memories\n3. A full reprocessing of transcripts with new extraction logic\n\nThe CLAUDE.md mentions that to fully reset thinking memories: `rm local-recall/thinking-processed-log.jsonl && rm local-recall/orama-thinking-index.json && rm -rf local-recall/thinking-memory/`","timestamp":"2025-12-21T19:27:11.751Z"}
{"action":"add","id":"bf432d1b-60d2-475f-9de2-25ae06927889","subject":"Hooks architecture: three main hooks for Claude Code integration","keywords":["hooks","session-start","user-prompt-submit","stop","claude-code-integration","memory-injection"],"applies_to":"global","occurred_at":"2025-12-21T18:19:53.806Z","content_hash":"50c8ebd74cb2c1b7","content":"Local Recall has three main hooks that integrate with Claude Code:\n\n1. **SessionStart Hook** (`src/hooks/session-start.ts`) - Triggered when a Claude Code session begins, loads memory index and injects relevant memories into context\n2. **UserPromptSubmit Hook** (`src/hooks/user-prompt-submit.ts`) - Runs before Claude processes user prompts, performs semantic search on memories\n3. **Stop Hook** (`src/hooks/stop.ts`) - Processes transcripts and extracts new memories\n\nHooks are configured in `.claude/settings.json` and receive JSON via stdin, outputting results to stdout for injection into Claude's context.","timestamp":"2025-12-21T19:27:11.752Z"}
{"action":"add","id":"7e8b4e12-ef3a-442d-903d-72cb608c4c5f","subject":"Plugin needs to stay synchronized with main source code","keywords":["plugin","maintenance","synchronization","stale-files","hook-updates"],"applies_to":"area:plugin","occurred_at":"2025-12-21T19:21:22.678Z","content_hash":"462d60523ce27fcc","content":"The plugin architecture has bundled copies of hook files that can become stale when the main codebase changes. When updating hooks or switching libraries (like from better-sqlite3 to Orama), the plugin's bundled versions must be updated and rebuilt. Key files to keep in sync:\n\n- `src/hooks/*.ts` → `dev-marketplace/local-recall-plugin/scripts/hooks/*.js`\n- Hook configurations in both locations\n- Dependencies and environment assumptions\n\nConsider adding a build step or symlinks to reduce duplication.","timestamp":"2025-12-21T19:27:11.753Z"}
{"action":"add","id":"d174e203-f891-481d-bbd8-5b1bf16cb04f","subject":"Duplicate event handlers in async child process patterns cause race conditions","keywords":["child process","event handlers","race condition","promise","close event"],"applies_to":"global","occurred_at":"2025-12-21T18:28:08.458Z","content_hash":"87eca5e4048e69f4","content":"## Pattern Issue\nWhen working with child processes in Node.js and promises, having multiple event listeners for the same event (like `close`) can cause race conditions where the promise resolves multiple times.\n\n## Why This Matters\nIn the user-prompt-submit hook's `callClaudeForKeywords` function, having two `child.on('close', ...)` handlers meant:\n- Both handlers could execute when the process closes\n- Both could attempt to resolve the promise\n- This creates unpredictable behavior and potential resource leaks\n\n## Best Practice\n- Use a single event handler or combine logic into one handler\n- Use a \"safeResolve\" wrapper that ensures the promise only resolves once\n- Consider using `once()` instead of `on()` for single-fire events like `close`","timestamp":"2025-12-21T19:27:11.753Z"}
