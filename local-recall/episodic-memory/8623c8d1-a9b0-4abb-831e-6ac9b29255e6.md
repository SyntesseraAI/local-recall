---
id: 8623c8d1-a9b0-4abb-831e-6ac9b29255e6
subject: >-
  Memory extraction workflow: condense transcript → pass to Claude → parse
  memories → store with deduplication
keywords:
  - memory-extraction-flow
  - workflow
  - deduplication
  - claude-subprocess
  - content-hash
applies_to: 'area:memory-extraction'
occurred_at: '2025-12-03T09:49:49.357Z'
content_hash: d7558f24177f5a99
---
# Memory Extraction Workflow

## Process Flow
1. **Condense**: Use `TranscriptCondenser.condense()` to parse JSONL and extract minimal content
2. **Extract**: Pass condensed data to Claude via subprocess using memory extraction prompt
3. **Parse**: Parse Claude's JSON response to get memory objects
4. **Deduplicate**: Check for duplicates using `occurred_at` + `content_hash`
5. **Store**: Save unique memories to disk and vector store

## Key Optimization
The condenser reduces input token count significantly by:
- Removing full file contents (keeping only file paths)
- Skipping large bash outputs
- Extracting only reasoning from thinking blocks
- Focusing on semantic content relevant to memory creation

## Related Components
- `TranscriptCondenser` - Condenses JSONL to minimal format
- `MemoryExtractor` - Calls Claude subprocess with condensed data
- `MemoryManager` - Handles deduplication and storage
