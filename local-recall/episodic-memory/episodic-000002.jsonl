{"action":"add","id":"699deaec-794d-4d71-bee7-3981d8ad6afe","subject":"Multiple Claude Code instances may run old cached MCP server versions","keywords":["claude code","multiple instances","plugin cache","version mismatch"],"applies_to":"global","occurred_at":"2025-12-21T19:26:32.435Z","content_hash":"d29281d89915392f","content":"When multiple Claude Code instances run the same local-recall plugin, they may use the cached plugin version rather than local development builds. The plugin cache location is `~/.claude/plugins/cache/local-recall-marketplace/local-recall/<version>/scripts/mcp-server/server.js`.\n\nTo force a specific version:\n1. Manually copy the dev build to the cache location, OR\n2. Reinstall the plugin and restart Claude Code instances\n\nAlways restart Claude Code after updates to pick up changes.","timestamp":"2025-12-21T19:27:11.753Z"}
{"action":"add","id":"f065a563-c37a-46b5-b120-26427b7243cc","subject":"Stop hook changed to process entire transcript history instead of 30-second window","keywords":["stop_hook","transcript","processing","time_window","history"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T18:20:12.298Z","content_hash":"c6b425c6cd518e6b","content":"# Stop Hook History Processing\n\n## Previous Behavior\n- Filtered transcript messages to only those within 30 seconds of stop event\n- Messages older than 30 seconds were discarded\n- Result: Most memories weren't created because messages had aged out\n\n## New Behavior\n- Processes entire transcript history from the session\n- No time-based filtering\n- Relies on deduplication (occurred_at + content_hash) to prevent creating duplicate memories on repeated hook runs\n\n## Implication\nMemory extraction is more comprehensive, captures the full session's learning even if hook runs at the very end of a long session.","timestamp":"2025-12-21T19:27:11.754Z"}
{"action":"add","id":"233c79a8-494d-4c7e-8d35-2ba1393e539a","subject":"Thinking memory extraction runs in parallel (20 concurrent) for performance","keywords":["thinking-memory","extraction","parallel","concurrency","performance","transcript-processing"],"applies_to":"area:thinking-memories","occurred_at":"2025-12-21T18:23:00.278Z","content_hash":"d1440a37212bc576","content":"The thinking memory extractor processes transcripts using 20 parallel workers to extract thinking blocks and their corresponding outputs efficiently.\n\n**Implementation detail**: `src/core/thinking-extractor.ts` uses Promise.all() with a concurrency limit of 20 to process large transcripts in parallel.\n\n**Why parallelism**: Thinking memory extraction is I/O-bound (reading transcripts, generating embeddings) and can be parallelized safely since each extraction is independent.\n\n**Configuration**: The 20-worker limit is hardcoded but could be made configurable based on system resources.\n\n**Related files**:\n- `src/core/thinking-extractor.ts` - Main extraction logic\n- `src/core/thinking-processed-log.ts` - Track which transcripts have been processed","timestamp":"2025-12-21T19:27:11.754Z"}
{"action":"add","id":"e1d2bdff-c3c2-45c0-8e99-6365ec9621f2","subject":"Session guarding issue: memory extraction prompt wasn't filtered by [LOCAL_RECALL_INTERNAL] prefix","keywords":["session guarding","memory extraction","local recall internal","prompt filtering","recursion prevention"],"applies_to":"global","occurred_at":"2025-12-21T19:22:59.576Z","content_hash":"a7e3f89afd3b5098","content":"The UserPromptSubmit hook guards against processing internal prompts by checking for `[LOCAL_RECALL_INTERNAL]` prefix, but the memory extraction prompt generated by `buildMemoryExtractionPrompt()` in `src/prompts/memory-extraction.ts` didn't include this prefix. This caused the memory extraction prompt itself to be processed as a regular user prompt, creating unwanted recursion in logs. Fixed by adding the prefix to the start of the memory extraction prompt (line 62-63).","timestamp":"2025-12-21T19:27:11.755Z"}
{"action":"add","id":"e87a0728-83bf-4910-bb49-412eab405951","subject":"Plugin deployment requires bundled dependencies - unbundled versions fail in other Claude instances","keywords":["plugin","deployment","bundled","dependencies","mcp server","cache","node_modules"],"applies_to":"global","occurred_at":"2025-12-21T18:15:57.311Z","content_hash":"6e0a932282b1039e","content":"The local-recall plugin deploys to `~/.claude/plugins/cache/local-recall-marketplace/local-recall/VERSION/` but the MCP server needs all dependencies bundled since node_modules aren't shipped with plugins. The build script must NOT use the `--external` flag when bundling server.js. Without bundled deps, the server.js fails to run on other Claude instances with module resolution errors. The plugin cache becomes stale and needs to be cleared when upgrading versions.","timestamp":"2025-12-21T19:27:11.755Z"}
{"action":"add","id":"35196511-5dab-484f-b57d-30b702af93e4","subject":"Mutex errors caused by onnxruntime-node native bindings in fastembed","keywords":["mutex","fastembed","onnxruntime-node","native bindings","concurrent processes","hooks"],"applies_to":"global","occurred_at":"2025-12-21T18:27:48.823Z","content_hash":"512db5d6644aef2f","content":"After migrating from sqlite-vec to Orama, mutex errors persisted because fastembed (used for embeddings) depends on onnxruntime-node which has native bindings. When multiple hook processes load onnxruntime-node concurrently, mutex contention occurs - same issue as sqlite-vec had.\n\nThe solution implemented: file-based locking using proper-lockfile to serialize access to fastembed initialization and embedding operations. Lock file at `/tmp/local-recall-embedding.lock` with 10 retries and 30-second stale timeout.","timestamp":"2025-12-21T19:27:11.755Z"}
{"action":"add","id":"96d25607-6b3c-4a1e-90c1-67801ee1e19b","subject":"Transcript format uses content array with content blocks, not flat string","keywords":["transcript","parsing","content blocks","thinking","claude code format"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:30:41.521Z","content_hash":"a9e110f4e00eebfa","content":"Claude Code transcripts have messages with `content` as an array of content blocks, not a simple string. Each block has a `type` field:\n- `type: \"thinking\"` with `thinking` field (internal reasoning)\n- `type: \"text\"` with `text` field (assistant output)\n- `type: \"tool_use\"` / `type: \"tool_result\"` for tool interactions\n\nThe actual format also uses `type` field for message role classification (not `role`), though some older/legacy formats may still use `role`.","timestamp":"2025-12-21T19:27:11.756Z"}
{"action":"add","id":"a299d8c3-ee42-4967-a00a-cb11aabf39c2","subject":"Episodic and thinking memories use separate vector stores and search paths","keywords":["episodic-memory","thinking-memory","vector-store","search","independent","configuration"],"applies_to":"global","occurred_at":"2025-12-21T18:28:54.683Z","content_hash":"8ca27141d4efc2d7","content":"Episodic and thinking memories are completely independent systems with separate vector stores, search implementations, and configuration.\n\n**Episodic Memories**:\n- Core memory storage in `src/core/episodic-jsonl-store.ts`\n- Vector store: `src/core/vector-store.ts` (Orama-based)\n- Search: `src/core/search.ts`\n- Configuration: `episodicEnabled`, `episodicMaxTokens`, `episodicMinSimilarity`\n\n**Thinking Memories**:\n- Separate storage in `src/core/thinking-jsonl-store.ts`\n- Vector store: `src/core/thinking-vector-store.ts` (distinct Orama index)\n- Search: `src/core/thinking-search.ts`\n- Configuration: `thinkingEnabled`, `thinkingMaxTokens`, `thinkingMinSimilarity`\n\n**Index Files**:\n- Episodic: `local-recall/orama-episodic-index.json`\n- Thinking: `local-recall/orama-thinking-index.json`\n- Both are gitignored and auto-generated\n\n**UserPromptSubmit Hook**:\n- Unified hook that searches both types based on configuration\n- Each memory type has independent thresholds and token budgets\n- Results are combined and injected into context\n- Allows enabling/disabling each type independently","timestamp":"2025-12-21T19:27:11.756Z"}
{"action":"add","id":"bd324235-6080-48c5-ba80-7a1ce94e409b","subject":"Thinking memories capture Claude's reasoning paired with output","keywords":["thinking-memory","reasoning","thought-output-pairs","extraction"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"363c2eea563c93ae","content":"Thinking memories store Claude's internal reasoning blocks alongside their corresponding text outputs. Each thinking memory has two sections: 'Thought' (the internal reasoning) and 'Output' (the text response). These memories are extracted from transcripts and help future sessions understand how similar problems were approached.","timestamp":"2025-12-21T19:27:11.759Z"}
{"action":"add","id":"c5c9f602-ea2e-4e22-924a-055db081447b","subject":"Plugin rebuild requires npm run build to compile TypeScript sources","keywords":["plugin","build","typescript","dist","hooks"],"applies_to":"file:dev-marketplace/local-recall-plugin","occurred_at":"2025-12-21T19:22:18.525Z","content_hash":"e2aa6b1b53bc6f4b","content":"After updating the main source files or hooks.json in the plugin, `npm run build` must be run from the root project directory to recompile TypeScript sources and regenerate the plugin's `dist/` and `scripts/hooks/` directories. The plugin distribution is generated from the main project's build output.","timestamp":"2025-12-21T19:27:11.760Z"}
{"action":"add","id":"a814db08-9481-4c92-bc0f-6fead7a822d4","subject":"Memory extraction testing requires comprehensive field variation coverage","keywords":["testing","memory-extractor","field-normalization","test-cases","edge-cases"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T18:19:47.354Z","content_hash":"02c9d58ca49329fb","content":"Added comprehensive test cases to verify field name normalization works correctly:\n\n- Test for alternative field names (`title`, `summary`, `description`, `scope`, `tags`)\n- Test for mixed field usage in same batch\n- Test for missing required fields after normalization (validation still fails as expected)\n- Test for different wrapper formats combined with field normalization\n\nAll 228 tests pass including these new normalization tests, confirming the fix handles Claude's field name variations properly.","timestamp":"2025-12-21T19:27:11.762Z"}
{"action":"add","id":"55980445-0c89-483d-9a0f-a06dd1687f41","subject":"UUID validation required for transcript filenames in transcript-collector","keywords":["transcript","uuid","filename","validation","transcript-collector","source transcripts"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:28:51.693Z","content_hash":"c65f8add1a3d38c7","content":"Only JSONL files with UUID filenames (e.g., `550e8400-e29b-41d4-a716-446655440000.jsonl`) should be processed as transcripts. Non-UUID `.jsonl` files should be ignored. This validation was added to `transcript-collector.ts` lines 17-20 with:\n\n- `UUID_REGEX` pattern for matching standard UUID format\n- `isUuidFilename()` helper function to validate filenames\n- Three update locations in `findClaudeProjectDir()` method\n- One update in `listSourceTranscripts()` method\n- One update in `listLocalTranscripts()` method\n\nThis prevents accidentally processing or copying files that aren't proper transcript files.","timestamp":"2025-12-21T19:27:11.764Z"}
{"action":"add","id":"b4895b25-3573-464e-b910-8b3a92963f43","subject":"Stop hook is working in VS Code and successfully creating memories","keywords":["stop hook","vs code","memory creation","hooks","working"],"applies_to":"global","occurred_at":"2025-12-21T17:19:22.943Z","content_hash":"d8d7dc48ee1f3c0b","content":"The Stop hook IS firing successfully in VS Code. Verified through recall.log which shows Stop hook firing and creating memories from conversations. All three hooks are functional: SessionStart loads memories, UserPromptSubmit searches and injects memories, and Stop hook creates new memories from transcripts.","timestamp":"2025-12-21T19:27:11.766Z"}
{"action":"add","id":"3a0a53b9-7ca6-4788-b986-df1d746a9bd0","subject":"Orama uses cosine distance for similarity scoring","keywords":["similarity-scoring","cosine-distance","ranking","orama"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"00fbe2789ec81672","content":"Search results are ranked by cosine similarity score (0.0 = no match, 1.0 = identical). Scores are rounded to 2 decimal places. When scores are equal, recency tie-breaking applies (more recent memories ranked first by occurred_at timestamp). This provides consistent, predictable ranking across searches.","timestamp":"2025-12-21T19:27:11.768Z"}
{"action":"add","id":"114044ae-68a2-440e-b721-24052915ab61","subject":"Memory files use YAML frontmatter with metadata for search and deduplication","keywords":["memory-format","yaml-frontmatter","metadata","deduplication"],"applies_to":"global","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"dab51ad11d431317","content":"Each memory file contains YAML frontmatter with:\n- `id` - UUID for unique identification\n- `subject` - Brief one-line description\n- `keywords` - Array of searchable terms\n- `applies_to` - Scope (global, file:<path>, area:<name>)\n- `occurred_at` - ISO-8601 timestamp for chronological sorting\n- `content_hash` - SHA-256 prefix for deduplication detection\n\nMemories are idempotent - creating a duplicate returns the existing memory instead of creating a new file.","timestamp":"2025-12-21T19:27:11.769Z"}
{"action":"add","id":"7435a38b-112e-433b-8a95-aae87f64d7e7","subject":"Timeout configuration for memory extraction is critical","keywords":["memory extraction","timeout","claude cli","10 minutes"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:30:03.315Z","content_hash":"c73ce12f62e4a626","content":"Memory extraction timeout must be set to 10 minutes (600000ms) to accommodate:\n- Large transcript processing\n- Vector embedding generation via Ollama\n- JSON validation and response formatting\n\nThe timeout is configured in the `DEFAULT_OPTIONS` constant and passed to the `callClaudeCLI` method. Previous 2-minute timeout was insufficient.","timestamp":"2025-12-21T19:27:11.769Z"}
{"action":"add","id":"5384074e-e591-4f27-aad6-e8b2bce9bc15","subject":"Transformers.js and TensorFlow.js have same ONNX-based mutex issues as fastembed","keywords":["transformers.js","tensorflow.js","onnx","alternative","not-viable"],"applies_to":"global","occurred_at":"2025-12-21T18:27:27.411Z","content_hash":"ed8347367cafe604","content":"Investigated alternative embedding libraries (transformers.js, TensorFlow.js USE) but they also use ONNX runtime natively, making them subject to the same mutex issues as fastembed. They are not suitable replacements for solving concurrent embedding problems.","timestamp":"2025-12-21T19:27:11.770Z"}
{"action":"add","id":"c2e2b8d6-7d6e-452a-9225-ba21cfc66feb","subject":"Session-start hook outputs memory content formatted for Claude context injection","keywords":["session-start","hook","output","memories","formatting"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:26:23.982Z","content_hash":"9f809704102f9096","content":"The session-start hook reads recent memories from disk and outputs them to stdout. This output is injected into Claude's context at the start of a session. The hook reads up to 5 most recent memories directly from the `local-recall/` directory, sorted by `occurred_at` timestamp. Output format is plain text suitable for context injection.","timestamp":"2025-12-21T19:27:11.770Z"}
{"action":"add","id":"99ce2f49-d1fe-488c-bb37-d9868720f37a","subject":"Mutex lock errors occur when multiple processes load sqlite-vec concurrently","keywords":["sqlite-vec","mutex","concurrency","native extension","error handling"],"applies_to":"global","occurred_at":"2025-12-03T11:21:33.144Z","content_hash":"b0622b59ebdf2b10","content":"The sqlite-vec native extension can cause \"mutex lock failed: Invalid argument\" errors when multiple processes try to load it simultaneously. This is why the hook-daemon architecture was designed: hooks communicate with the MCP daemon via HTTP (localhost:7847) instead of loading sqlite-vec directly. The daemon owns sqlite-vec and prevents concurrent access issues. Reference: src/mcp-server/server.ts:230","timestamp":"2025-12-21T19:27:11.771Z"}
{"action":"add","id":"f6327af5-6777-4d77-9031-52ae9fa8cf5e","subject":"Memory collection refactoring: idempotent create-only pattern","keywords":["memory patterns","idempotent","deduplication","schema changes"],"applies_to":"global","occurred_at":"2025-12-21T19:19:53.624Z","content_hash":"3009a41639153111","content":"Recent refactoring changed memory collection to use an idempotent create-only pattern:\n\n1. **Removed updateMemory**: Memories are never updated, only created or deleted\n2. **Removed created_at field**: Memories now only track `occurred_at` (when the original event happened)\n3. **Deduplication**: Uses `occurred_at + content_hash` to prevent duplicate memory files\n4. **Sorting**: Memories sorted by `occurred_at` for chronological ordering\n\nBranch: `claude/refactor-memory-collection-01HQY8jXfJm7zh35BcYYiE1u`\n\nThis simplifies the memory model and makes deduplication deterministic.","timestamp":"2025-12-21T19:27:11.771Z"}
{"action":"add","id":"ee0b3e97-6d17-466e-8e54-5f0ce9c1bb68","subject":"Local Recall has three main hooks: SessionStart, UserPromptSubmit, and Stop","keywords":["hooks","session-start","user-prompt-submit","stop","integration","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T19:17:14.934Z","content_hash":"5dbc8f66661446fc","content":"Local Recall integrates with Claude Code through three hooks:\n\n1. **SessionStart Hook** (`src/hooks/session-start.ts`) - Triggered when a Claude Code session begins. Loads the memory index and searches for relevant memories, outputting them to stdout for injection into Claude's context.\n\n2. **UserPromptSubmit Hook** (`src/hooks/user-prompt-submit.ts`) - Handles semantic search for episodic and thinking memories, filtering by similarity threshold and token budget before injection.\n\n3. **Stop Hook** (`src/hooks/stop.ts`) - Parses transcripts and creates memories asynchronously via MCP server daemon.\n\nHooks receive JSON input via stdin and output memory content via stdout for context injection.","timestamp":"2025-12-21T19:27:11.772Z"}
{"action":"add","id":"59d1b4f3-d693-480a-a91a-77f6f10ea9da","subject":"Use [LOCAL_RECALL_INTERNAL] token prefix to prevent UserPromptSubmit hook recursion","keywords":["recursion guard","internal prompts","hook loop","token prefix","mcp disable"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:18:58.237Z","content_hash":"ee1266e10c810388","content":"To prevent UserPromptSubmit from recursively firing when calling `claude -p` for memory extraction:\n\n1. Prefix internal prompts with `[LOCAL_RECALL_INTERNAL]` token\n2. In the hook, check `inputJSON.prompt.startsWith('[LOCAL_RECALL_INTERNAL]')` and return early if true\n3. When calling `claude -p` for extraction, prepend the token to the prompt\n4. Pass `--strict-mcp-config` parameter to disable MCP servers during the extraction subprocess\n\nThis allows testing with extraction-related prompts without triggering the guard, since the guard checks for the token rather than specific text content.","timestamp":"2025-12-21T19:27:11.772Z"}
{"action":"add","id":"5e9adca7-261a-4aa3-b3a6-e04616b2563e","subject":"Hook files are compiled to dist/hooks/ directory","keywords":["hooks","build","compilation","dist directory","session-start","stop"],"applies_to":"global","occurred_at":"2025-12-21T18:28:17.619Z","content_hash":"2c8ba432f3391b12","content":"The hook source files in `src/hooks/` are compiled to `dist/hooks/` during the build process. Both session-start.ts and stop.ts are compiled to executable JavaScript files that can be invoked directly. Check the `dist/hooks/` directory to verify hooks have been built successfully.","timestamp":"2025-12-21T19:27:11.772Z"}
{"action":"add","id":"6ad3a0c9-0f48-4aaa-9dc8-753de37b3f78","subject":"Session start does full reload of all memories, not delta","keywords":["session-start","memory-loading","hook","full-reload","performance"],"applies_to":"global","occurred_at":"2025-12-21T18:26:56.199Z","content_hash":"85643be371ec2349","content":"The session-start hook performs a **full reload** of all memories on every session, not a delta. In `src/hooks/session-start.ts:57-63`, a fresh `MemoryManager` instance is created and all memories are listed. Only the 5 most recent memories (sorted by `occurred_at` descending) are selected for session context injection.\n\nThis approach is simpler than delta tracking but means all memories are re-read from disk on every session start, even though only 5 are used.","timestamp":"2025-12-21T19:27:11.773Z"}
{"action":"add","id":"a12b2639-4100-4c27-a1e1-ba7a1bfedc79","subject":"Gitignore no longer references removed sqlite dependencies","keywords":["gitignore","cleanup","sqlite-vec","better-sqlite3"],"applies_to":"file:local-recall/.gitignore","occurred_at":"2025-12-21T18:30:01.408Z","content_hash":"5ecab7b936b0a59d","content":"Updated `.gitignore` and `src/utils/gitignore.ts` to remove outdated sqlite references (sqlite-vec patterns, better-sqlite3, etc.). These were left over from pre-Orama architecture and no longer apply.","timestamp":"2025-12-21T19:27:11.773Z"}
{"action":"add","id":"088a9d1a-ed05-4539-a917-141322746ab6","subject":"Environment variables for enabling/disabling episodic and thinking memory systems","keywords":["configuration","environment variables","episodic memory","thinking memory","feature flags"],"applies_to":"global","occurred_at":"2025-12-21T18:27:35.712Z","content_hash":"1c944ef35453c27f","content":"Added two environment variables to control memory systems:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory retrieval in hooks and extraction in MCP server\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory retrieval in hooks and extraction\n\nThese flags are parsed in `src/utils/config.ts` and added to the config schema in `src/core/types.ts`. The flags are used in:\n- `src/hooks/user-prompt-submit.ts` - Skips episodic memory injection if disabled\n- `src/hooks/user-prompt-submit-thinking.ts` - Skips thinking memory injection if disabled\n- `src/hooks/session-start.ts` - Skips loading episodic memories if disabled\n- `src/mcp-server/server.ts` - Skips extraction and processing of disabled memory types\n\nDesign decision: Episodic defaults to OFF (optional feature), thinking defaults to ON (core feature).","timestamp":"2025-12-21T19:27:11.773Z"}
{"action":"add","id":"aa8e224f-5473-4788-809a-59e6f29ab9e6","subject":"Thinking memories now extract successfully with 616+ memories from transcripts","keywords":["thinking-memory","extraction-success","transcript-processing","feature-working"],"applies_to":"global","occurred_at":"2025-12-21T18:17:33.752Z","content_hash":"7a40f001e2fa1aad","content":"After fixing the message grouping and mutex issues, thinking memory extraction now successfully processes transcripts and creates properly formatted thinking memories. Each memory contains both `## Thought` and `## Output` sections with correct YAML frontmatter including id, subject, applies_to, and occurred_at fields. Successfully extracted 616 thinking memories from 59 transcripts in a test run.","timestamp":"2025-12-21T19:27:11.774Z"}
{"action":"add","id":"684a9344-d7a2-4e84-97e6-d03eb4ad76c5","subject":"SessionStart hook loads recent memories directly from files without vector search","keywords":["session-start","hook","memory-retrieval","episodic-memory"],"applies_to":"global","occurred_at":"2025-12-21T19:17:41.738Z","content_hash":"f15873d86e58a43b","content":"The SessionStart hook reads the 5 most recent memories directly from the episodic-memory/ directory by file modification time, without using vector search. This is intentional for performance - it avoids expensive embedding operations at session start. Memories are sorted by `occurred_at` timestamp in descending order and output to stdout for context injection.","timestamp":"2025-12-21T19:27:11.775Z"}
{"action":"add","id":"fc41aaff-bd1c-45ab-a9b5-8548e742c088","subject":"JSONL storage migration: multi-file format with 6-digit padding","keywords":["jsonl","storage","multi-file","500 entries","padding","sequential","episodic","thinking"],"applies_to":"global","occurred_at":"2025-12-21T19:03:33.302Z","content_hash":"8cf94f43ed0ff9d7","content":"Migrated memory storage from individual markdown files to JSONL format with three entry types: 'add', 'delete', 'embedding'. Memories are split across multiple files with 500 entries each, using sequential file naming with 6-digit padding (episodic-000001.jsonl, episodic-000002.jsonl, etc.) to support up to 999,999 files (~500 million memories). Files are loaded sequentially in order, allowing proper replay of entry history. This design prevents single large files that cause git/performance issues.","timestamp":"2025-12-21T19:27:11.775Z"}
{"action":"add","id":"2a279e11-e590-49a3-9f47-25bca0b79181","subject":"Refactor transcript parsing to centralize JSONL processing logic","keywords":["transcript parsing","jsonl","memory extraction","stop hook","code duplication","refactoring"],"applies_to":"global","occurred_at":"2025-12-21T19:20:20.675Z","content_hash":"fb4f65f56ba17001","content":"The stop.ts hook had duplicate parsing logic that reimplemented transcript parsing instead of using shared utilities from transcript.ts. The refactored architecture now:\n\n1. **Centralized parsing in transcript.ts**: Exported `parseTranscriptForMemories()` function that takes raw JSONL content and returns memory suggestions\n2. **Simplified stop.ts**: Now just reads the transcript file, calls `parseTranscriptForMemories()`, and saves the results\n3. **Fixed thinking block handling**: Previously, stop.ts checked `c.text` for thinking blocks (which have `c.thinking` property), causing thinking content to be dropped\n4. **Enables reusability**: Same parsing logic can now be used by other parts of the codebase that need to extract memories from transcripts\n\nThis pattern avoids code duplication and makes the parsing logic testable in isolation.","timestamp":"2025-12-21T19:27:11.776Z"}
{"action":"add","id":"3846ec3e-e80f-45ca-bfaa-023dc9828024","subject":"Documentation structure includes architecture, hooks, mcp-server, memory-format, and configuration","keywords":["documentation","docs folder","architecture","configuration","mcp","hooks"],"applies_to":"global","occurred_at":"2025-12-21T18:13:49.919Z","content_hash":"394027c00a7168f3","content":"Documentation is organized in `docs/` folder with separate files for: architecture.md (system design), hooks.md (Claude Code integration), mcp-server.md (MCP tool documentation), memory-format.md (memory file structure), and configuration.md (environment variables and settings).","timestamp":"2025-12-21T19:27:11.777Z"}
{"action":"add","id":"1fc10b0a-f532-4308-8f3c-6089d7cf3876","subject":"Debug logs help identify transcript collection issues","keywords":["debugging","transcript collector","logger","recall.log"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:30.211Z","content_hash":"c5303c529baedd18","content":"Debug logging in findClaudeProjectDir() is helpful for identifying why transcripts aren't being found. Key log messages: 'Claude project found but no transcripts folder' (path found but wrong subfolder assumption), 'Found Claude project via path convention' (successful discovery). Check recall.log to troubleshoot project discovery failures.","timestamp":"2025-12-21T19:27:11.777Z"}
{"action":"add","id":"a055c540-e282-4624-aa7e-420be05c7e3c","subject":"Memory extraction uses condensed transcript data to reduce Claude API calls and tokens","keywords":["memory extractor","condensed data","api optimization","transcript processing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:25:46.514Z","content_hash":"3f84d5ecfd816a10","content":"The memory extractor was modified to:\n\n1. **Read transcript content** from JSONL files\n2. **Condense using TranscriptCondenser** - Extracts minimum necessary content\n3. **Pass structured data** to memory extraction prompt instead of raw JSONL\n4. **Reduce token usage** - Only essential context (user prompts, assistant responses, tool names) is sent to Claude\n\nThe `buildMemoryExtractionPrompt` function now receives pre-processed transcript data, avoiding wasteful transmission of full file contents and verbose bash outputs that don't contribute to memory creation.","timestamp":"2025-12-21T19:27:11.778Z"}
{"action":"add","id":"71651aa7-e58b-45bf-b9cd-8fa515e32083","subject":"Stop hook not triggered in VS Code extension, preventing memory creation","keywords":["stop hook","vs code extension","memory creation","hooks","memory extraction"],"applies_to":"global","occurred_at":"2025-12-21T19:02:06.379Z","content_hash":"ea342fe04b212d2b","content":"# Stop Hook Not Triggered in VS Code Extension\n\nThe Stop hook is not being triggered by the VS Code extension, which prevents automatic memory creation. The Stop hook is responsible for:\n- Parsing transcripts after a session ends\n- Extracting memories from the conversation\n- Creating memory files via `src/hooks/stop.ts:77-108`\n\nBecause this hook never fires in VS Code, memories are not automatically created, even though SessionStart and UserPromptSubmit hooks work correctly.\n\n## Investigation Notes\n- Checked logs in `local-recall/recall.log` - no Stop hook entries\n- The plugin configuration in `dev-marketplace/local-recall-plugin/config/hooks.json` has Stop hook registered\n- VS Code extension may not support Stop hook event or triggers it only in limited circumstances\n\n## Workarounds\n1. Use the MCP server `memory_create` tool directly (independent of hooks)\n2. Use the daemon transcript processing (background async approach)\n3. Implement alternative memory creation mechanism for VS Code extension","timestamp":"2025-12-21T19:27:11.778Z"}
{"action":"add","id":"df409763-9a3d-4867-8e39-a08e259ae35c","subject":"Memory format uses JSONL with 6-digit padding for file organization","keywords":["memory format","jsonl","padding","episodic","thinking","storage"],"applies_to":"global","occurred_at":"2025-12-21T19:14:23.787Z","content_hash":"fb56467091a122ca","content":"## Recent Storage Migration\nMemory system recently migrated from individual markdown files to a hybrid JSONL + markdown approach with 6-digit zero-padded file organization.\n\n## Current Format\n- Memories stored as individual markdown files in `local-recall/episodic-memory/` and `local-recall/thinking-memory/`\n- Each memory file contains YAML frontmatter with metadata (id, subject, keywords, applies_to, occurred_at, content_hash)\n- JSONL files (`episodic-000001.jsonl`, `thinking-000001.jsonl`) track memory entries across sessions\n- Files use 6-digit padding: episodic-000001, episodic-000002, etc.\n\n## Important Details\n- Git tracks individual markdown memory files (they are version-controlled)\n- Index files (`orama-episodic-index.json`, `orama-thinking-index.json`) are gitignored\n- Gitignore is auto-generated by the system\n- Migration was recent (commit: \"feat: Migrate memory storage to JSONL format with multi-file support\")","timestamp":"2025-12-21T19:27:11.779Z"}
{"action":"add","id":"31db9fc8-257d-4f95-b96a-33a3813afd54","subject":"Memory extraction prompt updated to work with condensed transcript format","keywords":["memory extraction","prompt","condenser","token efficiency"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:25:23.828Z","content_hash":"cfc1035457a66cee","content":"Updated `buildMemoryExtractionPrompt()` to accept condensed transcript data from the transcript condenser instead of raw JSONL. The prompt now works with a structured, pre-filtered format that contains only essential information:\n\n- User queries and assistant responses (full text)\n- Tool invocations with names and outcomes\n- System messages when relevant\n\nThis change maintains memory extraction quality while dramatically reducing token consumption by eliminating verbose file contents, bash output, and other non-essential data from the prompt context.","timestamp":"2025-12-21T19:27:11.779Z"}
{"action":"add","id":"e861f4aa-a3f8-46e4-a74c-04004744b23e","subject":"Configuration system with environment variables and .local-recall.json file support","keywords":["configuration","environment-variables","config-file","settings"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"e649c9d43202135c","content":"Local Recall uses a flexible configuration system supporting both environment variables and `.local-recall.json` file:\n- `LOCAL_RECALL_DIR` / `memoryDir` (default: ./local-recall)\n- `LOCAL_RECALL_EPISODIC_ENABLED` / `episodicEnabled` (default: true)\n- `LOCAL_RECALL_EPISODIC_MAX_TOKENS` / `episodicMaxTokens` (default: 1000)\n- `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY` / `episodicMinSimilarity` (default: 0.5)\n- `LOCAL_RECALL_THINKING_ENABLED` / `thinkingEnabled` (default: true)\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` / `thinkingMaxTokens` (default: 1000)\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` / `thinkingMinSimilarity` (default: 0.5)\n- `LOCAL_RECALL_LOG_LEVEL` (default: error)\n\nEnvironment variables take precedence over config file.","timestamp":"2025-12-21T19:27:11.779Z"}
{"action":"add","id":"de88d655-a0b0-46e5-a446-e581c5a0a614","subject":"Thinking memory extraction was not running in daemon - added parallel execution","keywords":["thinking-extractor","daemon","mcp-server","parallel","memory-extraction"],"applies_to":"area:memory-extraction","occurred_at":"2025-12-21T18:29:45.308Z","content_hash":"f1c75f456466875c","content":"The thinking memory extraction was implemented in `src/core/thinking-extractor.ts` but was never being called by the MCP server daemon. The daemon in `src/mcp-server/server.ts` only called `runTranscriptProcessing()` for episodic memories, leaving thinking extraction inactive. A separate daemon call was added to run thinking memory extraction in parallel with episodic extraction using flags `isEpisodicProcessing` and `isThinkingProcessing` to prevent concurrent runs of each type.","timestamp":"2025-12-21T19:27:11.780Z"}
{"action":"add","id":"6324eca4-5cb4-4bcc-998c-60258b05cd33","subject":"MCP search tools now return content and implement recency weighting","keywords":["mcp-tools","search-results","content-returned","recency-weighting","token-limit"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"253bcce583126a1c","content":"MCP `episodic_search` and `thinking_search` tools were updated to:\n1. Return full memory `content` in results (was missing before)\n2. Include `occurred_at` timestamp for recency-based ranking\n3. Include `tokens_used` count for response budgeting\n4. Accept `max_tokens` parameter (default 2000) to limit context injection\n5. Apply 10% recency boost to similarity scores in both `VectorStore` and `ThinkingVectorStore`\n\nRecency factor ranges 0.0 (oldest) to 1.0 (newest), so final score = `similarity * (1 + 0.1 * recencyFactor)`","timestamp":"2025-12-21T19:27:11.780Z"}
{"action":"add","id":"3ee2a930-d798-42f7-b2ae-debc9575d07b","subject":"Thinking blocks extracted with 20 parallel workers from transcripts","keywords":["thinking-extraction","parallel","workers","transcript","llm-api"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:16:47.225Z","content_hash":"794e6b1b2bcf9ed8","content":"ThinkingExtractor processes transcripts to extract Claude's thinking blocks paired with their outputs:\n\n**Process**:\n1. Reads transcript file to find all assistant messages\n2. For each message with a thinking block:\n   - Extracts the `<claude:thinking>` content\n   - Pairs it with the text response that followed\n   - Skips tool-only responses (no text output)\n3. Uses 20 parallel worker processes to speed up extraction\n4. Returns array of thought-output pairs\n\n**Output format**: Each extracted item has `thinking` (the thought) and `output` (text response).\n\n**Key detail**: Thinking blocks are ONLY extracted from assistant messages that also have text content (not pure tool responses). This ensures we capture the reasoning that led to an actual response the user saw.\n\n**Concurrency**: 20 parallel workers means transcripts are processed in batches, improving performance on multi-core systems.","timestamp":"2025-12-21T19:27:11.782Z"}
{"action":"add","id":"f1e4f958-cf9e-470b-a653-21fb24f47e1b","subject":"Understanding thinking memory structure and formatting","keywords":["thinking-memory","memory-format","markdown","thought-output-pair","formatting"],"applies_to":"global","occurred_at":"2025-12-21T18:58:21.298Z","content_hash":"756c013e463894ff","content":"Thinking memories have a distinct structure from episodic memories, storing reasoning patterns along with their outputs. The system provides `formatThinkingMemoryForDisplay()` utility to format them consistently for context injection.\n\n### Key Understanding\n- Thinking memories pair Claude's internal reasoning (the `thought` field) with the corresponding text output\n- They are stored as markdown files with the same YAML frontmatter metadata as episodic memories\n- The formatter creates readable sections with clear separation between the thinking and output\n- Thinking memories help future sessions by providing examples of \"how I reasoned â†’ what I produced\"\n\n### File References\n- Storage: `src/core/thinking-memory.ts` contains the ThinkingMemoryManager\n- Formatting: `src/utils/markdown.ts` contains `formatThinkingMemoryForDisplay()`","timestamp":"2025-12-21T19:27:11.783Z"}
{"action":"add","id":"f0084683-da1a-4f68-8884-0b36f396c413","subject":"Memory extraction uses Claude Haiku with JSON-only output","keywords":["haiku model","memory extraction","json output","single turn","claude-haiku-4-5"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:23:52.480Z","content_hash":"4e794d255367b086","content":"The `callClaudeCLI()` method in memory-extractor.ts uses the Haiku model (`claude-haiku-4-5-20251001`) with `--max-turns 1` to ensure single-turn responses. The memory extraction prompt in `src/prompts/memory-extraction.ts` explicitly requires JSON-only output with no explanation text, markdown formatting, or code blocks - just raw valid JSON. This ensures predictable parsing and prevents issues with unexpected response formats.","timestamp":"2025-12-21T19:27:11.784Z"}
{"action":"add","id":"cb33cd20-e433-4729-8a33-a60a383ef14d","subject":"Gitignore file was not being updated for new users","keywords":["gitignore","memory.sqlite","auto-generated","initialization"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T19:14:59.526Z","content_hash":"ce3cf8ba89bc3adf","content":"The `ensureGitignore()` function only created the gitignore file if it didn't exist, so existing files were never updated with new patterns. Since the gitignore is auto-generated, it should always be written to ensure new users get the correct patterns (e.g., memory.sqlite exclusion). Changed to unconditionally write the file every time.","timestamp":"2025-12-21T19:27:11.784Z"}
{"action":"add","id":"b913e254-b624-42de-be1d-806ed9379cb9","subject":"Memory extraction prompt updated to accept condensed transcript data","keywords":["memory-extraction-prompt","prompt-engineering","condensed-format","input-reduction"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"d1ea06d69feca3ae","content":"Modified `buildMemoryExtractionPrompt()` to accept condensed transcript data instead of raw JSONL. The prompt now:\n\n1. Receives `CondensedTranscript` objects with pre-parsed, filtered events\n2. Works with structured event data rather than raw strings\n3. Focuses on semantic analysis of condensed content\n4. Still extracts comprehensive memories with proper scope and keywords\n\nThe prompt format remains similar but now expects data that's already been filtered for relevance, making token usage more efficient and allowing Claude to focus on memory quality rather than parsing raw transcripts.","timestamp":"2025-12-21T19:27:11.785Z"}
{"action":"add","id":"0dc2e245-0540-4435-b950-98fa9fa5874c","subject":"ToolResultContent.content can be array or string, not just string","keywords":["transcript","tool result","content type","array","type mismatch","toLowerCase"],"applies_to":"file:src/core/transcript-condenser.ts","occurred_at":"2025-12-21T19:00:26.631Z","content_hash":"98538df4a157b68b","content":"The TypeScript type for `ToolResultContent.content` is declared as `string`, but Claude's actual transcript format sometimes has `content` as an array of content blocks (e.g., for multi-part results with images + text).\n\nCalling `.toLowerCase()` or `.split()` on this field causes runtime errors. The fix is to check if content is a string before calling string methods, and handle array content appropriately.\n\nFile: `src/core/transcript-condenser.ts:205` - `isErrorResult()` function","timestamp":"2025-12-21T19:27:11.785Z"}
{"action":"add","id":"0b86209e-c4ac-47f9-846f-bb7952f30035","subject":"Thinking blocks in transcripts have 'thinking' property, not 'text'","keywords":["thinking","content blocks","transcript format","extraction","bug"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:19:37.035Z","content_hash":"5c211d820d5ff55c","content":"When processing transcript content blocks, thinking blocks use the 'thinking' property (e.g., {type: 'thinking', thinking: '...'}) while text blocks use 'text' property. The bug in stop.ts was checking c.text on thinking blocks, causing them to be silently dropped. Use extractThinkingFromBlocks() helper which properly checks block.type === 'thinking' and accesses block.thinking.","timestamp":"2025-12-21T19:27:11.785Z"}
{"action":"add","id":"bc9e83a9-6767-4e68-82e6-1acd46893883","subject":"Testing hooks requires npm dependencies to be installed first","keywords":["hooks","testing","dependencies","npm install","rake-pos"],"applies_to":"global","occurred_at":"2025-12-21T18:27:35.568Z","content_hash":"2ac79da51b5d805f","content":"When testing the session-start and stop hooks, npm dependencies must be installed. The hooks depend on the `rake-pos` package for natural language processing. Running `npm install` is necessary before hooks can execute successfully.","timestamp":"2025-12-21T19:27:11.786Z"}
{"action":"add","id":"b06b9814-55c4-4966-95a8-a07488888dc8","subject":"Local Recall plugin successfully installed and requires Claude Code restart","keywords":["local-recall","plugin","installation","setup","restart"],"applies_to":"global","occurred_at":"2025-12-21T19:13:47.788Z","content_hash":"61940d23954f786f","content":"The local-recall plugin was installed successfully via local command. After installation, Claude Code must be restarted to load the new plugin. This is a standard plugin installation workflow.","timestamp":"2025-12-21T19:27:11.793Z"}
{"action":"add","id":"f493c02a-9678-462f-b7fa-2150734196a7","subject":"UserPromptSubmit hook needs recursion guard for internal extraction prompts","keywords":["recursion guard","internal prompts","extraction process","hook loop prevention"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:19:12.033Z","content_hash":"e22bf87cb8aacc0c","content":"The UserPromptSubmit hook triggers when calling `claude -p` for keyword extraction, which creates a recursive loop. Add a recursion guard by prefixing internal prompts with [LOCAL_RECALL_INTERNAL] token and checking for it at the start. Also pass --strict-mcp-config to the claude subprocess to disable MCP servers during internal extraction calls, adding an additional layer of protection against recursion.","timestamp":"2025-12-21T19:27:11.794Z"}
{"action":"add","id":"35d1c7dd-16a0-41f8-9dfe-ce886e6c8b1c","subject":"MCP server runs background daemon for transcript processing every 5 minutes","keywords":["mcp server","daemon","transcript processing","memory extraction","background"],"applies_to":"global","occurred_at":"2025-12-21T19:17:45.599Z","content_hash":"0e39314e597479a0","content":"The MCP server includes a background daemon that runs every 5 minutes to sync transcripts from Claude's cache, process them to extract memories, and track processed transcripts using content hashes for change detection. This replaces the Stop hook which is now disabled. The daemon creates and recreates memories when transcripts change.","timestamp":"2025-12-21T19:27:11.794Z"}
{"action":"add","id":"13a8b168-fdd1-4a53-93c1-2b17ed7b40ba","subject":"UserPromptSubmit hook now handles both episodic and thinking memories via single hook","keywords":["hook","user-prompt-submit","episodic","thinking","unified","configuration"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:29:21.341Z","content_hash":"deca1e2d0133d334","content":"The UserPromptSubmit hook is now unified and handles both episodic and thinking memory retrieval based on configuration flags rather than having separate hook files. The hook checks `episodicEnabled` and `thinkingEnabled` configuration options to determine which memory types to search and inject. This replaces the previous approach of having separate user-prompt-submit-thinking.js and user-prompt-submit.js files. The hook uses Orama (pure JavaScript) for vector search, making it safely bundleable without native module issues.","timestamp":"2025-12-21T19:27:11.795Z"}
{"action":"add","id":"f4ed241d-5906-46b7-9b19-53c069dcbd7c","subject":"Orama vector store lacks proper initialization sequence and error handling for missing indexes","keywords":["orama","vector-store","initialization","index-files","error-handling"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:22:39.533Z","content_hash":"8a5e1a8d1f3ed2db","content":"The vector store initialization in `src/core/vector-store.ts` has issues:\n\n**Problem**: When Orama index files (`orama-episodic-index.json`, `orama-thinking-index.json`) are missing or corrupted, the initialization may fail silently or throw unclear errors.\n\n**Current implementation**:\n- `initialize()` tries to load existing index or create new one\n- No validation of loaded index structure\n- No error recovery if deserialization fails\n- Depends on Ollama being available for embedding generation\n\n**Missing error handling**:\n- File not found - silently creates new empty index (correct)\n- File corrupted - throws error without context\n- Ollama unavailable - blocks initialization\n- Embedding failures - not caught during add/sync operations\n\n**Recommendations**:\n- Add try-catch around `JSON.parse()` with fallback to new index\n- Validate index structure after loading\n- Test initialization when Ollama is offline\n- Consider graceful degradation when embeddings unavailable\n\n**Related files**:\n- `src/core/embedding.ts` - Ollama integration for embeddings\n- `src/core/thinking-vector-store.ts` - Similar issues likely present","timestamp":"2025-12-21T19:27:11.795Z"}
{"action":"add","id":"7bdbb391-b865-4323-916d-1aa970d7ccaf","subject":"analyzeForMemories function only saves multi-line content","keywords":["memory extraction","content analysis","multi-line detection"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:22:24.167Z","content_hash":"6b42ecb8599ffd57","content":"The analyzeForMemories function filters messages to only save those with multi-line content (containing newlines). Single-line messages are skipped. This is intentional to avoid creating memories for brief responses that lack sufficient depth for future context.","timestamp":"2025-12-21T19:27:11.795Z"}
{"action":"add","id":"3d4a0f5d-ec7e-4b91-9774-6d4a23dc3a18","subject":"Architecture: user-prompt-submit hook uses sync keyword extraction via Claude CLI","keywords":["user-prompt-submit","keywords","extraction","claude cli","callClaudeForKeywords","semantic search"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:20:20.014Z","content_hash":"2d8ae1c5425e1a4a","content":"## Implementation Detail\nThe user-prompt-submit hook extracts keywords from user prompts by calling the Claude CLI synchronously via `spawn()`. This happens inside `callClaudeForKeywords()` function.\n\n## Process Flow\n1. Hook receives user prompt text\n2. Calls `callClaudeForKeywords()` which spawns `claude` command with internal prompt\n3. Waits for Claude to extract structured keywords from the prompt\n4. Returns extracted keywords for memory search\n\n## Important Note\nThis uses `[LOCAL_RECALL_INTERNAL]` prefix in prompts to indicate these are internal system prompts used for memory extraction, not user-facing interactions. The hook specifically skips processing when this prefix is detected to avoid recursive loops.\n\n## Configuration\nThe timeout behavior is controlled via spawn options - ensure any timeout implementation properly handles process abortion.","timestamp":"2025-12-21T19:27:11.796Z"}
{"action":"add","id":"24d04ada-a068-4c54-bca7-8f7c4e196518","subject":"Thinking memories use padded JSONL filenames with 6-digit suffixes","keywords":["thinking-memory","jsonl","storage","filename-format","migration"],"applies_to":"global","occurred_at":"2025-12-21T19:09:10.487Z","content_hash":"da9ce24233e673fa","content":"The thinking memory storage has been migrated to use JSONL format with padded 6-digit suffixes. Files are named as `thinking-000001.jsonl`, `thinking-000002.jsonl`, etc., not a single `thinking.jsonl` file.\n\nIf a bare `thinking.jsonl` file exists, it's likely a remnant from an older storage format and should be deleted as part of the migration cleanup.\n\nRelevant files:\n- `src/core/thinking-jsonl-store.ts` - Handles the JSONL storage with padded filenames\n- `src/core/migration.ts` - Handles migration between old and new storage formats\n\nThis pattern prevents any single file from becoming too large and allows for better file organization.","timestamp":"2025-12-21T19:27:11.796Z"}
{"action":"add","id":"d1425151-277b-4791-aa2f-aaa96b509604","subject":"Backward compatibility required for transcript parsing to support both old and new formats","keywords":["backward compatibility","transcript format","parsing","format detection"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:29:39.576Z","content_hash":"c877f5d40551c493","content":"When updating transcript parsing to support new Claude Code format with content blocks, backward compatibility is essential:\n\n- Tests and existing code may use the old string-based `content` format\n- New production Claude Code transcripts use the content blocks array format\n- Solution: Implement format detection that tries new format first, then falls back to legacy\n- Use `extractThinkingFromContent()` helper to parse content blocks and extract thinking\n- Silently skip invalid messages rather than throwing errors (better for real-world transcripts)\n\nThis ensures old test data continues to work while supporting new transcript format.","timestamp":"2025-12-21T19:27:11.796Z"}
{"action":"add","id":"aa0bb058-8283-4c69-808c-325dba5dfafd","subject":"Orama migration resolves sqlite-vec mutex contention issues","keywords":["orama","mutex","sqlite-vec","hooks","concurrency","migration"],"applies_to":"global","occurred_at":"2025-12-21T19:01:52.332Z","content_hash":"e8c73cf031d7ef8f","content":"The migration from sqlite-vec to Orama (pure JavaScript vector store) has successfully resolved mutex contention issues that were occurring in hooks. With Orama's pure JS implementation, there are no longer process isolation or mutex conflicts when multiple hooks execute concurrently. This eliminates the need for mutex handling and simplifies the hook architecture.","timestamp":"2025-12-21T19:27:11.797Z"}
{"action":"add","id":"24c621f0-2591-4cde-b6bd-cd5e18df77c7","subject":"Nomic-embed-text model has 2048 token context limit","keywords":["ollama","embedding","nomic-embed-text","context window","truncation"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T19:00:39.886Z","content_hash":"af4ab2aecbcae285","content":"The `nomic-embed-text` embedding model is trained with a maximum context window of 2048 tokens. Sending inputs exceeding this limit causes Ollama to fail with internal subprocess communication errors (\"requested context size too large for model\").\n\nFix: Truncate all inputs to 6000 characters (~1500 tokens) before sending to Ollama. This ensures the embedding service stays within safe margins and avoids triggering Ollama's panic behavior on oversized requests.\n\nNote: Different embedding models have different context limits - always check the model's specifications.","timestamp":"2025-12-21T19:27:11.797Z"}
{"action":"add","id":"b4ffe89d-b2c8-4b2a-913e-8e4d1d9452bc","subject":"Version synchronization across plugin manifest files","keywords":["version","package.json","plugin.json","marketplace.json","sync","claude code plugins"],"applies_to":"global","occurred_at":"2025-12-21T19:00:26.631Z","content_hash":"a9ae58fc8447285b","content":"Claude Code plugins require version synchronization across three files:\n- `package.json` - npm package version\n- `.claude-plugin/plugin.json` - plugin manifest\n- `.claude-plugin/marketplace.json` - marketplace distribution metadata\n\nAll three must be kept in sync when bumping versions. Missing any of these can cause version mismatch issues in marketplace distribution.","timestamp":"2025-12-21T19:27:11.798Z"}
{"action":"add","id":"3bee2bd9-33a4-4fe7-a39c-d1fa1418c97a","subject":"SessionStart hook outputs 5 most recent memories directly from files","keywords":["hooks","session-start","recent-memories","recency"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"37acfb263b4115c5","content":"The SessionStart hook reads the 5 most recent memory files (sorted by occurred_at) and outputs them to stdout for context injection. This doesn't use semantic search - it just retrieves recent memories to bootstrap context at session start.","timestamp":"2025-12-21T19:27:11.798Z"}
{"action":"add","id":"13507eaf-4630-40d4-84dc-ba74d2b7d134","subject":"Memory compaction/pruning is not implemented","keywords":["compaction","memory-limits","maxMemories","cleanup","pruning"],"applies_to":"global","occurred_at":"2025-12-21T18:19:53.806Z","content_hash":"c0c84e7f9e906cee","content":"Currently, memories are not compacted or automatically cleaned up. While a `maxMemories` configuration option exists in `src/utils/config.ts` (default: 1000), there is no logic in place to enforce this limit or to consolidate/merge similar memories. Memories grow indefinitely unless manually deleted. This could be a future optimization area if memory count or storage becomes a concern.","timestamp":"2025-12-21T19:27:11.799Z"}
{"action":"add","id":"44628ec7-311a-4423-8079-6e94fbcfb831","subject":"Local Recall memory model changed from mutable to immutable episodic log","keywords":["memory-design","idempotency","episodic","deduplication","architecture-decision"],"applies_to":"global","occurred_at":"2025-12-21T18:20:31.269Z","content_hash":"2cf9508d6bd71e13","content":"## Key Decision: Immutable Episodic Memory Model\n\nChanged from a mutable knowledge base (where memories could be updated/deleted) to an immutable episodic memory log.\n\n### Rationale\n- Memories are now permanent records tied to specific moments in time\n- They can only be removed manually by the user\n- This models how human memory actually works - episodic logs of events\n\n### Deduplication Strategy\nMemories are deduplicated using a composite key:\n- **`occurred_at`** - ISO-8601 timestamp from the transcript (when the conversation happened)\n- **`content_hash`** - SHA-256 hash of content, truncated to 16 chars (for exact content matching)\n\nBefore creating a memory, check if one exists with the same `occurred_at` + `content_hash`. If yes, skip creation (idempotent).\n\n### Implementation Details\n- Removed `updated_at` field (memories don't change)\n- Removed `updateMemory()` and `deleteMemory()` methods from MCP tools\n- Added `computeContentHash()` using SHA-256\n- Added `findDuplicate(occurredAt, contentHash)` method for dedup checks\n- Stop hook now processes entire transcript history (not just 30-second window)\n- Added `created_at` field to track when the memory file was written","timestamp":"2025-12-21T19:27:11.799Z"}
{"action":"add","id":"90fb8f6b-d799-46c9-a2bd-108ad2bbbb49","subject":"Transcript format structure for memory extraction","keywords":["transcript format","parsing","event structure","json schema"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:03:16.962Z","content_hash":"b6fab2c2ecf15e8c","content":"Transcripts are parsed into events with the following structure (from `src/utils/transcript.ts`):\n- `[User]` - User requests or questions\n- `[Assistant]` - Claude's responses and explanations\n- `[Tool: Name]` - Tool invocations (Read, Edit, Write, Bash, Grep, etc.)\n- `[Result: OK/ERROR]` - Outcome of tool invocations\n\nThe `src/hooks/stop.ts` file processes these events to extract memories. When Stop hook works, it uses this event-based structure to identify important moments in the conversation.","timestamp":"2025-12-21T19:27:11.800Z"}
{"action":"add","id":"5d1864be-32b1-45a3-8668-c629719e2d74","subject":"Local Recall project architecture and implementation status","keywords":["architecture","local-recall","memory-system","components","mcp-server","hooks"],"applies_to":"global","occurred_at":"2025-12-21T18:21:31.415Z","content_hash":"c38adea4ffd20d2c","content":"Local Recall is a markdown-powered memory system with the following implemented components:\n\n**Core Systems:**\n- Memory CRUD operations (memory.ts)\n- Index management (index.ts)\n- Fuzzy search using Fuse.js (search.ts)\n- MCP Server with 6 exposed tools\n- Session-start hook that loads relevant memories\n- Stop hook that auto-extracts memories from transcripts\n- Keyword extraction for memory indexing\n\n**Architecture:**\n- Memories stored as markdown files with YAML frontmatter\n- Uses Orama vector store for semantic search\n- Ollama integration for embeddings (nomic-embed-text model, 768 dimensions)\n- Background daemon processes transcripts every 5 minutes\n- Two memory types: episodic and thinking memories\n\n**Key Features:**\n- Version-controlled memory files\n- Idempotent memory creation (deduplication via content hash)\n- Semantic search with similarity scoring\n- Configurable token budgets and similarity thresholds\n- Thinking memory format: captures reasoning paired with output","timestamp":"2025-12-21T19:27:11.800Z"}
{"action":"add","id":"a0992047-3d0f-4925-ae81-9f4b510cd270","subject":"File-based semaphore locks serialize fastembed access across concurrent hook processes","keywords":["proper-lockfile","file lock","fastembed","mutex solution","embedding serialization"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T19:22:44.635Z","content_hash":"7ebd5b9f2ae9b658","content":"Implemented file-based locking using `proper-lockfile` package to serialize access to fastembed/onnxruntime-node native modules. Lock is acquired at both initialization and embedding operation levels.\n\n**Implementation details:**\n- Lock file: `/tmp/local-recall-embedding.lock`\n- Retries: 10 with exponential backoff (100ms - 2s)\n- Stale lock timeout: 30 seconds\n- Wraps both `initialize()` and `embed()` methods\n- Logs \"Acquired embedding lock\" and \"Released embedding lock\" for debugging\n\nThis prevents concurrent access to the native module without requiring a daemon architecture, allowing hooks to run independently while safely sharing the resource.","timestamp":"2025-12-21T19:27:11.801Z"}
{"action":"add","id":"5ed8a0fb-f4ed-468b-94b5-746c79cf86ce","subject":"Hooks architecture: SessionStart injects recent memories, UserPromptSubmit performs semantic search","keywords":["hooks","session-start","user-prompt-submit","context-injection","semantic-search"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"ba9e43cdaddc1dab","content":"Claude Code integration uses two main hooks:\n\n**SessionStart Hook** (`session-start.js`): Reads 5 most recent memories directly from files (sorted by `occurred_at`) and outputs to stdout for context injection. No search needed.\n\n**UserPromptSubmit Hook** (`user-prompt-submit.js`): Unified hook handling both episodic and thinking memories. Performs semantic search using Orama + Ollama embeddings, filters by similarity threshold and token budget, then injects results. Skips internal prompts containing `[LOCAL_RECALL_INTERNAL]` marker.\n\n**Stop Hook**: Currently disabled. Memory extraction now handled by MCP server daemon running every 5 minutes.","timestamp":"2025-12-21T19:27:11.802Z"}
{"action":"add","id":"477c71ce-c9b5-463a-9d72-6fa7ed96ed24","subject":"UserPromptSubmit hook consolidated into single unified hook that handles both episodic and thinking memories","keywords":["hooks","user-prompt-submit","episodic","thinking","unified","consolidation"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-03T09:50:15.512Z","content_hash":"f4c02fdcb9ec61a8","content":"The separate `user-prompt-submit.ts` and `user-prompt-submit-thinking.ts` hooks were consolidated into a single `user-prompt-submit.ts` hook that dynamically calls either episodic memory search, thinking memory search, or both based on configuration flags.\n\nThis unified approach allows the hook to handle both memory types intelligently based on `episodicEnabled` and `thinkingEnabled` environment variables rather than maintaining two separate implementations.\n\nThe old `user-prompt-submit-thinking.ts` file was deleted as part of this refactor.","timestamp":"2025-12-21T19:27:11.802Z"}
{"action":"add","id":"1749c8e9-8a89-4eb0-aaa8-cc4f0230c1ed","subject":"Memory extraction response format must handle markdown code blocks","keywords":["memory-extractor","markdown","code-blocks","json-parsing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:22:56.476Z","content_hash":"194836909885bef3","content":"Claude may wrap JSON responses in markdown code blocks (e.g., \\`\\`\\`json...\\`\\`\\`). The parser must strip these before parsing JSON. This is especially common when Claude responds to extraction prompts that explicitly ask for JSON output.","timestamp":"2025-12-21T19:27:11.803Z"}
{"action":"add","id":"eac796ca-a7c1-4979-8bde-655f0eb02a8d","subject":"Config system uses getConfig helper alongside loadConfig for accessing parsed configuration","keywords":["configuration","config.ts","loadConfig","getConfig","utils"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T19:22:32.316Z","content_hash":"dbebc1207a4459ef","content":"The configuration system in `src/utils/config.ts` exports both `loadConfig` and `getConfig` functions. Multiple hook files import both functions, suggesting:\n- `loadConfig` - Initializes/loads configuration from environment or `.local-recall.json`\n- `getConfig` - Retrieves the already-loaded configuration object\n\nThis pattern appears across hooks: `src/hooks/user-prompt-submit.ts`, `src/hooks/user-prompt-submit-thinking.ts`, `src/hooks/session-start.ts`, and MCP server `src/mcp-server/server.ts`.\n\nBoth the episodic and thinking enabled flags integrate with this config loading pattern to control feature activation.","timestamp":"2025-12-21T19:27:11.803Z"}
{"action":"add","id":"4e4f7d51-6f98-4270-8726-f7f2266674df","subject":"Folder structure: 'memories' renamed to 'episodic-memory' across codebase","keywords":["folder rename","episodic-memory","directory structure","codebase refactoring"],"applies_to":"global","occurred_at":"2025-12-21T19:26:56.234Z","content_hash":"5f65774db772f58f","content":"The 'memories' folder has been renamed to 'episodic-memory' to better reflect its purpose. This change was applied to:\n\n- `src/core/memory.ts:34` - memoriesDir path definition\n- `src/core/index.ts:30` - memoriesDir path definition\n- `tests/unit/core/memory.test.ts:54` - test file path expectations\n- `CLAUDE.md:51` - architecture documentation\n- `docs/mcp-server.md:235` - MCP server documentation\n- `docs/architecture.md:44,181` - architecture diagrams\n\nThe .gitignore was also updated to reference the new directory name. Note: The 'memories' key in JSON schemas (like the LLM extraction prompt) is unchanged as it refers to the response field, not the folder structure.","timestamp":"2025-12-21T19:27:11.804Z"}
{"action":"add","id":"172f0cad-3d7e-4b9f-bf19-4bfc98fe2cc0","subject":"Separate user-prompt-submit hooks for episodic vs thinking memories","keywords":["hooks","user-prompt-submit","episodic","thinking","separation of concerns","architecture"],"applies_to":"global","occurred_at":"2025-12-21T18:27:36.139Z","content_hash":"d4fb5a8ae22b8cee","content":"The project maintains separate user-prompt-submit hooks:\n\n- `src/hooks/user-prompt-submit.ts` - Handles episodic memory search and injection\n- `src/hooks/user-prompt-submit-thinking.ts` - Handles thinking memory search and injection\n\nBoth hooks now check their respective enabled flags before executing. This modular approach allows each memory type to be independently configured and controlled, making it easier to debug issues and adjust behavior for each system separately.","timestamp":"2025-12-21T19:27:11.804Z"}
{"action":"add","id":"e1992901-8291-445c-a73c-cbe78badcd0c","subject":"SessionStart hook loads 5 most recent memories to provide context at session start","keywords":["hooks","session-start","context-injection","recency"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:30:59.171Z","content_hash":"899685f4931801ba","content":"The SessionStart hook triggers when a Claude Code session begins. It reads the 5 most recent memories directly from filesystem sorted by `occurred_at` timestamp and outputs their content to stdout. This context is injected into Claude's conversation, providing continuity from previous sessions without requiring database queries.","timestamp":"2025-12-21T19:27:11.805Z"}
{"action":"add","id":"212291bd-c88e-418c-ae2e-b8634cfe2983","subject":"Transcript validation: 39,879 total files with 51 containing thinking blocks","keywords":["transcripts","thinking blocks","validation","structure","claude-opus-4-5"],"applies_to":"global","occurred_at":"2025-12-21T18:15:46.377Z","content_hash":"bcc43492d7fd5f43","content":"The local-recall/transcripts directory contains 39,879 JSONL transcript files. Of these:\n- 51 files contain thinking blocks (claude-opus-4-5-20251101 model with thinkingMetadata)\n- 1,101 total thinking blocks across all transcripts\n- 12,594 synthetic files (model: \"<synthetic>\") generated during memory extraction\n- 27,285 real user transcripts to process\n\nThinking blocks can be identified by:\n1. Model: \"claude-opus-4-5-20251101\"\n2. thinkingMetadata: {\"level\":\"high\",\"disabled\":false,\"triggers\":[]}\n3. Content blocks with type: \"thinking\" containing thinking and signature fields\n\nSynthetic files should be excluded from all processing as they are internal memory extraction artifacts.","timestamp":"2025-12-21T19:27:11.805Z"}
{"action":"add","id":"fdfe1b3e-a1c1-4102-9449-7bda59a4b818","subject":"Synthetic transcript handling in transcript collector uses isSyntheticFile() check","keywords":["synthetic transcripts","isSyntheticFile","filtering","transcript-collector","performance"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-03T09:48:42.505Z","content_hash":"a4e032fc1387c4d8","content":"The transcript collector uses `isSyntheticFile(transcript.sourcePath)` to determine if a transcript should be skipped during the sync process. This check is applied before copying transcripts from Claude's cache to avoid processing synthetic files that are generated by Claude Code for internal purposes and don't contain user interactions.","timestamp":"2025-12-21T19:27:11.806Z"}
{"action":"add","id":"73b88bf4-18d1-43a3-b2e9-50b3187a6558","subject":"Similarity threshold lowered to 0.5 (50%) for better recall","keywords":["similarity-threshold","configuration","episodic-memories","thinking-memories"],"applies_to":"global","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"269c8608d658a144","content":"Default similarity threshold changed from 0.8 to 0.5 for both episodic and thinking memories. This means memories scoring 50% or higher are included. The threshold comparison is `score >= minSimilarity` so a 0.5 threshold includes memories at exactly 50% similarity. Config locations: `src/core/types.ts` (line 125-126) and environment variables `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY`, `LOCAL_RECALL_THINKING_MIN_SIMILARITY`.","timestamp":"2025-12-21T19:27:11.806Z"}
{"action":"add","id":"d6eaf37e-1501-4e3d-bf6a-367f25a4e2a2","subject":"ONNX runtime mutex errors occur during concurrent model loading in multi-process environments","keywords":["onnx","mutex","concurrency","embedding","fastembed","multi-process","race condition"],"applies_to":"global","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"9524e5b9145c42ee","content":"The local-recall system experienced 'mutex lock failed' errors when multiple Claude instances or concurrent processes tried to load the ONNX embedding model simultaneously. This is NOT a sqlite-vec issue (resolved by Orama migration), but an ONNX runtime problem during model initialization. The `proper-lockfile` mechanism doesn't prevent ONNX's internal mutex issues. The problem occurs at startup when ONNX loads - once loaded, it can be safely shared by multiple clients via HTTP calls.","timestamp":"2025-12-21T19:27:11.808Z"}
{"action":"add","id":"5e0d108f-fd68-4010-b3a0-f727a51d30f9","subject":"Transcript processing uses 20 parallel workers for thinking extraction","keywords":["thinking-extraction","parallel-processing","concurrency","transcripts"],"applies_to":"global","occurred_at":"2025-12-03T09:51:05.046Z","content_hash":"efb8268b9f4a9eec","content":"The thinking memory extraction system processes thinking blocks from transcripts in parallel using 20 concurrent workers. This is mentioned in the architecture as 'thinking-extractor.ts: Extract thinking blocks (20 parallel)'. This enables efficient batch processing of thinking blocks across multiple transcripts, though this may need tuning based on system resources.","timestamp":"2025-12-21T19:27:11.809Z"}
{"action":"add","id":"dd96808e-9fa6-4d2e-9159-23975349409c","subject":"Transcript collector needs INFO-level logging for debugging new repo setup","keywords":["transcript-collector","logging","debugging","new-repo","search-process","info-level"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:59:05.449Z","content_hash":"6c0b65217dce6e02","content":"The transcript collector searches for Claude transcripts in ~/.claude/projects/<project-name>/transcripts/. When setting up local-recall in a new repo, users cannot see if transcripts are being found because logging is only at DEBUG level. Added INFO-level logging to show:\n\n1. **Search initialization**: Logs what path is being searched\n2. **Directory existence checks**: Shows whether ~/.claude/projects exists\n3. **Project folder detection**: Logs expected folder name based on cwd hash\n4. **Results summary**: Shows how many transcripts were found and sync details\n\nThis helps users verify the transcript collection is working correctly in new repositories.","timestamp":"2025-12-21T19:27:11.810Z"}
{"action":"add","id":"515f91a9-45d7-470a-b4f1-cf948213b510","subject":"Project has comprehensive test requirements: unit, integration, and documentation","keywords":["testing","documentation","development-requirements","code-quality"],"applies_to":"global","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"fc90fb3c2d014826","content":"Development requirements state:\n- All new features must have corresponding unit tests in `tests/unit/`\n- Integration tests go in `tests/integration/`\n- Documentation must be placed in `docs/` folder\n- Must update existing docs when modifying functionality\n- Tests should cover both happy paths and edge cases\n\nThis is a non-negotiable requirement for all contributions.","timestamp":"2025-12-21T19:27:11.810Z"}
{"action":"add","id":"c2e78d3e-bc5a-4ba4-8f3b-86c0cdff83c5","subject":"File-based locking solution for fastembed/onnxruntime","keywords":["proper-lockfile","embedding lock","file lock","serialization","concurrency"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T18:27:48.862Z","content_hash":"22f1e607cb63dfc5","content":"Implemented file-based locking using `proper-lockfile` package to serialize access to fastembed's onnxruntime-node native bindings. Lock file located at `/tmp/local-recall-embedding.lock`. Both `initializeEmbedding()` and embedding inference operations are wrapped with lock acquisition (retries: 10, stale timeout: 30s). This prevents mutex errors from concurrent hook processes trying to load the native module simultaneously.","timestamp":"2025-12-21T19:27:11.811Z"}
{"action":"add","id":"1a6f0953-a1c6-4e29-a42d-4087b69dcf1a","subject":"ensureGitignore() only creates gitignore on first run, not updating existing files","keywords":["gitignore","auto-generated","memory.sqlite","configuration"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T19:15:15.466Z","content_hash":"cd1d83d666f17e3e","content":"The `ensureGitignore()` function checks if gitignore exists and skips creation if it does, preventing updates to existing gitignore files. Since the gitignore is auto-generated, it should always be written to ensure new patterns (like memory.sqlite) are included for all users. Changed the function to always write the gitignore file.","timestamp":"2025-12-21T19:27:11.811Z"}
{"action":"add","id":"978711f0-eca0-4931-999b-0a584d18f617","subject":"Memory extraction parser handles alternative field names from Claude","keywords":["memory-extractor","field-normalization","claude-response","parser","robustness"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:17:04.759Z","content_hash":"4d0976e15eacc2a5","content":"The memory extraction parser in `parseClaudeResponse` now normalizes field names to handle variations Claude might return. Normalization rules (lines 179-186):\n\n- `subject` â† accepts: `subject`, `title`, `summary`, `name`\n- `keywords` â† accepts: `keywords`, `tags`, `key_terms`, `keytopics`\n- `applies_to` â† accepts: `applies_to`, `scope`, `appliesTo`\n- `content` â† accepts: `content`, `body`, `text`, `memory`\n\nThis handles inconsistencies in how Claude formats JSON responses across different model versions. The normalization is applied before Zod validation to prevent failures on structurally correct memories with non-standard field names.","timestamp":"2025-12-21T19:27:11.812Z"}
{"action":"add","id":"c2077e4b-a870-471f-8fff-605e897b013f","subject":"Memory deduplication uses occurred_at timestamp and content_hash","keywords":["deduplication","duplicate-prevention","content_hash","occurred_at","memory-creation"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:19:53.806Z","content_hash":"e638a314377453e8","content":"The `MemoryManager.findDuplicate()` method (lines 52-67) prevents duplicate memories by checking if a memory with the same `occurred_at` timestamp AND `content_hash` already exists. If found, it returns the existing memory instead of creating a new one. This is the only deduplication mechanism - memories are not compacted or pruned over time, though a `maxMemories` configuration option exists but is not actively enforced in the codebase.","timestamp":"2025-12-21T19:27:11.812Z"}
{"action":"add","id":"b4e66a76-d529-45dc-8acd-f158b4f0ced4","subject":"Memory types (episodic and thinking) are enabled by default in configuration","keywords":["memory types","episodic","thinking","default config","enabled"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:26:58.164Z","content_hash":"6d64ce31b1699f7b","content":"Both `episodicEnabled` and `thinkingEnabled` are set to `true` by default in `src/core/types.ts` lines 118-121. This means new installations will have both episodic and thinking memory retrieval active without requiring additional configuration.","timestamp":"2025-12-21T19:27:11.813Z"}
{"action":"add","id":"4a9b909c-8979-48e1-b4ba-d96f573f383e","subject":"VS Code extension does not trigger Stop hook, preventing memory creation","keywords":["stop hook","vs code extension","memory creation","hook support","claude code","transcript processing"],"applies_to":"global","occurred_at":"2025-12-03T09:51:20.667Z","content_hash":"d2a5330955723404","content":"The Stop hook is not triggered by the Claude Code VS Code extension, which prevents the automatic memory creation pipeline from running. The Stop hook is responsible for parsing transcripts and creating memories via `src/hooks/stop.ts:77-108`. This is a limitation of the VS Code extension compared to other Claude Code environments.\n\nWorkaround: Use MCP tools directly (`episodic_create`) or enable the MCP server daemon which processes transcripts asynchronously every 5 minutes, regardless of hook support.","timestamp":"2025-12-21T19:27:11.813Z"}
{"action":"add","id":"e2514988-b853-470f-870b-2defccdb632c","subject":"Git status shows large number of untracked episodic and thinking memory files from recent session","keywords":["git-status","untracked-files","episodic-memory","thinking-memory"],"applies_to":"global","occurred_at":"2025-12-21T18:22:39.533Z","content_hash":"67d89a91373418d1","content":"Large number of new memory files created in recent sessions:\n\n**Untracked episodic memories**: 260+ new files in `local-recall/episodic-memory/` (UUIDs as filenames)\n**Untracked thinking memories**: 260+ new files in `local-recall/thinking-memory/` (UUIDs as filenames)\n\n**Modified files**:\n- `src/core/episodic-jsonl-store.ts`\n- `src/core/jsonl-store.ts`\n- `src/core/thinking-jsonl-store.ts`\n- Hook files in `local-recall-plugin/`\n\n**Deleted thinking memories**: 73 thinking memory files were deleted (marked with D in git status)\n\n**Recent commits**:\n- \"chore: gitignore processed-log.jsonl files\"\n- \"chore: track processed-log.jsonl files in git\"\n- \"feat: add pre-computed embeddings and auto-compaction integration\"\n- \"feat: migrate memory storage from markdown to JSONL format\"\n\nThis suggests:\n1. Migration from markdown-based thinking memories to JSONL is in progress\n2. Episodic memories are being created frequently\n3. Some cleanup or reorganization happened (73 deleted thinking memories)\n4. Git ignore configuration is being adjusted to exclude index files and logs","timestamp":"2025-12-21T19:27:11.813Z"}
{"action":"add","id":"ebfe1ac2-65b8-45f7-b1c9-311245ec8a99","subject":"Test suite setup includes field name normalization tests for memory extraction","keywords":["testing","memory-extractor","field-normalization","zod"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T18:21:17.810Z","content_hash":"6d912f6ee2c15598","content":"Added comprehensive tests for field name normalization in the memory extractor test suite (lines 224-277). Test cases cover:\n\n1. Alternative field names (summary, title, tags, scope, description, body)\n2. Mixed valid and invalid field names in same memory object\n3. Normalized fields pass Zod validation after normalization\n4. Original fields remain if no alternatives present\n\nTests ensure the normalization logic handles Claude's field name variations gracefully. All 228 tests pass.","timestamp":"2025-12-21T19:27:11.814Z"}
{"action":"add","id":"2dd3cfa2-e726-43ff-ab07-f3fec49f08d8","subject":"Transcript parsing must be backward-compatible with both old and new formats","keywords":["transcript parsing","backward compatibility","content blocks","legacy format"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:22:24.167Z","content_hash":"b0c6c129c0ee349a","content":"The transcript parser should support both formats:\n1. **New format**: content as array of blocks with type field\n2. **Old format**: content as string, thinking as optional string\n\nThe parser tries to detect which format is being used and normalizes to a common structure. This allows existing tests and code to continue working while supporting the actual Claude Code transcript format.","timestamp":"2025-12-21T19:27:11.814Z"}
{"action":"add","id":"480e2ab1-b77d-43b5-a5f2-1cc96435efd6","subject":"Logger utility expects single string argument, not multiple parameters","keywords":["logger","api-design","logging","function-signature"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:17:53.529Z","content_hash":"c556c20c81e86bfa","content":"The logger.ts utility functions (debug, info, warn, error) expect a single string argument, not multiple parameters or template literals with separate args. Correct usage is `logger.debug('message')` not `logger.debug('message', data)`. This requires string formatting before calling the logger function. Fix any calls that pass multiple parameters to the logger.","timestamp":"2025-12-21T19:27:11.815Z"}
{"action":"add","id":"6deba01f-1016-4cc9-96a7-fa94508e6b1d","subject":"JSONL format enables efficient append-only memory operations and embedded vector storage","keywords":["jsonl","append-only","vectors","embeddings","performance"],"applies_to":"global","occurred_at":"2025-12-21T17:34:47.718Z","content_hash":"b36d4c415d8db389","content":"The new JSONL format provides several advantages over individual markdown files:\n\n1. **Append-only writes** - New memories are appended to JSONL files, eliminating directory traversal overhead\n2. **Embedded embeddings** - Vector embeddings are stored directly in each entry, reducing separate index file lookups\n3. **Efficient operations** - \"add\" and \"delete\" operations create clear operation history\n4. **Atomic file operations** - Each JSONL line is independently parseable\n5. **Version control friendly** - JSONL format is easier to diff and merge than directory structures\n6. **Single file per type** - Two files (episodic, thinking) are simpler to manage than dozens of individual markdown files","timestamp":"2025-12-21T19:27:11.815Z"}
{"action":"add","id":"0432dfaa-98d3-40c4-8c37-a36de59e8f96","subject":"Local Recall plugin version 0.1.3 released with memory skills","keywords":["version","release","skills","plugin","memory","discoverability"],"applies_to":"global","occurred_at":"2025-12-21T18:29:25.453Z","content_hash":"67aa706b4776865e","content":"Version 0.1.3 of the local-recall plugin was released with significant improvements:\n\n- Two new skills added: `check-memories` and `proactive-recall` for improved memory management\n- MCP tool descriptions enhanced with usage guidance\n- Plugin metadata updated to improve discoverability in Claude Code marketplace\n- Eight thinking memory files added to support the new skills\n\nCommit: ff16fae on main branch","timestamp":"2025-12-21T19:27:11.816Z"}
{"action":"add","id":"830ad8d5-f559-475a-a03e-18fcba45baa0","subject":"Transcript types schema defines all Claude Code JSONL entry formats","keywords":["transcript-schema","JSONL","typescript-types","Claude-Code","transcript-structure"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"0c6772bf1c031b09","content":"Created comprehensive TypeScript types for parsing Claude Code transcript JSONL files in `src/types/transcript-schema.ts`. The schema covers:\n\n**Entry Types:**\n- `UserEntry` - User prompts with session context\n- `AssistantEntry` - Claude responses with thinking blocks, content blocks\n- `SystemEntry` - System messages and status updates\n- `FileHistorySnapshot` - File state snapshots for change detection\n- `QueueOperation` - Tool invocations and results (Bash, Read, Write, Grep, LSP, etc.)\n\n**Content Block Types:**\n- `TextBlock` - Plain text responses\n- `ToolUseBlock` - Tool invocations with parameters\n- `ToolResultBlock` - Tool execution results\n\n**Common Fields:**\n- `sessionId` - Session identifier\n- `timestamp` - ISO-8601 timestamp\n- `type` - Entry type discriminator\n\nUse these types to safely parse and extract data from transcripts without string manipulation.","timestamp":"2025-12-21T19:27:11.816Z"}
{"action":"add","id":"0519a94d-5ca0-42b5-8621-6661500b6f2b","subject":"sqlite-vec requires 'k = ?' parameter in vector search queries","keywords":["sqlite-vec","vector-search","query","syntax"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:17:30.301Z","content_hash":"e9231241783d026a","content":"The sqlite-vec extension requires the 'k = ?' parameter in the vector search clause when using JOINs. Initial implementation failed because scope filtering was applied in the SQL JOIN, causing sqlite-vec to enforce the k limit before the JOIN filtered results. Fixed by fetching more results than needed (k * 2) and filtering by scope in JavaScript post-processing to avoid this constraint.","timestamp":"2025-12-21T19:27:11.817Z"}
{"action":"add","id":"22b2dac7-0811-4978-9415-ebbb83122186","subject":"UserPromptSubmit hook: Unified search handling both episodic and thinking memories","keywords":["userpromptsubmit","hook","semantic search","unified search","episodic","thinking","memory injection"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:04:31.826Z","content_hash":"9f388c5faf23a9d0","content":"## Purpose\n\nThe UserPromptSubmit hook is triggered when a user submits a prompt. It searches for relevant memories (both episodic and thinking) and injects them into Claude's context before processing.\n\n## Flow\n\n1. **Input** (JSON via stdin):\n   - `session_id` - Current session identifier\n   - `transcript_path` - Path to transcript\n   - `cwd` - Current working directory\n   - `prompt` - The user's prompt text\n\n2. **Skip internal prompts**:\n   - Skips prompts containing `[LOCAL_RECALL_INTERNAL]` (used for memory extraction)\n   - This prevents memory extraction prompts from triggering memory searches\n\n3. **Search episodic memories** (if enabled):\n   - Uses Orama vector store + Ollama embeddings\n   - Filters by `episodicMinSimilarity` threshold\n   - Respects `episodicMaxTokens` budget\n   - Returns ranked results with similarity scores\n\n4. **Search thinking memories** (if enabled):\n   - Uses separate Orama vector store\n   - Filters by `thinkingMinSimilarity` threshold\n   - Respects `thinkingMaxTokens` budget\n   - Returns ranked results with similarity scores\n\n5. **Output** (stdout):\n   - Combined results from both searches\n   - Formatted for injection into Claude's context\n   - Includes similarity scores and metadata\n\n## Configuration\n\n**Episodic**:\n- `LOCAL_RECALL_EPISODIC_ENABLED` - Enable/disable (default: true)\n- `LOCAL_RECALL_EPISODIC_MAX_TOKENS` - Token budget (default: 1000)\n- `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY` - Threshold 0.0-1.0 (default: 0.5)\n\n**Thinking**:\n- `LOCAL_RECALL_THINKING_ENABLED` - Enable/disable (default: true)\n- `LOCAL_RECALL_THINKING_MAX_TOKENS` - Token budget (default: 1000)\n- `LOCAL_RECALL_THINKING_MIN_SIMILARITY` - Threshold 0.0-1.0 (default: 0.5)\n\n## Key Design\n\n- **Independent searches**: Episodic and thinking are searched separately\n- **Separate thresholds**: Each can have different quality bars\n- **Combined output**: Results are merged and formatted together\n- **No duplicates**: Same memory isn't included twice even if matching multiple searches","timestamp":"2025-12-21T19:27:11.817Z"}
{"action":"add","id":"2ade853b-9ce4-481f-ab67-ed2c2823dfc7","subject":"Mutex errors caused by concurrent sqlite-vec database operations across processes","keywords":["sqlite-vec","mutex","concurrency","database","locking","hooks"],"applies_to":"global","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"2046221de9c3da82","content":"The mutex lock errors (\"libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument\") were caused by concurrent database operations in sqlite-vec. The root cause:\n\n1. Multiple processes (hooks) and the daemon were opening separate database connections\n2. Each connection loaded sqlite-vec independently\n3. sqlite-vec's internal mutexes corrupted when operations overlapped\n\nThe HTTP server approach (hooks â†’ daemon â†’ HTTP â†’ vector store) was insufficient because it only serialized HTTP requests, not the actual database operations within the daemon.\n\nSolution: Implemented cross-process file-based locking that serializes ALL sqlite-vec operations, not just the load step.","timestamp":"2025-12-21T19:27:11.818Z"}
{"action":"add","id":"9e6a9dd0-8ab9-474e-a2c4-45ff1dec8e47","subject":"Thinking memories paired with episodic memories in vector store","keywords":["thinking-memories","vector-store","search","embeddings","dual-store"],"applies_to":"global","occurred_at":"2025-12-21T19:16:47.225Z","content_hash":"59be4be42fe8ba62","content":"Local Recall now maintains TWO separate vector stores and indices:\n\n1. **Episodic Memories** (`orama-episodic-index.json`)\n   - Traditional semantic memories about codebase\n   - Generated from transcripts via memory extraction\n   - Injected on UserPromptSubmit via `user-prompt-submit.ts` hook\n\n2. **Thinking Memories** (`orama-thinking-index.json`)\n   - Claude's internal reasoning paired with outputs\n   - Extracted from thinking blocks in transcripts\n   - Shows \"how I thought â†’ what I produced\"\n   - Injected on UserPromptSubmit via `user-prompt-submit.ts` hook\n\n**Configuration**: Both have independent settings:\n- `episodicEnabled/thinkingEnabled` - Toggle each type\n- `episodicMaxTokens/thinkingMaxTokens` - Budget per type\n- `episodicMinSimilarity/thinkingMinSimilarity` - Threshold per type\n\n**Classes**:\n- `ThinkingVectorStore` - Manages thinking memory embeddings\n- `ThinkingExtractor` - Extracts thinking blocks (20 parallel) from transcripts\n- `ThinkingProcessedLog` - Tracks processed transcripts for thinking extraction","timestamp":"2025-12-21T19:27:11.819Z"}
{"action":"add","id":"0b58ddd9-7c29-4cf3-9e8d-7561a16d8099","subject":"Orama vector store handles 768-dimensional embeddings via Ollama nomic-embed-text","keywords":["vector-store","orama","embeddings","ollama","nomic-embed-text","768-dimensions"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"1ca01241b9a25fe8","content":"Local Recall uses Orama (pure JavaScript) for vector storage with Ollama generating 768-dimensional embeddings using the `nomic-embed-text` model. Index files are stored as JSON (`orama-episodic-index.json`, `orama-thinking-index.json`) and are gitignored. When migrating from older embedding models (like fastembed with 384 dimensions), vector indexes must be deleted and rebuilt because the dimension mismatch causes errors.","timestamp":"2025-12-21T19:27:11.819Z"}
{"action":"add","id":"7006634b-e084-43d2-b08d-c657e5ca6a5f","subject":"Session-start hook reads memory files and outputs to stdout for Claude context injection","keywords":["hooks","session-start","memory","context","stdout"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:20:29.762Z","content_hash":"254d53ca4adc3ee1","content":"The session-start hook takes JSON input with session_id, transcript_path, and cwd, then reads existing memory files and outputs them to stdout so Claude's hook system can inject them into the context. This is the mechanism for making memories available at the start of each session.","timestamp":"2025-12-21T19:27:11.820Z"}
{"action":"add","id":"267692c8-f89b-4878-9476-cad9e489226b","subject":"Recency weighting boosts recent memories by up to 10%","keywords":["recency-weighting","vector-store","scoring","time-decay"],"applies_to":"file:src/core/vector-store.ts, file:src/core/thinking-vector-store.ts","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"c1d0da728d3bc5c5","content":"Added recency weighting to search scoring in both `VectorStore` and `ThinkingVectorStore`. Formula: `adjustedScore = similarity * (1 + 0.1 * recencyFactor)` where `recencyFactor` ranges from 0.0 (oldest memory) to 1.0 (newest memory). This gives recent memories up to 10% score boost as a tie-breaker when similarity is equal, improving relevance for recent context.","timestamp":"2025-12-21T19:27:11.820Z"}
{"action":"add","id":"5e0642b6-cdaf-458f-9852-a5dfa77a45b4","subject":"TranscriptMessage type extended with optional thinking field to track Claude's reasoning separately","keywords":["types","transcript","thinking","message structure","schema"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:15:55.194Z","content_hash":"61c202bebfb086b5","content":"Added optional `thinking?: string` field to TranscriptMessage interface at line 118. This allows storing Claude's internal reasoning/thinking blocks separately from the main response content. Validation in transcript.ts was updated to handle this optional field.","timestamp":"2025-12-21T19:27:11.820Z"}
{"action":"add","id":"1bf1f1f8-48a9-41ce-a062-1cb17c1cc504","subject":"Migration service: markdown to JSONL conversion","keywords":["migration","markdown","jsonl","convert","one-time"],"applies_to":"file:src/core/migration.ts","occurred_at":"2025-12-21T19:03:33.302Z","content_hash":"2163ac55505da0d5","content":"Created MigrationService that handles one-time conversion from markdown files to JSONL format. Reads all existing .md files from episodic-memory/ and thinking-memory/ directories, parses YAML frontmatter, creates 'add' entries in JSONL files, and deletes original markdown files and directories. Tracks migration state with a .migrated flag file to prevent re-running. Called automatically on MCP server startup.","timestamp":"2025-12-21T19:27:11.821Z"}
{"action":"add","id":"6795e0d0-750b-47fc-87a1-30db621b66e8","subject":"Memory schema now uses occurred_at for temporal tracking instead of updated_at","keywords":["schema","frontmatter","occurred_at","created_at","temporal"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T19:18:18.497Z","content_hash":"77181919ca70122f","content":"Updated memory schema in types.ts: Removed `updated_at` field (memories are immutable). Kept `occurred_at` (when the event/conversation happened) as the sole timestamp for temporal ordering. This single timestamp is part of the deduplication key. Memory files sort by `occurred_at` descending to show most recent events first, supporting chronological memory retrieval.","timestamp":"2025-12-21T19:27:11.821Z"}
{"action":"add","id":"e493d5f4-dfc8-48d1-9923-03578102f226","subject":"Documentation structure for memory extraction and hooks","keywords":["documentation","architecture","hooks","memory format","configuration"],"applies_to":"global","occurred_at":"2025-12-21T19:10:34.378Z","content_hash":"2f69b25c64b99c21","content":"Updated documentation files clarify the memory extraction process:\n- docs/architecture.md explains the Stop Flow and filtering rules\n- docs/hooks.md details the filtering rules (user messages excluded, multi-line requirement)\n- docs/memory-format.md provides examples and validation rules\n- docs/mcp-server.md documents available tools\n- docs/configuration.md covers configuration options","timestamp":"2025-12-21T19:27:11.822Z"}
{"action":"add","id":"153602f1-e653-4ea5-adf0-fc66fc789d33","subject":"Logger configuration defaults to error level but can be set to debug via LOCAL_RECALL_LOG_LEVEL","keywords":["logging","logger","log-level","configuration","recall.log"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T19:02:53.332Z","content_hash":"446172752dae9cc6","content":"The logging system writes to `local-recall/recall.log` with configurable log levels via the LOCAL_RECALL_LOG_LEVEL environment variable. Default is 'error' level. Debug-level logs won't be visible to users by default, so important diagnostic information should use INFO level for visibility during troubleshooting.","timestamp":"2025-12-21T19:27:11.822Z"}
{"action":"add","id":"ef0217d7-bb38-4821-a020-a17a2b04cc79","subject":"Mutex errors with sqlite-vec in concurrent process scenarios","keywords":["sqlite-vec","mutex","concurrent","process","locking","error","mcp-server"],"applies_to":"global","occurred_at":"2025-12-21T19:17:32.370Z","content_hash":"4691c88790bff4fa","content":"The codebase has concerns about 'mutex lock failed: Invalid argument' errors that occur when multiple processes load sqlite-vec concurrently. The MCP server (src/mcp-server/server.ts:230) mentions using cross-process file locking to prevent these sqlite-vec mutex errors. This is a known issue to be aware of when implementing concurrent access patterns.","timestamp":"2025-12-21T19:27:11.823Z"}
{"action":"add","id":"753c471d-9ac4-4420-8e4b-1c8f3fdd5082","subject":"Transcript cleanup removes malformed files and synthetic transcripts automatically","keywords":["cleanup","transcript collector","validation","file format","uuid"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:15:46.377Z","content_hash":"7a960b3cd8bf3c35","content":"Added `cleanupTranscripts()` method (lines 353-403) that:\n1. Validates file format - expects UUID.jsonl naming pattern\n2. Removes files that don't match format (e.g., .DS_Store, readme.txt, malformed names)\n3. Removes synthetic transcripts (containing '<synthetic>' model marker)\n4. Returns cleanup stats: {invalidFormat: number, synthetic: number}\n\nThe cleanup is automatically called at the start of `syncTranscripts()` so malformed and synthetic files are cleaned before any processing begins.","timestamp":"2025-12-21T19:27:11.824Z"}
{"action":"add","id":"d250ee7b-99ce-4851-af3e-b99e4dc36bf2","subject":"Plugin hooks configuration uses old user-prompt-submit-thinking.js that requires better-sqlite3","keywords":["plugin","hooks","better-sqlite3","stale","user-prompt-submit-thinking"],"applies_to":"file:dev-marketplace/local-recall-plugin/config/hooks.json","occurred_at":"2025-12-21T19:22:18.525Z","content_hash":"d58569a1ec761148","content":"The plugin's hooks.json was pointing to a stale `user-prompt-submit-thinking.js` file that attempted to import `better-sqlite3`, a native module that cannot be bundled. This file is from an older version before the codebase migrated to Orama (pure JavaScript) for vector search. The fix is to update hooks.json to use `user-prompt-submit.js` instead, which handles both episodic and thinking memories and uses only Orama (pure JS, no native dependencies).","timestamp":"2025-12-21T19:27:11.824Z"}
{"action":"add","id":"643f9a5e-30ea-4cde-981a-cd32ba65efa7","subject":"Architecture: Hooks should not directly load sqlite-vec, use HTTP daemon instead","keywords":["architecture","hooks","daemon","process isolation","sqlite-vec"],"applies_to":"global","occurred_at":"2025-12-21T18:19:08.315Z","content_hash":"3a2ef456d96a04ac","content":"The local-recall system has a fundamental architectural issue: hooks (SessionStart, UserPromptSubmit) are attempting to directly load sqlite-vec for vector operations, but they run in sandboxed Claude Code hook processes that don't have proper process isolation.\n\nThe correct architecture:\n- Hooks should NOT load sqlite-vec directly\n- Hooks should use HTTP communication to a background daemon (MCP server) for vector operations\n- Only the daemon process should load sqlite-vec to avoid mutex contention\n\nThis prevents mutex errors and provides better separation of concerns. The MCP daemon can run persistently while hooks remain lightweight.","timestamp":"2025-12-21T19:27:11.825Z"}
{"action":"add","id":"ec701e54-e42d-4a11-a963-b534a080dc91","subject":"Plugin cache MCP server requires bundled dependencies, not external imports","keywords":["plugin","bundling","esbuild","external","mcp sdk","dependencies"],"applies_to":"global","occurred_at":"2025-12-21T19:26:32.435Z","content_hash":"1f6a0c10ea02a976","content":"The plugin system doesn't ship node_modules. The MCP server must be bundled with ALL its dependencies into a single server.js file. The build script had `--external:@modelcontextprotocol/sdk` which prevented bundling, causing the plugin cache version to fail with missing dependencies.\n\nFix: Remove the `--external:@modelcontextprotocol/sdk` flag from the esbuild command in package.json build:scripts.\n\nResult: bundled server.js grows from 704KB to 1.1MB but becomes self-contained and works in plugin cache.","timestamp":"2025-12-21T19:27:11.825Z"}
{"action":"add","id":"f62b572b-f3d0-408e-b74f-e587ee3ae2c0","subject":"Vector search results now sorted by similarity score, then recency","keywords":["vector-store","scoring","ranking","occurred_at","sorting"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:19:24.814Z","content_hash":"a8713a7e8f1aeb85","content":"Vector search results in `src/core/vector-store.ts:200-270` are sorted by cosine distance similarity score (0.0 to 1.0 range). Scores are rounded to 2 decimal places (e.g., 0.65). When multiple results have identical rounded scores, they are secondarily sorted by `occurred_at` in descending order (newest first) to break ties and ensure recent memories are prioritized. This provides clean, predictable scoring and recency-based ranking for equivalent results.","timestamp":"2025-12-21T19:27:11.826Z"}
{"action":"add","id":"1bfee409-4463-45a7-87d6-c7e93cce8e26","subject":"Hook testing revealed missing rake-pos dependency for stop hook","keywords":["hooks","stop-hook","rake-pos","dependency","testing","npm-install"],"applies_to":"global","occurred_at":"2025-12-21T19:20:40.036Z","content_hash":"503c755dfc437d5d","content":"When testing the stop hook (src/hooks/stop.ts), the initial execution failed with exit code 1 due to a missing rake-pos dependency. The dependency is required by the stop hook for keyword extraction. This was resolved by running `npm install` to ensure all dependencies in package.json were properly installed. The rake-pos module provides RAKE (Rapid Automatic Keyword Extraction) and POS (Part-of-Speech) tagging functionality needed for memory keyword extraction.","timestamp":"2025-12-21T19:27:11.827Z"}
{"action":"add","id":"d002180f-c487-422d-ab0c-d95912334edb","subject":"UserPromptSubmit hook uses Orama vector search for both episodic and thinking memories","keywords":["userpromptsubmit","vector search","orama","ollama embeddings","semantic search","thinking memories"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:16:18.307Z","content_hash":"78cc6a92692f9f65","content":"## Implementation\nThe UserPromptSubmit hook performs semantic search on two independent memory types:\n\n### Episodic Memories\n- Uses Orama vector store with Ollama embeddings\n- Configuration: `episodicEnabled`, `episodicMinSimilarity` (default 0.5), `episodicMaxTokens` (default 1000)\n- Returns memories ranked by cosine similarity score\n\n### Thinking Memories\n- Uses separate Orama vector store (`orama-thinking-index.json`)\n- Configuration: `thinkingEnabled`, `thinkingMinSimilarity` (default 0.5), `thinkingMaxTokens` (default 1000)\n- Stores thought+output pairs for reasoning examples\n\n## Execution Flow\n1. Parse JSON input with session_id, transcript_path, cwd, prompt\n2. Skip internal prompts (containing `[LOCAL_RECALL_INTERNAL]`)\n3. Generate embedding for user prompt via Ollama\n4. Search both episodic and thinking vector stores (if enabled)\n5. Filter by similarity threshold and token budget\n6. Combine results and output to stdout\n\n## Potential Issues\n- Depends on Ollama running and nomic-embed-text model available\n- Vector indexes must exist and be valid JSON\n- Token counting must be accurate to respect budget\n- Embedding generation can be slow for long prompts","timestamp":"2025-12-21T19:27:11.827Z"}
{"action":"add","id":"222e8652-ea45-4755-8c80-07d88a0933a4","subject":"Three pathways for loading data into SQLite vector store","keywords":["vector-store","data-loading","sync","memory-creation","initialization"],"applies_to":"global","occurred_at":"2025-12-21T18:24:20.066Z","content_hash":"1abbb9018ecd4468","content":"Data enters the SQLite vector store through three pathways:\n\n1. **On Memory Creation** (immediate): When `MemoryManager.createMemory()` is called, the memory is written to disk as markdown, then immediately added to the vector store via `vectorStore.add(memory)`, generating an embedding and inserting into both `memories` and `memory_embeddings` tables.\n\n2. **During MCP Server Startup** (src/mcp-server/server.ts:73): `vectorStore.sync(memories)` reconciles the vector store with all memories from disk, adding missing ones and removing deleted ones.\n\n3. **Via Search Engine** (src/core/search.ts): When memories are retrieved via search, they interact with the vector store's index.","timestamp":"2025-12-21T19:27:11.828Z"}
{"action":"add","id":"5fd6c581-f7e3-4a8f-80a7-15fe08f348c9","subject":"Three pathways for data to enter the vector store","keywords":["vector store","data loading","sqlite","sync","memory creation","embedding"],"applies_to":"global","occurred_at":"2025-12-21T18:25:49.095Z","content_hash":"d581cc8f2f25f765","content":"Data enters the SQLite vector store through three pathways: (1) On memory creation - when `MemoryManager.createMemory()` writes a markdown file, it immediately calls `vectorStore.add(memory)` to generate embedding and insert into SQLite; (2) MCP tools sync - when episodic/thinking search tools are called, they sync memories via `vectorStore.sync(memories)`; (3) Daemon sync in MCP server - the background daemon calls `vectorStore.sync(memories)` to ensure the vector store matches file-based memories.","timestamp":"2025-12-21T19:27:11.828Z"}
{"action":"add","id":"4fed4091-632c-4bd0-b906-55d76705a586","subject":"Plugin hook configuration in dev-marketplace must match current implementation","keywords":["plugin","hooks.json","configuration","maintenance"],"applies_to":"file:dev-marketplace/local-recall-plugin/config/hooks.json","occurred_at":"2025-12-03T11:22:02.028Z","content_hash":"df84037edd2b54a4","content":"The plugin's `hooks.json` must be kept in sync with the main project's hook implementation. When the main project changes from using `user-prompt-submit-thinking.js` to a unified `user-prompt-submit.js` that handles both episodic and thinking memories, the plugin configuration must be updated to match.\n\nStale hook files that reference deleted dependencies will cause plugin hook failures. Always verify that bundled hook files exist and use only pure JavaScript libraries before deploying to users.","timestamp":"2025-12-21T19:27:11.829Z"}
{"action":"add","id":"cc96a229-3f5d-4591-b328-40564615f70e","subject":"analyzeForMemories only saves multi-line content by design","keywords":["memory extraction","content filtering","multi-line content"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:23:27.035Z","content_hash":"161d56bb7ee5236a","content":"The `analyzeForMemories` function filters out single-line responses because they're typically too brief to be useful memories. It checks `content.split('\\n').length > 1` before creating memory entries. This is intentional behavior to avoid cluttering the memory store with trivial or single-sentence outputs.\n\nWhen thinking messages are being extracted, the same filter applies - only multi-line thinking + output pairs are saved as thinking memories.","timestamp":"2025-12-21T19:27:11.830Z"}
{"action":"add","id":"75b6737d-a9a7-4155-8407-a44a000e1937","subject":"Concurrent database initialization requires file-based locking due to sqlite-vec C++ constraints","keywords":["sqlite-vec","concurrency","native extension","database","initialization"],"applies_to":"area:database","occurred_at":"2025-12-03T09:47:36.366Z","content_hash":"7496ee74f5f3b4bc","content":"The sqlite-vec native extension (C++ binding) has thread-safety issues when loaded concurrently by multiple processes. When multiple hooks try to initialize the database in parallel, sqlite-vec.load() throws a mutex lock error. The solution is file-based locking (not process locks) in `src/utils/database.ts`:\n\n- Creates a `db-init.lock` file to serialize sqlite-vec loading\n- Processes wait to acquire the lock file before calling sqlite-vec.load()\n- Lock is released immediately after successful initialization\n- Stale locks are cleaned up to prevent deadlocks\n\nThis is a workaround for the C++ extension's inability to handle concurrent initialization.","timestamp":"2025-12-21T19:27:11.830Z"}
{"action":"add","id":"d5b68af9-1a6b-4aa6-9543-186d8612c578","subject":"Orama vector store chosen over sqlite-vec for pure JavaScript implementation","keywords":["orama","vector-store","pure-javascript","embeddings","semantic-search","sqlite-vec"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"052a64efb478217a","content":"Local Recall switched from sqlite-vec to Orama as the vector store backend. Orama is a pure JavaScript vector database that works directly in Node.js without native dependencies or threading issues. It stores indexes as JSON files (`orama-episodic-index.json`, `orama-thinking-index.json`) that are gitignored. Uses Ollama for generating embeddings (nomic-embed-text model, 768 dimensions). Eliminates concurrency problems that plagued sqlite-vec.","timestamp":"2025-12-21T19:27:11.830Z"}
{"action":"add","id":"1d0b2d72-f3e9-467f-868c-4d7d0e7cfdc3","subject":"Session start memory injection uses recency sorting and token budgeting","keywords":["session-start","memory-injection","episodic-memory","token-budget","recency","hooks"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"42ed0063db89856b","content":"The SessionStart hook injects the 5 most recent episodic memories into context. Memories are sorted by `occurred_at` timestamp (most recent first) and selected based on a token budget. This provides recent context from previous sessions without overwhelming the prompt with irrelevant historical information. The implementation reads memory files directly from disk rather than using the vector store for simplicity and performance.","timestamp":"2025-12-21T19:27:11.830Z"}
{"action":"add","id":"4829d35d-be54-425e-b254-892158ce0397","subject":"Plugin has multiple version files that need synchronization","keywords":["plugin","version","package.json","plugin.json","marketplace.json","sync"],"applies_to":"global","occurred_at":"2025-12-21T19:04:30.207Z","content_hash":"ee96887fbd350eef","content":"The local-recall plugin maintains version information in multiple locations that must be kept in sync:\n- `package.json` - npm package version\n- `.claude-plugin/plugin.json` - Claude plugin manifest\n- `.claude-plugin/marketplace.json` - Marketplace deployment file\n\nWhen updating the version, all three files must be updated and the marketplace.json must be explicitly deployed/published to reflect changes.","timestamp":"2025-12-21T19:27:11.831Z"}
{"action":"add","id":"ad2e9407-6b3e-4bd8-85bf-9fa01c5f142b","subject":"MCP server daemon processes transcripts asynchronously every 5 minutes (Stop hook disabled)","keywords":["mcp server","daemon","transcript processing","async","background job","polling interval"],"applies_to":"global","occurred_at":"2025-12-21T18:59:50.981Z","content_hash":"ead7df9c4d516fb9","content":"The MCP server runs a background daemon that handles memory extraction instead of using the Stop hook:\n\n1. **No Stop hook** - The Stop hook is currently disabled\n2. **Async daemon process** - Runs in background every 5 minutes\n3. **Transcript syncing** - Reads from ~/.claude/projects/<project>/transcripts/\n4. **Content hash tracking** - Uses processed-log.jsonl to detect transcript changes\n5. **Automatic recreation** - Deletes and recreates memories when transcripts change\n6. **20 parallel extractors** - For thinking blocks, uses 20 parallel extraction tasks\n\nThis async approach is more reliable than Stop hooks and allows graceful handling of large transcripts without blocking the main Claude Code session.","timestamp":"2025-12-21T19:27:11.832Z"}
{"action":"add","id":"a51ab036-caeb-46e9-af75-bd022264d6a0","subject":"Mutex error in UserPromptSubmit hook caused by sqlite-vec loading in multi-process environment","keywords":["mutex error","sqlite-vec","hook","file locking","concurrency","user-prompt-submit"],"applies_to":"global","occurred_at":"2025-12-21T19:16:09.210Z","content_hash":"1604d360b8cd44bc","content":"The UserPromptSubmit hook was throwing 'mutex lock failed: Invalid argument' because it directly instantiated SearchEngine and ThinkingSearchEngine, which load sqlite-vec. This causes mutex issues when multiple processes try to load the same native module.\n\n**Root Cause**: sqlite-vec uses native file locking mechanisms that fail when accessed from multiple concurrent processes (hooks run in separate processes).\n\n**Solution**: Add comprehensive logging with PID tracking to identify which processes are failing and when. Log:\n- Process ID (PID) for all operations\n- Lock acquisition attempts and elapsed time\n- sqlite-vec loading timing separately\n- Full stack traces on errors\n\nThis helps differentiate between file locking issues and actual mutex problems. The file locking mechanism exists in database.ts but didn't provide enough visibility into the failure point.","timestamp":"2025-12-21T19:27:11.833Z"}
{"action":"add","id":"2c866c70-6a6d-493c-b550-a83b27cb99b3","subject":"Thinking memory retrieval changed from count-based to token-based limiting","keywords":["thinking-memory","retrieval","token-limit","memory-injection"],"applies_to":"file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-03T09:47:22.389Z","content_hash":"352669b55e9488da","content":"Memory retrieval now uses token-based limiting instead of fixed count limits. Configurable via LOCAL_RECALL_THINKING_MAX_TOKENS (default 1000). Memories are added until hitting the token budget. Also added LOCAL_RECALL_THINKING_MIN_SIMILARITY (default 0.8) for similarity threshold filtering. This provides more consistent context injection regardless of memory sizes.","timestamp":"2025-12-21T19:27:11.833Z"}
{"action":"add","id":"c4f03b2e-b86c-43a1-acbe-0301ac327239","subject":"Memory deduplication uses content_hash and occurred_at timestamp","keywords":["deduplication","memory-creation","idempotent-operations","content-hash"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"8c14c273e8491089","content":"Memory creation is idempotent - before creating a new memory, the system checks for duplicates using:\n1. `content_hash` - SHA-256 prefix (first 16 chars) of content\n2. `occurred_at` - ISO-8601 timestamp of when the event occurred\n\nIf a duplicate exists (same occurred_at and content_hash), the existing memory is returned instead of creating a new one. This prevents duplicate memories from identical events across multiple sessions or re-runs of transcript processing.\n\nThis is important for both SessionStart hook (which reads memories) and Stop hook (which creates new memories from transcripts).","timestamp":"2025-12-21T19:27:11.834Z"}
{"action":"add","id":"7f4373ef-232a-4679-8fb4-8ce8be264245","subject":"Plugin hook configuration needs manual sync when main hooks change","keywords":["plugin","maintenance","hooks-sync","dev-marketplace","configuration"],"applies_to":"area:plugin-development","occurred_at":"2025-12-21T19:21:32.710Z","content_hash":"7db393674f424f45","content":"The dev-marketplace/local-recall-plugin maintains its own `config/hooks.json` and bundled hook scripts that can become out of sync with the main source code. When the main project's hooks are refactored (e.g., migrating from SQLite to Orama), the plugin's configuration and bundled files must be manually updated.\n\nThe plugin appears to bundle its own versions of hooks rather than using the main project's compiled output. This requires manual maintenance when architectures change.\n\nConsider: For future plugin updates, ensure hooks.json and bundled scripts are regenerated from the current main source during plugin builds.","timestamp":"2025-12-21T19:27:11.834Z"}
{"action":"add","id":"f5726fe2-5e78-4467-b459-d042fad18942","subject":"Shared gitignore utility created to avoid duplication","keywords":["gitignore","utility","code-reuse","shared-function"],"applies_to":"global","occurred_at":"2025-12-21T18:14:47.343Z","content_hash":"538dde665b5d9a13","content":"Both `src/core/memory.ts` and `src/core/index.ts` had identical gitignore creation logic. This was extracted into a shared utility function `ensureGitignore(baseDir)` in `src/utils/gitignore.ts`. Both files now import and call this function instead of duplicating the logic. This is a DRY principle application for file management utilities.","timestamp":"2025-12-21T19:27:11.835Z"}
{"action":"add","id":"eca018be-2faa-46e1-a9ff-2e0338ebe8c5","subject":"Memory extraction updated to use condensed transcripts via transcript-condenser module","keywords":["memory-extractor","transcript-condenser","prompt-building","integration"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:30:38.769Z","content_hash":"2ff6709d83b3a459","content":"Updated `src/core/memory-extractor.ts` to integrate the new transcript condenser:\n\n**Changes made:**\n1. Added import for `TranscriptCondenser`\n2. Reads raw JSONL transcript content\n3. Condenses transcript using `TranscriptCondenser.condense(jsonlContent)`\n4. Passes condensed data to `buildMemoryExtractionPrompt()` instead of raw content\n5. Claude processes only the essential information, reducing token usage significantly\n\n**Impact:**\n- Extraction prompts are much smaller\n- Faster processing\n- Lower API costs\n- Better focus on actual memory-worthy content\n\nThe integration is seamless and backwards-compatible with existing memory extraction logic.","timestamp":"2025-12-21T19:27:11.835Z"}
{"action":"add","id":"3f693714-2a45-4d13-83ea-e78b6c4032b2","subject":"Streaming artifact patterns in transcripts: thinking blocks are duplicated, not interleaved","keywords":["transcripts","streaming","message structure","jsonl format","duplicates"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:23:20.556Z","content_hash":"87e7a743eb74f7d0","content":"When processing Claude transcripts in JSONL format, the same thinking block can appear multiple times in a single message as a streaming artifact. The pattern observed is thinking â†’ tool_use â†’ thinking (identical) â†’ text. This is NOT true interleaved thinking but rather duplicate logging from the streaming API. Deduplication using `[...new Set(array)]` is effective at removing these duplicates before joining.","timestamp":"2025-12-21T19:27:11.836Z"}
{"action":"add","id":"2d275b2c-b91b-4863-956d-e4bfa613fa8c","subject":".gitignore should be created in local-recall/ directory root, not subdirectories","keywords":["gitignore","structure","directory-layout","initialization"],"applies_to":"global","occurred_at":"2025-12-21T18:17:51.449Z","content_hash":"89e785d8942fb7e5","content":"The `.gitignore` file for the local-recall project should be created in the `local-recall/` directory root, not in `memories/` or other subdirectories. It should contain patterns to ignore:\n- Generated index files (`orama-*.json`)\n- Log files (`recall.log`, `processed-log.jsonl`)\n- Local cache directories\n\nThe file is version-controlled and ensures that auto-generated files don't pollute the git repository while allowing hand-written memory files to be tracked.","timestamp":"2025-12-21T19:27:11.836Z"}
{"action":"add","id":"fde924ad-161e-4544-82cd-74f720a745d7","subject":"Claude project directories use path-to-dashes naming convention in ~/.claude/projects","keywords":["claude projects","transcript discovery","path convention","project directory naming"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:19:12.033Z","content_hash":"c5432029964cd635","content":"Claude stores project directories in ~/.claude/projects/ using a naming convention where the full path has slashes replaced with dashes. For example, /Users/joe/Code/Syntessera/local-recall becomes -Users-joe-Code-Syntessera-local-recall. The transcript files are stored directly in this project directory, not in a subfolder. When discovering projects, prioritize this naming pattern first before falling back to other methods.","timestamp":"2025-12-21T19:27:11.837Z"}
{"action":"add","id":"7d4a9c9d-c5a9-429c-8cfb-d7e43645181a","subject":"Use git filter-branch with FILTER_BRANCH_SQUELCH_WARNING=1 to safely rewrite history and remove unwanted files","keywords":["git","filter-branch","history rewriting","remove files","git cleanup"],"applies_to":"global","occurred_at":"2025-12-03T12:59:07.634Z","content_hash":"206ef0204fca3989","content":"When local_cache files were accidentally committed, they were removed using `git filter-branch --force --index-filter` with the environment variable `FILTER_BRANCH_SQUELCH_WARNING=1` to suppress warnings. After rewriting history, cleanup backup refs with `git update-ref -d refs/original/refs/heads/main`. Always verify no commits have been pushed before rewriting history, and use `git push --force-with-lease` when pushing rewritten commits to ensure safety.","timestamp":"2025-12-21T19:27:11.837Z"}
{"action":"add","id":"5e85eb2a-3174-443d-9488-75cc3f90c2ef","subject":"SessionStart and UserPromptSubmit hooks need stdout output verification","keywords":["hooks","stdout","debug","logging","session-start","user-prompt-submit"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:59:35.657Z","content_hash":"e63dffc5f849c1bf","content":"## Issue\n\nHooks may not be outputting to stdout correctly. The SessionStart hook should output recent memories, and UserPromptSubmit should output search results.\n\n## Next Steps\n\n1. Add explicit console logging to verify hook execution flow\n2. Ensure memory content is properly formatted and written to stdout\n3. Test hooks with sample input to verify output\n4. Check that hook output is being properly read by Claude Code\n\n## Hook Responsibilities\n\n- **SessionStart**: Read 5 most recent memories and output to stdout\n- **UserPromptSubmit**: Search memories and output results to stdout","timestamp":"2025-12-21T19:27:11.838Z"}
{"action":"add","id":"7b62efb5-624f-44eb-946e-fb5ac41c1b26","subject":"session-start hook is safe (file-based only, no embeddings)","keywords":["session-start","hook","safe","no embeddings","memory manager"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:20:35.399Z","content_hash":"dd54f92f4d93f956","content":"The session-start hook only uses MemoryManager (file-based operations) and does not load the embedding model. Therefore it's safe from mutex errors and can run concurrently without issues. Only user-prompt-submit hook has the embedding model loading problem.","timestamp":"2025-12-21T19:27:11.838Z"}
{"action":"add","id":"5e226b66-a25e-4db1-a659-d7fcbcc45b1f","subject":"Memory extraction prompt must explicitly request JSON-only response","keywords":["json-response","prompt-engineering","memory-extraction","output-format"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:29:15.440Z","content_hash":"70f0e5dff0f437dc","content":"The memory extraction prompt must clearly state that the response should be:\n1. ONLY valid JSON with no markdown formatting\n2. ONLY valid JSON with no explanation or comments\n3. Start directly with the JSON object\n\nThis is critical because the response is parsed as JSON without any text preprocessing. Any explanation before the JSON or markdown code blocks will cause parsing to fail.","timestamp":"2025-12-21T19:27:11.838Z"}
{"action":"add","id":"b823af7d-c507-4787-9ba3-bbd812c4d318","subject":"Memory file format uses YAML frontmatter with id, subject, keywords, applies_to, and occurred_at fields","keywords":["memory format","yaml","frontmatter","metadata","markdown"],"applies_to":"global","occurred_at":"2025-12-21T18:15:33.474Z","content_hash":"f8fdcc774a1a7337","content":"Memory files use YAML frontmatter to store metadata:\n- `id`: UUID for unique identification\n- `subject`: Brief one-line description\n- `keywords`: Array of searchable keywords\n- `applies_to`: Scope (global, file:<path>, or area:<name>)\n- `occurred_at`: ISO-8601 timestamp\n- `content_hash`: SHA-256 prefix for deduplication\n\nContent follows the frontmatter as markdown.","timestamp":"2025-12-21T19:27:11.839Z"}
{"action":"add","id":"cd77cae8-6818-4144-acfe-ed1dca99e1d1","subject":"Stop hook parses transcripts to extract memories asynchronously","keywords":["stop-hook","transcript-extraction","async-memory-creation","background-processing"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"4c20dc5e345f86eb","content":"The Stop hook (triggered when Claude Code session ends) processes the transcript to extract and create memories:\n1. Receives the transcript path, session ID, and working directory\n2. Parses the transcript using `transcript.ts` to extract meaningful events and reasoning\n3. Calls Claude with the transcript to identify key insights and learnings\n4. Creates episodic memories with proper metadata (keywords, scope, timestamp, content hash)\n\nThe hook operates asynchronously to avoid blocking session exit. This enables the system to learn from each session by capturing important discoveries, bug fixes, architectural decisions, and problem-solving patterns for future reference.","timestamp":"2025-12-21T19:27:11.839Z"}
{"action":"add","id":"591832fb-58df-4769-b45b-841923377dd7","subject":"Plugin version bumped from 0.1.1 to 0.1.2","keywords":["version","plugin","0.1.2","release","package"],"applies_to":"global","occurred_at":"2025-12-21T19:20:03.546Z","content_hash":"ebfc79fa29278ba8","content":"The plugin version is managed in two files that must be kept in sync:\n1. package.json - root package version\n2. dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json - plugin metadata\n\nBoth files must be updated together when bumping the version. The current version is 0.1.2 (bumped from 0.1.1).","timestamp":"2025-12-21T19:27:11.839Z"}
{"action":"add","id":"0284624c-b456-43bb-9261-468bef040ad5","subject":"Thinking memories successfully extracted and stored with thought+output pairs","keywords":["thinking-memory","extraction","memory creation","episodic vs thinking","markdown format"],"applies_to":"global","occurred_at":"2025-12-21T19:15:00.052Z","content_hash":"1809c5848ade9920","content":"The thinking extraction pipeline now successfully:\n1. Processes 59+ transcripts from the session history\n2. Extracts and creates 600+ thinking memories\n3. Stores each memory with `## Thought` and `## Output` sections in markdown\n4. Groups related thinking blocks with their corresponding assistant text responses\n5. Maintains JSONL-based tracking via `thinking-processed-log.jsonl`\n\nThinking memories store 'how I thought â†’ what I produced' pairs, providing examples of reasoning patterns that help future sessions tackle similar problems.","timestamp":"2025-12-21T19:27:11.840Z"}
{"action":"add","id":"a5a9ec91-b09a-4a84-b21f-f10f0f545c18","subject":"Hooks are compiled to dist/hooks/ directory and can be tested with JSON input via stdin","keywords":["hooks","testing","compilation","dist","stdin","json"],"applies_to":"global","occurred_at":"2025-12-21T19:21:19.454Z","content_hash":"dd2f3101a99882c0","content":"Hooks are TypeScript files in src/hooks/ that are compiled to dist/hooks/. They can be tested by piping JSON input to them via stdin. The JSON should contain fields like `session_id`, `transcript_path`, `cwd`, etc. depending on which hook is being tested.","timestamp":"2025-12-21T19:27:11.840Z"}
{"action":"add","id":"a774723b-47d4-4899-9dce-d74cbc0dd801","subject":"Memory system redesigned to use episodic/idempotent model with content deduplication","keywords":["architecture","memory","episodic","idempotent","deduplication","occurred_at","content_hash"],"applies_to":"global","occurred_at":"2025-12-21T18:20:12.298Z","content_hash":"0071ec0d99e5c055","content":"# Memory System Redesign\n\nShifted from mutable knowledge base to episodic memory log model:\n\n## Key Changes\n1. **Immutability**: Memories cannot be updated or deleted via API - only manually by user\n2. **Deduplication**: Uses `occurred_at` + `content_hash` (SHA-256, 16 char prefix) as dedup key\n3. **Timestamps**: Each memory has:\n   - `occurred_at`: When the conversation/event happened (from transcript)\n   - `created_at`: When the memory file was written\n   - `content_hash`: Hash of content for deduplication\n4. **Idempotency**: Creating the same memory twice checks the dedup key; if exists, skips creation\n\n## Rationale\nThis mirrors how human episodic memory works - preserving events with timestamps rather than maintaining a mutable knowledge base. Allows reframing memories as needed without modification.\n\n## Implementation\n- Removed `updateMemory()` and `deleteMemory()` from API\n- Removed `updated_at` field from schema\n- Added `findDuplicate(occurredAt, contentHash)` method to check before creation\n- Memory `computeContentHash()` uses SHA-256 truncated to 16 characters\n- Removed `timeWindow` configuration (now processes entire history)\n\n## Stop Hook Behavior\nNo longer filters by 30-second time window. Processes entire transcript history, relying on deduplication to prevent duplicate memories from repeated hook runs.","timestamp":"2025-12-21T19:27:11.840Z"}
{"action":"add","id":"97208e7d-37c1-4327-aa4b-d97dcdf45207","subject":"Local-recall plugin update requires Claude Code restart","keywords":["plugin","update","restart","deployment","installation"],"applies_to":"global","occurred_at":"2025-12-03T11:22:41.598Z","content_hash":"33852eb72ea64015","content":"When local-recall is updated via the plugin system, changes take effect only after restarting Claude Code. This is standard plugin behavior and should be communicated to users if they experience stale behavior after an update.","timestamp":"2025-12-21T19:27:11.841Z"}
{"action":"add","id":"b3aac688-39b2-4f02-882a-921390180aba","subject":"Hooks are compiled to dist/hooks/ before testing","keywords":["hooks","build","compilation","dist","session-start","stop"],"applies_to":"global","occurred_at":"2025-12-21T18:26:16.493Z","content_hash":"de1743a185f099bd","content":"Session-start and stop hooks must be built/compiled to dist/hooks/ directory before they can be tested. The TypeScript source files in src/hooks/ are compiled to JavaScript in dist/hooks/ which is what actually gets executed.","timestamp":"2025-12-21T19:27:11.841Z"}
{"action":"add","id":"bd6588a6-8eee-438e-9456-8f0b6bcefbb7","subject":"Thinking blocks in transcripts are identified by type='thinking' in content","keywords":["thinking blocks","transcript structure","content type","detection"],"applies_to":"global","occurred_at":"2025-12-21T18:15:34.664Z","content_hash":"468db32e8ab7713b","content":"Thinking blocks appear in Claude's transcripts as content elements with `\"type\":\"thinking\"`. This is how the codebase identifies and extracts Claude's reasoning from transcripts.\n\nUsed in:\n- `thinking-extractor.ts` for extracting thinking blocks\n- `transcript-collector.ts` for filtering transcripts during sync\n\nThis is the standard way to detect whether a transcript contains thinking (and thus is worth processing for thinking memories).","timestamp":"2025-12-21T19:27:11.842Z"}
{"action":"add","id":"4e7e3995-b1df-490e-b934-9e60c001eac0","subject":"VectorStore integration: pre-computed embeddings and Orama sync","keywords":["vector-store","embedding","orama","pre-computed","sync"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:03:33.302Z","content_hash":"a41d7f88c9ae33a8","content":"Added `addWithEmbedding()` method to VectorStore to accept pre-computed embeddings instead of computing them via Ollama. Added `syncWithJsonlStore()` method that syncs memories/embeddings between JSONL store and Orama index. Automatically detects new memories (add entries), deletes (delete entries), and new embeddings (embedding entries). Computes missing embeddings on-demand via Ollama. This allows JSONL to be the source of truth while Orama remains the search index.","timestamp":"2025-12-21T19:27:11.842Z"}
{"action":"add","id":"3196faa8-06d8-4818-8da7-cc3717418052","subject":"File locking mechanism for database initialization","keywords":["file lock","concurrent access","database initialization","resource sharing"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-03T10:22:44.117Z","content_hash":"59b2061d57cd9af4","content":"A file-based locking mechanism using a lock file at `{memoryDir}/.db.lock` was implemented to serialize database initialization. The lock is acquired with retry logic and released after initialization. Lock acquisition includes timing information and attempt counting. However, this approach only works within a single machine and only for file I/O - it cannot prevent the mutex error from sqlite-vec's internal C++ locking when multiple processes load the extension simultaneously.","timestamp":"2025-12-21T19:27:11.843Z"}
{"action":"add","id":"15137161-ea1e-421a-8131-4abe6e827f8a","subject":"E2BIG error when passing large transcripts to claude CLI","keywords":["e2big","transcript","cli","argument-size","stdin"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:22:56.476Z","content_hash":"68a7a888138427a9","content":"Large transcripts passed as command-line arguments to `claude -p` exceed OS limits (~262KB on macOS). Solution: pass the prompt via stdin using `-p -` instead of `-p <argument>`. This handles transcripts of any size without hitting argument size limits.","timestamp":"2025-12-21T19:27:11.844Z"}
{"action":"add","id":"6937cc45-e898-40ed-a378-749a1eea248f","subject":"Episodic memories default changed from false to true","keywords":["episodic","default","enabled","configuration","memory retrieval"],"applies_to":"global","occurred_at":"2025-12-21T19:04:42.107Z","content_hash":"9e7482131e078096","content":"Changed the default value of `episodicEnabled` from `false` to `true` in the codebase. This means episodic memories are now retrieved by default when users submit prompts, unless explicitly disabled via configuration.\n\n**Files modified:**\n- `src/core/types.ts:118` - Updated the Zod schema default\n- `CLAUDE.md` - Updated configuration documentation table\n\nThis is a user preference change to improve the default experience with memory retrieval.","timestamp":"2025-12-21T19:27:11.844Z"}
{"action":"add","id":"3a627813-7e96-473f-8282-bb3385bd3718","subject":"Memory extraction requires comprehensive test coverage for field normalization","keywords":["memory-extractor","testing","field-normalization","vitest","zod-schema"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T18:19:06.772Z","content_hash":"98d78af5c5b581e2","content":"Added test coverage for field name normalization in memory extraction to ensure robustness against Claude's varying response formats. Tests verify:\n\n1. Direct array responses with normalized fields are parsed correctly\n2. Wrapped responses (memories inside objects) are unwrapped and normalized\n3. Mixed field names (some standard, some normalized) work together\n4. Edge cases like undefined values are handled gracefully\n5. Zod validation succeeds after normalization\n\nTests added to describe block starting at line 277. Total test suite now has 228 passing tests with 0 failures.","timestamp":"2025-12-21T19:27:11.845Z"}
{"action":"add","id":"a77790b3-5ca0-4cc5-8980-a6fd962fee40","subject":"UUID validation required for transcript filenames in Claude projects","keywords":["transcript","uuid","filename","validation","claude-project","jsonl"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:27:59.719Z","content_hash":"231602df075eab52","content":"Transcript files in Claude's project directory should only be processed if they have UUID filenames (e.g., `550e8400-e29b-41d4-a716-446655440000.jsonl`). The transcript collector was processing all `.jsonl` files without validating the filename format. Added UUID validation using a regex pattern to ensure only proper transcript files are copied and processed. This prevents processing non-UUID `.jsonl` files that might exist in the transcripts folder.\n\nImplementation: Added `UUID_REGEX` pattern and `isUuidFilename()` helper function at lines 17-20, then updated `findClaudeProjectDir()` and `listSourceTranscripts()` to validate filenames before processing.","timestamp":"2025-12-21T19:27:11.846Z"}
{"action":"add","id":"23669f1a-fc7a-4e12-b67e-35c1d3025f70","subject":"MCP server bundling requires no --external flag in esbuild configuration","keywords":["esbuild","bundling","mcp-server","dependencies","external"],"applies_to":"file:dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json","occurred_at":"2025-12-21T19:13:59.315Z","content_hash":"33c1a45c021a8126","content":"The build script for the MCP server was fixed by removing the `--external` flag from esbuild configuration. This allows all dependencies to be bundled into the server.js file. Without bundling, the server fails in deployed plugin environments where node_modules aren't available. The bundled output is approximately 1.15MB and includes the Orama vector store, Ollama client, and other dependencies needed for embedding generation and memory search.","timestamp":"2025-12-21T19:27:11.846Z"}
{"action":"add","id":"8f98ca62-dfe2-4988-9d93-1a9c30186e59","subject":"Comprehensive test coverage for transcript condenser with 20+ test cases","keywords":["transcript-condenser-tests","unit-tests","edge-cases","test-coverage"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-21T18:30:38.769Z","content_hash":"0fceeef6e27dad32","content":"Created `tests/unit/core/transcript-condenser.test.ts` with comprehensive test coverage including:\n\n**Test categories:**\n1. **Happy path**: Normal transcript condensing with mixed entry types\n2. **Edge cases**: Empty transcripts, single entries, very large transcripts\n3. **Entry type specific**: User messages, assistant responses, tool invocations, results\n4. **Content blocks**: Text blocks, thinking blocks, tool use blocks, results\n5. **Truncation**: Long content handling, token limits\n6. **Error handling**: Invalid JSONL, malformed entries\n7. **Performance**: Large transcript processing\n\n**Key test scenarios:**\n- Parses valid JSONL into proper structure\n- Handles mixed entry types correctly\n- Truncates content appropriately\n- Preserves metadata and timestamps\n- Skips irrelevant content\n- Recovers from parsing errors gracefully\n\nAll tests pass and provide confidence in the condenser's reliability.","timestamp":"2025-12-21T19:27:11.847Z"}
{"action":"add","id":"b617836e-c4ad-4c40-9673-80051ea388d8","subject":"Memory extraction happens in background daemon running every 5 minutes","keywords":["memory extraction","daemon","transcript processing","background job","5 minutes"],"applies_to":"global","occurred_at":"2025-12-21T18:30:50.750Z","content_hash":"eeaae6cbd1440f41","content":"The MCP server includes a background daemon that processes transcripts every 5 minutes. This daemon runs the memory extraction logic from `src/core/memory-extractor.ts` to automatically create episodic memories from transcripts. The daemon is started when the MCP server starts and runs continuously in the background.","timestamp":"2025-12-21T19:27:11.847Z"}
{"action":"add","id":"65efb958-1967-402d-8f30-91a93886b88a","subject":"Two storage format migrations have occurred: Markdown â†’ single JSONL â†’ multi-file JSONL","keywords":["migration","jsonl","format","history","evolution"],"applies_to":"global","occurred_at":"2025-12-21T19:13:54.006Z","content_hash":"c3f7a46078a52a52","content":"Git history shows two major migrations: (1) commit 346e499 migrated from markdown files to a single thinking.jsonl file, (2) a recent commit changed to multi-file format (thinking-000001.jsonl). The old thinking.jsonl (2.8MB with 2,121 lines) is a leftover artifact that should be cleaned up. Current thinking-000001.jsonl has only 155 lines, indicating incomplete migration of all markdown records.","timestamp":"2025-12-21T19:27:11.847Z"}
{"action":"add","id":"e9024b04-8ffa-460d-b0c3-32f3d1a8b352","subject":"Architecture change: Migrate memory storage from individual markdown files to JSONL format","keywords":["storage format","jsonl","migration","memory architecture","episodic","thinking"],"applies_to":"global","occurred_at":"2025-12-21T17:34:47.718Z","content_hash":"293c60546c8c91af","content":"The project is undergoing a significant architectural change to move from individual markdown files in `local-recall/episodic-memory/` and `local-recall/thinking-memory/` directories to a JSONL (JSON Lines) format.\n\n## New Storage Format\n\nTwo JSONL files in the root `local-recall/` folder:\n- `episodic-memories.jsonl` - for episodic memories\n- `thinking-memories.jsonl` - for thinking memories\n\nEach line is a JSON object with:\n- `type` - \"add\" or \"delete\"\n- `memory` - the memory object (id, subject, keywords, applies_to, occurred_at, content_hash, content)\n- `embeddings` - vector embeddings for the memory\n\n## Migration Strategy\n\nA migration check must be implemented to:\n1. Load all existing memories from individual markdown files\n2. Write them to the corresponding JSONL file with \"add\" type entries\n3. Delete the old `episodic-memory/` and `thinking-memory/` directories\n4. Run on startup if the old directories exist but new JSONL files don't\n\n## Components to Update\n\nThis affects:\n- Memory CRUD operations (src/core/memory.ts)\n- Vector store implementation (src/core/vector-store.ts)\n- Thinking memory operations (src/core/thinking-memory.ts)\n- MCP server tools and daemon\n- Hooks that read/write memories\n- All tests that work with memory files","timestamp":"2025-12-21T19:27:11.848Z"}
{"action":"add","id":"c8013292-be0f-404b-bc71-2b3faf2a448a","subject":"Vector store migrated from JSON index to SQLite with embedding storage","keywords":["vector-store","sqlite","migration","embeddings","index","architecture"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:24:20.066Z","content_hash":"5c635e2d2b592bf6","content":"The vector store has been migrated from Orama with JSON index files (`orama-episodic-index.json`, `orama-thinking-index.json`) to SQLite with embedding storage. The new implementation:\n\n- Stores embeddings in SQLite tables with `memory_embeddings` table containing normalized distance values\n- Performs vector similarity search using SQLite's vector search capabilities\n- No longer generates or persists `orama-*.json` index files\n- Uses the same Ollama service for generating embeddings (nomic-embed-text, 768 dimensions)","timestamp":"2025-12-21T19:27:11.848Z"}
{"action":"add","id":"d9d5d0e3-b87d-4f8e-ba1f-3bc3d2ebe670","subject":"Shared gitignore utility extracted to reduce duplication","keywords":["gitignore","utility","shared","refactoring","duplication"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T19:11:11.958Z","content_hash":"814fd0712d972dc7","content":"Created `src/utils/gitignore.ts` with a shared `ensureGitignore(baseDir)` function to eliminate duplicate gitignore creation logic. Previously, both `src/core/memory.ts` and `src/core/index.ts` had identical implementations of gitignore creation. Now they import and call the shared utility function, reducing code duplication and making maintenance easier.","timestamp":"2025-12-21T19:27:11.849Z"}
{"action":"add","id":"44140e9a-1740-4ca4-b3f8-d6887752bbb6","subject":"Vector search scoring: cosine distance converted to 0-1 scale, rounded to 2 decimals with recency tie-breaking","keywords":["scoring","similarity","ranking","vector-search","recency"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:20:08.847Z","content_hash":"d11eb41a5beb25f8","content":"# Vector Search Scoring and Ranking\n\nVector store search results use the following scoring mechanism:\n\n**Similarity Score Calculation**:\n- Raw distance from sqlite-vec is in range 0-2 (cosine distance)\n- Converted to 0-1 similarity scale: `1 - (distance / 2)`\n- Rounded to 2 decimal places: `Math.round(score * 100) / 100`\n- Results in scores like 0.65, 0.81, etc.\n\n**Result Ranking**:\n1. Primary sort: By similarity score (descending, highest first)\n2. Secondary sort (tie-breaking): By `occurred_at` timestamp (newest first)\n- When two results have identical rounded scores, more recent memories appear first\n\nThis ensures:\n- Clean, readable similarity scores\n- Consistent, deterministic ordering\n- Newer memories preferred when relevance is equal","timestamp":"2025-12-21T19:27:11.850Z"}
{"action":"add","id":"b89afba9-cee4-485d-b475-63275c50f8d6","subject":"Tests must be updated when transcript parsing behavior changes","keywords":["testing","transcript parsing","validation tests","test updates"],"applies_to":"file:tests/unit/utils/transcript.test.ts","occurred_at":"2025-12-21T19:22:24.167Z","content_hash":"88272a9e5ea715c9","content":"When updating transcript parsing logic, test expectations must be updated accordingly:\n- Validation tests that expected errors now silently skip invalid messages (better for real transcripts)\n- analyzeForMemories tests must use multi-line content since single-line messages are filtered\n- All tests in transcript.test.ts must reflect the actual parsing behavior","timestamp":"2025-12-21T19:27:11.850Z"}
{"action":"add","id":"059b478f-b5e9-4959-9b6b-f51ee4bc4925","subject":"Removed ts-textrank NPM package in favor of simple text parsing","keywords":["dependencies","simplification","text processing","package.json"],"applies_to":"global","occurred_at":"2025-12-21T18:18:43.074Z","content_hash":"873ea8310b45f9bb","content":"Removed the `ts-textrank` NPM package (^1.0.3) from dependencies as it was replaced with simpler logic. The new implementation:\n- Uses basic string operations (split, indexOf)\n- No external NLP processing\n- Deterministic and testable\n- Reduces dependency complexity\n\nThis is part of a broader effort to simplify the summarization logic while maintaining the same output quality.","timestamp":"2025-12-21T19:27:11.851Z"}
{"action":"add","id":"550ba150-a0ba-4a93-a7a9-751b3a87aa3d","subject":"Current hooks use Orama for vector search instead of better-sqlite3","keywords":["orama","vector-store","hooks","pure-javascript","embedding","search"],"applies_to":"global","occurred_at":"2025-12-21T18:27:23.198Z","content_hash":"7c5f3de3a552fdbc","content":"The project transitioned from using better-sqlite3 (native dependency with bundling issues) to Orama (pure JavaScript vector store). This eliminates process isolation issues and allows hooks to run directly without daemon processes. The UserPromptSubmit hook now handles both episodic and thinking memory search using Orama + Ollama embeddings, configured via environment variables (episodicEnabled, thinkingEnabled, etc.).","timestamp":"2025-12-21T19:27:11.851Z"}
{"action":"add","id":"682db950-03ea-4f62-a135-5fdf6274b7f3","subject":"Memory extraction workflow: condense transcript â†’ pass to Claude â†’ parse memories â†’ store with deduplication","keywords":["memory-extraction-flow","workflow","deduplication","claude-subprocess","content-hash"],"applies_to":"area:memory-extraction","occurred_at":"2025-12-03T09:49:49.357Z","content_hash":"d7558f24177f5a99","content":"# Memory Extraction Workflow\n\n## Process Flow\n1. **Condense**: Use `TranscriptCondenser.condense()` to parse JSONL and extract minimal content\n2. **Extract**: Pass condensed data to Claude via subprocess using memory extraction prompt\n3. **Parse**: Parse Claude's JSON response to get memory objects\n4. **Deduplicate**: Check for duplicates using `occurred_at` + `content_hash`\n5. **Store**: Save unique memories to disk and vector store\n\n## Key Optimization\nThe condenser reduces input token count significantly by:\n- Removing full file contents (keeping only file paths)\n- Skipping large bash outputs\n- Extracting only reasoning from thinking blocks\n- Focusing on semantic content relevant to memory creation\n\n## Related Components\n- `TranscriptCondenser` - Condenses JSONL to minimal format\n- `MemoryExtractor` - Calls Claude subprocess with condensed data\n- `MemoryManager` - Handles deduplication and storage","timestamp":"2025-12-21T19:27:11.852Z"}
{"action":"add","id":"80b4bfce-04af-4df2-b4f9-aeb79b9756c8","subject":"Memory extraction prompt updated to specify extracting from condensed transcript format","keywords":["memory-extraction-prompt","prompt-engineering","condenser-integration","instructions"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-03T09:49:49.357Z","content_hash":"2fe73a9619d21239","content":"# Memory Extraction Prompt Update\n\nUpdated `buildMemoryExtractionPrompt()` in `src/prompts/memory-extraction.ts` to:\n\n1. **Accept condensed data** - Takes pre-parsed, minimal transcript format instead of raw JSONL\n2. **Clear instructions** - Specifies extraction from already-condensed content\n3. **Consistent format** - Maintains expected JSON output structure for memories\n\nThe prompt now receives a much smaller input while maintaining the semantic information needed for accurate memory extraction. This improves:\n- Token efficiency (fewer input tokens)\n- Speed (faster Claude processing)\n- Cost (less API usage)\n- Quality (focused content, less noise)","timestamp":"2025-12-21T19:27:11.852Z"}
{"action":"add","id":"50d50540-58c6-416b-9fca-64a168db496d","subject":"Hook implementation should use HTTP daemon client instead of direct vector store","keywords":["hook architecture","daemon client","http communication","separation of concerns"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-03T10:22:44.117Z","content_hash":"e59653d3f139e394","content":"The UserPromptSubmit hook should not directly instantiate VectorStore, SearchEngine, or ThinkingSearchEngine classes. Instead, it should use the DaemonClient to make HTTP requests to the MCP daemon on localhost:7847. The daemon owns the sqlite-vec connection and handles all vector store operations. This prevents the mutex error that occurs when hooks try to load sqlite-vec concurrently. The hook implementation exists but needs verification that it's actually using HTTP calls and not accidentally loading the vector stores directly.","timestamp":"2025-12-21T19:27:11.852Z"}
{"action":"add","id":"648dd36d-a07f-4925-bfdf-297f4651a70e","subject":"Migration should delete markdown files after JSONL conversion","keywords":["migration","markdown","deletion","cleanup","jsonl"],"applies_to":"global","occurred_at":"2025-12-21T19:13:54.006Z","content_hash":"9ff910ef2730f47d","content":"The migration process currently leaves markdown files in place after converting to JSONL format. Expected behavior: after all markdown memories are successfully migrated to their respective JSONL files (episodic-memory/*.md â†’ episodic-000001.jsonl, thinking-memory/*.md â†’ thinking-000001.jsonl), the markdown files should be deleted entirely. This requires verification that no data is lost before deletion.","timestamp":"2025-12-21T19:27:11.853Z"}
{"action":"add","id":"8775d593-66eb-4d9e-9911-3a9a81e1e2a3","subject":"Session context shows active development on local-recall memory system","keywords":["local-recall","memory-system","episodic","thinking","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T18:24:32.614Z","content_hash":"ae13f5dab194caa2","content":"# Local Recall Development Session\n\nThe project is actively being worked on with recent changes to memory storage and embedding systems. Key recent commits show:\n\n- **Migration to JSONL format**: Memory storage was migrated from markdown to JSONL (`episodic-jsonl-store.ts`, `thinking-jsonl-store.ts`)\n- **Pre-computed embeddings**: Added support for auto-compaction integration\n- **Large memory deletions**: ~80 thinking memory files were deleted (clean-up operation)\n- **Large memory additions**: ~400+ new episodic and thinking memory files created\n\nThe system now supports both episodic and thinking memories with dual vector stores (Orama indices).\n\n## Current Hooks State\n\nThree hooks are modified:\n- `session-start.js` - Loads recent memories on session start\n- `user-prompt-submit.js` - Unified semantic search for both memory types\n- `stop.js` - Currently disabled, memory extraction via MCP daemon\n\nThe Stop hook is disabled because memory extraction is handled asynchronously by the MCP server daemon (runs every 5 minutes).","timestamp":"2025-12-21T19:27:11.853Z"}
{"action":"add","id":"25bc919b-ee34-437d-8a04-243a4e542959","subject":"Improved logging added to debug concurrent database access issues","keywords":["logging","debugging","database access","process identification","performance timing"],"applies_to":"global","occurred_at":"2025-12-03T10:22:44.117Z","content_hash":"7f1f16ba7a1caa2c","content":"Enhanced logging was added to src/utils/database.ts and src/hooks/user-prompt-submit.ts to help debug the mutex error:\n\n1. All log entries now include [PID:xxxx] to identify which process is executing\n2. Lock acquisition logs show attempt count and elapsed time\n3. sqlite-vec load timing shows separate vec load time and total initialization time\n4. Hook error handling includes full stack traces and timing information for better diagnosis\n5. Logger writes to 'recall.log' in the memory directory\n\nThese improvements make it easier to trace concurrent access patterns and identify where the mutex contention occurs.","timestamp":"2025-12-21T19:27:11.854Z"}
{"action":"add","id":"4aaae189-3ece-46b8-a7ca-473d332b03de","subject":"Standard Claude Code marketplace plugin structure at root level","keywords":["marketplace","plugin","structure","claude-code",".claude-plugin","root","plugin.json"],"applies_to":"global","occurred_at":"2025-12-21T19:04:06.127Z","content_hash":"881b024d3a8f7315","content":"Local Recall follows the standard Claude Code marketplace plugin structure (matching code-farm pattern):\n\n- `.claude-plugin/` directory at project root containing:\n  - `plugin.json` - Plugin metadata and configuration\n  - `marketplace.json` - Marketplace definition with name `syntesseraai-local-recall`\n- `local-recall-plugin/` at root level (not nested) containing:\n  - `config/hooks.json` - Hook configurations\n  - `.mcp.json` - MCP server configuration\n  - `scripts/` - Bundled compiled hooks and MCP server output\n\nThe old nested `dev-marketplace/local-recall-plugin/` structure has been replaced with this flatter, standard layout.","timestamp":"2025-12-21T19:27:11.855Z"}
{"action":"add","id":"b7127bf7-7f1e-41ef-8133-3744bc82adaa","subject":"ProcessedLog tracks transcript processing state with content hashing","keywords":["processed log","content hash","deduplication","transcript state"],"applies_to":"file:src/core/processed-log.ts","occurred_at":"2025-12-21T19:27:03.117Z","content_hash":"710c4a4a0efb3e47","content":"The ProcessedLog maintains state for each processed transcript including content hash. When a transcript is reprocessed:\n1. New content hash is computed\n2. If hash differs from stored hash, old memories are deleted\n3. New memories are created from the updated transcript\n4. Hash is updated in the log\n\nThis enables automatic reprocessing when transcripts change while avoiding duplicate memory creation.","timestamp":"2025-12-21T19:27:11.856Z"}
{"action":"add","id":"5d42aff8-2bd7-4089-a0f2-9774243c1042","subject":"Fix AbortError in user-prompt-submit hook from unhandled process timeout","keywords":["abort error","spawn timeout","user-prompt-submit","process handling","child process","error handling"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:21:11.638Z","content_hash":"e495c107fbc646eb","content":"# AbortError in callClaudeForKeywords Function\n\n## Problem\nThe `callClaudeForKeywords` function in the user-prompt-submit hook was throwing an unhandled AbortError when the spawned child process timed out. This occurred because:\n\n1. The `spawn` function was configured with a `timeout` option (line 41)\n2. When Node.js aborts a process due to timeout, it throws an `AbortError`\n3. This abort error wasn't being properly caught, causing an unhandled promise rejection\n4. There were also duplicate `child.on('close', ...)` event handlers that could cause race conditions\n\n## Solution\nApplied the following fixes:\n\n1. **Removed the `timeout` option from `spawn`** - This prevents Node.js from automatically killing the process and throwing AbortError\n2. **Added `safeResolve` wrapper function** - Ensures the promise only resolves once, preventing race conditions between timeout logic and normal process completion\n3. **Removed duplicate `close` handler** - Consolidated the two `child.on('close', ...)` listeners into a single handler to prevent duplicate event handling\n4. **Added early-exit guards** - The `close` handler now checks if the promise has already been resolved before attempting to resolve again\n\n## Impact\nThese changes eliminate the unhandled AbortError and prevent race conditions in child process handling within the hook.","timestamp":"2025-12-21T19:27:11.856Z"}
{"action":"add","id":"615be345-24cf-468b-af2a-da442e4e7e0c","subject":"Transcript parsing architecture: consolidate in transcript.ts, not stop.ts","keywords":["transcript","parsing","architecture","refactoring","stop.ts","transcript.ts"],"applies_to":"global","occurred_at":"2025-12-21T18:26:21.981Z","content_hash":"4f38ff26d2d9d7ec","content":"The transcript parsing should be centralized in `transcript.ts` as a single function `parseTranscriptForMemories(rawContent)` that takes raw JSONL content and returns memory suggestions. The `stop.ts` hook should then simply: 1) read the file, 2) call `parseTranscriptForMemories()`, 3) save the results. This removes duplicate parsing logic and allows the same functionality to be reused elsewhere in the codebase.\n\nThis prevents bugs from emerging when parsing logic changes - there's only one place to update.","timestamp":"2025-12-21T19:27:11.856Z"}
{"action":"add","id":"a5939557-3dfd-43b1-b029-9ef642f4985b","subject":"Vector store concurrency bug in parallel memory creation","keywords":["concurrency-bug","vector-store","race-condition","parallel-operations"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"5d4e95275c039a44","content":"When multiple memories are created in parallel, each calls `getVectorStore()` creating independent instances. Each instance loads, modifies, and persists the index separately, causing race conditions and data loss. The test `should handle vector store sync while creating memories in parallel` exposes this issue. The test was marked as TODO for fixing. A proper fix requires either:\n1. Locking/mutex for vector store operations\n2. Batching concurrent adds before persisting\n3. Using a shared instance with atomic operations","timestamp":"2025-12-21T19:27:11.857Z"}
{"action":"add","id":"d271e9ac-7207-4ee7-a7c7-1a8f8b45a6d9","subject":"Plugin deployment issue: unbundled dependencies cause MCP server failures","keywords":["plugin","mcp-server","deployment","bundling","dependencies","node_modules"],"applies_to":"global","occurred_at":"2025-12-12T10:19:41.481Z","content_hash":"4d2bfd7851475c88","content":"The local-recall plugin deploys to `~/.claude/plugins/cache/local-recall-marketplace/local-recall/[VERSION]/scripts/mcp-server/server.js` but fails when other Claude instances try to run it because node_modules aren't shipped with plugins. The solution is to ensure the build script bundles all dependencies into server.js (remove `--external` flag from esbuild config). When plugin cache becomes outdated, users must uninstall and reinstall the plugin to force a fresh deployment.","timestamp":"2025-12-21T19:27:11.857Z"}
{"action":"add","id":"0cac5627-db2b-4b68-a243-3799181814f4","subject":"Thinking memory extraction implementation exists in codebase","keywords":["thinking extractor","thinking memory","parallel extraction","20 workers","implementation"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T09:49:02.141Z","content_hash":"263b288f3981bebf","content":"ThinkingExtractor class exists (lines 103-310) with capability to extract thinking blocks from transcripts in parallel (20 workers as noted in architecture docs). The implementation was complete but the daemon never called it. The extractor handles extracting thought+output pairs from transcripts and storing them as thinking memories, separate from episodic memory extraction.","timestamp":"2025-12-21T19:27:11.858Z"}
{"action":"add","id":"634e3ba5-79c3-44e5-aba5-27b4dff3b392","subject":"Episodic memory retrieval disabled by default","keywords":["episodic memory","default configuration","memory retrieval","env vars"],"applies_to":"global","occurred_at":"2025-12-21T18:24:27.336Z","content_hash":"d1ffd030246324b0","content":"Changed the default value of `episodicEnabled` from `true` to `false`. This means episodic memory retrieval is now disabled by default in the configuration schema. Users can still enable it by setting `LOCAL_RECALL_EPISODIC_ENABLED=true` environment variable or adding `\"episodicEnabled\": true` to `.local-recall.json`.\n\nConfiguration is defined in `src/core/types.ts:118` using Zod schema with `.default(false)`. Documentation updated in CLAUDE.md configuration table.","timestamp":"2025-12-21T19:27:11.858Z"}
{"action":"add","id":"ad3ed268-d5fc-4a19-aaa1-e387ce31c325","subject":"Thinking blocks have 'thinking' property, not 'text' - was causing content loss","keywords":["thinking","blocks","content","extraction","bug","memory"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:26:21.981Z","content_hash":"0da6d9182aa8ba41","content":"Thinking content blocks have structure `{type: 'thinking', thinking: string}`, NOT `{type: 'thinking', text: string}`. The old code in `stop.ts` was checking `c.text` on thinking blocks, which was undefined, causing all thinking content to be dropped. Use `extractThinkingFromBlocks()` utility which correctly filters for `block.type === 'thinking'` and accesses `block.thinking`.","timestamp":"2025-12-21T19:27:11.859Z"}
{"action":"add","id":"46e06fb9-3b65-4f37-9bb3-540c553b8800","subject":"Memory extractor parseClaudeResponse fails when Claude returns array directly","keywords":["memory-extractor","parseClaudeResponse","zod-validation","claude-response-format","array-wrapping","haiku-model"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:18:46.281Z","content_hash":"151058a89cb4f412","content":"The `parseClaudeResponse` method in memory-extractor.ts expects Claude to return an object with a `memories` key: `{ memories: [...] }`. However, Claude (particularly Haiku) sometimes returns memories as a plain array directly: `[...]`. This causes Zod validation to fail with 'Expected object, received array'. The fix wraps raw arrays in the expected format before validation (lines 174-177). Added comprehensive unit tests in tests/unit/core/memory-extractor.test.ts covering this scenario.","timestamp":"2025-12-21T19:27:11.860Z"}
{"action":"add","id":"d4ae0c9a-aeed-4e82-869f-0db16adba0de","subject":"Environment variables for enabling/disabling memory systems independently","keywords":["configuration","environment variables","feature flags","episodic memory","thinking memory","LOCAL_RECALL_EPISODIC_ENABLED","LOCAL_RECALL_THINKING_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T18:27:36.139Z","content_hash":"ee24d339bcdf6819","content":"Two new environment variables control which memory systems are active:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory search, session-start injection, and extraction\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory search and extraction\n\nThese defaults mean thinking memories are enabled by default while episodic memories are disabled unless explicitly enabled via environment variable. This allows independent control of each memory system.\n\nImplementation details:\n- Config schema updated in `src/core/types.ts:118-119` with `episodicEnabled` and `thinkingEnabled` boolean fields\n- Environment variable parsing added in `src/utils/config.ts:56-61`\n- All hooks (`user-prompt-submit.ts`, `user-prompt-submit-thinking.ts`, `session-start.ts`) updated to import and use `getConfig()` to access these flags\n- MCP server (`src/mcp-server/server.ts`) updated to respect these flags for extraction/processing","timestamp":"2025-12-21T19:27:11.860Z"}
{"action":"add","id":"b01848c5-870a-4686-aeae-898562e25073","subject":"Local Recall plugin directory structure in dev-marketplace","keywords":["plugin","directory","structure","dev-marketplace","local-recall-plugin","skills"],"applies_to":"file:dev-marketplace/local-recall-plugin","occurred_at":"2025-12-21T18:29:21.545Z","content_hash":"57e3c9941980958d","content":"The Local Recall plugin is organized in the `dev-marketplace/local-recall-plugin/` directory with a dedicated skills subdirectory.\n\n- **Skills Directory**: Contains individual skill files for plugin functionality\n- **Plugin Metadata**: Updated to include better descriptions and usage information\n- **Version Management**: Plugin version is tracked and bumped in configuration files\n\nThis structure allows for modular skill management and better discoverability when the plugin is published to marketplaces.","timestamp":"2025-12-21T19:27:11.860Z"}
{"action":"add","id":"aa919661-4bf4-4557-8eea-5c299e683e94","subject":"File-based locking prevents sqlite-vec concurrent initialization errors","keywords":["locking","concurrency-control","file-lock","sqlite-vec","synchronization"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T18:17:33.752Z","content_hash":"e1a504853746dc1b","content":"Implemented a file-based locking mechanism using `openSync()` and `closeSync()` with a `.lock` file at `<dbPath>.lock`. Multiple processes wait for lock acquisition with exponential backoff (starting at 10ms, max 2000ms). Lock files older than 30 seconds are considered stale and forcibly removed to prevent deadlocks. This serializes sqlite-vec extension loading while allowing concurrent database operations once the extension is initialized.","timestamp":"2025-12-21T19:27:11.861Z"}
{"action":"add","id":"24062c0a-373b-4c27-b466-53cc7387dfbb","subject":"Version bumping forces fresh plugin deployment and cache invalidation","keywords":["version","bump","plugin","cache","deployment","0.1.1"],"applies_to":"global","occurred_at":"2025-12-21T18:15:57.311Z","content_hash":"c460a033891285ce","content":"When the bundled plugin server is fixed, bump both `package.json` version and `.claude-plugin/plugin.json` version to force a fresh deployment. Users must uninstall the old plugin version and reinstall to get the updated bundled code from the new cache location. The version number triggers a new cache directory creation (e.g., 0.1.0 â†’ 0.1.1 changes the deployment path).","timestamp":"2025-12-21T19:27:11.861Z"}
{"action":"add","id":"ce66e951-c324-4f7c-998b-14d28630aad1","subject":"fastembed/onnxruntime-node causes same mutex errors as sqlite-vec due to native bindings","keywords":["mutex","fastembed","onnxruntime-node","native-bindings","concurrent-processes","error"],"applies_to":"global","occurred_at":"2025-12-21T18:30:01.408Z","content_hash":"301bef8dcd3a3071","content":"After migration to Orama, mutex errors persisted because `onnxruntime-node` (dependency of `fastembed`) has native bindings that cause the same mutex/lock contention issue as `sqlite-vec` when multiple hook processes load it concurrently. This is not specific to SQLite - any native module with internal mutexes will have this problem. Solution: serialize access to fastembed using file-based locks (proper-lockfile) in `src/core/embedding.ts`.","timestamp":"2025-12-21T19:27:11.862Z"}
{"action":"add","id":"203e93df-24fa-4f01-a02a-2fe5b3ed9210","subject":"Episodic memory is disabled by default in configuration","keywords":["episodic memory","default config","disabled","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T18:22:46.309Z","content_hash":"e0f105ee5e2d7370","content":"The `episodicEnabled` configuration option defaults to `false` (disabled). This is defined in `src/core/types.ts:118` in the Zod schema. Users must explicitly enable episodic memory retrieval by setting `LOCAL_RECALL_EPISODIC_ENABLED=true` environment variable or adding `\"episodicEnabled\": true` to `.local-recall.json` config file. This change was made to turn off episodic memory by default while keeping thinking memories enabled.","timestamp":"2025-12-21T19:27:11.862Z"}
{"action":"add","id":"cc2edf11-c1b7-452e-a6a0-45cb7f8bcf80","subject":"Memory tool descriptions include usage guidance","keywords":["mcp tools","descriptions","documentation","usability"],"applies_to":"global","occurred_at":"2025-12-21T19:23:20.420Z","content_hash":"e4eb5ca71bd9ed4d","content":"MCP tool descriptions for the local-recall plugin were improved to include usage guidance. This enhancement helps users understand when and how to use each tool, improving overall discoverability and usability of the memory system.","timestamp":"2025-12-21T19:27:11.863Z"}
{"action":"add","id":"b1f30b02-7a04-47db-886d-6c71d9733cd7","subject":"Ollama-based embeddings integrate with user-prompt hook for semantic search","keywords":["embedding","ollama","semantic search","user-prompt-submit","keywords"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:28:08.458Z","content_hash":"bae87931211db364","content":"## Integration Pattern\nThe user-prompt-submit hook uses Claude itself (via spawn) to extract keywords from user prompts, which are then used for semantic searching against the memory vector stores.\n\n## Process\n1. User submits a prompt to Claude Code\n2. The hook spawns a child process that calls Claude CLI to generate keywords from the prompt\n3. These keywords are used to search both episodic and thinking memory vectors\n4. Results are filtered by similarity threshold and injected into context\n\n## Key Detail\nThis approach leverages Claude's own language understanding to identify relevant keywords, which improves the quality of semantic searches compared to simple keyword extraction.","timestamp":"2025-12-21T19:27:11.863Z"}
{"action":"add","id":"bf0d63b1-92c9-4ae8-a61b-ad5983274de1","subject":"Migrated from index.json to SQLite with vector embeddings for semantic search","keywords":["sqlite","migration","vector-store","indexing","architecture"],"applies_to":"global","occurred_at":"2025-12-03T09:47:48.632Z","content_hash":"6c34eb744294ee1e","content":"The project has migrated from a JSON-based index (`index.json`) to SQLite with vector embeddings for semantic search. The new architecture uses:\n\n- `src/core/vector-store.ts`: SQLite-backed vector store using `better-sqlite3` with the `sqlite-vec` extension\n- `src/core/embedding.ts`: Generates embeddings using `fastembed` with BGE-small-en-v1.5 model\n- `local-recall/memory.sqlite`: Auto-generated database (gitignored)\n\nData flows into SQLite through three pathways:\n1. On memory creation: `MemoryManager.createMemory()` â†’ `vectorStore.add(memory)`\n2. On MCP server startup: `vectorStore.sync(memories)` loads all disk memories\n3. During transcript processing: Memories are added as they're extracted","timestamp":"2025-12-21T19:27:11.863Z"}
{"action":"add","id":"9ab523f0-c1ae-48af-8d32-60660037e58a","subject":"No existing mutex or concurrency tests in test suite","keywords":["testing","mutex","concurrent","test coverage","missing tests"],"applies_to":"global","occurred_at":"2025-12-21T18:23:08.846Z","content_hash":"e1977b0c89b9e17c","content":"Testing for mutex errors and concurrent process scenarios is not currently covered in the test suite (no files found matching patterns like tests/**/*mutex* or tests/**/*concurrent*). This represents a gap in test coverage for the cross-process synchronization mechanisms.","timestamp":"2025-12-21T19:27:11.864Z"}
{"action":"add","id":"e2554c50-f3e2-4675-9cf5-19029d9d6379","subject":"All tests pass with field normalization in memory extractor","keywords":["testing","memory-extractor","unit-tests","ci-passing","coverage"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T19:17:53.529Z","content_hash":"ea4b12adbfc34156","content":"Total of 228 unit tests pass after implementing field name normalization in memory-extractor.ts. Added comprehensive test coverage including:\n- normalizeMemoryFields() helper testing all field name variations\n- Tests for common alternative field names: description, tags, scope, text\n- Tests for partial field mappings and missing fields\n- All existing tests continue to pass\n\nRun with: npm run test:unit -- --run","timestamp":"2025-12-21T19:27:11.864Z"}
{"action":"add","id":"23a5408c-03fb-45a5-b756-08ff8a41ac5f","subject":"MCP tools should not expose memory update or delete operations","keywords":["mcp-tools","api-design","tools","immutability"],"applies_to":"file:src/mcp-server/tools.ts","occurred_at":"2025-12-21T18:20:31.269Z","content_hash":"66687ce84bbfefcc","content":"## MCP Tool Design\n\n### User Preference\nRemoved `memory_update` and `memory_delete` from MCP tools.\n\n### Rationale\n- Memories are immutable episodic records\n- Users can manually remove memories by deleting files\n- AI assistants should not have delete/update capabilities\n\n### Available Tools (after changes)\n- `memory_create` - Create new memory (idempotent)\n- `memory_get` - Retrieve memory by ID\n- `memory_list` - List all memories with optional filter\n- `memory_search` - Semantic search\n\nThis enforces the immutable memory model at the API level.","timestamp":"2025-12-21T19:27:11.865Z"}
{"action":"add","id":"d2fd4b9c-3ff6-49c7-b1e1-202a5559d953","subject":"Plugin version management across multiple files","keywords":["version bump","package.json","plugin.json","0.1.2","version coordination"],"applies_to":"global","occurred_at":"2025-12-21T18:25:33.738Z","content_hash":"3418e5dfe8860a8f","content":"When bumping the plugin version, updates must be coordinated across two files:\n1. package.json - main package version\n2. dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json - plugin manifest version\n\nKeep both in sync to maintain version consistency across the published npm package and the plugin marketplace distribution.","timestamp":"2025-12-21T19:27:11.865Z"}
{"action":"add","id":"f80c5018-3a24-4ea5-8e7e-f384a985e44e","subject":"Memory extraction uses claude-haiku-4-5 with single-turn constraint and JSON-only output","keywords":["memory extraction","haiku model","json output","single turn","claude cli"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:29:11.578Z","content_hash":"d7a74512a1889a15","content":"Memory extraction via `callClaudeCLI()` now uses:\n- Model: `claude-haiku-4-5` (faster, cheaper than Sonnet)\n- Max turns: 1 (prevents multi-turn conversation)\n- Timeout: 10 minutes (600000ms, increased from 2 minutes)\n- Output: JSON-only format enforced in prompt\n\nThe `claude` CLI is invoked with `--model haiku --max-turns 1`. The prompt explicitly requires returning ONLY valid JSON with no additional text or explanation.","timestamp":"2025-12-21T19:27:11.865Z"}
{"action":"add","id":"11df01d5-ef29-4c6f-a069-4612b30a42df","subject":"Session guarding requires [LOCAL_RECALL_INTERNAL] prefix on memory extraction prompts","keywords":["session guarding","memory extraction","prompt prefix","hook filtering","recursion prevention"],"applies_to":"global","occurred_at":"2025-12-03T09:48:52.171Z","content_hash":"33d333ba2d68e52e","content":"The UserPromptSubmit hook filters prompts by checking for the `[LOCAL_RECALL_INTERNAL]` prefix at line 161 of `src/hooks/user-prompt-submit.ts`. The memory extraction prompt in `src/prompts/memory-extraction.ts` must include this prefix (added at line 62-63) to prevent the MCP daemon's `claude -p` calls from being processed by the hook again, which would cause infinite recursion.","timestamp":"2025-12-21T19:27:11.866Z"}
{"action":"add","id":"540d9b73-29cc-490e-ab84-9668445520b2","subject":"User preference: Multiple Claude instances must be supported without shared daemon constraint","keywords":["user-preference","requirements","multiple-instances","architecture-decision"],"applies_to":"global","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"eedd559e5541e962","content":"The user explicitly does not want a single shared daemon architecture because it would prevent running multiple Claude instances simultaneously. This is a hard constraint on the solution.\n\n**Context**: Initial suggestion of an HTTP daemon within MCP server was rejected because multiple Claude instances would each need their own daemon, which recreates the concurrency problem. Any solution must allow N concurrent Claude instances without architectural conflicts.","timestamp":"2025-12-21T19:27:11.866Z"}
{"action":"add","id":"52bd74d5-4e82-4c43-8a63-d08f45e1d0fe","subject":"Session start hook receives transcript path and must load memories asynchronously","keywords":["sessionstart","hook","transcript","memory loading","async","json input"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:15:33.474Z","content_hash":"ca19644aa575da4c","content":"The SessionStart hook receives JSON input with `session_id`, `transcript_path`, and `cwd` fields. The hook should asynchronously load and inject recent memories. The input is passed via stdin, and output should be sent to stdout in the plugin hook JSON format with `hookSpecificOutput.additionalContext`.","timestamp":"2025-12-21T19:27:11.867Z"}
{"action":"add","id":"3a07d24a-1b28-44b8-995e-27fdb9db77a9","subject":"Episode and thinking memory searches need independent configuration options","keywords":["episodic memory","thinking memory","configuration","search","similarity threshold","token budget"],"applies_to":"global","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"178351708e8bb2bf","content":"The UserPromptSubmit hook should support independent configuration for episodic and thinking memory searches. Each memory type should have its own:\n- Maximum tokens to inject (`episodicMaxTokens` vs `thinkingMaxTokens`)\n- Minimum similarity threshold (`episodicMinSimilarity` vs `thinkingMinSimilarity`)\n- Enable/disable flags (`episodicEnabled` vs `thinkingEnabled`)\n\nThis allows fine-tuning the balance between memory types based on user preferences and token budgets. The configuration should be read from the merged config object and passed to separate search operations for each memory type.","timestamp":"2025-12-21T19:27:11.867Z"}
{"action":"add","id":"397e8a3b-f9e0-4985-893e-b087dd5b9b9d","subject":"Claude Code architecture uses Skills, Settings, CLAUDE.md, and MCP descriptions rather than formal Rules system","keywords":["claude code","architecture","skills","mcp servers","settings configuration","plugin system"],"applies_to":"global","occurred_at":"2025-12-21T18:59:50.981Z","content_hash":"2f06c134f4515a00","content":"Claude Code does not have a formal 'Rules system'. Instead, behavior is controlled through:\n\n1. **Skills** - Autonomously triggered based on user intent and conditions\n2. **Settings** (.claude/settings.json) - Configuration for hooks, MCP servers, and tool behavior\n3. **CLAUDE.md** - Project-specific instructions and conventions\n4. **MCP Server Descriptions** - Tool documentation and availability constraints\n\nThis distributed approach allows flexibility but requires understanding where each behavior is controlled. Skills can check CLAUDE.md at runtime to adapt behavior to project conventions.","timestamp":"2025-12-21T19:27:11.868Z"}
{"action":"add","id":"6ba4cc60-e14e-43f0-bc5b-084a5aa4d6aa","subject":"Memory deduplication strategy - only duplicate prevention, no compaction","keywords":["deduplication","duplicate prevention","memory management","findDuplicate","content-hash","occurred_at"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:19:38.550Z","content_hash":"503ce70cd7b52b3a","content":"The MemoryManager implements duplicate prevention (not compaction):\n\n- Uses `findDuplicate()` method before creating memories\n- Checks for matching `occurred_at` timestamp AND `content_hash`\n- Returns existing memory instead of creating duplicate if found\n- Located in `src/core/memory.ts:52-67`\n\nMemories are NOT compacted or merged over time. There is a `maxMemories` configuration option (default: 1000) in `src/utils/config.ts`, but no active cleanup logic removes old memories when limit is exceeded.","timestamp":"2025-12-21T19:27:11.868Z"}
{"action":"add","id":"4c9850b6-4f29-4907-92da-002a28b906e4","subject":"Session guarding: Memory extraction prompt needs [LOCAL_RECALL_INTERNAL] prefix","keywords":["session guarding","memory extraction","prompt prefix","internal flag","recursion prevention"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:30:03.315Z","content_hash":"25c7e59bf573adba","content":"The memory extraction prompt generated by `buildMemoryExtractionPrompt()` must include the `[LOCAL_RECALL_INTERNAL]` prefix at the start of the returned prompt string. This allows the UserPromptSubmit hook to detect and skip processing these internal extraction requests, preventing recursion when the MCP daemon calls `claude -p` for memory extraction. The guard checks for this prefix at line 161 of `user-prompt-submit.ts`.","timestamp":"2025-12-21T19:27:11.868Z"}
{"action":"add","id":"3e01bbe4-5e75-4962-ae5b-e8a9afbdf52e","subject":"Memory extraction uses Haiku model with 10 minute timeout and JSON-only output","keywords":["memory extraction","haiku model","timeout","json output","claude cli"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-03T09:48:52.171Z","content_hash":"a834ef9d499a5b2a","content":"The `callClaudeCLI` method at line 70-120 was updated to:\n1. Use `--model haiku` (line 79-80) instead of Sonnet for faster, cheaper extraction\n2. Set timeout to 600000ms (10 minutes) at line 40 to handle transcript processing\n3. Add `--max-turns 1` (line 83-84) to ensure single turn responses\n4. The prompt in `src/prompts/memory-extraction.ts` was updated to explicitly require JSON-only output with no markdown formatting or code blocks, preventing formatting errors during JSON parsing","timestamp":"2025-12-21T19:27:11.869Z"}
{"action":"add","id":"8b1b1ce3-9d69-4a02-9040-1bf4efbb46ff","subject":"Migration from better-sqlite3 to Orama for vector search eliminated native module dependency issues","keywords":["orama","better-sqlite3","migration","vector-search","pure-javascript"],"applies_to":"global","occurred_at":"2025-12-21T19:22:18.525Z","content_hash":"b894a57d2bc90ad4","content":"The codebase migrated from using `better-sqlite3` (native module) to Orama (pure JavaScript) for vector storage and semantic search. This eliminates dependency issues in bundled hooks and simplifies deployment. The unified `user-prompt-submit.js` hook now handles both episodic and thinking memory retrieval using Orama, replacing the separate hooks approach. All Orama operations are synchronous and direct, avoiding process isolation and mutex issues.","timestamp":"2025-12-21T19:27:11.869Z"}
{"action":"add","id":"8c5018eb-275d-4e2b-a18e-f3fb51f860a6","subject":"sqlite-vec extension requires 'k = ?' parameter in JOIN queries","keywords":["sqlite-vec","vector-search","query","limit","performance"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:15:15.466Z","content_hash":"78ef7f80eb794713","content":"The sqlite-vec extension requires explicit `k = ?` in the JOIN clause for vector similarity queries. When filtering by scope, the k limit must be applied as a parameter in the SQL. If scope filtering is needed, retrieve more results and filter in JavaScript code after the vector search, since sqlite-vec applies k before WHERE clauses take effect.","timestamp":"2025-12-21T19:27:11.870Z"}
{"action":"add","id":"a1d1535b-2bb8-4492-bbd0-96f7b0f1f41b","subject":"Hook testing reveals missing rake-pos dependency - needs npm install","keywords":["hooks","testing","dependencies","rake-pos","installation"],"applies_to":"global","occurred_at":"2025-12-21T19:20:29.762Z","content_hash":"7c23132d8395cb27","content":"When testing the session-start hook, it failed with exit code 1 due to missing rake-pos dependency. Running `npm install` resolved the issue. The rake-pos package is required for the hooks to function properly and should be installed before hook testing.","timestamp":"2025-12-21T19:27:11.870Z"}
{"action":"add","id":"bffb2ec2-ee5a-4d99-a263-26f3c6032060","subject":"MCP server runs background daemon for asynchronous transcript processing and memory extraction","keywords":["mcp-server","daemon","transcript","async","background","extraction"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"0c601ea9ac9874e9","content":"The MCP server includes a background daemon that runs every 5 minutes to:\n1. Sync transcripts from Claude's cache (`~/.claude/projects/<project>/transcripts/`)\n2. Process transcripts to extract memories using claude -p\n3. Track processed transcripts with content hashes for change detection\n4. Delete and recreate memories when transcripts change\n5. Expose memory tools via MCP protocol\n\nThis asynchronous approach avoids blocking the Stop hook and provides better performance. See `src/mcp-server/server.ts` for implementation.","timestamp":"2025-12-21T19:27:11.871Z"}
{"action":"add","id":"09481b08-076c-470e-8b3d-b5919aafc733","subject":"ToolResultContent.content can be string or array, not just string","keywords":["transcript","tool result","content","type mismatch","array"],"applies_to":"file:src/core/transcript-condenser.ts","occurred_at":"2025-12-21T19:00:39.886Z","content_hash":"cedafe4b124d21bb","content":"TypeScript types define `ToolResultContent.content` as `string`, but Claude's actual transcript format can have `content` as either a string OR an array of content blocks (for multi-part results like images + text).\n\nCode calling `.toLowerCase()` or `.split()` on this field fails when it's an array. Functions that process tool result content must check the type at runtime and handle both cases, not rely on the TypeScript type definition.","timestamp":"2025-12-21T19:27:11.871Z"}
{"action":"add","id":"2fd75772-d978-41a0-82bd-89911d65a76b","subject":"Thinking memories capture Claude's reasoning paired with its output","keywords":["thinking-memory","reasoning","thought-blocks","output","paired-extraction"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"e55328372c818592","content":"Thinking memories store Claude's internal reasoning (from thinking blocks) paired with the corresponding text output. Format includes:\n- `## Thought` section: Claude's reasoning\n- `## Output` section: The actual response that followed\n\nExtraction happens in background daemon. Only text responses are captured (tool-only responses skipped). Provides examples of 'how I thought â†’ what I produced' for future sessions to learn from. Settable configuration: `thinkingEnabled`, `thinkingMaxTokens`, `thinkingMinSimilarity`.","timestamp":"2025-12-21T19:27:11.872Z"}
{"action":"add","id":"1fabe49f-d325-432c-9cd3-abb4d2d0893f","subject":"Memory subject extraction happens inline in transcript.ts using generateSubject utility function","keywords":["memory-extraction","subject-generation","transcript-analysis"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:16:50.918Z","content_hash":"2d7158b8a95d2cdd","content":"The `generateSubject()` function in transcript.ts (lines 105-120) mirrors the logic in summarize.ts for consistency. When extracting thinking and answer memories from transcript analysis, subjects are generated using this function which handles both single-line and multi-line text appropriately.","timestamp":"2025-12-21T19:27:11.872Z"}
{"action":"add","id":"bd07536b-e98e-4c70-bce7-12646c34c5f7","subject":"Synthetic transcript detection utility is available and should be used proactively","keywords":["isSyntheticFile","synthetic detection","transcript filtering","transcript-collector"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:28:15.275Z","content_hash":"05058899f4decbb2","content":"The `isSyntheticFile()` utility function exists in transcript-collector and can identify synthetic transcripts by their file paths. This function should be used BEFORE file operations (copying, processing) rather than after, to avoid wasted I/O and processing on files that will be discarded.\n\nWhen syncing or processing transcripts from any source, check `isSyntheticFile()` before:\n- Copying files\n- Creating memories\n- Processing transcripts\n\nThis prevents cascading cleanup operations and keeps the system efficient.","timestamp":"2025-12-21T19:27:11.873Z"}
{"action":"add","id":"c81d694f-5185-4754-baf9-546034ad6fcd","subject":"Transcript JSONL schema includes user, assistant, system, file-history-snapshot, and queue-operation entry types","keywords":["transcript-schema","jsonl-format","entry-types","typescript-types"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-03T09:49:49.357Z","content_hash":"0e385ccc0c1d459e","content":"# Transcript Schema Types\n\nThe `src/types/transcript-schema.ts` file defines TypeScript interfaces for parsing Claude Code JSONL transcripts.\n\n## Entry Types\n- **UserEntry** - User prompts with text content\n- **AssistantEntry** - Claude responses with content blocks (text, code, thinking)\n- **SystemEntry** - System messages for events/context\n- **FileHistorySnapshotEntry** - File state snapshots\n- **QueueOperationEntry** - Tool queue operations\n\nEach entry includes:\n- `type` - Discriminator for union type\n- `timestamp` - ISO-8601 timestamp\n- `content` - Entry-specific payload\n\nThese types are essential for parsing and condensing transcripts efficiently.","timestamp":"2025-12-21T19:27:11.874Z"}
{"action":"add","id":"fc056201-b4f9-49f7-8408-23816dff4faf","subject":"Project preference: comprehensive memory over filtered memory","keywords":["memory philosophy","user preference","transcript capture"],"applies_to":"global","occurred_at":"2025-12-21T19:01:42.936Z","content_hash":"1529ed1d40fec33f","content":"The user explicitly chose to capture ALL conversation messages rather than selectively filtering for trigger phrases or detected patterns. This indicates a preference for:\n\n- **Comprehensive context preservation** - every message is potentially valuable for future sessions\n- **No artificial filtering** - avoid missing context by eliminating selective patterns\n- **Complete transcript history** - maintain full conversation records for semantic search and analysis\n\nThis is a deliberate architectural choice that simplifies the memory extraction logic and maximizes information retained across sessions.","timestamp":"2025-12-21T19:27:11.875Z"}
{"action":"add","id":"e5fa1c51-9ae1-4343-9fbf-613853c4c3f1","subject":"Session start loads full memory list, not delta - lists all memories then takes 5 most recent","keywords":["session-start","hook","memory-loading","full-reload","occurred_at"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:19:15.418Z","content_hash":"d1a6a707978362a9","content":"On session startup, the system performs a **full reload** rather than a delta load. The session-start hook (lines 57-63) creates a fresh MemoryManager instance, calls listMemories() to get all memories from disk, then sorts by occurred_at descending and takes only the 5 most recent memories for context injection.\n\nThis means every session starts with the same approach regardless of what was loaded in the previous session.","timestamp":"2025-12-21T19:27:11.875Z"}
{"action":"add","id":"d5a2121b-8e1e-400a-a858-436f1b6ebccc","subject":"Concurrency setting for memory extraction increased from 10 to 20","keywords":["concurrency","memory-extractor","parallel","performance"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:14:47.343Z","content_hash":"75b08723d7353f63","content":"The `memory-extractor.ts` has a `concurrency` configuration setting at line 39 that controls how many transcripts are processed in parallel. This was increased from 10 to 20 concurrent extractors for better performance. Located in the options object passed to the extraction function.","timestamp":"2025-12-21T19:27:11.876Z"}
{"action":"add","id":"e1369f89-22d6-4543-af47-7e9e03b66187","subject":"Folder renamed from thinking-memories to thinking-memory for consistency","keywords":["folder","rename","thinking","consistency","structure"],"applies_to":"global","occurred_at":"2025-12-21T19:04:16.673Z","content_hash":"8e3d30284b8d6d91","content":"## Folder Rename\n\nRenamed `local-recall/thinking-memories/` to `local-recall/thinking-memory/` for consistency with episodic memory naming.\n\n### Files Updated\n- `src/core/thinking-memory.ts` - Updated path reference\n- `tests/unit/core/thinking-memory.test.ts` - Updated test paths\n- `docs/thinking-memories.md` - Updated documentation\n- `docs/hooks.md` - Updated cross-references\n- `docs/mcp-server.md` - Updated storage structure docs\n- `CLAUDE.md` - Updated architecture diagram and documentation\n- Multiple episodic memory files that referenced the old path\n\n**Pattern**: The project now follows a singular naming convention: `episodic-memory/` and `thinking-memory/`","timestamp":"2025-12-21T19:27:11.876Z"}
{"action":"add","id":"382546c4-3650-4d39-bba3-b13fc191f75e","subject":"Plugin version is maintained in two locations","keywords":["version bump","plugin.json","package.json","0.1.2","version management"],"applies_to":"global","occurred_at":"2025-12-21T18:27:36.265Z","content_hash":"f08d6fe9dbf16a93","content":"The plugin version must be updated in both:\n1. `package.json` - main project version\n2. `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` - plugin manifest version\n\nBoth files should be kept in sync when bumping versions. Current version: 0.1.2","timestamp":"2025-12-21T19:27:11.877Z"}
{"action":"add","id":"a6626137-6100-4a44-abf1-a3cbdaadadb5","subject":"UUID filename validation for transcript files in Claude project directories","keywords":["transcript","uuid","filename","validation","transcript-collector","claude-project"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:52.265Z","content_hash":"5dcb5931d549b93a","content":"Transcript files in Claude project directories must have UUID filenames (format: `550e8400-e29b-41d4-a716-446655440000.jsonl`). The transcript collector should validate filenames with a UUID regex pattern before processing. This prevents processing of non-transcript `.jsonl` files that may exist in the transcripts folder.\n\n**Implementation details:**\n- Added `UUID_REGEX` pattern: `/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i`\n- Created `isUuidFilename(filename: string)` helper function that strips `.jsonl` extension and validates against pattern\n- Applied validation in three locations:\n  1. `findClaudeProjectDir()` - when checking for transcript files to locate project directory\n  2. `listSourceTranscripts()` - when filtering source transcripts from Claude cache\n  3. `listLocalTranscripts()` - when filtering locally stored transcripts\n\nThis ensures consistency and prevents false positives from non-UUID files in transcript directories.","timestamp":"2025-12-21T19:27:11.877Z"}
{"action":"add","id":"6452c59b-fbfb-4b7c-b23b-58b0081037e4","subject":"Simplified subject generation to use first line for multiline text or first sentence for single-line","keywords":["subject generation","summarize","first line","first sentence","multiline","single-line"],"applies_to":"file:src/utils/summarize.ts","occurred_at":"2025-12-21T18:19:48.301Z","content_hash":"b2716a46f4b2f2ee","content":"Removed `ts-textrank` dependency and implemented simpler logic: for multiline text, extract the first line; for single-line text, extract up to the first period (.) or return the entire text if no period exists. This applies to both `generateSubject()` in summarize.ts and the local `generateSubject()` in transcript.ts.","timestamp":"2025-12-21T19:27:11.878Z"}
{"action":"add","id":"9f086362-5624-4c6b-bb03-45c5b98bb2ad","subject":"Gitignore entries for local-recall folder must include transcripts and processed logs","keywords":["gitignore","transcripts","processed-log","local-recall","auto-generated"],"applies_to":"global","occurred_at":"2025-12-21T19:00:03.739Z","content_hash":"fc0e810bf9960a20","content":"The local-recall folder's `.gitignore` file is auto-generated when the memory system is initialized. It must include entries for:\n\n1. `transcripts/` - Directory containing Claude Code session transcripts\n2. `processed-log.json` - File that tracks which transcripts have been processed to avoid reprocessing\n\nThese entries are defined in two places that must be kept in sync:\n- `src/core/index.ts` - Template for auto-generation\n- `src/core/memory.ts` - Backup template definition\n\nThe existing `.gitignore` file at `local-recall/.gitignore` won't be automatically regenerated, so it must be manually updated when adding new entries.","timestamp":"2025-12-21T19:27:11.878Z"}
{"action":"add","id":"188fdeed-52ff-4def-9a1f-46ca2dcef3f7","subject":"Memory extraction only saves assistant messages, not user messages","keywords":["memory extraction","transcript processing","filtering","assistant messages","user messages"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:10:34.378Z","content_hash":"406123007d8af178","content":"The `analyzeForMemories()` function in transcript.ts now filters out user messages completely. Only assistant messages are processed and saved as memories. This reduces noise and focuses memories on Claude's reasoning and outputs rather than user requests.","timestamp":"2025-12-21T19:27:11.879Z"}
{"action":"add","id":"64933c7e-09be-4569-90eb-92a6075795d3","subject":"Similarity scores are rounded to 2 decimal places for cleaner display","keywords":["similarity score","rounding","decimal places","display","search results"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:25:49.095Z","content_hash":"488822d46baec693","content":"Search result similarity scores are rounded to 2 decimal places using `Math.round((1 - row.distance / 2) * 100) / 100`. This produces clean scores like 0.65 instead of 0.65234... for better readability and reporting in search results.","timestamp":"2025-12-21T19:27:11.879Z"}
{"action":"add","id":"6968cf0f-718c-491a-942f-5ac168313c51","subject":"SQLite concurrent access race condition between episodic and thinking hooks","keywords":["sqlite","race-condition","mutex","hooks","concurrent-access","thinking-vector-store"],"applies_to":"global","occurred_at":"2025-12-21T18:29:45.308Z","content_hash":"d218176e4eea5214","content":"Both `user-prompt-submit.js` and `user-prompt-submit-thinking.js` hooks run as separate processes and attempt to access the same `memory.sqlite` database simultaneously. This creates a race condition where the `sqlite-vec` extension's native C++ mutex fails with error: `libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument`. The hooks need to either use JSON-based indexes (like Orama) instead of SQLite, or implement cross-process locking mechanisms.","timestamp":"2025-12-21T19:27:11.880Z"}
{"action":"add","id":"6f78121b-494b-4555-aa78-0161b15c839b","subject":"User preference: Multiple Claude instances must be able to run simultaneously without shared daemon conflicts","keywords":["architecture","claude","instances","concurrency","user preference"],"applies_to":"global","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"961c7e9b903c14f0","content":"The user requires that multiple Claude Code instances can run concurrently. This rules out daemon approaches that would conflict on ports or file locks. Instead, embedding services should be externalized (Ollama) or hooks should use text-based search only. Each Claude instance can have its own MCP server, but shared embedding infrastructure (like Ollama) prevents the ONNX concurrency problem entirely.","timestamp":"2025-12-21T19:27:11.880Z"}
{"action":"add","id":"100c2024-3899-410d-9d25-796d0279a93f","subject":"Mutex lock failed error in UserPromptSubmit hook is caused by direct sqlite-vec loading","keywords":["mutex error","sqlite-vec","hook","file locking","concurrent access"],"applies_to":"area:hooks","occurred_at":"2025-12-03T10:22:44.117Z","content_hash":"6d2ff7063fe1d0bc","content":"The 'libc++abi: terminating due to uncaught exception of type std::__1::system_error: mutex lock failed: Invalid argument' error in UserPromptSubmit hook occurs when the hook directly instantiates SearchEngine and ThinkingSearchEngine, which attempt to load the sqlite-vec native extension. This causes mutex contention when multiple processes try to load sqlite-vec concurrently. The fix is to use the HTTP daemon client instead of direct vector store instantiation, which is already implemented via DaemonClient. The hook should not instantiate VectorStore or SearchEngine directly - it should only call HTTP endpoints on the daemon.","timestamp":"2025-12-21T19:27:11.881Z"}
{"action":"add","id":"6456bbd6-37a2-4e89-94f8-e58d4c4bc2fb","subject":"Backward compatibility maintained in transcript parsing","keywords":["backward compatibility","transcript","format migration","parsing"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:28:38.979Z","content_hash":"602970627f5761ee","content":"Updated transcript parsing to support both message formats:\n\n1. **Old format** (from tests/mocks): `content` as string, `role` field\n2. **New format** (from Claude Code): `content` as array, `type` field\n\nThe parser attempts to normalize both to internal format during `parseTranscript`. This prevents breaking existing code while supporting the actual Claude Code transcript structure.\n\nInvalid messages (missing required fields) are silently skipped rather than throwing errors, which is more robust for processing real transcripts.","timestamp":"2025-12-21T19:27:11.881Z"}
{"action":"add","id":"d473b648-dcfb-468f-99b5-e62b063dbe9c","subject":"Each Claude Code instance spawns its own MCP server process","keywords":["claude code","mcp","process","stdio","transport","isolation"],"applies_to":"global","occurred_at":"2025-12-21T18:31:15.659Z","content_hash":"64a04aa4ca373c37","content":"Claude Code instances use stdio transport for MCP communication and each instance spawns its own independent MCP server process. This means:\n\n- Different projects have separate MCP servers\n- Same project opened in multiple Claude Code windows may have multiple MCP servers writing to the same recall.log\n- Each server instance independently runs transcript collection and vector syncing\n\nThis can lead to duplicate log entries if multiple servers are active for the same project directory.","timestamp":"2025-12-21T19:27:11.882Z"}
{"action":"add","id":"efe61999-0ef5-4944-905d-b4e9eab73af6","subject":"Vector search uses Orama with Ollama embeddings (nomic-embed-text model, 768 dimensions)","keywords":["vector store","orama","ollama","embeddings","semantic search"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"aa5a1f2b176239d6","content":"Local Recall uses Orama (pure JavaScript vector store) with Ollama for embedding generation. The nomic-embed-text model produces 768-dimensional embeddings. Index files are stored as JSON (orama-episodic-index.json, orama-thinking-index.json) and are gitignored as auto-generated. Cosine distance is used for similarity scoring (0.0-1.0, rounded to 2 decimals). Results are ranked by score descending with recency tie-breaking.","timestamp":"2025-12-21T19:27:11.882Z"}
{"action":"add","id":"8068b2f7-a4d0-4716-adb3-fe3237921af7","subject":"Comprehensive tests verify transcript condenser handles all entry types and edge cases","keywords":["tests","transcript condenser","unit tests","edge cases"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-21T19:25:46.514Z","content_hash":"6fccc3af95eeb259","content":"Created comprehensive test suite (`tests/unit/core/transcript-condenser.test.ts`) covering:\n\n1. **All entry types** - UserPrompt, AssistantResponse, ToolUse, ToolResult, FileHistory, QueueOperation\n2. **Content extraction** - Verifies correct content is extracted from each type\n3. **Edge cases** - Handles empty content, missing fields, malformed data\n4. **Tool operations** - Special handling for tool results (skips stderr/full output when possible)\n5. **Result formatting** - Verifies condensed format is correct\n\nAll tests pass (122 tests total in the test suite), confirming the condenser works correctly across various transcript scenarios.","timestamp":"2025-12-21T19:27:11.882Z"}
{"action":"add","id":"8045f05e-5b86-47b5-8f3e-fa58ca4b9eb3","subject":"Gitignore file should always be written, not just created if missing","keywords":["gitignore","sqlite","auto-generated","initialization"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:17:30.301Z","content_hash":"e31c113eea73cf09","content":"The `ensureGitignore()` function only created the gitignore file if it didn't exist. Since it's auto-generated and should always reflect the current patterns, it should always write the file. This ensures new SQLite patterns are added for users with existing memory directories.","timestamp":"2025-12-21T19:27:11.883Z"}
{"action":"add","id":"ebf6f575-afb6-4df2-943c-37c94a89df7e","subject":"Session-start hook is safe because it uses only MemoryManager (file operations) without embeddings","keywords":["session-start","hook","memory-manager","thread-safe","file-based"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-03T11:35:39.170Z","content_hash":"81032af2c9a1e8dd","content":"The session-start hook only uses MemoryManager for file-based memory retrieval - no embedding model initialization. This makes it safe to run concurrently across multiple Claude instances. Only user-prompt-submit and search operations trigger ONNX loading.","timestamp":"2025-12-21T19:27:11.883Z"}
{"action":"add","id":"d7d0894d-3f23-4919-963d-64bdcdc4889f","subject":"Vector store singleton needs reset function for test isolation","keywords":["vector-store","singleton","testing","test-isolation","reset"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:17:02.145Z","content_hash":"b4570e2f7cb9fb44","content":"Added resetVectorStore() function to allow tests to reset the singleton instance between test runs. Without this, the in-memory SQLite database persists across tests causing test failures. Export the reset function for test utilities to call in beforeEach/afterEach hooks.","timestamp":"2025-12-21T19:27:11.884Z"}
{"action":"add","id":"fcef8bf8-b407-42fa-9762-e072cfa11e9f","subject":"Memory deduplication prevents duplicate memories but there is no compaction or consolidation","keywords":["deduplication","duplicate prevention","compaction","memory management","content-hash","occurred_at"],"applies_to":"global","occurred_at":"2025-12-21T19:18:04.336Z","content_hash":"90958ac7f576b560","content":"The `MemoryManager` in `src/core/memory.ts` implements basic duplicate prevention:\n\n- Before creating a memory, it checks if one with the same `occurred_at` timestamp AND `content_hash` already exists\n- If a duplicate is found, it returns the existing memory instead of creating a new one\n- This prevents accidental duplication but does NOT compact or consolidate memories\n- There is a `maxMemories` configuration option but it appears to be for limits only, not active pruning\n- Compaction/merging of similar memories is not implemented\n\nThis means memories accumulate over time with only duplicate filtering at creation.","timestamp":"2025-12-21T19:27:11.885Z"}
{"action":"add","id":"dbf40d46-f32c-485a-9f58-28e6231bdfb5","subject":"Comprehensive test coverage for transcript condenser with 20+ test cases","keywords":["transcript-condenser-tests","unit-tests","edge-cases","JSONL-parsing","test-coverage"],"applies_to":"file:tests/unit/core/transcript-condenser.test.ts","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"a8a1f4b7fe4c19df","content":"Created `tests/unit/core/transcript-condenser.test.ts` with comprehensive test coverage (20+ test cases) covering:\n\n**Basic Functionality:**\n- Empty transcript handling\n- User and assistant entry parsing\n- Thinking block extraction\n- Tool invocation and result condensing\n\n**Content Filtering:**\n- Removal of metadata while preserving message content\n- Truncation of overly long outputs\n- Proper handling of tool parameters\n\n**Edge Cases:**\n- Malformed JSONL entries\n- Missing optional fields\n- Very large transcripts\n- Special characters and encoding\n\n**Integration:**\n- Proper type preservation\n- Timestamp formatting\n- Array length validation\n\nAll tests pass and validate the condenser handles real-world transcript data correctly.","timestamp":"2025-12-21T19:27:11.885Z"}
{"action":"add","id":"0c1ec74d-bcb4-4845-bacb-3efa23c3b95c","subject":"Claude Code plugins fetch from Git - distribution files must be committed and tracked","keywords":["claude-code","plugin","git","gitignore","distribution","cache","mcp"],"applies_to":"global","occurred_at":"2025-12-21T19:02:32.602Z","content_hash":"d7a8827c65f3d983","content":"Claude Code fetches plugins from Git repositories (e.g., GitHub) and caches them locally. Only files that are committed to Git make it into the plugin distribution. Files in .gitignore are excluded from the plugin cache, even if they exist locally.\n\nThis is critical for local-recall: the `dist/` directory must be committed to Git for plugins to work correctly. The .gitignore excludes index files and log files, but the compiled distribution must be tracked.","timestamp":"2025-12-21T19:27:11.886Z"}
{"action":"add","id":"52960c8c-b69d-4bf0-9e0c-ca22dd202b22","subject":"TypeScript regex capture group safety: use optional chaining for defensive access","keywords":["typescript","regex","capture-group","optional-chaining","defensive-programming","undefined-check"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:58:55.753Z","content_hash":"495957ff9d635fbd","content":"When accessing regex capture groups in TypeScript, always use optional chaining (`match?.[1]`) rather than direct indexing (`match[1]`). Even when the regex match is truthy, capture groups can be undefined if the group didn't participate in the match. This was discovered when fixing a TS2532 error on line 211 of memory-extractor.ts where `codeBlockMatch[1]` was accessed without checking if the capture group actually matched. The fix uses `codeBlockMatch?.[1]?.trim()` to safely handle both the match being null/undefined and the capture group being undefined.","timestamp":"2025-12-21T19:27:11.886Z"}
{"action":"add","id":"e43b4268-6b72-45cb-8b38-5927d451a961","subject":"Local Recall memory system uses separate index.json and individual markdown files","keywords":["memory storage","index.json","markdown files","local-recall directory"],"applies_to":"global","occurred_at":"2025-12-21T19:01:42.936Z","content_hash":"53cec57d87b7b11a","content":"The Local Recall memory system uses a dual-file structure:\n\n1. **index.json** - Central metadata file at `/local-recall/index.json` that likely tracks all memories\n2. **Individual markdown files** - Stored in `/local-recall/memories/` with UUID filenames (e.g., `d451a49a-f08e-480f-b7cd-27373f49ced9.md`)\n\nMemory files contain conversation content with message role prefixes (`**user**:` and `**assistant**:`). The system appears designed for semantic search and long-term retention of session transcripts.","timestamp":"2025-12-21T19:27:11.887Z"}
{"action":"add","id":"d8861a1c-ca4d-40f0-8897-a0a3bdf92b63","subject":"Current hooks architecture uses Orama pure JavaScript instead of SQLite","keywords":["architecture","hooks","orama","vector-store","embeddings","no-native-modules"],"applies_to":"global","occurred_at":"2025-12-21T19:21:32.710Z","content_hash":"fb4cb977b8d56e74","content":"The hooks system has been refactored to use Orama (pure JavaScript) for vector storage and search instead of better-sqlite3. This provides several benefits:\n\n- No native module dependencies that can't be bundled\n- Works seamlessly in hook processes without mutex/process isolation issues\n- Embeddings still generated via Ollama, but storage/search is pure JavaScript\n- Single `user-prompt-submit.js` hook handles both episodic and thinking memories\n\nThis is important when updating plugin code or adding new hooks - never introduce native module dependencies into hook files as they execute in ephemeral processes.","timestamp":"2025-12-21T19:27:11.887Z"}
{"action":"add","id":"9e6eb1d2-a60b-404a-a1a7-e86040868038","subject":"Memory extraction uses internal prompt token instead of text matching","keywords":["extraction process","prompt token","recursion prevention","testability"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:24:15.046Z","content_hash":"0e635436c5b9578b","content":"Instead of checking for specific text like 'Extract keywords from this text' to identify internal extraction prompts, use a dedicated `[LOCAL_RECALL_INTERNAL]` token at the start of the prompt. This approach is more reliable, easier to test (users can test with prompts containing extraction keywords), and makes the intent explicit.","timestamp":"2025-12-21T19:27:11.887Z"}
{"action":"add","id":"d932c238-c252-4a73-8694-352af002e850","subject":"Hooks return empty stdout in user environments despite working when tested manually","keywords":["hooks","debugging","stdout","plugin","empty response","troubleshooting"],"applies_to":"global","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"bc6bacd339256683","content":"Discovered that hooks (SessionStart, UserPromptSubmit) execute but return empty stdout in Claude Code transcripts, even though manual testing shows they work correctly and produce proper output. The hooks.json configuration appears correct, but users report empty responses. This suggests either:\n1. Execution context differences between manual testing and Claude Code plugin environment\n2. Possible timing issues or async/await problems in hook execution\n3. Plugin sandboxing or output capture differences\n\nNext steps: Add detailed logging to hooks to diagnose where output is lost, investigate if plugin environment sets different NODE_ENV or handles stdout differently, check if promise rejections are being silently caught.","timestamp":"2025-12-21T19:27:11.888Z"}
{"action":"add","id":"a3410270-e272-4845-bcfe-9d145b3e3939","subject":"IndexManager and index.json are redundant after SQLite vector migration","keywords":["indexmanager","redundant","sqlite","vector-store","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T19:15:15.466Z","content_hash":"540a5cb13ce15f67","content":"The IndexManager class and index.json file were used for keyword lookups before SQLite migration. With vector embeddings stored in SQLite (memory.sqlite), this is now redundant. Removed: IndexManager class, index.ts file, index_rebuild MCP tool, and all related imports. Vector search now uses VectorStore.sync() instead of IndexManager.refreshIndex().","timestamp":"2025-12-21T19:27:11.888Z"}
{"action":"add","id":"71941627-acab-467c-8018-19666e82bc2d","subject":"Child process handling in Node.js spawn requires proper error catching for abort signals","keywords":["spawn","child process","abort error","timeout","error handling","promise rejection"],"applies_to":"global","occurred_at":"2025-12-21T19:20:27.934Z","content_hash":"ce7dadeab21e1ea3","content":"When using Node.js `spawn()` with a `timeout` option, the process is killed with an AbortError. This error must be explicitly caught in the `error` event handler or wrapped in a timeout handler. Simply having a `close` event handler is not sufficient, as the AbortError will propagate as an unhandled promise rejection.\n\n**Best practice**: Use a custom timeout wrapper with proper promise resolution guards rather than relying on the built-in spawn timeout option, as this provides better control over error handling and prevents race conditions.","timestamp":"2025-12-21T19:27:11.888Z"}
{"action":"add","id":"06759e76-c919-4552-9223-e363bda86642","subject":"Memory system redesigned to be immutable episodic log with content-based deduplication","keywords":["memory","idempotency","deduplication","architecture","episodic"],"applies_to":"global","occurred_at":"2025-12-21T19:17:28.905Z","content_hash":"6f6a9c92768134df","content":"# Memory System Architecture Change\n\nShifted from mutable knowledge base to immutable episodic memory log, similar to how human memory works.\n\n## Key Design Changes\n\n1. **Immutability**: Memories cannot be updated or deleted programmatically. Only manual user deletion is allowed.\n\n2. **Deduplication Strategy**: Each memory has three timestamps/hashes:\n   - `occurred_at` - When the conversation/event happened (from transcript)\n   - `created_at` - When the memory file was written\n   - `content_hash` - SHA-256 hash prefix (16 chars) of memory content\n   \n   Deduplication key is `occurred_at + content_hash`. If a memory with the same timestamp and content hash already exists, it's skipped rather than recreated.\n\n3. **Processing Scope**: Changed from processing only recent messages (30-second window) to processing entire transcript history. This allows full context capture while deduplication prevents duplicates when the same transcript is re-processed.\n\n## Implementation Details\n\n- `computeContentHash()` function uses SHA-256 truncated to 16 characters\n- `findDuplicate()` method checks for existing memory by occurred_at + content_hash\n- Removed mutable operations: no `updateMemory()` or deleteMemory operations from MCP tools\n- Stop hook now processes entire transcript instead of using 30-second time window","timestamp":"2025-12-21T19:27:11.888Z"}
{"action":"add","id":"af44f6d4-64c3-4b99-93c9-b089a9eb1a62","subject":"Removed HTTP daemon layer - hooks now call vector stores directly","keywords":["architecture","refactor","daemon","http-server","direct-access","hooks"],"applies_to":"global","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"77bf527a2c9d9970","content":"The architecture previously had hooks making HTTP requests to a background daemon (MCP server) which created SearchEngine/ThinkingSearchEngine instances. This added complexity and latency.\n\nNew approach: Hooks now directly import and use VectorStore/ThinkingVectorStore with file-based locking. Benefits:\n- Eliminates HTTP roundtrips\n- Simpler code path (fewer moving parts)\n- File-based locks work across processes\n- Removed: `daemon-client.ts` and `http-server.ts`","timestamp":"2025-12-21T19:27:11.889Z"}
{"action":"add","id":"85c6157c-7805-4e17-b7e9-3c35115005b5","subject":"IndexManager and index.json are redundant with SQLite vector store","keywords":["indexmanager","redundant","sqlite","vector-store","refactor"],"applies_to":"global","occurred_at":"2025-12-21T18:17:30.301Z","content_hash":"3130596badf6b671","content":"The old IndexManager class and index.json file became redundant after migrating to SQLite with vector embeddings. IndexManager provided keyword-based lookups which SQLite now handles directly. The index.json was used for caching keyword searches but SQLite index files are more efficient. Removed: src/core/index.ts, src/core/index.test.ts, and removed IndexManager from exports and all usage sites (mcp-server/tools.ts, hooks/stop.ts, core/memory-extractor.ts).","timestamp":"2025-12-21T19:27:11.889Z"}
{"action":"add","id":"cbe23b78-c03b-4d7f-b9af-3089198222d2","subject":"Session-start hook is safe because it avoids embeddings - only uses file-based MemoryManager","keywords":["session-start","hook","safety","no-embeddings","file-based"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:19:54.289Z","content_hash":"940ab6418b0ae565","content":"The `session-start.ts` hook is concurrent-safe because it only uses `MemoryManager` for file-based reads. It doesn't load the embedding model and doesn't instantiate search engines. This is why session-start can run without mutex errors even with multiple Claude instances.\n\n**Implication**: Any hook that avoids loading embeddings can support multiple concurrent instances. The danger is only in hooks that trigger model loading.","timestamp":"2025-12-21T19:27:11.889Z"}
{"action":"add","id":"ca80a071-9bea-40ee-bcf8-61f8447c2369","subject":"Session-start hook is safe for concurrent execution (file-based only)","keywords":["session-start","hook","safe","concurrent","memory-manager","file-based"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:24:57.085Z","content_hash":"03f8937a641d9721","content":"The session-start hook only uses MemoryManager (pure file-based operations with no embeddings), so it's safe to run in multiple concurrent Claude instances without mutex issues. Only user-prompt-submit hook has the ONNX concurrency problem.","timestamp":"2025-12-21T19:27:11.890Z"}
{"action":"add","id":"6a4de5af-8d71-47f2-9459-bb79c699632f","subject":"Session-start hook receives transcript and cwd in JSON input","keywords":["session-start","hook input","json format","transcript_path","cwd","working directory"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:26:19.771Z","content_hash":"ecd6f37c8166ea45","content":"The session-start hook receives JSON input with `session_id`, `transcript_path`, and `cwd` fields. These provide the transcript location and working directory context needed to read memories and load relevant project information.","timestamp":"2025-12-21T19:27:11.891Z"}
{"action":"add","id":"910583bd-7858-4c0e-920c-c579f94e3f54","subject":"Claude Code transcript format has content as array of blocks with thinking extraction","keywords":["transcript","thinking","content blocks","parsing","claude code format"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:29:39.576Z","content_hash":"34d991f9e8c5960c","content":"Claude Code transcripts have a different structure than initially expected:\n\n- `content` is an **array of content blocks**, not a string\n- Thinking blocks have `type: \"thinking\"` with a `thinking` field\n- Text blocks have `type: \"text\"` with a `text` field\n- Tool blocks have `type: \"tool_use\"` or `type: \"tool_result\"`\n\nThe `parseTranscript` function now extracts thinking from content blocks during parsing and normalizes it into a `thinking` field on the normalized message object. This allows the rest of the codebase to work with the same structure regardless of whether thinking is present.\n\nImplementation uses backward-compatible detection:\n1. First tries new format (check for `content` array with blocks)\n2. Falls back to legacy format (check for `content` string)\n3. Silently skips invalid messages instead of throwing errors\n\nSee `src/core/types.ts` for `RawTranscriptMessage` and content block types.","timestamp":"2025-12-21T19:27:11.891Z"}
{"action":"add","id":"019654ab-e6b2-454f-b8d5-8daa008bd6c6","subject":"User-prompt-submit hook has unhandled AbortError from spawn timeout","keywords":["spawn","timeout","aborterror","child process","user-prompt-submit","bug"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:27:26.099Z","content_hash":"976f3562f74c0016","content":"The `callClaudeForKeywords` function in user-prompt-submit.ts had an unhandled AbortError caused by Node.js's built-in `spawn` timeout option. When the timeout fires, Node.js aborts the child process and throws an AbortError that wasn't being caught, causing unhandled promise rejections. The timeout option should be removed from spawn calls and instead handled with a manual timeout wrapper using Promise.race() with setTimeout.","timestamp":"2025-12-21T19:27:11.892Z"}
{"action":"add","id":"159ed3dc-8024-4d97-9b19-ade149b443aa","subject":"Transcript discovery logging at DEBUG level indicates old MCP process running","keywords":["logging","transcript discovery","debug level","duplicate entries","old process"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:26:25.094Z","content_hash":"57524e0e01258c4f","content":"When examining recall.log, transcript discovery logs at DEBUG level with older messages indicate an old MCP server process is still running alongside the newer version. This was detected by:\n\n1. Duplicate log entries appearing in recall.log\n2. Log messages showing DEBUG level instead of INFO level\n3. Mismatch between source code (INFO logs) and actual output (DEBUG logs)\n\nKilling the old process or restarting Claude Code instances resolves this. Check `local-recall/recall.log` for duplicate patterns to detect this issue.","timestamp":"2025-12-21T19:27:11.892Z"}
{"action":"add","id":"63027bf1-852b-4abc-a0d1-138ae453e612","subject":"Vector search now sorts by similarity score rounded to 2 decimals, with recency as tiebreaker","keywords":["search","scoring","ranking","similarity","occurred_at","tiebreaker"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:26:56.199Z","content_hash":"446b201d35e4cd65","content":"Search results in `vector-store.ts:258-268` now use:\n\n1. **Rounded Similarity Scores**: Scores are rounded to 2 decimal places using `Math.round((1 - distance / 2) * 100) / 100`, producing values like 0.65 instead of 0.6534\n\n2. **Recency Tiebreaker**: When multiple results have the same rounded score, they are sorted by `occurred_at` descending (newest first)\n\n3. **Score Range**: 0.0 (no match) to 1.0 (perfect match) based on cosine distance\n\nThis provides cleaner output and ensures newer memories are preferred when equally relevant.","timestamp":"2025-12-21T19:27:11.893Z"}
{"action":"add","id":"578cdeea-11cf-42b2-a58f-bad4837746f9","subject":"TypeScript regex capture group safety check with optional chaining","keywords":["typescript","regex","optional chaining","capture groups","undefined check"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:02:42.674Z","content_hash":"c629aea32bb59d15","content":"When using regex capture groups in TypeScript, checking if the match exists is not sufficient to access capture groups safely. Even when `codeBlockMatch` is truthy, `codeBlockMatch[1]` can be undefined if the capture group didn't match.\n\nFix: Use optional chaining `codeBlockMatch?.[1]` to safely access capture groups. This handles both cases:\n- Match doesn't exist (optional chaining returns undefined)\n- Match exists but capture group is undefined (optional chaining returns undefined)\n\nLocation: src/core/memory-extractor.ts:211 in `stripMarkdownCodeBlocks()` method","timestamp":"2025-12-21T19:27:11.893Z"}
{"action":"add","id":"8d3e99e7-d043-49dc-82fe-74562c2f3325","subject":"Recall.log location and format for debugging hook execution","keywords":["recall.log","debugging","logs","hook execution","timestamps"],"applies_to":"global","occurred_at":"2025-12-21T17:19:22.943Z","content_hash":"7d99f610f678f794","content":"Debug logs are written to `local-recall/recall.log` with ISO-8601 timestamps. This file shows detailed execution information about hook firing, memory creation, and search operations. Useful for verifying that hooks are actually running and debugging issues.","timestamp":"2025-12-21T19:27:11.894Z"}
{"action":"add","id":"9ef740c1-2f5e-4492-b190-61ceb3736ca8","subject":"Local Recall uses JSONL format for episodic and thinking memory storage","keywords":["memory-storage","jsonl","episodic","thinking","migration","multi-file"],"applies_to":"global","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"e0d97d8713855618","content":"Local Recall has migrated from individual markdown memory files to JSONL (JSON Lines) format for efficient storage. The system now:\n\n- Stores episodic memories in `episodic-XXXXXX.jsonl` files with 6-digit padding\n- Stores thinking memories in `thinking-XXXXXX.jsonl` files with 6-digit padding\n- Uses multi-file support to organize memories across multiple JSONL files\n- Individual markdown files in `episodic-memory/` and `thinking-memory/` directories contain extracted and deduplicated memories\n\nThis migration improves performance and scalability while maintaining human-readable markdown files for version control.","timestamp":"2025-12-21T19:27:11.895Z"}
{"action":"add","id":"a3fc5baf-8766-419e-862f-4176c14a97bb","subject":"UserPromptSubmit hook uses unified search combining episodic and thinking memories","keywords":["user-prompt-submit","hook-architecture","memory-search","unified-retrieval"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:17:33.752Z","content_hash":"ede4b5ac3a5aa8bc","content":"The UserPromptSubmit hook performs unified semantic search combining both episodic and thinking memories based on configuration flags. It searches episodic memories if `episodicEnabled` is true and thinking memories if `thinkingEnabled` is true, filtering results by similarity threshold and token budget. Results from both sources are combined and injected into Claude's context as 'Previous Thoughts' with similarity scores.","timestamp":"2025-12-21T19:27:11.895Z"}
{"action":"add","id":"f791a2b8-b365-4797-9f46-6c3b663e0616","subject":"IndexManager and MemoryManager both create .gitignore - coordination needed","keywords":["indexmanager","memory-manager","initialization","duplicate-logic"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:17:51.449Z","content_hash":"961b2e60f62012b5","content":"Both `IndexManager` and `MemoryManager` were responsible for creating `.gitignore`, leading to inconsistent initialization. The `.gitignore` should be created by whichever manager is instantiated first. In the current fix, `MemoryManager` is responsible for creating it since it's initialized earlier and represents the core memory functionality. The `IndexManager` should not duplicate this logic.","timestamp":"2025-12-21T19:27:11.896Z"}
{"action":"add","id":"3581ada9-9754-435e-9148-9683e19bd8ba","subject":"Project uses native Node.js fs promises for async file operations","keywords":["filesystem","async","node:fs","promises","typescript"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:27:59.719Z","content_hash":"19c54527e3b90a16","content":"The transcript-collector uses `import { promises as fs } from 'node:fs'` for asynchronous file system operations. This is the standard modern Node.js approach for handling files in TypeScript/async code. When working with file operations in this codebase, always use the fs.promises API rather than callbacks or synchronous operations.","timestamp":"2025-12-21T19:27:11.897Z"}
{"action":"add","id":"490eee7a-b5e8-46e9-8b2a-8bfb7b96d511","subject":"No summarization or filtering of memory content","keywords":["memory extraction","summarization","filtering","raw content","deduplication"],"applies_to":"global","occurred_at":"2025-12-21T19:10:34.378Z","content_hash":"f49c4317ac6035de","content":"Memories are stored as raw content without summarization or filtering (beyond the basic role and multiline checks). All messages from Claude that meet the criteria are saved in full. Deduplication happens based on occurred_at timestamp and content_hash, but no content transformation occurs.","timestamp":"2025-12-21T19:27:11.897Z"}
{"action":"add","id":"e08fab13-accc-48be-b706-44afeedd148f","subject":"Daemon architecture removed - hooks work directly without HTTP","keywords":["hooks","daemon","http-server","architecture","simplification"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"d1ad139719c26903","content":"The daemon-based architecture (http-server.ts, daemon-client.ts, database.ts) was removed. Hooks (session-start.ts, user-prompt-submit.ts) now work directly without needing to communicate with a background daemon via HTTP. This simplifies the codebase and eliminates inter-process communication complexity.","timestamp":"2025-12-21T19:27:11.897Z"}
{"action":"add","id":"1f9f7a73-f82d-4764-8ff8-dc3987fa3b2a","subject":"Transcript structure: thinking blocks stream separately in JSONL format, not interleaved within message","keywords":["transcript","jsonl","message-id","streaming","structure"],"applies_to":"global","occurred_at":"2025-12-21T19:24:36.877Z","content_hash":"19c5eef3bf6168bb","content":"Transcripts are stored as JSONL where each entry has a content_type (thinking, text, tool_use, etc.) and message_id. Interleaved patterns like 'thinking â†’ tool_use â†’ thinking' actually belong to different messages (different message_ids). Within a single message, multiple thinking entries are duplicates from streaming, not true interleaving. This affects how thinking memories are aggregated and deduplicated.","timestamp":"2025-12-21T19:27:11.898Z"}
{"action":"add","id":"48564dae-91c4-49de-baac-9ac637a01111","subject":"local_cache directory was accidentally committed to git history","keywords":["git history","local_cache","filter-branch","gitignore","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T19:12:57.471Z","content_hash":"97b0b2aa99091abc","content":"The `local_cache/` directory was added to git in recent commits before being pushed. This directory should not be version-controlled as it contains build artifacts or temporary files. Used `git filter-branch` with `--force --index-filter` to rewrite the last 2 unpushed commits and remove all references to `local_cache/` from history. After rewriting, used `git push --force-with-lease` to update remote. The `.gitignore` file was updated to include `local_cache/` to prevent future commits of this directory.","timestamp":"2025-12-21T19:27:11.898Z"}
{"action":"add","id":"101c4686-e00a-4d94-8562-2d9434be2611","subject":"Memory deduplication uses occurred_at timestamp and content_hash","keywords":["deduplication","occurred_at","content hash","duplicate detection","idempotent"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T17:42:21.784Z","content_hash":"03bb9c8603d14e40","content":"Memory deduplication checks for existing entries using `occurred_at` and `content_hash` (SHA-256 prefix, 16 chars). The `findDuplicate()` method prevents storing duplicate memories. This enables idempotent memory creation - calling `createMemory()` multiple times with the same data returns the existing memory rather than creating duplicates.","timestamp":"2025-12-21T19:27:11.899Z"}
{"action":"add","id":"d68c1628-0db0-432f-bacd-8736f4f50638","subject":"All unit tests pass after memory extractor array wrapper fix (220 total tests)","keywords":["tests","memory-extractor","vitest","unit-tests","parsing"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T18:26:15.052Z","content_hash":"ab208f7cf95d8a27","content":"Created comprehensive test suite for `memory-extractor.ts` covering both the wrapped object format and raw array format that Claude returns. All 220 unit tests pass including the new test cases that verify:\n\n1. Raw array parsing: Claude returning `[{...}, {...}]` is correctly wrapped to `{ memories: [...] }`\n2. Wrapped object parsing: Claude returning `{ memories: [...] }` works as expected\n3. Error handling: Invalid data structures are properly caught and reported\n\nTests are in `tests/unit/core/memory-extractor.test.ts` and cover both happy paths and edge cases.","timestamp":"2025-12-21T19:27:11.899Z"}
{"action":"add","id":"1cebddbc-1c4c-4425-94a0-f04216c26406","subject":"MemoryManager must ensure gitignore exists before file operations","keywords":["initialization","setup","directory-structure"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:15:59.803Z","content_hash":"6e5e19195b27f259","content":"The MemoryManager constructor should call ensureGitignore() to guarantee the .gitignore exists in the local-recall/ directory before any memory operations occur. This prevents race conditions where the directory structure exists but the gitignore rules haven't been applied yet.","timestamp":"2025-12-21T19:27:11.900Z"}
{"action":"add","id":"2645274a-9d35-4139-ac43-871e03115909","subject":"MCP server tools exposed via plugin are automatically discovered by Claude Code","keywords":["mcp","tools","plugin","claude-code","episodic","thinking","search"],"applies_to":"area:mcp-server","occurred_at":"2025-12-21T19:02:32.602Z","content_hash":"4ca6f3f6ca2030f3","content":"When the local-recall MCP server is properly configured as a plugin in Claude Code, tools defined in the MCP server are automatically discovered and available to Claude.\n\nThe current available tools are:\n- `episodic_create` - Create episodic memories\n- `episodic_get` - Retrieve specific episodic memories\n- `episodic_search` - Search episodic memories\n- `thinking_get` - Retrieve thinking memories\n- `thinking_search` - Search thinking memories\n\nThese tools handle both episodic and thinking memory management automatically.","timestamp":"2025-12-21T19:27:11.900Z"}
{"action":"add","id":"0436fdd4-8aef-4f3e-9f65-c8ac814288f7","subject":"Memory file storage format uses message role prefixes in memory content","keywords":["memory format","role prefix","message storage","user messages","assistant messages"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-03T09:50:51.143Z","content_hash":"a0ec9a9c880af70b","content":"When messages are saved to memory files, they are prefixed with their role identifier:\n- User messages are prefixed with `**user**:`\n- Assistant messages are prefixed with `**assistant**:`\n\nThis allows the memory system to preserve context about who said what when storing full conversation snippets.","timestamp":"2025-12-21T19:27:11.900Z"}
{"action":"add","id":"cee2e52d-67d7-44dd-902a-13f367043059","subject":"Transcript processing must filter for UUID-named .jsonl files only","keywords":["transcript","jsonl","uuid","file-filtering","robustness"],"applies_to":"area:transcript-collection","occurred_at":"2025-12-21T18:26:54.287Z","content_hash":"5733570723db3449","content":"The transcript collection system should only process .jsonl files with valid UUID filenames. Previously it would filter for any .jsonl file, but this could lead to processing non-transcript files. Implemented a UUID regex pattern and validation function to ensure only proper transcript files (those that Claude Code generates with UUID names) are processed. This adds robustness to the transcript discovery and collection pipeline.","timestamp":"2025-12-21T19:27:11.901Z"}
{"action":"add","id":"2866486b-0751-45ac-adbf-bbf8e095c792","subject":"No existing mutex or concurrency tests in the test suite","keywords":["testing","mutex","concurrent","test coverage","gap"],"applies_to":"global","occurred_at":"2025-12-21T18:20:32.021Z","content_hash":"881666f45edc401c","content":"When searching for existing tests related to mutex errors or concurrent operations, no test files were found in the tests/ directory. This indicates a gap in test coverage for concurrent/multi-process scenarios that could trigger sqlite-vec mutex issues.","timestamp":"2025-12-21T19:27:11.901Z"}
{"action":"add","id":"9a494f4f-e9a2-4015-a85b-db3abe7fcd3a","subject":"MCP server daemon no longer needs HTTP endpoint for search operations","keywords":["mcp-server","daemon","cleanup","architecture"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"ba09afb331a9aa53","content":"Removed HTTP server code that exposed `/search/episodic` and `/search/thinking` endpoints. The daemon now only:\n\n1. Runs periodic transcript syncing and processing\n2. Maintains MCP tool interface for programmatic access\n3. Uses file-based locking internally for safety\n\nHooks no longer depend on daemon being running - they use vector stores directly with their own file-based locking. This decouples hook execution from daemon health.","timestamp":"2025-12-21T19:27:11.902Z"}
{"action":"add","id":"409048e7-1732-498a-8530-095fd4f20d44","subject":"SessionStart hook implementation: Direct file reading for recent memories without vector store load","keywords":["sessionstart","hook","optimization","memory loading","file reading","occurred_at"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:04:31.826Z","content_hash":"1728e2f555a37d97","content":"## Implementation Pattern\n\nThe SessionStart hook loads recent memories efficiently by:\n\n1. Reading memory files directly from the file system (not using vector store)\n2. Parsing YAML frontmatter to extract `occurred_at` timestamp\n3. Sorting memories by timestamp (most recent first)\n4. Taking the 5 most recent memories\n5. Outputting their content for injection into Claude's context\n\n## Why Not Use Vector Store?\n\nThe vector store (Orama) is not used for SessionStart because:\n- Vector search requires loading and indexing the entire store\n- SessionStart just needs recent memories, not semantic relevance\n- Direct file reading is simpler and faster\n- Only 5 memories are needed, so sorting is cheap\n\n## Input/Output\n\n**Input** (JSON via stdin):\n- `session_id` - Current session identifier\n- `transcript_path` - Path to transcript file\n- `cwd` - Current working directory\n\n**Output** (stdout):\n- Raw memory content (markdown format)\n- Injected into Claude's context automatically by Claude Code\n\n## Configuration\n\nConfigurable via:\n- Environment variables\n- `.local-recall.json` file\n- `LOCAL_RECALL_DIR` - Memory directory (default: `./local-recall`)\n- `LOCAL_RECALL_MAX_CONTEXT` - Number of recent memories to load (default: 10, but hook typically uses 5)","timestamp":"2025-12-21T19:27:11.902Z"}
{"action":"add","id":"58cdb9ef-1fcd-465b-ac14-6dbb15a69f21","subject":"Session-start hook enhanced to include both episodic and thinking memories","keywords":["session-start","thinking memories","episodic memories","hook implementation","context injection"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T17:22:22.424Z","content_hash":"8e6601b7b78ed5f7","content":"The session-start hook (`src/hooks/session-start.ts`) was enhanced to retrieve and inject both episodic and thinking memories on session start, not just episodic memories.\n\n**Implementation details:**\n- Retrieves the 5 most recent episodic memories (if `episodicEnabled` config is true)\n- Retrieves the 5 most recent thinking memories (if `thinkingEnabled` config is true)\n- Both sorted by `occurred_at` timestamp in descending order (most recent first)\n- Uses `formatEpisodicÂ­MemoryForDisplay()` and `formatThinkingMemoryForDisplay()` utilities from `src/utils/markdown.ts` for consistent formatting\n- Outputs separate sections for each memory type\n- Respects existing configuration flags to allow enabling/disabling each type independently\n\n**Why this matters:**\n- Session start now provides fuller context continuity - both factual knowledge (episodic) and reasoning patterns (thinking)\n- Helps Claude understand not just what was learned but how similar problems were approached before\n- Allows future sessions to benefit from both types of memories without requiring explicit search","timestamp":"2025-12-21T19:27:11.902Z"}
{"action":"add","id":"b934f895-dd3d-4157-a4f6-d41836dfc66f","subject":"Vector search results are scored by cosine distance and sorted by recency as tie-breaker","keywords":["similarity-scoring","cosine-distance","recency","ranking","search-results"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:19:15.418Z","content_hash":"90c195a216695e56","content":"Vector search scoring uses cosine distance similarity with these specifications:\n\n**Scoring**: Calculated as `Math.round((1 - distance/2) * 100) / 100` which produces scores from 0.0 (no match) to 1.0 (identical), rounded to 2 decimal places (e.g., 0.65).\n\n**Ranking**: Results are sorted first by similarity score descending. When multiple memories have identical rounded scores, they are sorted by `occurred_at` descending to place newer memories first as a recency tie-breaker.\n\nThis prevents arbitrary ordering of equally-relevant results and ensures most recent memories surface first when similarity is equivalent.","timestamp":"2025-12-21T19:27:11.903Z"}
{"action":"add","id":"01bdae3e-3f2f-4559-a651-497f7e9e228e","subject":"Transcript processing concurrency reduced from 20 to 5","keywords":["concurrency","performance","transcript","memory-extractor","parallel","processing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:58:34.079Z","content_hash":"f3a6b93f57418db9","content":"## Concurrency Configuration Change\n\n**Location**: `src/core/memory-extractor.ts` line 148\n\n**Change**: Reduced `MAX_CONCURRENT_PROCESSORS` from 20 to 5\n\n**Config**: `concurrency: 5` in the p-queue configuration\n\n## Rationale\nThis change reduces parallel transcript processing load, likely to:\n- Prevent system resource exhaustion\n- Reduce memory pressure from concurrent Ollama embedding requests\n- Ensure more stable performance when processing transcripts\n\nNote: The actual code comment still references \"20\" as the max - this documentation comment should be updated to reflect the new value of 5.","timestamp":"2025-12-21T19:27:11.903Z"}
{"action":"add","id":"0bc0312d-c9e2-4f08-9ff3-815939f7e26a","subject":"Version bumping forces fresh plugin deployment and cache invalidation","keywords":["version","plugin deployment","cache","plugin.json","package.json","marketplace"],"applies_to":"global","occurred_at":"2025-12-21T18:16:19.596Z","content_hash":"40ab0eb466d363f2","content":"When updating the local-recall plugin, bump the version number in both:\n1. `/package.json` (main project version)\n2. `/dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` (plugin metadata)\n\nIncrementing the version number forces Claude's plugin system to deploy a fresh copy to the cache directory with a versioned path like `~/.claude/plugins/cache/local-recall-marketplace/local-recall/0.1.1/`. This invalidates any cached old versions and ensures all Claude instances use the updated plugin.\n\nOther Claude instances can then reinstall from the marketplace to get the new bundled version.","timestamp":"2025-12-21T19:27:11.903Z"}
{"action":"add","id":"dfb1b721-106d-4961-9eb1-36e71b029f4d","subject":"Plugin hooks must use pure JavaScript - native modules like better-sqlite3 cannot be bundled","keywords":["plugin","bundling","native-modules","better-sqlite3","orama","hooks"],"applies_to":"area:plugin-development","occurred_at":"2025-12-03T11:22:02.028Z","content_hash":"252501e1fb438d8a","content":"When bundling hooks for plugins, native Node modules like `better-sqlite3` cannot be included in the bundle. The solution is to use pure JavaScript alternatives like Orama for vector search. The main project migrated from SQLite+better-sqlite3 to Orama for this reason, allowing hooks to be bundled and distributed without native dependencies.\n\nStale bundled hooks that reference `better-sqlite3` will fail at runtime with `ERR_MODULE_NOT_FOUND`. Always ensure plugin hook configurations point to hooks that use pure JavaScript libraries only.","timestamp":"2025-12-21T19:27:11.904Z"}
{"action":"add","id":"cbbddca6-b53b-439d-8be7-c5ef23b59987","subject":"MCP server daemon processes transcripts every 5 minutes for episodic memory extraction","keywords":["mcp server","daemon","transcript processing","memory extraction","background job"],"applies_to":"global","occurred_at":"2025-12-21T18:30:50.594Z","content_hash":"44e7ef3f5dab07d2","content":"The MCP server (`src/mcp-server/server.ts`) runs a background daemon that automatically processes transcripts every 5 minutes when episodic memory processing is enabled. This daemon handles memory extraction from Claude transcripts, allowing the system to create episodic memories without requiring manual intervention or the Stop hook.","timestamp":"2025-12-21T19:27:11.904Z"}
{"action":"add","id":"58cb7f8d-8e35-4135-824f-09dfcbbae8dc","subject":"Gitignore cleanup - removed outdated sqlite references","keywords":["gitignore","sqlite-vec","better-sqlite3","cleanup","migration"],"applies_to":"file:local-recall/.gitignore","occurred_at":"2025-12-21T19:21:53.918Z","content_hash":"d532243d5bff67af","content":"## Changes Made\n\nRemoved outdated gitignore patterns from both:\n- `local-recall/.gitignore` (the actual gitignore file)\n- `src/utils/gitignore.ts` (the code that generates it)\n\n## References Removed\n\n- SQLite database files patterns\n- better-sqlite3 related entries\n- sqlite-vec index patterns\n\n## Context\n\nThese were leftover from the migration to Orama. The codebase no longer uses sqlite-vec or better-sqlite3, so the gitignore patterns were misleading and should not be regenerated.","timestamp":"2025-12-21T19:27:11.904Z"}
{"action":"add","id":"3470d46c-8222-4ec8-bfde-ea0c492b2746","subject":"user-prompt-submit hook directly loads embedding model, causing concurrency issues","keywords":["user-prompt-submit","embedding","concurrent","hook","search-engine"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:25:17.343Z","content_hash":"688a815361ec1273","content":"The user-prompt-submit hook instantiates SearchEngine and ThinkingSearchEngine directly, which load the embedding model on initialization. This causes mutex errors when multiple Claude instances execute the hook simultaneously. session-start.ts is safe because it only uses MemoryManager (file-based, no embeddings). To fix concurrent execution, either use Ollama daemon (one process, multiple clients) or switch to text-based search for hooks with vector search only in MCP tools.","timestamp":"2025-12-21T19:27:11.905Z"}
{"action":"add","id":"fc1046c4-5008-4a36-bf59-04d2b8cff63d","subject":"File-based locking implementation for cross-process database access","keywords":["file-locking","database","mutex","concurrency","cross-process"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-03T10:13:19.759Z","content_hash":"ee5b1c22f95a6d51","content":"Added `withDbMutex(dbPath, operation)` function that uses file-based locking to serialize database operations across processes:\n\n- Creates lock file: `{dbPath}.lock`\n- Implements spin-lock with 10ms polling (max 30 second timeout)\n- Includes stale lock detection (locks older than 5 minutes are forcefully released)\n- Wraps entire database operation, from connection open to operation completion\n- Works across both hooks (separate processes) and daemon (single process)\n\nAll VectorStore and ThinkingVectorStore operations now use `withDbMutex(this.dbPath, ...)` to ensure safe concurrent access.","timestamp":"2025-12-21T19:27:11.905Z"}
{"action":"add","id":"887dc405-3550-4b7d-986c-01f436e4a547","subject":"VectorStore singleton needs reset capability for testing","keywords":["vector-store","singleton","testing","test-isolation"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:15:38.757Z","content_hash":"ab04d100e1eba78e","content":"The VectorStore uses a singleton pattern via getVectorStore(). Between tests, the singleton wasn't being reset, causing test data from one test to leak into the next. Added resetVectorStore() function to clear the singleton instance, used in test beforeEach() hooks to ensure clean state between tests.","timestamp":"2025-12-21T19:27:11.905Z"}
{"action":"add","id":"92d38900-accb-4044-834b-2285145ffeec","subject":"Logger utility requires string-only arguments in memory-extractor","keywords":["logger","memory-extractor","error-handling","string-arguments"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:19:06.772Z","content_hash":"fe2c50ef262da2fe","content":"The logger utility in src/utils/logger.ts expects string-only arguments for debug/info/error methods. When adding logging statements to memory-extractor, avoid passing structured data as second arguments. Use string interpolation or JSON.stringify() within the string argument to format complex objects.\n\nExample:\n- Wrong: `logger.debug('Parsed structure:', parsedData)`\n- Correct: `logger.debug('Parsed structure: ' + JSON.stringify(parsedData))`","timestamp":"2025-12-21T19:27:11.906Z"}
{"action":"add","id":"7a1e815f-ec3e-41e9-af31-861e06a974dc","subject":"JSONL format for transcript processing and memory storage","keywords":["jsonl","streaming","large-files","transcript","storage","migration"],"applies_to":"global","occurred_at":"2025-12-21T19:16:47.225Z","content_hash":"7de2b37fd3b0cc95","content":"Recent migration from single JSON file to JSONL (JSON Lines) format for storing processed transcripts and memories.\n\n**Why JSONL**: Supports streaming processing of large files without loading entire file into memory. Each line is a valid JSON object, allowing line-by-line reading.\n\n**Key classes**:\n- `EpisodicJsonlStore` - Stores episodic memories in JSONL format with file padding (6-digit indexes)\n- `ThinkingJsonlStore` - Stores thinking memories in JSONL format\n- `ProcessedLog` - Tracks which transcripts have been processed (JSONL format)\n\n**File naming**: Uses 6-digit padding for JSONL files (e.g., `episodic-000001.jsonl`, `thinking-000001.jsonl`) to support multiple files if needed.\n\n**Important**: When reading JSONL files, parse line-by-line to handle large files efficiently. Each line must be a complete valid JSON object.","timestamp":"2025-12-21T19:27:11.906Z"}
{"action":"add","id":"64a61c10-c4d9-4513-a8fa-6aa09d4eb9bb","subject":"Vector store migrated from JSON index files to SQLite with embedded vectors","keywords":["sqlite","vector-store","migration","sql-js","embeddings","database"],"applies_to":"global","occurred_at":"2025-12-21T18:24:38.922Z","content_hash":"3e7ccbb394573f9c","content":"The codebase has migrated from using JSON index files (`orama-episodic-index.json`, `orama-thinking-index.json`) to storing vector embeddings in SQLite using sql.js. The vector store implementation in `src/core/vector-store.ts` now:\n\n1. Creates/initializes SQLite database with `memories` and `memory_embeddings` tables\n2. Stores embeddings as BLOB data in the `embeddings` column\n3. Uses SQLite's vector similarity search (MATCH operator) to find nearest neighbors\n4. Maintains index files for persistence (written as JSON)\n\nThis provides better scalability and native similarity search capabilities compared to the previous Orama-based approach.","timestamp":"2025-12-21T19:27:11.906Z"}
{"action":"add","id":"02ce229f-90a8-4739-b1b7-7556ff077098","subject":"Configuration system supports both .local-recall.json file and environment variables","keywords":["configuration","env-vars","config-file","environment","settings"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"b231c96ed99d12ba","content":"The config system loads settings with this precedence:\n\n1. Environment variables (highest priority)\n2. `.local-recall.json` file in the project root\n3. Default values (lowest priority)\n\nKey configuration options:\n- `memoryDir` - Location of memory storage (default: `./local-recall`)\n- `maxMemories` - Maximum memory count (default: 1000)\n- `episodicEnabled` / `thinkingEnabled` - Toggle memory types\n- `episodicMaxTokens` / `thinkingMaxTokens` - Token budget per injection\n- `episodicMinSimilarity` / `thinkingMinSimilarity` - Similarity thresholds (0.0-1.0)\n\nEnvironment variables follow the pattern `LOCAL_RECALL_*` (e.g., `LOCAL_RECALL_EPISODIC_ENABLED`).","timestamp":"2025-12-21T19:27:11.907Z"}
{"action":"add","id":"d33914e2-5a2e-408b-96fa-a96859ecb73b","subject":"Session-start hook is safe because it only uses file-based MemoryManager, no embeddings","keywords":["session-start","hook","memory","safe","no-embeddings","file-based"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:27:27.411Z","content_hash":"9a31aee7e3e12715","content":"The session-start hook only uses `MemoryManager` (file-based operations, no embeddings) to read the 5 most recent memories. This makes it safe from concurrent execution issues because it doesn't load the embedding model. Only `user-prompt-submit.ts` directly loads embeddings via `SearchEngine` and `ThinkingSearchEngine`.","timestamp":"2025-12-21T19:27:11.907Z"}
{"action":"add","id":"a94e4c81-0a74-448f-bc84-a4f0da285701","subject":"Vector store uses SQLite instead of Orama JSON index files","keywords":["vector store","sqlite","index","storage","migration","orama"],"applies_to":"global","occurred_at":"2025-12-21T18:25:49.095Z","content_hash":"6594b60f80a9923b","content":"The project migrated from Orama (pure JavaScript vector store with JSON index files) to SQLite for vector storage. Previously used `orama-episodic-index.json` and `orama-thinking-index.json` files, now uses SQLite database for storing embeddings. The vector store (`src/core/vector-store.ts`) manages the SQLite backend with `memory_embeddings` and `memories` tables.","timestamp":"2025-12-21T19:27:11.907Z"}
{"action":"add","id":"2338bc46-a19d-4d8d-af65-3a32a1cafe51","subject":"Thinking extractor now deduplicates streaming artifacts to improve memory quality","keywords":["thinking-extractor","deduplication","memory quality","implementation"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:23:20.556Z","content_hash":"05d048830197d419","content":"Modified lines 146-148 of thinking-extractor.ts to deduplicate thinking and text parts before joining them. Uses `[...new Set(array)]` to remove duplicate blocks caused by streaming artifacts. This prevents memories from containing repeated content while maintaining all unique thinking blocks. All 288 tests pass after this change.","timestamp":"2025-12-21T19:27:11.908Z"}
{"action":"add","id":"9f5ab060-9411-486e-89ad-d63503850ac1","subject":"Memories are stored as individual markdown files with YAML frontmatter","keywords":["memories","markdown","storage","episodic-memory","thinking-memory","frontmatter"],"applies_to":"global","occurred_at":"2025-12-21T18:27:35.568Z","content_hash":"c4738e693d6cabc2","content":"Each memory is stored as a separate markdown file in either `local-recall/episodic-memory/` or `local-recall/thinking-memory/`. Each file contains YAML frontmatter with metadata (id, subject, keywords, applies_to, occurred_at, content_hash) followed by the memory content in markdown format.","timestamp":"2025-12-21T19:27:11.908Z"}
{"action":"add","id":"160c64c6-e459-4381-bbd1-a35137fa2a3b","subject":"Migration system handles legacy thinking.jsonl cleanup","keywords":["migration","cleanup","legacy","jsonl","data-format"],"applies_to":"file:src/core/migration.ts","occurred_at":"2025-12-21T19:09:10.487Z","content_hash":"4706bcc6908a79c3","content":"The migration module includes logic to handle upgrades from older storage formats. When migrating to the new padded JSONL format, the system should detect and clean up legacy files like the bare `thinking.jsonl`.\n\nUsers encountering both `thinking.jsonl` and `thinking-000001.jsonl` files should run the migration to consolidate storage to the new format. This ensures consistent file organization going forward.","timestamp":"2025-12-21T19:27:11.908Z"}
{"action":"add","id":"520ab697-3431-4320-8bd6-bedb96e482a8","subject":"Episodic memories enabled by default in configuration","keywords":["episodic","default","enabled","configuration","memory retrieval"],"applies_to":"global","occurred_at":"2025-12-21T19:03:54.460Z","content_hash":"16531f1a880b12f3","content":"Changed the default value of `episodicEnabled` from `false` to `true` in the configuration schema. This means episodic memory retrieval is now active by default for all sessions.\n\n**Files modified:**\n- `src/core/types.ts:118` - Updated schema default: `episodicEnabled: z.boolean().default(true)`\n- `CLAUDE.md` - Updated documentation table reflecting the new default\n\n**Rationale:** Episodic memories provide valuable context from previous sessions and should be available by default to improve Claude's understanding of the codebase and project-specific patterns.","timestamp":"2025-12-21T19:27:11.909Z"}
{"action":"add","id":"7a854ab6-4f11-4d23-927b-8dc46d49e5f5","subject":"Use --strict-mcp-config to disable MCP during internal subprocess calls","keywords":["mcp servers","subprocess","strict config","recursion prevention"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:26:30.211Z","content_hash":"35e756d8fe7e0a99","content":"When calling `claude -p` for internal operations like keyword extraction, add the `--strict-mcp-config` flag to the subprocess command. This disables all MCP servers in that subprocess session, providing an additional layer of protection against recursive hook firing.","timestamp":"2025-12-21T19:27:11.909Z"}
{"action":"add","id":"4316a1bb-9d13-4a71-b37a-9141a57e2ade","subject":"Environment variables control episodic vs thinking memory systems independently","keywords":["configuration","episodic memory","thinking memory","environment variables","LOCAL_RECALL_EPISODIC_ENABLED","LOCAL_RECALL_THINKING_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:22:32.316Z","content_hash":"d5431bef376f6a19","content":"Two environment variables control memory system activation:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` - Defaults to `false`, controls episodic memory search, session-start injection, and extraction\n- `LOCAL_RECALL_THINKING_ENABLED` - Defaults to `true`, controls thinking memory search and extraction\n\nThese flags allow independent control of each memory system. When disabled, the system skips:\n- Search operations in user-prompt-submit hooks\n- Memory injection during session-start\n- Transcript processing and extraction for that memory type\n\nImplemented in `src/core/types.ts` (config schema), `src/utils/config.ts` (parsing), and applied to hooks in `src/hooks/user-prompt-submit.ts`, `src/hooks/user-prompt-submit-thinking.ts`, `src/hooks/session-start.ts`, and MCP server in `src/mcp-server/server.ts`.","timestamp":"2025-12-21T19:27:11.910Z"}
{"action":"add","id":"4e2d1c69-646a-4790-9481-13e95af348dd","subject":"Thinking blocks can be duplicated by streaming artifacts but never truly interleaved","keywords":["thinking blocks","streaming artifacts","deduplication","transcript processing","claude api"],"applies_to":"global","occurred_at":"2025-12-21T19:23:20.556Z","content_hash":"01f5a89941964615","content":"Investigation of 69,308 transcript lines found that Claude's API can log the same thinking block multiple times due to streaming artifacts, but there are no instances of true interleaved thinking (different thinking blocks separated by tool calls within a single message). All 14 cases of multiple thinking blocks had identical content (100% duplicates). The thinking-extractor correctly handles multiple blocks via `thinkingParts[]` array, but deduplication prevents redundant content in generated memories.","timestamp":"2025-12-21T19:27:11.910Z"}
{"action":"add","id":"e012d880-ee68-49de-ab2f-c41dd4854165","subject":"User-prompt-submit hook directly loads embedding models, causing mutex conflicts","keywords":["user-prompt-submit","hook","embedding","search-engine","concurrency","race-condition"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:26:49.611Z","content_hash":"e5a9a58450d4cb81","content":"The user-prompt-submit hook directly instantiates SearchEngine and ThinkingSearchEngine, which load the ONNX embedding model via fastembed. This creates a race condition when multiple Claude instances run concurrently - each hook process tries to load ONNX simultaneously, triggering mutex errors.\n\nConcurrent execution test results: 15 mutex errors from 15 parallel hook processes, confirming the issue is systematic and reproducible.","timestamp":"2025-12-21T19:27:11.910Z"}
{"action":"add","id":"66b27256-2c4f-449d-99f7-a1a18fa29f2c","subject":"Ollama is recommended solution for embedding inference across multiple Claude instances","keywords":["ollama","embedding","server","daemon","inference","multi-instance"],"applies_to":"global","occurred_at":"2025-12-21T19:19:42.881Z","content_hash":"87965dc8b4d3ea31","content":"Ollama provides a shared embedding inference daemon that multiple Claude instances can call via HTTP API. Unlike in-process ONNX loading, a single Ollama server instance can safely handle concurrent embedding requests from multiple Claude processes without mutex issues. Ollama runs on port 11434 by default and supports the nomic-embed-text model (768 dimensions, ~274MB). Installation: macOS (brew install ollama), Linux (curl install script), Windows (installer from ollama.com). Must pull model with 'ollama pull nomic-embed-text' before use.","timestamp":"2025-12-21T19:27:11.911Z"}
{"action":"add","id":"3a23ef00-78b5-42b4-ac9a-795d71dd25d1","subject":"MCP server runs background daemon to process transcripts asynchronously every 5 minutes","keywords":["mcp-server","background-daemon","transcript-processing","memory-extraction"],"applies_to":"area:mcp-server","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"a89fe0d90b1ed7ab","content":"The MCP server includes a background daemon that:\n1. Syncs transcripts from Claude's cache at `~/.claude/projects/<project>/transcripts/`\n2. Processes transcripts to extract memories\n3. Tracks processed transcripts with content hashes for change detection\n4. Deletes and recreates memories when transcripts change\n5. Runs every 5 minutes (300 second refresh interval)\n\nThis replaced the previous Stop hook approach for memory extraction.","timestamp":"2025-12-21T19:27:11.911Z"}
{"action":"add","id":"34191fb6-65fd-4545-9cf1-1bc029593ebf","subject":"Documentation gaps in vector store and embedding architecture","keywords":["documentation","architecture","vector-store","embedding-service","setup-instructions"],"applies_to":"global","occurred_at":"2025-12-21T19:25:27.646Z","content_hash":"e2847c6596f49e53","content":"Several documentation files were missing important information about the vector store and embedding components:\n\n1. **CLAUDE.md** - Missing explanation of embedding model download requirements\n2. **docs/architecture.md** - Missing details on VectorStore and EmbeddingService components\n3. **Setup instructions** - Didn't clearly explain the automatic model download process\n\nThese were updated to include:\n- Embedding model setup and first-run behavior\n- Architecture diagram updates to show vector store components\n- Troubleshooting section for tokenizer file issues\n- Information about local_cache directory and gitignore requirements\n\nThis prevents confusion for developers new to the project who encounter the embedding model download on first use.","timestamp":"2025-12-21T19:27:11.912Z"}
{"action":"add","id":"4e87a949-7f21-4cb3-8071-55eb6b8a788c","subject":"Similarity threshold changed to 50% for memory retrieval","keywords":["similarity-threshold","memory-retrieval","configuration","0.5"],"applies_to":"global","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"d2f738106477d91b","content":"Default similarity threshold for both episodic and thinking memories lowered from 80% (0.8) to 50% (0.5). This is configured in `src/core/types.ts` with environment variables `LOCAL_RECALL_EPISODIC_MIN_SIMILARITY` and `LOCAL_RECALL_THINKING_MIN_SIMILARITY`. The hook uses `if (result.score < minSimilarity) continue` to filter results, so a 0.5 threshold includes memories scoring 50% or higher.","timestamp":"2025-12-21T19:27:11.912Z"}
{"action":"add","id":"0c6f9066-3e25-4d7c-8395-6f9375261b54","subject":"Memory extractor handles Claude field name variations for robustness","keywords":["memory-extractor","field-normalization","claude-response","zod-validation","resilience"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:17:53.529Z","content_hash":"33a2865df2bfbb78","content":"Added field name normalization in parseClaudeResponse() to handle cases where Claude returns memory objects with alternative field names. Maps common variations (descriptionâ†’subject, tagsâ†’keywords, scopeâ†’applies_to, textâ†’content) to expected fields before Zod validation. This prevents validation failures when Claude uses slightly different terminology while extracting memories from transcripts.\n\nImplemented in two places:\n1. Main parsing path (lines 179-186): normalizeMemoryFields() helper\n2. Fallback JSON extraction (lines 200-207): Same normalization applied\n\nAlso added comprehensive test coverage in memory-extractor.test.ts for field variations.","timestamp":"2025-12-21T19:27:11.912Z"}
{"action":"add","id":"e1548077-7c01-44ec-beaf-7a3e52fe4e2e","subject":"Episodic memory is disabled by default in the configuration","keywords":["episodic memory","default configuration","disabled","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:18:32.087Z","content_hash":"6c2d9a339b7cd0e7","content":"The `episodicEnabled` configuration option has been changed to default to `false`. This means episodic memory retrieval is disabled by default unless explicitly enabled by users.\n\n**Location**: `src/core/types.ts:118` in the schema definition\n\n**How to enable**: Users can enable episodic memory by:\n- Setting environment variable: `LOCAL_RECALL_EPISODIC_ENABLED=true`\n- Or adding to `.local-recall.json`: `\"episodicEnabled\": true`\n\n**Documentation**: Updated in `CLAUDE.md` configuration table to reflect the new default value.","timestamp":"2025-12-21T19:27:11.912Z"}
{"action":"add","id":"1909964f-f07b-45a4-bb36-e503d38c9b03","subject":"Mutex errors occur with sqlite-vec when multiple processes load concurrently","keywords":["sqlite-vec","mutex","concurrent","loading","cross-process","file locking"],"applies_to":"global","occurred_at":"2025-12-21T18:20:32.021Z","content_hash":"165d4f806a47cc64","content":"The codebase has a known issue where sqlite-vec can throw 'mutex lock failed: Invalid argument' errors when multiple processes attempt to load the library simultaneously. This is a cross-process synchronization problem that requires file locking mechanisms to prevent concurrent initialization. The concern is documented in src/mcp-server/server.ts around line 230.","timestamp":"2025-12-21T19:27:11.913Z"}
{"action":"add","id":"50c56d8c-5dea-4f2c-91ae-31b7be5eebd6","subject":"Processed log files track transcript processing state to prevent duplicate memory extraction","keywords":["processed-log","transcript","deduplication","state-tracking","json"],"applies_to":"area:transcript-processing","occurred_at":"2025-12-21T19:00:03.739Z","content_hash":"bbb490067d00777b","content":"The `processed-log.json` file (or `.jsonl` variant) is critical for the transcript processing pipeline. It tracks:\n\n1. Which transcripts have already been processed\n2. Content hashes to detect when transcripts change\n3. Prevents duplicate memory extraction from the same transcript\n\nThis file should be added to `.gitignore` to prevent:\n- Merge conflicts when multiple sessions process transcripts\n- False change detection from processing state updates\n- Git bloat from frequent updates\n\nThe processed-log is used by the MCP server daemon (runs every 5 minutes) to determine which transcripts need processing.","timestamp":"2025-12-21T19:27:11.913Z"}
{"action":"add","id":"57b1c53a-9712-48a5-9447-5372064b2294","subject":"Transcript condenser optimizes memory extraction by parsing JSONL and extracting minimal content","keywords":["transcript","condenser","memory extraction","token optimization","jsonl parsing"],"applies_to":"global","occurred_at":"2025-12-21T19:25:46.514Z","content_hash":"d970d77a3c3c56cc","content":"The transcript condenser (`src/core/transcript-condenser.ts`) improves memory extraction efficiency by:\n\n1. **Parsing JSONL transcripts** - Uses TypeScript types to parse raw Claude Code transcript entries\n2. **Extracting minimal content** - Only extracts relevant data from each line (user prompts, assistant responses, tool invocations)\n3. **Structured format** - Creates a condensed, structured format passed to the memory extractor\n4. **Token reduction** - Eliminates full file contents, bash outputs, and other verbose data\n\nThis approach vastly reduces token usage and speeds up memory creation by only sending essential context to Claude for memory extraction. Each transcript line is processed to extract its minimum meaningful content before passing to the extractor prompt.","timestamp":"2025-12-21T19:27:11.913Z"}
{"action":"add","id":"f22e00cd-21a4-41e7-88ee-1ba2c1dc1c86","subject":"Local Recall plugin successfully installed and requires Claude Code restart","keywords":["plugin","installation","local-recall","setup","restart"],"applies_to":"global","occurred_at":"2025-12-21T18:59:53.020Z","content_hash":"6c9a438a0feffa11","content":"The local-recall plugin was successfully installed via the `/plugin` command. After installation, Claude Code needs to be restarted to load the new plugins and make them available for use.","timestamp":"2025-12-21T19:27:11.914Z"}
{"action":"add","id":"ebf5063e-609c-479d-87ec-b545d8d6290a","subject":"Default logging level changed from 'info' to 'error' to minimize log noise","keywords":["logging","log-level","default","error","noise","configuration"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T18:58:05.285Z","content_hash":"07ad2e5544c6fa7e","content":"The default logging level in `getMinLogLevel()` function was changed from 'info' to 'error' to reduce log output noise. Users can still override this behavior using the `LOCAL_RECALL_LOG_LEVEL` environment variable with values like 'debug', 'info', or 'warn' for more verbose logging when needed.","timestamp":"2025-12-21T19:27:11.914Z"}
{"action":"add","id":"f1c43273-5ebb-4005-9a3a-ddf226128097","subject":"Removed ts-textrank npm package dependency","keywords":["dependencies","ts-textrank","package.json","removed"],"applies_to":"global","occurred_at":"2025-12-21T18:19:48.301Z","content_hash":"17922051efbc2bf9","content":"Removed the `ts-textrank` npm package from dependencies in package.json as it was replaced with simpler text processing logic in summarize.ts. The new implementation doesn't require external NLP libraries.","timestamp":"2025-12-21T19:27:11.915Z"}
{"action":"add","id":"f90e83d4-2942-4431-97ae-eee69ee5f914","subject":"MCP server configuration uses LOCAL_RECALL_DIR for memory directory path","keywords":["mcp server","environment variable","LOCAL_RECALL_DIR","configuration","memory directory"],"applies_to":"global","occurred_at":"2025-12-03T09:49:57.517Z","content_hash":"207cfce498c48bab","content":"The MCP server requires the `LOCAL_RECALL_DIR` environment variable to be set in the configuration (typically in `.claude/settings.local.json`). This specifies the path to the local-recall directory where memories are stored. Default path is `./local-recall` relative to the project root.","timestamp":"2025-12-21T19:27:11.915Z"}
{"action":"add","id":"808cd676-2da6-4675-b016-fdb2addadffa","subject":"Thinking memory extraction now combines thought blocks with text output","keywords":["thinking-memory","extraction","thought-output","transcript-processing"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-03T09:47:22.389Z","content_hash":"c3e3fd8139831e59","content":"Changed thinking memory extraction to capture both the thinking block AND the corresponding text output in a single memory. Format is: ## Thought\\n\\n{thinking}\\n\\n## Output\\n\\n{output}. Tool-only responses are now skipped (memories are only created when there's text output). This provides concrete examples of 'how I reasoned â†’ what I produced' for future sessions.","timestamp":"2025-12-21T19:27:11.916Z"}
{"action":"add","id":"f6e1636b-b8fb-4ac0-9e24-5b1abf3b7a4a","subject":"GitHub MCP server not configured in this project","keywords":["github","mcp","integration","settings","configuration"],"applies_to":"global","occurred_at":"2025-12-21T19:26:51.998Z","content_hash":"01bbf404cdd4807b","content":"The local-recall project does not currently have a GitHub MCP server configured. To access GitHub features like PR comments and suggestions through Claude Code, a GitHub MCP server would need to be installed and configured in `.claude/settings.json`. The user attempted to use GitHub MCP to view inline suggestions from a PR but discovered this capability is not available in the current setup.","timestamp":"2025-12-21T19:27:11.916Z"}
{"action":"add","id":"f65d6438-4435-4aad-bc00-a391c47d51c5","subject":"Memory storage classes handle JSONL serialization and file rotation","keywords":["episodic-jsonl-store","thinking-jsonl-store","serialization","file-rotation","chunk-size"],"applies_to":"file:src/core/episodic-jsonl-store.ts file:src/core/thinking-jsonl-store.ts","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"c087415f752e7eb5","content":"The `EpisodicJsonlStore` and `ThinkingJsonlStore` classes manage JSONL file storage with:\n\n- **File naming**: Uses 6-digit zero-padded numbers (e.g., `episodic-000001.jsonl`, `episodic-000002.jsonl`)\n- **Chunk size management**: Rotates to new files when reaching size limits\n- **Serialization**: Each line is a valid JSON object representing a memory or thinking block\n- **Migration support**: `migration.ts` handles legacy format conversion\n\nThese classes abstract the complexity of managing multiple JSONL files while providing a unified interface for memory operations.","timestamp":"2025-12-21T19:27:11.916Z"}
{"action":"add","id":"cc0cf847-ab60-45e5-8ab4-59daac045f50","subject":"Hook configuration uses command array format in hooks.json instead of string","keywords":["hooks","configuration","json format","command array"],"applies_to":"file:dist/hooks/hooks.json","occurred_at":"2025-12-21T19:02:46.136Z","content_hash":"acb0f1352a84a627","content":"The hooks.json configuration file uses a `commands` array format where each hook object contains `{\"type\": \"command\", \"commands\": [...]}`. The actual hook command is in a nested array structure, not a simple string. This is the format used when hooks are deployed to user environments.","timestamp":"2025-12-21T19:27:11.916Z"}
{"action":"add","id":"7ff17a0c-61b1-4d5d-9754-00df60f9d25f","subject":"Memory text for embedding combines subject and content fields","keywords":["embedding","memory","subject","content","text-concatenation"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-03T09:50:05.007Z","content_hash":"fb492169d6e7f1bd","content":"When embedding memories for the vector store, Local Recall concatenates the memory's subject and content fields with a newline separator: `${memory.subject}\\n\\n${memory.content}`. This combined text is then passed to passageEmbed() to create the 384-dimensional embedding. This approach ensures both the memory's title and detailed content are considered during semantic similarity searches.","timestamp":"2025-12-21T19:27:11.917Z"}
{"action":"add","id":"4d8b7c98-97be-4b2c-b88b-98a8d67c9486","subject":"Vector store migrated from JSON index files to SQLite with vector search","keywords":["sqlite","vector-store","migration","orama","architecture"],"applies_to":"global","occurred_at":"2025-12-21T19:19:24.814Z","content_hash":"8cc6d7881cb7c96c","content":"The project migrated from storing vector indexes as JSON files (`orama-episodic-index.json`, `orama-thinking-index.json`) to using SQLite with vector embeddings. The new `src/core/vector-store.ts` uses SQLite with a vector search extension for semantic similarity searches. Index files are no longer used; instead, data is persisted in a SQLite database with separate tables for memories and embeddings.","timestamp":"2025-12-21T19:27:11.917Z"}
{"action":"add","id":"5a63d94b-73ae-4f71-b0e8-29feca3f5389","subject":"SessionStart hook was timing out due to vector store initialization downloading embedding model","keywords":["session-start","hook","timeout","vector-store","embedding","performance"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:17:30.301Z","content_hash":"d5317cd0fc7a04f2","content":"The SessionStart hook was initializing the vector store which downloads a 133MB embedding model on first use, causing the 30-second hook timeout to be exceeded. Fixed by removing vector store initialization - the hook now just loads the 5 most recent memories directly from files without vector operations. Vector store is initialized lazily by the MCP server or user-prompt-submit hook when actually needed.","timestamp":"2025-12-21T19:27:11.917Z"}
{"action":"add","id":"e9578842-ec70-4abb-b491-68b4f80c706d","subject":"SessionStart hook was timing out due to vector store initialization","keywords":["session-start","hook","timeout","vector-store","embedding","performance"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:14:59.526Z","content_hash":"04efd4bead46d54f","content":"The SessionStart hook was initializing the full vector store on session start, which downloads a 133MB embedding model on first use and takes too long for the 30-second hook timeout. Fixed by loading just the 5 most recent memories directly from files without vector store initialization. Vector store is now lazily initialized by the MCP server or UserPromptSubmit hook.","timestamp":"2025-12-21T19:27:11.918Z"}
{"action":"add","id":"7bdfe693-18ca-4e98-92f8-facb5483b78f","subject":"Plugin hooks require JSON output format with hookSpecificOutput, not plain console.log","keywords":["hooks","plugin","output format","json","hookSpecificOutput","additionalContext","session-start"],"applies_to":"global","occurred_at":"2025-12-21T19:26:19.771Z","content_hash":"4df748dedcdd386d","content":"Claude Code plugin-layer hooks (identified by `:Callback` suffix in hook_name) require output in JSON format with `hookSpecificOutput.additionalContext` to inject content into Claude's context. Plain stdout/console.log does NOT work for context injection in plugin hooks. The session-start hook must output: `{\"hookSpecificOutput\": {\"additionalContext\": \"content here\"}}`","timestamp":"2025-12-21T19:27:11.918Z"}
{"action":"add","id":"b7bef08f-8bdb-4fc2-863a-25218e701810","subject":"Vector store concurrent creation has race condition bug","keywords":["concurrency","vector-store","race-condition","memory-creation","parallel"],"applies_to":"file:src/core/memory.ts, file:tests/integration/memory-lifecycle.test.ts","occurred_at":"2025-12-21T17:21:11.889Z","content_hash":"7b276ab8c4ea2b25","content":"Discovered race condition when creating memories in parallel: each `getVectorStore()` call in `MemoryManager` creates a new instance that loads, modifies, and persists the Orama index independently. When multiple memories are created simultaneously, their modifications overwrite each other. Test `should handle vector store sync while creating memories in parallel` exposed this bug. Currently skipped with TODO marker. Needs fix: use singleton pattern or mutex for vector store access.","timestamp":"2025-12-21T19:27:11.918Z"}
{"action":"add","id":"8b5b9299-0372-44a4-8496-5037cb3cf7e6","subject":"Three pathways for data to load into SQLite vector store","keywords":["vector-store","sqlite","data-loading","sync","embedding"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:19:24.814Z","content_hash":"e76dc606591341ff","content":"Data enters the SQLite vector store through three pathways:\n\n1. **On Memory Creation**: `MemoryManager.createMemory()` (in `src/core/memory.ts:107-113`) creates the markdown file and immediately calls `vectorStore.add(memory)` to insert it into SQLite with embedding\n\n2. **On MCP Server Start**: `src/mcp-server/server.ts:73` calls `vectorStore.sync(memories)` which adds any memories that aren't yet in the store\n\n3. **Daemon Processing**: The background daemon creates new memories via `episodic_create` which triggers pathway 1\n\nThis multi-pathway approach ensures memories are searchable immediately while also handling out-of-sync cases.","timestamp":"2025-12-21T19:27:11.918Z"}
{"action":"add","id":"b312bcde-1575-41ee-81be-125f9e20b181","subject":"Session guarding for memory extraction prompts requires [LOCAL_RECALL_INTERNAL] prefix","keywords":["session-guarding","local-recall-internal","memory-extraction","recursion-prevention","hooks"],"applies_to":"global","occurred_at":"2025-12-21T18:29:15.440Z","content_hash":"225895eeafa6918b","content":"The UserPromptSubmit hook filters out internal prompts that start with `[LOCAL_RECALL_INTERNAL]` to prevent infinite recursion. Memory extraction prompts sent by the MCP daemon via `claude -p` must include this prefix in the prompt itself. Without it, the hook processes the memory extraction prompt as a regular prompt, causing unwanted semantic search lookups. The prefix should be added at the start of `buildMemoryExtractionPrompt()` in `src/prompts/memory-extraction.ts`.","timestamp":"2025-12-21T19:27:11.919Z"}
{"action":"add","id":"c24b48dd-b8fc-427d-a3ad-3b3c85bde38a","subject":"MCP server distribution requires git-tracked scripts for Claude Code plugins","keywords":["mcp-server","plugin","distribution","github","git-tracked","local-recall-plugin"],"applies_to":"global","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"fc4c70a32527e014","content":"Claude Code fetches plugins from GitHub repositories. The MCP server startup failure was caused by `local-recall-plugin/scripts/` being in .gitignore, so the plugin couldn't execute the startup script. When distributing the local-recall plugin via GitHub, the hook scripts in `local-recall-plugin/scripts/` must be git-tracked (not in .gitignore) for Claude Code to find and execute them. This applies to: `session-start.js`, `stop.js`, and `user-prompt-submit.js`.","timestamp":"2025-12-21T19:27:11.919Z"}
{"action":"add","id":"d5b8d2a0-6c66-4362-af48-19f7aeaf5f35","subject":"SessionStart hook timeout caused by vector store initialization","keywords":["session-start","hook","timeout","vector-store","embedding-model","performance"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:17:55.902Z","content_hash":"e54d080f05ce06b7","content":"The SessionStart hook was timing out (30s limit) because it initialized the vector store, which downloads a ~133MB embedding model on first use. Fixed by removing vector store initialization from the hook - it now just loads the 5 most recent memories directly from files. Vector store is lazily initialized by MCP server or user-prompt-submit hook instead.","timestamp":"2025-12-21T19:27:11.920Z"}
{"action":"add","id":"4c192e12-bcd1-4b5b-aa7f-a92a54c193c6","subject":"Plugin deployment uses versioned cache directory that requires fresh deploy on version bumps","keywords":["plugin","deployment","cache","version","mcp-server","bundling"],"applies_to":"global","occurred_at":"2025-12-21T19:13:59.315Z","content_hash":"966d4a209894d235","content":"The local-recall plugin deploys to `~/.claude/plugins/cache/local-recall-marketplace/local-recall/{version}/` with bundled dependencies. When the MCP server is updated (especially after fixing bundling), the version number must be bumped in both `package.json` and `.claude-plugin/plugin.json` to force a fresh deployment. Without a version bump, Claude instances will continue using the cached outdated version. The bundled server.js includes all dependencies (~1.1MB) since node_modules aren't shipped with plugins.","timestamp":"2025-12-21T19:27:11.921Z"}
{"action":"add","id":"19766d4e-4468-4110-9537-4af7e2d29b40","subject":"Thinking vector store uses SQLite with CREATE TABLE IF NOT EXISTS pattern","keywords":["thinking vector store","sqlite","database schema","idempotency","table creation"],"applies_to":"file:src/core/thinking-vector-store.ts","occurred_at":"2025-12-21T19:14:45.298Z","content_hash":"27d6f464a6316620","content":"The thinking vector store uses SQLite with `CREATE TABLE IF NOT EXISTS` pattern in `createTables()` method (lines 78-118). This makes table creation idempotent.\n\nKey behavior:\n- Tables can be safely recreated without errors\n- If the database file is deleted, tables are automatically recreated on next initialization\n- The processed log JSONL file can also be safely deleted - it will restart with empty cache on next load\n- Deletion of both the processed log and memories allows complete reprocessing from scratch","timestamp":"2025-12-21T19:27:11.921Z"}
{"action":"add","id":"b2aa7cea-144b-4f21-b275-f2e5d33afb0e","subject":"analyzeForMemories filters thinking and answers separately","keywords":["transcript","analysis","memory","filtering","logic"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:16:05.970Z","content_hash":"3badd9be31f8d673","content":"Updated `analyzeForMemories()` function (lines 169-192) to:\n- Save all thinking blocks regardless of length using `generateSubject()` for subjects\n- Save only multiline answers (content with 2+ lines) to reduce noise from single-line tool responses\n- Use simplified subject generation: first line for multi-line, first sentence for single-line","timestamp":"2025-12-21T19:27:11.921Z"}
{"action":"add","id":"1e48be16-1f2d-4314-bd65-63df403f34cc","subject":"Vector search scores are rounded to 2 decimal places with recency tie-breaking","keywords":["vector-store","scoring","similarity","rounding","recency"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-03T09:47:48.632Z","content_hash":"2f3f6f8df6b61c77","content":"Vector search results use the following scoring and ranking:\n\n- **Score range**: 0.0 (no match) to 1.0 (perfect match)\n- **Calculation**: `Math.round((1 - distance / 2) * 100) / 100` (rounded to 2 decimal places)\n- **Primary sort**: By similarity score (descending)\n- **Secondary sort (tie-breaker)**: When scores are equal, sort by `occurred_at` descending (newest first)\n\nThis ensures cleaner score display (e.g., 0.65 instead of 0.65234) and guarantees most recent memories appear first when relevance is equivalent.","timestamp":"2025-12-21T19:27:11.922Z"}
{"action":"add","id":"9b5afcee-0bf4-4893-9283-720fe57b79d3","subject":"Future development priorities for Local Recall identified during planning session","keywords":["roadmap","features","next-steps","development-priorities","cli","deduplication"],"applies_to":"global","occurred_at":"2025-12-21T18:21:31.415Z","content_hash":"f22e9a80adec1a6d","content":"Identified potential development directions:\n\n1. **CLI Implementation** - Add command-line interface with `init`, `search`, `list`, `create` commands for memory management outside of Claude Code\n\n2. **Memory Deduplication** - Detect and intelligently merge similar memories to reduce redundancy and improve search accuracy\n\n3. **Memory Decay/Pruning** - Implement automatic archival or deletion of stale memories based on age and relevance\n\n4. **Context-Aware Retrieval** - Enhance memory loading to be aware of currently open files and project context\n\n5. **Improved Stop Hook Analysis** - Better automatic memory extraction from transcripts with smarter keyword and summary generation\n\n6. **Live Testing** - Install and test the plugin in a real project to validate functionality and identify improvements\n\nSession was focused on assessing what exists and what needs building rather than implementation.","timestamp":"2025-12-21T19:27:11.922Z"}
{"action":"add","id":"43077fc6-f7a4-4f6e-8a44-9945f25d2829","subject":"Memory extractor successfully works with Haiku model","keywords":["memory-extractor","haiku","model-switching","cost-optimization","performance"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:15:07.227Z","content_hash":"cfc0dc836ce01642","content":"# Memory Extractor Model Optimization\n\nTested and validated that Claude Haiku can successfully handle the memory extraction task from transcripts. Haiku correctly extracts structured memories with valid markdown formatting that the existing `stripMarkdownCodeBlocks` method already handles.\n\n## Performance and Cost Benefits\n\n- Haiku is approximately **20x cheaper** than Sonnet for this task\n- Haiku is significantly **faster** than Sonnet\n- The structured extraction task (parsing transcripts into JSON memories) is well-suited to Haiku's capabilities\n- Memory extraction is a high-volume workload (daemon processes transcripts every 5 minutes), making cost savings substantial\n\n## Implementation\n\nUpdated `callClaudeCLI` method in `src/core/memory-extractor.ts` (lines 80-81) to add `--model haiku` flag to Claude CLI invocation. All 32 unit tests pass with this change.\n\n## Testing\n\nVerified with integration test that Haiku correctly:\n1. Extracts valid memories from transcript samples\n2. Returns properly formatted JSON with code blocks\n3. Handles the full memory extraction pipeline","timestamp":"2025-12-21T19:27:11.923Z"}
{"action":"add","id":"5528e1d3-f151-4586-af94-bdc738206f81","subject":"Claude project discovery uses path-to-dashes naming convention in ~/.claude/projects","keywords":["claude","project-discovery","transcript-collector","path-convention","~/.claude/projects"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:23:40.594Z","content_hash":"e93970d6555b73f4","content":"Claude stores projects in ~/.claude/projects using a naming convention where the full file path has slashes replaced with dashes. For example, /Users/joe/Code/Syntessera/local-recall becomes -Users-joe-Code-Syntessera-local-recall. The transcripts (.jsonl files) are stored directly in the project folder, NOT in a transcripts/ subfolder. The TranscriptCollector must prioritize this path-to-dashes lookup method to correctly find projects and their transcripts.","timestamp":"2025-12-21T19:27:11.923Z"}
{"action":"add","id":"33d653e0-8ac8-445f-aedb-ec82a0802aca","subject":"ExtractorOptions now supports configurable concurrency parameter","keywords":["extractor options","concurrency","configuration","parallelism","memory-extractor"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:01:37.581Z","content_hash":"1f5d892ef092f234","content":"The `ExtractorOptions` interface was extended to include a `concurrency` parameter (optional, defaults to 10). This allows callers to control how many transcript extractors run in parallel when processing multiple transcripts. The parameter is passed to the internal semaphore used by `processAllTranscripts` to control concurrent execution.","timestamp":"2025-12-21T19:27:11.924Z"}
{"action":"add","id":"358d8ea1-fa8b-4628-8f62-a65f01e89c20","subject":"Transcripts stored directly in Claude project folder, not in subdirectory","keywords":["transcripts location","claude project structure","jsonl files"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:26:30.211Z","content_hash":"0f61299022510178","content":"Claude stores transcript JSONL files directly in the project folder (~/.claude/projects/PROJECT_NAME/*.jsonl), not in a `transcripts/` subdirectory. The code previously looked for a `transcripts` subfolder which doesn't exist. Update listSourceTranscripts() to look for .jsonl files in the project root.","timestamp":"2025-12-21T19:27:11.924Z"}
{"action":"add","id":"24b42443-5a03-405c-96a1-6e12c96fa132","subject":"Thinking memories successfully extracted from 59 transcripts (616 memories created)","keywords":["thinking extraction","processing success","transcripts","memories","daemon"],"applies_to":"global","occurred_at":"2025-12-03T09:47:36.366Z","content_hash":"ebd042c231c22135","content":"After fixing the thinking extractor and mutex lock issues, successfully extracted thinking memories from the transcript archive:\n\n- **Transcripts processed**: 59\n- **Thinking memories created**: 616 (average ~10.4 per transcript)\n- **Format**: Each memory has `## Thought` and `## Output` sections\n- **Status**: All memories correctly written to `local-recall/thinking-memory/` directory with unique UUIDs\n\nThis demonstrates the thinking memory extraction pipeline is now functioning correctly and can process the full transcript history.","timestamp":"2025-12-21T19:27:11.924Z"}
{"action":"add","id":"409af17f-ddae-4297-b52c-a92023c92e25","subject":"Episodic memory is now enabled by default in Local Recall","keywords":["episodic memory","default configuration","env var","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T19:00:54.454Z","content_hash":"bd646989fb470668","content":"Changed the default value of `episodicEnabled` from `false` to `true` in `src/core/types.ts:118`. This means episodic memory retrieval is now active by default unless explicitly disabled via environment variable `LOCAL_RECALL_EPISODIC_ENABLED=false`.","timestamp":"2025-12-21T19:27:11.925Z"}
{"action":"add","id":"7be90a90-412b-4ae8-97d0-c2021d8aefed","subject":"Mutex errors from onnxruntime-node in fastembed, not SQLite","keywords":["mutex","fastembed","onnxruntime-node","native bindings","concurrent processes","embedding service"],"applies_to":"global","occurred_at":"2025-12-21T18:27:48.862Z","content_hash":"7cc2dbdc26c5f54f","content":"The mutex errors occurring after migrating from sqlite-vec to Orama were actually caused by `onnxruntime-node` (a dependency of `fastembed`), not SQLite. Both have native bindings that cause mutex locks when loaded by multiple concurrent hook processes. The embedding service initialization and inference operations need to be serialized with a file-based lock to prevent concurrent access to the native module.","timestamp":"2025-12-21T19:27:11.925Z"}
{"action":"add","id":"ed8ee080-7ff5-45ad-8783-4563a84d0b3e","subject":"MemoryManager must ensure .gitignore exists in parent directory","keywords":["gitignore","memory-manager","initialization","directory-setup","file-creation"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:17:51.449Z","content_hash":"c5f95466dab65a32","content":"The `MemoryManager` class creates the `local-recall/memories/` subdirectory but was not ensuring the parent `local-recall/.gitignore` file exists. This caused `.gitignore` to not be created when memory operations occurred. The fix involves:\n\n1. Store the base directory as a class property to access it in the constructor\n2. Call `ensureGitignore()` in the constructor to create the `.gitignore` file at `baseDir/.gitignore`\n3. The `.gitignore` file should contain patterns to ignore generated index files and logs\n\nThis ensures the `.gitignore` is created whenever the MemoryManager is instantiated, making it a reliable initialization step.","timestamp":"2025-12-21T19:27:11.925Z"}
{"action":"add","id":"6060bd7a-2005-40b1-b54b-356246b4530f","subject":"MCP server exposes episodic_search and episodic_create tools","keywords":["mcp-server","memory-tools","episodic-search","semantic-search"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"62ecd685d4b31208","content":"The MCP server in `src/mcp-server/server.ts` exposes memory tools for any MCP-compatible client (Claude Desktop, other tools). Key tools:\n\n- `episodic_search` - Semantic search across episodic memories using vector embeddings\n- `episodic_create` - Create new episodic memories (idempotent)\n- `search` - General semantic search tool\n\nThe server can be configured via environment variable `LOCAL_RECALL_DIR` to point to the memory storage directory. This allows Claude Code and other tools to query and create memories programmatically without direct file manipulation.","timestamp":"2025-12-21T19:27:11.926Z"}
{"action":"add","id":"2506b9f7-ea02-49f2-b485-2704830410bd","subject":"Memory extraction prompt must return JSON-only without explanation","keywords":["json output","memory extraction","format specification","no markdown"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:30:03.315Z","content_hash":"12c7f0476f5dd931","content":"The memory extraction prompt (`buildMemoryExtractionPrompt()`) must explicitly state:\n- Return ONLY a valid JSON object\n- No explanation, no markdown formatting, no code blocks\n- If no valuable memories: return `{ \"memories\": [] }`\n- Each memory must have `subject`, `keywords`, `applies_to`, and `content` fields\n\nThis strict specification is necessary for reliable JSON parsing in `memory-extractor.ts` and prevents Claude from including explanatory text that would break the parsing.","timestamp":"2025-12-21T19:27:11.926Z"}
{"action":"add","id":"3171ab06-ba99-414d-bd82-f570cdc1320c","subject":"Ollama is recommended solution for multi-Claude-instance embedding problem","keywords":["ollama","embedding","daemon","api","nomic-embed-text","multi-process"],"applies_to":"global","occurred_at":"2025-12-21T18:25:17.343Z","content_hash":"b90d1f9da46fb183","content":"Ollama provides a single embedding daemon that supports multiple concurrent clients via HTTP API. This solves the ONNX mutex issue because only one process loads the model. Installation: `brew install ollama` (macOS), `curl -fsSL https://ollama.com/install.sh | sh` (Linux), or download from ollama.com (Windows). Pull model: `ollama pull nomic-embed-text`. Server runs on http://localhost:11434 with `/api/embed` endpoint. This allows multiple Claude instances to share one embedding service without concurrency issues.","timestamp":"2025-12-21T19:27:11.926Z"}
{"action":"add","id":"be045998-7422-4a98-9bd4-dd39c391eda6","subject":"IndexManager and index.json are redundant after SQLite migration","keywords":["indexmanager","redundant","sqlite","vector-store","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T19:15:38.757Z","content_hash":"5dee2862d048450e","content":"After migrating to SQLite with vector embeddings, the IndexManager class and index.json file became redundant. The vector store now handles all memory indexing and search. Removed IndexManager entirely, deleted src/core/index.ts, removed all references from mcp-server/tools.ts, hooks/stop.ts, core/memory-extractor.ts, and tests. The index_rebuild MCP tool was replaced with a simple sync call to VectorStore.sync().","timestamp":"2025-12-21T19:27:11.927Z"}
{"action":"add","id":"986be84b-866f-44e3-84d5-385a6575e8bc","subject":"Memory extraction prompt structure: starts with [LOCAL_RECALL_INTERNAL] prefix","keywords":["memory extraction","prompt prefix","internal guard","session guarding"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:22:59.576Z","content_hash":"c21b8e23bfdc0de4","content":"All memory extraction prompts must start with the `[LOCAL_RECALL_INTERNAL]` prefix (on line 62-63 of `buildMemoryExtractionPrompt()`). This prefix is detected by the UserPromptSubmit hook (line 161 of `user-prompt-submit.ts`) to skip processing internal prompts and prevent recursion. Without this prefix, the memory extraction prompt itself will be processed as a regular prompt.","timestamp":"2025-12-21T19:27:11.927Z"}
{"action":"add","id":"8ce487c0-0ddb-4372-b6e4-3ab5f30f3d3d","subject":"Concurrent database access race condition between episodic and thinking hooks","keywords":["mutex","sqlite","race condition","concurrent access","hook","user-prompt-submit"],"applies_to":"global","occurred_at":"2025-12-03T09:49:02.141Z","content_hash":"b04c2c3f14d22115","content":"Both `user-prompt-submit.js` (episodic) and `user-prompt-submit-thinking.js` (thinking) hooks fire simultaneously when a user submits a prompt. Both attempt to open and lock the same `memory.sqlite` database file via different vector store instances (VectorStore and ThinkingVectorStore). This creates a race condition where the sqlite-vec native C++ mutex fails with 'mutex lock failed: Invalid argument'. The solution is to run thinking memory extraction in the daemon instead of the hook, avoiding concurrent database access.","timestamp":"2025-12-21T19:27:11.927Z"}
{"action":"add","id":"148e7dcb-97eb-4716-9151-3008c643de8c","subject":"Plugin configuration points to external hook scripts that must be rebuilt","keywords":["plugin","hooks","configuration","build","rebuild","npm"],"applies_to":"file:dev-marketplace/local-recall-plugin/config/hooks.json","occurred_at":"2025-12-21T18:27:23.198Z","content_hash":"dd9c247f7673e527","content":"The plugin's hooks.json file uses references like '${CLAUDE_PLUGIN_ROOT}/scripts/hooks/...' which point to compiled JavaScript files in the dist/ folder. When updating hook logic in src/, the plugin scripts must be rebuilt (npm run build) for changes to take effect. The hooks configuration should point to user-prompt-submit.js (unified hook) rather than separate episodic/thinking hooks.","timestamp":"2025-12-21T19:27:11.928Z"}
{"action":"add","id":"14cc7859-e661-40db-9e60-9000fff81eb6","subject":"Orama replaced HTTP server - pure JavaScript vector store eliminates concurrency issues","keywords":["orama","vector-store","architecture","http-server","concurrency","pure-javascript"],"applies_to":"global","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"3b96cdd765cbef99","content":"The local-recall project migrated from SQLite + HTTP server to Orama for vector storage. Orama is a pure JavaScript library with no native dependencies, eliminating mutex and process isolation issues. The HTTP server (http-server.ts) is now obsolete - hooks communicate directly with Orama using stdio. The MCP server uses stdio transport for MCP protocol and doesn't need an HTTP health endpoint.","timestamp":"2025-12-21T19:27:11.928Z"}
{"action":"add","id":"3b667a67-272d-4ca0-98a4-fc0b01601e37","subject":"Thinking memories store thought+output pairs in single markdown file","keywords":["thinking memory","thought","output","markdown","format","reasoning"],"applies_to":"file:src/core/thinking-memory.ts","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"cce20f394c7390c9","content":"Thinking memories capture Claude's internal reasoning paired with its actual output. Each thinking memory file contains:\n- YAML frontmatter with metadata (id, subject, applies_to, occurred_at, content_hash)\n- A `## Thought` section with Claude's reasoning/thinking block\n- An `## Output` section with the text response that followed\n\nThis format allows future sessions to see concrete examples of 'how I reasoned â†’ what I produced' for similar tasks. Tool-only responses are skipped during extraction.","timestamp":"2025-12-21T19:27:11.929Z"}
{"action":"add","id":"0dd9f6f1-a9c1-47bd-a5a4-a1e28a22260a","subject":"Hooks execute but return empty stdout - breaks memory injection for users","keywords":["hooks","empty stdout","SessionStart","UserPromptSubmit","bug","memory injection"],"applies_to":"global","occurred_at":"2025-12-21T18:59:35.657Z","content_hash":"3a840d4e0487605b","content":"## Problem\n\nHooks are executing without errors but returning empty stdout, which prevents memory content from being injected into Claude's context. This breaks the entire memory injection system for end users.\n\n## Root Cause\n\nThe hooks are being called correctly by Claude Code, but:\n1. They may not be outputting to stdout properly\n2. The memory files may not exist or be readable\n3. The hook logic may be silently failing without throwing errors\n\n## Impact\n\nWithout proper stdout output, memories are not injected into Claude's context, making the memory system non-functional for users even though the underlying infrastructure works.\n\n## Investigation Points\n\n- Check that hook scripts properly output JSON or memory content to stdout\n- Verify memory files are being created and stored correctly\n- Ensure hooks have proper error handling and logging\n- Test hooks in isolation to verify they output expected data","timestamp":"2025-12-21T19:27:11.929Z"}
{"action":"add","id":"557a30b0-f7d4-45c2-a3a2-f6251c9e9ca6","subject":"Thinking memories should save all thinking but only multiline answers","keywords":["thinking","memory","extraction","transcript","multiline"],"applies_to":"global","occurred_at":"2025-12-21T19:16:05.970Z","content_hash":"1a5aba5cc27a1e5d","content":"When extracting thinking memories from transcripts:\n- Save ALL thinking blocks, even if single-line\n- Only save ANSWERS if they span multiple lines\n- Subject extraction: for multi-line text take first line, for single-line take up to first period or all text if no period present\n\nThis was updated in src/core/types.ts and src/utils/transcript.ts to support separate thinking field and filtering logic.","timestamp":"2025-12-21T19:27:11.929Z"}
{"action":"add","id":"c19cae38-769f-4dc7-8a41-8fe9389addcc","subject":"Plugin cache becomes stale; users must reinstall to get updated versions","keywords":["plugin","cache","reinstall","update","version"],"applies_to":"global","occurred_at":"2025-12-21T19:13:59.315Z","content_hash":"16dc8833c6161a5d","content":"When deploying plugin updates, existing Claude instances will continue using the cached version from `~/.claude/plugins/cache/` even if the plugin source has been fixed. Users must manually uninstall (`/plugins uninstall local-recall`) and reinstall the plugin to get the updated version. This is particularly important when bug fixes affect the bundled server.js or other plugin components.","timestamp":"2025-12-21T19:27:11.930Z"}
{"action":"add","id":"f7d09b83-44b7-498f-9c2b-66350690f3a1","subject":"Mutex lock failed error caused by concurrent sqlite-vec loading across processes","keywords":["sqlite-vec","mutex","concurrency","threading","error","pthread","EINVAL"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"235c60364c642d75","content":"The 'mutex lock failed: Invalid argument' error occurs when multiple processes try to load sqlite-vec simultaneously. The error is a C++ pthread_mutex_lock() returning EINVAL, which happens when a thread attempts to lock an uninitialized or already-destroyed mutex. This occurs because sqlite-vec is a native module that creates static mutexes during initialization, and when multiple processes fork/spawn and try to initialize simultaneously, the mutex state becomes invalid. Solution: Switch from sqlite-vec to pure JavaScript Orama for vector storage to avoid native threading issues entirely.","timestamp":"2025-12-21T19:27:11.930Z"}
{"action":"add","id":"421540b9-d05e-4089-b3fd-a1312020a82c","subject":"Processed log file location and purpose","keywords":["processed-log","json","transcript","daemon","tracking"],"applies_to":"global","occurred_at":"2025-12-21T19:00:14.914Z","content_hash":"3dc5020e8b36fffd","content":"The `processed-log.json` file (or `.jsonl` variants for different memory types) tracks which transcripts have been processed by the memory extraction daemon. This prevents re-processing the same transcripts and allows change detection. The file should be in the `local-recall` folder root and must be gitignored since it's auto-generated by the daemon.","timestamp":"2025-12-21T19:27:11.930Z"}
{"action":"add","id":"828142e7-aed9-48e6-af3e-8163f78a54a2","subject":"MCP server daemon startup timing and intervals","keywords":["mcp","daemon","startup","initialization","timing","transcript","vector sync"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T18:31:15.659Z","content_hash":"4b475f75e391925d","content":"The MCP server daemon runs automatic startup sequences with specific timings:\n\n1. **Vector sync**: Begins 2 seconds after server startup, then runs every 10 minutes\n2. **Transcript processing**: Begins 5 seconds after server startup, then runs every 5 minutes\n\nThese initial delays ensure the server is fully initialized before starting critical background tasks. See lines 169-193 in server.ts for implementation details.","timestamp":"2025-12-21T19:27:11.931Z"}
{"action":"add","id":"aee971a6-4eca-4850-a271-608ef89e331d","subject":"Thinking extractor groups messages by ID from separate JSONL lines","keywords":["thinking-extractor","transcript-parsing","jsonl-format","message-grouping","streaming"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:17:33.752Z","content_hash":"00047c08302feccd","content":"Claude Code streams assistant responses as separate JSONL lines, each with its own content block (thinking, text, tool_use) but sharing the same `message.id`. The thinking extractor must group entries by message.id using a Map to aggregate thinking and text content from multiple lines before processing them together.\n\nExample: thinking block on line 3 and text block on line 4 both have `id: msg_01TriDi1rq2PacC13JUYuvB4`, requiring them to be grouped during parsing.","timestamp":"2025-12-21T19:27:11.931Z"}
{"action":"add","id":"4bf9c8dd-16b3-469a-b11c-9459ed96fbd8","subject":"Claude CLI with --output-format json returns conversation message array, not raw text","keywords":["claude-cli","json-output","parsing","message-array","conversation-format"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:22:56.476Z","content_hash":"47b6eff5b19b45ed","content":"When using `claude -p --output-format json`, the response is an array of conversation messages (not raw text). Each message has `type`, `content` fields. The assistant's text response is nested in `messages[i].content[0].text`. Wrapping this array as `{ memories: array }` incorrectly treats the message array as memory objects. Extract the assistant's text first using the message array format.","timestamp":"2025-12-21T19:27:11.932Z"}
{"action":"add","id":"dd5fa93d-0cc0-48fa-b528-55f8008d8655","subject":"File-based locking mechanism prevents sqlite-vec concurrent loading issues","keywords":["sqlite-vec","mutex lock","concurrency","database","locking","file lock"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-03T09:47:36.366Z","content_hash":"70ef0cea07ebaa62","content":"The C++ sqlite-vec extension throws mutex lock errors when multiple processes try to load it simultaneously during parallel transcript processing. Implemented file-based locking in `src/utils/database.ts` to prevent concurrent sqlite-vec loading:\n\n- Uses a `db-init.lock` file in the memory directory\n- Acquires lock before calling `sqlite-vec.load(db)`\n- Releases lock after initialization\n- Cleans up stale locks (older than 30 seconds)\n- Added try-catch wrapper to gracefully handle extension loading failures\n\nThis prevents the \"unable to open shared object file\" mutex errors when multiple hooks run in parallel.","timestamp":"2025-12-21T19:27:11.932Z"}
{"action":"add","id":"e5b422e4-0bf4-470f-bec5-926d36a459ca","subject":"All 228 tests pass after memory extraction field normalization implementation","keywords":["testing","build-success","memory-extraction","validation"],"applies_to":"global","occurred_at":"2025-12-21T19:16:58.381Z","content_hash":"60eabb39fb3647a2","content":"Successfully implemented field name normalization for memory extraction with all tests passing (228 total). The fix handles Zod validation failures that occurred when Claude returned memory objects with alternative field names. Build completes without errors.","timestamp":"2025-12-21T19:27:11.933Z"}
{"action":"add","id":"c0f6ea44-a7c5-4f8e-9dc6-d1caa21a939c","subject":"Transcript sync improved to check both modification time and file size","keywords":["transcript sync","change detection","file size","mtime","transcript-collector"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:31:46.868Z","content_hash":"e3f38d9d7a6a566d","content":"Enhanced the `syncTranscripts()` method in transcript-collector.ts to detect changes by checking both file modification time (mtime) AND file size, not just mtime alone. This provides more robust change detection:\n\n- Old approach: Only check mtime to determine if transcript needs reprocessing\n- New approach: Check both mtime and size to catch edge cases where timestamps might not update but content has changed\n- Implementation: When syncing, compare stored metadata (mtime, size) with current file stats before processing\n\nThe processed-log and memory-extractor already handle the actual reprocessing via content hash comparison, so this change just improves the initial change detection in the sync phase.","timestamp":"2025-12-21T19:27:11.933Z"}
{"action":"add","id":"865a2c7f-0bb2-4cfc-bcdd-a2908814229e","subject":"Configuration loaded from config.ts with maxMemories setting","keywords":["configuration","config","maxMemories","limits"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T18:19:38.550Z","content_hash":"274d7af78d16a8b0","content":"Configuration is centralized in `src/utils/config.ts` and includes `maxMemories` option (default: 1000). This is referenced in CLAUDE.md documentation as a configuration limit, but there is no active enforcement or cleanup mechanism that removes memories when the limit is exceeded. The configuration exists but is not actively used for memory management.","timestamp":"2025-12-21T19:27:11.933Z"}
{"action":"add","id":"0864e303-d29e-473d-90a8-3198a1b12924","subject":"Episodic memory is disabled by default, must be explicitly enabled","keywords":["episodic","memory","default","configuration","disabled","env-var"],"applies_to":"global","occurred_at":"2025-12-21T19:19:26.883Z","content_hash":"68d07913d41d3854","content":"The `episodicEnabled` configuration defaults to `false` as of this session. Users must explicitly enable episodic memory retrieval by either:\n1. Setting environment variable `LOCAL_RECALL_EPISODIC_ENABLED=true`\n2. Adding `\"episodicEnabled\": true` to their `.local-recall.json` config file\n\nThis default is defined in `src/core/types.ts:118` in the Zod schema definition.\n\nDocumentation for this configuration option is maintained in `CLAUDE.md` in the Configuration Options table.","timestamp":"2025-12-21T19:27:11.934Z"}
{"action":"add","id":"6b2673f6-614f-40bb-af15-62a9b912e9f0","subject":"Local Recall plugin successfully installed and available","keywords":["local-recall","plugin","installation","claude-code"],"applies_to":"global","occurred_at":"2025-12-21T18:16:25.530Z","content_hash":"39d913a2277bb578","content":"Local Recall has been installed as a Claude Code plugin. The plugin is now available and Claude Code needs to be restarted to load the new plugin functionality. This enables access to memory tools and hooks within Claude Code environment.","timestamp":"2025-12-21T19:27:11.934Z"}
{"action":"add","id":"b484fe20-8b2c-486a-b1cf-1a0981ac8638","subject":"Hooks not producing output - empty stdout despite execution","keywords":["hooks","sessionstart","userpromptsubmit","empty stdout","local-recall-plugin","hook_response"],"applies_to":"global","occurred_at":"2025-12-21T18:16:18.307Z","content_hash":"c70172a34d9ccc39","content":"## Problem\nHooks (SessionStart and UserPromptSubmit) are executing but returning empty stdout and stderr, preventing memory injection into Claude's context. The logs show empty `hook_response` values despite hook execution succeeding.\n\n## Root Cause\nThe hooks are likely failing silently before producing output. Common causes:\n1. Ollama not running or inaccessible at `http://localhost:11434`\n2. Missing environment variables or configuration\n3. Errors during embedding generation or vector store operations\n4. Unhandled exceptions that prevent stdout writing\n\n## Investigation Steps\n1. Check if Ollama is running: `ollama serve`\n2. Run hooks directly to see actual error output: `node ./dist/hooks/session-start.js < input.json`\n3. Add logging to hooks to trace execution path\n4. Check if vector indexes exist and are valid JSON\n5. Verify Ollama model is available: `ollama list`\n\n## Key Files\n- `src/hooks/session-start.ts` - Outputs recent memories\n- `src/hooks/user-prompt-submit.ts` - Searches memories and outputs context\n- `src/core/embedding.ts` - Ollama embedding service\n- `src/core/vector-store.ts` - Orama vector store implementation","timestamp":"2025-12-21T19:27:11.934Z"}
{"action":"add","id":"540f7eb4-c24c-439b-acfc-47a71d36a5ae","subject":"Memory extraction prompt updated to accept pre-condensed transcript data instead of raw JSONL","keywords":["memory extraction prompt","prompt optimization","condensed format","claude integration"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T19:26:56.552Z","content_hash":"de50d93a913cac8c","content":"Updated `buildMemoryExtractionPrompt()` to work with condensed transcript data:\n\n1. **Input format changed**: Now accepts `CondensedEvent[]` instead of raw JSONL strings\n2. **Structured format**: Events are pre-parsed with only relevant content included\n3. **Reduced verbosity**: Prompt receives compact event summaries instead of full tool outputs and file contents\n4. **Better context**: Condensed format makes patterns and relationships clearer for Claude to identify memories\n5. **Token efficiency**: Typically 50-70% reduction in tokens passed to the extraction prompt\n\nThe prompt still extracts memories following the same guidelines (subject, keywords, applies_to, content), but now works with higher signal-to-noise ratio data.","timestamp":"2025-12-21T19:27:11.934Z"}
{"action":"add","id":"fa2bd01c-ebab-48e9-8383-398d9c6b6cc4","subject":"MemoryManager must ensure .gitignore exists in parent directory","keywords":["gitignore","memory-manager","initialization","directory-structure"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:15:27.713Z","content_hash":"24bb339ea6ef7e1d","content":"The `MemoryManager` class creates the `local-recall/memories/` directory but wasn't ensuring the `.gitignore` file existed in the parent `local-recall/` directory. This caused the `.gitignore` to not be created unless the `IndexManager` was explicitly invoked first. The fix involves storing the base directory as a class property and calling an `ensureGitignore()` method during initialization to create the parent `.gitignore` file with appropriate ignore patterns for index files and logs.","timestamp":"2025-12-21T19:27:11.935Z"}
{"action":"add","id":"ecc86b0c-0c9d-4af0-b820-99f216efda6d","subject":"Transcript collector fixes for actual Claude project structure","keywords":["transcripts","jsonl files","project path","file discovery","codec"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:18:58.237Z","content_hash":"df1d2b7cd4228dac","content":"The actual Claude project structure stores `.jsonl` transcript files directly in the project folder (e.g., `~/.claude/projects/-Users-joe-Code-Syntessera-local-recall/`), not in a `transcripts` subfolder. The `listSourceTranscripts` method needs to:\n\n1. Look for `.jsonl` files directly in the Claude project directory\n2. Not expect a separate `transcripts` folder\n3. Handle cases where the directory may contain many files (230+ transcripts found in the test case)\n\nDebug logging showed the issue: \"Claude project found but no transcripts folder\" - the folder was being found correctly, but the code was looking for transcripts in the wrong location.","timestamp":"2025-12-21T19:27:11.935Z"}
{"action":"add","id":"9f30d1d6-8bf6-4986-9ed2-d39af0e52f02","subject":"parseTranscriptForMemories() is the main entry point for memory extraction","keywords":["parseTranscriptForMemories","memory","extraction","API","JSONL","transcript"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:26:21.981Z","content_hash":"8188f9530184f70f","content":"The function `parseTranscriptForMemories(rawContent: string): MemorySuggestion[]` (lines 377-413) is the primary interface for extracting memories from transcript files:\n\n1. Takes raw JSONL string as input\n2. Parses each line into transcript entries\n3. Filters for user/assistant messages only\n4. Extracts thinking and text from content blocks\n5. Calls `analyzeForMemories()` to apply filtering rules\n6. Returns array of memory suggestions ready to save\n\nThis is what `stop.ts` should call instead of reimplementing parsing.","timestamp":"2025-12-21T19:27:11.936Z"}
{"action":"add","id":"fd36e1d3-8b36-4181-ad79-44f80e975940","subject":"Orama vector store architecture handles both episodic and thinking memories independently","keywords":["vector-store","orama","episodic","thinking","search","embedding"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:14:44.781Z","content_hash":"e9f6b3427bb59669","content":"The system maintains separate Orama vector stores:\n- `orama-episodic-index.json` for episodic memories (project context, decisions, conventions)\n- `orama-thinking-index.json` for thinking memories (thought + output pairs from previous sessions)\n\nBoth use Ollama embeddings (nomic-embed-text, 768 dimensions) for semantic similarity. Memories are scored using cosine distance (0.0-1.0) with recency tie-breaking when scores are equal. Minimum similarity thresholds are configurable per memory type (default 0.5).","timestamp":"2025-12-21T19:27:11.936Z"}
{"action":"add","id":"cfd2fd28-0bbb-4272-9dea-b6b78819138b","subject":"Memory extractor parseClaudeResponse expects { memories: [...] } but Claude returns raw arrays sometimes","keywords":["memory-extractor","claude-response","parsing","array-wrapper","type-validation"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:26:15.052Z","content_hash":"6506d282342a660d","content":"In `parseClaudeResponse` at line 174, the schema expects an object with a `memories` key (`{ memories: [...] }`), but Claude (especially Haiku) sometimes returns a plain array directly (`[...]`). Added detection to wrap raw arrays in the expected format before validation. This handles the case where Claude returns memory objects as a top-level array instead of nested in an object.\n\nThe fix checks if the parsed JSON is an array and wraps it: `if (Array.isArray(parsed)) { parsed = { memories: parsed }; }`\n\nThis ensures consistent parsing regardless of whether Claude returns the structured format or the simpler array format.","timestamp":"2025-12-21T19:27:11.936Z"}
{"action":"add","id":"3a995e3e-fda9-4212-ba29-16dbcbe33fb8","subject":"TranscriptMessage type now includes optional thinking field","keywords":["types","transcript","thinking","message structure"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:19:48.301Z","content_hash":"be38a9f6d40e23ee","content":"Added optional `thinking?: string` field to the `TranscriptMessage` type to support storing Claude's thinking blocks separately from responses. This allows the system to capture and process thinking independently.","timestamp":"2025-12-21T19:27:11.936Z"}
{"action":"add","id":"1a1ad19e-1bbb-4717-8075-01501cdb8496","subject":"Agent memories require multi-line content to be saved","keywords":["memory extraction","filtering rules","multi-line","agent memories","single-line"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:10:34.378Z","content_hash":"979395aba7f1b61c","content":"Assistant messages must have 2 or more non-empty lines to be saved as memories. Single-line responses are filtered out. This ensures memories capture substantive content and reasoning, not brief acknowledgments or single-sentence responses.","timestamp":"2025-12-21T19:27:11.937Z"}
{"action":"add","id":"d0c56402-51e0-4895-8ab8-d84ed3f04ae0","subject":"stop.ts hook uses analyzeForMemories() from transcript.ts to extract memories","keywords":["stop hook","transcript analysis","memory extraction","hook integration"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-03T09:50:51.143Z","content_hash":"114a0c4b08722b2a","content":"The `stop.ts` hook is responsible for processing transcripts and extracting memories at the end of a session. It calls `analyzeForMemories()` from `src/utils/transcript.ts` to convert transcript messages into memory entries.","timestamp":"2025-12-21T19:27:11.937Z"}
{"action":"add","id":"102e4daf-6c73-4c7d-8267-3170b6bba74b","subject":"UserPromptSubmit hook improved error handling with timing and context information","keywords":["hook","error handling","timeout","initialization timing"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:20:26.357Z","content_hash":"314149bbad9aee27","content":"# UserPromptSubmit Hook Enhanced Logging\n\n## Improvements\n1. **Initialization timing**: Added logging for total hook execution time\n2. **Search operation timing**: Separate timing for episodic and thinking memory searches\n3. **Better error messages**: Include operation context (which memory type, when it failed)\n4. **Graceful failure handling**: Catches and logs errors without crashing\n5. **Configuration visibility**: Logs the actual configuration being used at startup\n\n## Purpose\nAllows debugging of hook performance issues and identifying bottlenecks in memory search operations.","timestamp":"2025-12-21T19:27:11.937Z"}
{"action":"add","id":"dbaf552f-4e8d-46a4-a6f1-e9fb30bf3aae","subject":"JSONL-based memory storage requires proper index syncing after file operations","keywords":["jsonl","memory-storage","index-sync","episodic-memory","vector-store","file-operations"],"applies_to":"global","occurred_at":"2025-12-21T18:23:00.278Z","content_hash":"a5b7c69f160ebdf7","content":"The migration from markdown to JSONL-based memory storage revealed that the vector store index must be synced after file operations to reflect new memories.\n\n**Key insight**: Simply storing memories in JSONL files doesn't automatically make them searchableâ€”they must be explicitly added to the Orama vector store via the `sync()` method.\n\n**Pattern**: When adding memories programmatically:\n1. Write memory to JSONL file\n2. Call `vectorStore.add(memory)` to index the embedding\n3. Call `vectorStore.persist()` to save the updated index\n\nOr use the higher-level `createMemory()` which handles this automatically.\n\n**Files involved**:\n- `src/core/episodic-jsonl-store.ts` - JSONL file operations\n- `src/core/vector-store.ts` - Orama indexing and search\n\n**Gotcha**: If index syncing is skipped, memories exist in JSONL but aren't searchable, leading to silent failures where memories appear to be lost.","timestamp":"2025-12-21T19:27:11.938Z"}
{"action":"add","id":"201aa2e6-1926-4abe-b910-c42ca5d9feaf","subject":"Multiple Claude instances cannot safely share an HTTP daemon on fixed port due to hook execution","keywords":["daemon","http","port","multiple-instances","architecture"],"applies_to":"global","occurred_at":"2025-12-21T19:19:42.881Z","content_hash":"b69f52767b21d92d","content":"Initial proposal to add HTTP server to MCP server won't work for multiple Claude instances because each instance would try to use the same port, creating conflicts. The original daemon concern applies: multiple MCP servers would each try to load ONNX, causing the same mutex problem. The solution must be truly external and shared (like Ollama), not embedded in per-instance services.","timestamp":"2025-12-21T19:27:11.938Z"}
{"action":"add","id":"f4fc0c36-f1de-47fe-944a-643b06ad0045","subject":"Database utility exports three functions for different access patterns","keywords":["database","utility","openDatabase","readonly","concurrency"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-03T09:48:06.256Z","content_hash":"a70bbf19084ffa7b","content":"The database utility (`src/utils/database.ts`) provides:\n\n1. **openDatabase(baseDir, readonly)** - Primary function for opening SQLite connections\n   - Configures busy timeout (30s)\n   - Enables WAL mode\n   - Supports readonly parameter\n   - Used by both vector stores\n\n2. **withRetry()** - Async retry wrapper (not currently used by vector stores due to better-sqlite3 limitations)\n\n3. **withRetrySync()** - Sync retry wrapper (not currently used)\n\n**Design note**: Better-sqlite3 is synchronous, so async retry functions aren't applied. Retries happen at database open-time via busy timeout.","timestamp":"2025-12-21T19:27:11.938Z"}
{"action":"add","id":"5f306c64-7fb3-499f-8d3d-757f98784dd9","subject":"Test coverage for field name normalization in memory extractor","keywords":["memory-extractor","test","field-normalization","unit-test","parsing"],"applies_to":"file:tests/unit/core/memory-extractor.test.ts","occurred_at":"2025-12-21T19:17:04.759Z","content_hash":"1bff069bdbf15ae3","content":"Added comprehensive test coverage for field name normalization in memory extraction (lines 140-275):\n\n- `normalizeMemoryFields()` helper function that mirrors production normalization logic\n- Test suite covering alternative field names: `title` for `subject`, `tags` for `keywords`, `scope` for `applies_to`, `body` for `content`\n- Tests verify partial field coverage works (e.g., mixed standard and alternative names)\n- Tests verify invalid field combinations are rejected\n- All 228 unit tests pass including new normalization tests\n\nThis ensures field normalization is robust and won't break on future Claude response format changes.","timestamp":"2025-12-21T19:27:11.939Z"}
{"action":"add","id":"042cc75f-a2ed-488a-80e8-05d93d488a4e","subject":"Hook configuration and socket communication for Claude Code integration","keywords":["hooks","socket","ipc","config","plugin layer","local recall"],"applies_to":"global","occurred_at":"2025-12-21T19:11:52.152Z","content_hash":"9a48aa36613bf86b","content":"Claude Code's plugin layer communicates with hooks via Unix sockets (or named pipes on Windows). Hooks are invoked as node processes that listen on a socket specified in the hook configuration. The hook output must be JSON with proper `hookSpecificOutput` structure. This is the mechanism by which local-recall injects context into Claude sessions at key moments (SessionStart, UserPromptSubmit).","timestamp":"2025-12-21T19:27:11.939Z"}
{"action":"add","id":"bdfa4357-02dc-45f6-b332-a80cd1b15fe2","subject":"Memories must be deduplicated by occurrence_at timestamp and content_hash to prevent duplicates","keywords":["deduplication","duplicate-detection","content_hash","occurred_at","memory","idempotent"],"applies_to":"area:memory-management","occurred_at":"2025-12-21T19:02:32.602Z","content_hash":"e35bf9c8a8b2b8b6","content":"Memory creation is idempotent - memories are deduplicated based on two fields:\n- `occurred_at` - ISO-8601 timestamp when the original event occurred\n- `content_hash` - SHA-256 prefix (16 characters) of the memory content\n\nBefore creating a new memory, the system checks for existing duplicates using `findDuplicate(occurredAt, contentHash)`. If a duplicate is found, the existing memory ID is returned instead of creating a new one.\n\nThis prevents the same memory from being created multiple times across different sessions, ensuring the memory system remains clean and efficient.","timestamp":"2025-12-21T19:27:11.939Z"}
{"action":"add","id":"6c6ffd12-d6bc-4c9a-b805-e9a84f2a493d","subject":"analyzeForMemories filters out single-line content to focus on substantial thinking","keywords":["thinking extraction","memory analysis","content filtering"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:30:41.521Z","content_hash":"890e0c610f53f804","content":"The `analyzeForMemories` function only saves thinking memories when:\n1. Content is **multi-line** (contains newlines)\n2. Thinking is present and extracted\n\nThis is intentional - single-line responses typically don't represent meaningful reasoning worth capturing. This reduces noise in thinking memories while keeping valuable reasoning patterns.","timestamp":"2025-12-21T19:27:11.940Z"}
{"action":"add","id":"8e8cd1f0-4374-4f81-a214-3e0455388750","subject":"GitHub Copilot inline suggestions visible in IDE but not accessible via MCP","keywords":["github","copilot","mcp","inline suggestions","ide integration"],"applies_to":"global","occurred_at":"2025-12-21T19:26:45.176Z","content_hash":"8a82495f46aaacd8","content":"GitHub Copilot inline suggestions appear directly in the IDE but are not accessible through MCP servers or Claude Code tools. To access Copilot suggestions or PR comments programmatically, a GitHub MCP server needs to be configured in `.claude/settings.json`. Copilot suggestions are IDE-local features, not exposed through standard APIs.","timestamp":"2025-12-21T19:27:11.940Z"}
{"action":"add","id":"0a498193-309a-4874-bc26-4a73ae176094","subject":"Stale MCP server processes can be identified by duplicate log entries","keywords":["logging","duplicate entries","stale processes","recall.log","debugging"],"applies_to":"global","occurred_at":"2025-12-21T18:31:23.288Z","content_hash":"8deb27e6360dbbca","content":"If `local-recall/recall.log` shows duplicate log entries, it indicates multiple MCP server instances are running for the same project and both writing to the log file. This typically happens when code is rebuilt but old server processes aren't killed. Check timestamps of source files vs dist files to identify if running against stale compiled code.","timestamp":"2025-12-21T19:27:11.940Z"}
{"action":"add","id":"a0f75652-42ce-442b-bd83-b61473824bfd","subject":"Synthetic transcript filtering happens after copying, not before","keywords":["synthetic transcripts","transcript-collector","transcript sync","filtering","cleanup"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:28:15.275Z","content_hash":"afe52bceb413e4ad","content":"The transcript collector's `syncTranscripts()` method (line 239) was copying synthetic transcripts from Claude's cache before cleaning them up. This created unnecessary I/O operations.\n\nThe fix checks `isSyntheticFile(transcript.sourcePath)` BEFORE copying each transcript (similar to how `cleanupTranscripts()` removes synthetic files after the fact).\n\nOptimal flow:\n1. `cleanupTranscripts()` removes any synthetic files that already exist locally\n2. For each new/modified source transcript, check if synthetic before copying\n3. Only copy non-synthetic transcripts\n4. This avoids wasted I/O from copying files destined for deletion\n\nThis is a performance optimization that reduces unnecessary file I/O during the sync process.","timestamp":"2025-12-21T19:27:11.941Z"}
{"action":"add","id":"d5d09b5f-b9da-4280-bed5-bfd3feca4c23","subject":"Mutex lock failed error caused by concurrent sqlite-vec loading across processes","keywords":["sqlite-vec","mutex","concurrency","threading","error","pthread","EINVAL"],"applies_to":"global","occurred_at":"2025-12-21T18:28:54.683Z","content_hash":"0d7b09e4c8b59ba1","content":"The 'mutex lock failed: Invalid argument' error occurs when multiple processes try to load sqlite-vec simultaneously. The error is a C++ pthread_mutex_lock() returning EINVAL, which happens when a thread attempts to lock a mutex that was destroyed or is in an invalid state.\n\n**Root Cause**: When the MCP server daemon and hooks run concurrently, both try to load the sqlite-vec module. The native binding gets partially initialized by one process, then the second process tries to use a destroyed mutex.\n\n**Solution Applied**: Migrate from sqlite-vec (C++ bindings) to Orama (pure JavaScript). This eliminates the mutex issue entirely since Orama has no native dependencies.\n\n**Migration Details**:\n- Replaced `src/core/vector-store.ts` implementation to use Orama instead of sqlite-vec\n- Updated embedding generation to work with Orama's JSON format\n- Changed index persistence from SQLite database to JSON file (`orama-*-index.json`)\n- Simplified thread safety - no more native mutex concerns\n\n**Status**: Migration complete and tested. Orama is now the primary vector storage backend.","timestamp":"2025-12-21T19:27:11.941Z"}
{"action":"add","id":"0e34e5cd-5d6f-4001-89f9-46d09840497c","subject":"Embeddings should be stored in JSONL files alongside Orama index","keywords":["embeddings","jsonl","storage","vector","persistence"],"applies_to":"global","occurred_at":"2025-12-21T19:13:54.006Z","content_hash":"8621b2b83630b300","content":"Current implementation stores embeddings only in the Orama index (orama-episodic-index.json, orama-thinking-index.json) files. Expected behavior: embeddings should be persisted within the JSONL files themselves as a field in each record. This ensures embeddings are part of the versioned memory storage, not just in the gitignored index files, improving portability and reproducibility.","timestamp":"2025-12-21T19:27:11.941Z"}
{"action":"add","id":"074e4f37-857c-4c36-bba2-b99800bcdbc7","subject":"Episodic memories default configuration changed from disabled to enabled","keywords":["episodic","default","configuration","enabled","memory","retrieval"],"applies_to":"global","occurred_at":"2025-12-03T11:22:46.856Z","content_hash":"bca572351de89c4f","content":"The default value for `episodicEnabled` has been changed from `false` to `true` in the codebase. This affects:\n\n1. **Schema definition** (`src/core/types.ts:118`): The Zod schema now defaults `episodicEnabled` to `true`\n2. **Documentation** (`CLAUDE.md`): The configuration table has been updated to reflect the new default\n\nBoth episodic and thinking memories are now enabled by default without requiring explicit configuration. This means that unless a user explicitly disables episodic memory retrieval via environment variables or `.local-recall.json`, the system will retrieve and inject episodic memories during sessions.","timestamp":"2025-12-21T19:27:11.942Z"}
{"action":"add","id":"b8a5d388-ceb6-4015-87ed-c30579f4da37","subject":"Configuration supports environment variables and .local-recall.json file","keywords":["configuration","environment-variables","config-file","settings","local-recall-json"],"applies_to":"file:src/utils/config.ts","occurred_at":"2025-12-21T18:23:39.604Z","content_hash":"284848f207d07ebd","content":"Configuration can be set via environment variables (e.g., `LOCAL_RECALL_DIR`, `LOCAL_RECALL_EPISODIC_MAX_TOKENS`) or a `.local-recall.json` file in the project root. Environment variables take precedence over the config file. Common settings include memory directory, max memories limit, and threshold settings for episodic/thinking memory retrieval.","timestamp":"2025-12-21T19:27:11.943Z"}
{"action":"add","id":"e8b668a9-f0f7-425b-8d44-17ec737fb938","subject":"Synthetic transcripts marked with '<synthetic>' model should be excluded from processing","keywords":["synthetic","transcripts","filter","memory extraction","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T18:15:46.377Z","content_hash":"4dd71de6ee9d0756","content":"Synthetic transcripts are generated during memory extraction and use the model marker '<synthetic>'. These files should be excluded from all processing pipelines.\n\nImplementation:\n- Added `isSyntheticTranscript()` method to TranscriptCollector to detect synthetic files\n- Added early exit checks in both ThinkingExtractor.processTranscript() and MemoryExtractor.processTranscript()\n- Added `cleanupTranscripts()` method that removes both malformed files and synthetic transcripts\n- Cleanup runs automatically at start of syncTranscripts()\n\nStats: 12,594 synthetic files out of 39,879 total transcripts need to be filtered.","timestamp":"2025-12-21T19:27:11.943Z"}
{"action":"add","id":"97c64b36-550e-4d52-82be-9e3919a3b5af","subject":"Plugin hooks were using stale better-sqlite3 dependency that was replaced with Orama","keywords":["plugin","hooks","better-sqlite3","orama","migration","stale-code"],"applies_to":"area:plugin-integration","occurred_at":"2025-12-21T18:29:21.341Z","content_hash":"c98e5a7bde5c8d8f","content":"The dev-marketplace/local-recall-plugin had stale hook files (user-prompt-submit-thinking.js) that tried to import better-sqlite3, a native module that cannot be bundled. The main codebase migrated from better-sqlite3 to Orama (pure JavaScript vector store) but the plugin's hooks.json still referenced the old thinking hook file. The fix involved:\n\n1. Removing the stale user-prompt-submit-thinking.js file\n2. Updating hooks.json to point to user-prompt-submit.js (which handles both episodic and thinking memories via configuration)\n3. Rebuilding the plugin scripts\n\nKey lesson: Plugin bundled hooks should be kept in sync with main project migrations, especially when swapping dependencies from native modules (better-sqlite3) to pure JavaScript (Orama).","timestamp":"2025-12-21T19:27:11.944Z"}
{"action":"add","id":"6bbe8d9f-e0df-4748-aae3-5a565989d0a3","subject":"Transcript condenser reduces token usage for memory extraction by 60-80%","keywords":["transcript-condenser","token-optimization","memory-extraction","performance","JSONL-parsing"],"applies_to":"global","occurred_at":"2025-12-21T18:31:32.415Z","content_hash":"cb966eb9dd75dc27","content":"Implemented a transcript condenser (`src/core/transcript-condenser.ts`) that parses raw JSONL transcripts and extracts only essential content for memory creation. Instead of passing entire transcript lines to Claude for memory extraction, the condenser:\n\n1. Parses JSONL using TypeScript types defined in `src/types/transcript-schema.ts`\n2. Filters and extracts minimum necessary content from each event type:\n   - **User/Assistant**: Message text only (no metadata)\n   - **Tool invocations**: Tool name + relevant params only\n   - **Results**: Success/error status + key output (not full output)\n   - **Thinking blocks**: Condensed thinking summary\n3. Creates structured `CondensedTranscript` objects with parsed events\n4. Passes condensed data to memory extractor instead of raw JSONL\n\nThis approach dramatically reduces token usage (estimated 60-80% reduction) and improves extraction speed while maintaining context quality for memory creation.","timestamp":"2025-12-21T19:27:11.944Z"}
{"action":"add","id":"fbb34769-0ecf-4552-9b17-68db756e0d78","subject":"sqlite-vec requires explicit k parameter in vector similarity queries","keywords":["sqlite-vec","query","limit","vector-search","k-parameter"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:17:55.902Z","content_hash":"13695186cf295fda","content":"sqlite-vec extension requires 'k = ?' parameter in the match() function for JOIN queries. When combining vector similarity with WHERE filters (like scope), the k limit is applied before the JOIN, so some matching vectors may be excluded. Solution: fetch k results without WHERE filter, then filter results in JavaScript code.","timestamp":"2025-12-21T19:27:11.944Z"}
{"action":"add","id":"1dc10b04-fddf-4e0f-9c7c-140e8fa0307f","subject":"Transcript JSONL format uses separate lines for each content block with shared message.id","keywords":["transcript format","jsonl","content blocks","message id","streaming","structure"],"applies_to":"file:src/types/transcript-schema.ts","occurred_at":"2025-12-21T19:15:00.052Z","content_hash":"41b6fb102ccd20ce","content":"Claude Code transcripts are stored as JSONL where each line is a complete event. Multiple content blocks (thinking, text, tool_use) from a single assistant message are stored as separate JSONL lines but share the same `message.id`.\n\nExample:\n- Line N: {type: 'message', message: {id: 'msg_XXX', content: [{type: 'thinking', ...}]}}\n- Line N+1: {type: 'message', message: {id: 'msg_XXX', content: [{type: 'text', ...}]}}\n- Line N+2: {type: 'message', message: {id: 'msg_XXX', content: [{type: 'tool_use', ...}]}}\n\nProcessing requires grouping entries by message.id to reconstruct complete messages.","timestamp":"2025-12-21T19:27:11.945Z"}
{"action":"add","id":"a29c4664-e008-43fa-b9b6-f9aaacdd40d2","subject":"Implemented proper-lockfile for serializing fastembed access","keywords":["proper-lockfile","file-based lock","embedding.ts","mutex","synchronization"],"applies_to":"file:src/core/embedding.ts","occurred_at":"2025-12-21T19:21:45.415Z","content_hash":"9e1f27214a11db51","content":"Added file-based locking using `proper-lockfile` to prevent concurrent access to fastembed/onnxruntime-node:\n\n- Lock file location: `/tmp/local-recall-embedding.lock`\n- Retries: 10 with exponential backoff (100ms - 2s)\n- Stale lock timeout: 30 seconds\n- Locked operations: Both `initialize()` and `embed()` methods\n\nThis serializes concurrent hook processes so only one at a time loads or uses the native onnxruntime module, preventing mutex errors.","timestamp":"2025-12-21T19:27:11.945Z"}
{"action":"add","id":"8a92b0c4-0a32-4c09-b840-2b725bdbdba9","subject":"Project structure uses dev-marketplace and hooks directories with configuration files","keywords":["project-structure","directory-layout","hooks","plugin","configuration"],"applies_to":"global","occurred_at":"2025-12-21T18:21:41.992Z","content_hash":"e98ac8be617b8308","content":"The Local Recall codebase has a specific directory structure:\n\n- `src/hooks/` - Contains hook implementations (session-start, stop, etc.)\n- `src/core/` - Core functionality (memory.ts, index.ts, search.ts)\n- `src/utils/` - Utility functions including `transcript.ts` for parsing transcripts\n- `dev-marketplace/local-recall-plugin/` - Plugin packaging and configuration\n- `dev-marketplace/local-recall-plugin/config/hooks.json` - Hook configuration file\n- Tests organized in `tests/integration/` for integration testing\n\nThe transcript parsing and memory extraction uses `analyzeForMemories()` function in `src/utils/transcript.ts` (line 105).","timestamp":"2025-12-21T19:27:11.945Z"}
{"action":"add","id":"866d370c-a3c2-41a1-a1d7-3785fd0775c3","subject":"Hooks architecture with three integration points for Claude Code","keywords":["hooks","session-start","user-prompt-submit","stop","claude code integration","context injection"],"applies_to":"global","occurred_at":"2025-12-21T18:19:38.550Z","content_hash":"2dc8594bd999b9c9","content":"Local Recall has three hooks that integrate with Claude Code:\n\n1. **SessionStart Hook** (`src/hooks/session-start.ts`): Triggered when a Claude Code session begins. Loads memory index, searches for relevant memories, and outputs them to stdout for context injection. Shows index stats (total memories).\n\n2. **UserPromptSubmit Hook** (`src/hooks/user-prompt-submit.ts`): Triggered when user submits a prompt. Handles semantic search and memory retrieval before Claude processes the prompt.\n\n3. **Stop Hook** (`src/hooks/stop.ts`): Executes when session ends. Used for transcript collection and memory extraction from session transcripts.\n\nAll hooks use stdout to inject memories into Claude's context.","timestamp":"2025-12-21T19:27:11.946Z"}
{"action":"add","id":"b419f1a7-ca36-4148-8816-025329fdbec6","subject":"Current implementation uses cross-process file locking for sqlite-vec coordination","keywords":["file locking","sqlite-vec","mutex","cross-process","synchronization"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T18:23:08.846Z","content_hash":"2016c14b3acff4cb","content":"The MCP server at line 230 implements cross-process file locking to prevent sqlite-vec mutex errors. This is the current mitigation strategy for coordinating access when multiple processes might load the sqlite-vec library simultaneously.","timestamp":"2025-12-21T19:27:11.947Z"}
{"action":"add","id":"fe2686eb-a9a9-45a9-baf6-965fab8e31d5","subject":"Debug logging added to memory search in hooks with memory details","keywords":["logging","debug","hooks","memory search","transparency"],"applies_to":"file:src/hooks/user-prompt-submit.ts|file:src/hooks/user-prompt-submit-thinking.ts","occurred_at":"2025-12-21T19:04:16.673Z","content_hash":"0d6ca21690e38283","content":"## Memory Search Debug Logging\n\nAdded detailed logging when memories are retrieved during hook execution.\n\n### What Gets Logged\nFor each matched memory from semantic search, the following information is logged:\n- Memory ID (filename without extension)\n- Similarity score (as percentage)\n- Memory subject/title\n\n**Format**: `{id}.md | {similarity}% | \"{subject}\"`\n\n### Location\n- Episodic search: `src/hooks/user-prompt-submit.ts`\n- Thinking search: `src/hooks/user-prompt-submit-thinking.ts`\n\n### Purpose\nProvides visibility into which memories were matched and how confident the similarity score is, useful for debugging memory retrieval quality and understanding what context was injected.","timestamp":"2025-12-21T19:27:11.947Z"}
{"action":"add","id":"7bba495e-0d79-4e25-995f-6205be39fc15","subject":"Added local_cache/ to .gitignore to prevent accidental commits","keywords":["gitignore","local_cache","cache","build artifacts"],"applies_to":"file:.gitignore","occurred_at":"2025-12-21T19:12:57.471Z","content_hash":"19376090240d3b0d","content":"Added `local_cache/` to the `.gitignore` file to exclude temporary cache files from version control. This is a critical entry to prevent build artifacts and temporary files from being accidentally committed to the repository in future sessions.","timestamp":"2025-12-21T19:27:11.948Z"}
{"action":"add","id":"062fe53e-e076-4f08-bf72-339608d1221d","subject":"Git status shows JSONL storage migration in progress","keywords":["jsonl","storage","migration","format-change","episodic-jsonl-store","thinking-jsonl-store"],"applies_to":"global","occurred_at":"2025-12-21T18:24:32.614Z","content_hash":"36c0bd0319128d78","content":"# Storage Format Migration\n\nThe codebase is migrating to JSONL storage format for memories. Key files modified:\n\n- `src/core/episodic-jsonl-store.ts` - New JSONL storage for episodic memories\n- `src/core/thinking-jsonl-store.ts` - New JSONL storage for thinking memories  \n- `src/core/jsonl-store.ts` - Base JSONL storage implementation\n- `tests/unit/core/episodic-jsonl-store.test.ts` - Tests for new storage\n\nThis represents a format change from the existing markdown-based storage described in CLAUDE.md. The JSONL format likely provides better performance for large memory collections and easier batch operations.","timestamp":"2025-12-21T19:27:11.948Z"}
{"action":"add","id":"6afb3e1b-8d28-49df-89ab-f992fa986c98","subject":"Thinking extractor requires explicit initialization in daemon loop before use","keywords":["thinking-extractor","initialization","vector-store","daemon","setup"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:23:44.640Z","content_hash":"57228d21f4178041","content":"The `ThinkingExtractor` requires initialization before being called in the daemon:\n1. `getThinkingVectorStore()` must be initialized first\n2. `ThinkingMemoryManager` must be instantiated\n3. `runThinkingExtraction()` is then invoked with these initialized components\n\nThis is done in the daemon loop in `src/mcp-server/server.ts` to ensure the thinking extractor has all required dependencies before execution.","timestamp":"2025-12-21T19:27:11.948Z"}
{"action":"add","id":"32744b1b-92b9-455f-8d64-be8a6da572c6","subject":"Plugin version is maintained in two locations for consistency","keywords":["version","plugin","package.json","plugin.json","semver"],"applies_to":"global","occurred_at":"2025-12-21T18:25:21.454Z","content_hash":"348db1dc1c1f3b75","content":"The plugin version must be updated in both `package.json` and `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` to keep them in sync. When bumping versions, update both files to avoid version mismatches between the npm package and the Claude plugin manifest.","timestamp":"2025-12-21T19:27:11.949Z"}
{"action":"add","id":"28efbfe6-3920-436e-8840-24885180b290","subject":"analyzeForMemories only saves multi-line content messages","keywords":["memory-extraction","content-filtering","multi-line","analysis"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:28:33.686Z","content_hash":"bf77019177c3e6e3","content":"The `analyzeForMemories` function filters messages and only saves those with multi-line content (2+ lines when split by newline). Single-line messages are skipped. This prevents trivial or incomplete responses from becoming memories.\n\nThe function correctly extracts thinking from messages and creates separate memory records for substantive responses. Tests should use multi-line content when testing memory creation.","timestamp":"2025-12-21T19:27:11.949Z"}
{"action":"add","id":"00d8c2e0-b0d2-4ee1-b203-e2eb013e004a","subject":"Thinking memory extraction shows 67% similarity scores in context injection","keywords":["thinking memory","similarity threshold","context injection","relevance scoring","previous thoughts"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:21:34.993Z","content_hash":"f354a27aa251ff43","content":"When thinking memories are injected into context via the UserPromptSubmit hook, they appear under a \"Local Recall: Previous Thoughts\" heading with similarity scores. During testing, multiple thinking excerpts appeared with 67% similarity scores, which suggests:\n\n1. The similarity threshold filtering is working (default 0.5 or 50%)\n2. Multiple thinking excerpts can relate to the same task at similar relevance levels\n3. The thinking memory retrieval successfully finds related past reasoning patterns\n\nThis validates that the thinking memory system is correctly matching user queries to previous thought+output pairs from past sessions.","timestamp":"2025-12-21T19:27:11.949Z"}
{"action":"add","id":"00f1104f-73cf-4e40-bd20-4a600242190e","subject":"Filter transcripts to only copy those containing thinking blocks","keywords":["transcript-collector","thinking blocks","sync transcripts","haiku transcripts","filtering"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:15:34.664Z","content_hash":"18c5be3c59d056c4","content":"Added filtering to `syncTranscripts()` to skip copying transcripts that don't contain thinking blocks. This excludes haiku (non-thinking) transcripts from being copied to the local cache.\n\nImplementation:\n- Added `hasThinkingBlocks()` method that checks for `\"type\":\"thinking\"` in transcript content blocks\n- Updated `syncTranscripts()` to skip non-thinking transcripts with debug logging\n- Updated `cleanupTranscripts()` to also remove previously copied transcripts without thinking blocks\n\nThis optimization reduces storage overhead by only retaining transcripts that contain Claude's reasoning (thinking blocks), which are the primary source for thinking memory extraction.","timestamp":"2025-12-21T19:27:11.950Z"}
{"action":"add","id":"d342777e-8a24-4b15-b30a-99fe8c4262ca","subject":"Ollama required for embeddings with nomic-embed-text model (768 dimensions)","keywords":["ollama","embeddings","nomic-embed-text","768-dimensions","vector-embeddings"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"c720ce83cd70f8a5","content":"Local Recall uses Ollama for generating vector embeddings. Prerequisites:\n1. Install Ollama: https://ollama.com\n2. Pull model: `ollama pull nomic-embed-text`\n3. Run server: `ollama serve`\n\nConfiguration:\n- `OLLAMA_BASE_URL`: Default `http://localhost:11434`\n- `OLLAMA_EMBED_MODEL`: Default `nomic-embed-text`\n\nModel info: nomic-embed-text produces 768-dimensional vectors. Significantly larger than previous fastembed model (BGE-small-en-v1.5: 384 dimensions), so vector indexes must be rebuilt when migrating.","timestamp":"2025-12-21T19:27:11.950Z"}
{"action":"add","id":"298be43a-c284-4e6f-95e0-602bf2bd9787","subject":"Transcript sync now filters synthetic transcripts before copying","keywords":["transcript-collector","synthetic","sync","optimization","filtering"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:30:22.170Z","content_hash":"15be961334e4fe10","content":"The `syncTranscripts()` method in transcript-collector.ts was updated to check if source transcripts are synthetic BEFORE copying them from Claude's cache. Previously, synthetic transcripts could be copied and then deleted during cleanup, causing unnecessary I/O. Now the flow is:\n\n1. `cleanupTranscripts()` runs first to remove any previously-copied synthetic files\n2. For each new/modified transcript, checks `isSyntheticFile(transcript.sourcePath)` before copying\n3. Skips synthetic files with a debug log\n\nThis optimization prevents unnecessary file I/O and keeps the transcript sync process cleaner.","timestamp":"2025-12-21T19:27:11.950Z"}
{"action":"add","id":"091efc9d-7f15-4af0-9d76-837eaf2f7447","subject":"Memory extraction validation uses Zod schema with required string fields","keywords":["zod","schema","validation","memory","types"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:17:04.759Z","content_hash":"46de01ae00865dd1","content":"Memory objects must pass Zod validation with all required fields being non-empty strings:\n- `subject`: string (one-line description)\n- `keywords`: array of strings (searchable tags)\n- `applies_to`: string (scope: `global`, `file:path`, or `area:name`)\n- `content`: string (markdown-formatted memory content)\n\nThis validation occurs after field normalization (line 188) and is strict - any missing or undefined fields cause validation failure. The extraction pipeline must either produce valid memories or return empty array.","timestamp":"2025-12-21T19:27:11.951Z"}
{"action":"add","id":"e431219a-44c4-4afe-a72a-cddb587174cb","subject":"Deduplication implemented in thinking-extractor.ts to remove duplicate thinking/text blocks","keywords":["deduplication","thinking-extractor","streaming","Set","performance"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T19:24:36.877Z","content_hash":"316be172b8e42a5a","content":"Added deduplication logic at lines 146-148 using JavaScript Set to filter out duplicate thinking and text parts before joining them. This prevents memories from containing repeated content that occurs due to streaming artifacts. The fix uses `[...new Set(array)]` pattern to maintain order while removing duplicates. All 288 tests pass after this change.","timestamp":"2025-12-21T19:27:11.951Z"}
{"action":"add","id":"1be1e920-b914-4499-965b-021e38dfcb41","subject":"Thinking memories should save all thinking including single-line, but only multiline answers","keywords":["thinking","memory extraction","transcript analysis","multiline","singleline"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:15:55.194Z","content_hash":"7ba7305d86656dec","content":"When extracting memories from transcripts:\n- Save ALL thinking blocks (even single-line ones)\n- Save ONLY multiline answers (content with 2+ lines)\n- Subject should be just the first sentence without modification\n- This was implemented in analyzeForMemories function at src/utils/transcript.ts:169-192","timestamp":"2025-12-21T19:27:11.952Z"}
{"action":"add","id":"02bde220-1d42-4fef-9ff2-8f9367718078","subject":"Thinking extractor fix: Claude Code streams thinking and text as separate JSONL lines","keywords":["thinking","transcript","jsonl","streaming","message-id","grouping"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:16:42.322Z","content_hash":"23e48fae68cfdac4","content":"Claude Code streams assistant responses as separate JSONL lines - each content block gets its own line. The thinking block and text output are on different lines but share the same `message.id`. The thinking extractor must group entries by message ID using a Map to aggregate thinking and text content from the same message, not expect them in the same content array.","timestamp":"2025-12-21T19:27:11.952Z"}
{"action":"add","id":"0893617d-921d-4a63-ae2b-5698e833999b","subject":"CLAUDE.md documentation updated to reflect unified hook and new configuration options","keywords":["documentation","hooks","configuration","environment-variables"],"applies_to":"file:CLAUDE.md","occurred_at":"2025-12-03T09:50:15.512Z","content_hash":"c3289b375811f8b3","content":"Updated CLAUDE.md to document:\n1. The unified UserPromptSubmit hook that handles both episodic and thinking memories based on configuration\n2. New configuration options for token limits and similarity thresholds for both memory types\n3. How the hook dynamically selects which memory types to search based on `episodicEnabled` and `thinkingEnabled` flags\n4. Default values for all new configuration options","timestamp":"2025-12-21T19:27:11.955Z"}
{"action":"add","id":"6d6005ab-941b-4986-b4ab-b5896388cd05","subject":"ToolResultContent.content can be array of content blocks, not just string","keywords":["transcript","tool-result","type-safety","content-blocks","bug","runtime"],"applies_to":"file:src/core/transcript-condenser.ts","occurred_at":"2025-12-20T22:38:28.607Z","content_hash":"8276022f62e089fe","content":"The TypeScript type definition for `ToolResultContent.content` is `string`, but Claude's actual transcript format can provide content as either a string OR an array of content blocks (for multi-part results like images + text).\n\nThis caused a runtime crash when calling `.toLowerCase()` on non-string content in the `isErrorResult()` function at line 205. The fix requires type guards to check if content is a string before calling string methods, or converting arrays to string representation.","timestamp":"2025-12-21T19:27:11.955Z"}
{"action":"add","id":"9f3457cc-3f5d-4740-9271-d18bae2a4829","subject":"Session started with transcript analysis for memory extraction","keywords":["session-start","memory-extraction","transcript-analysis"],"applies_to":"global","occurred_at":"2025-12-21T19:16:48.996Z","content_hash":"d901aac685e81a65","content":"The user initiated a session where Claude is analyzing a transcript to extract memories. The system is set up to extract valuable insights from Claude Code sessions that help future AI assistants working on the codebase. This is part of the local-recall project's memory management system.","timestamp":"2025-12-21T19:27:11.956Z"}
{"action":"add","id":"25390e41-5049-4e20-af49-d1c1195c06af","subject":"Memory extractor parseClaudeResponse must handle Claude returning memories as plain array","keywords":["memory-extractor","parsing","claude-response","array-handling","zod-validation"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:23:45.023Z","content_hash":"6577d927381b3e75","content":"The `parseClaudeResponse` function in memory-extractor.ts expected Claude to always return `{ memories: [...] }` format, but Claude Haiku sometimes returns a plain array `[{...}, {...}]` directly. Fixed by adding array detection at line 174-177 that wraps raw arrays in the expected format before Zod validation. This prevents 'Expected object, received array' errors during memory extraction.","timestamp":"2025-12-21T19:27:11.956Z"}
{"action":"add","id":"79d9d1e3-5d39-44e3-b1cb-fedc2303a1ca","subject":"UserPromptSubmit hook unifies episodic and thinking memory search","keywords":["UserPromptSubmit","semantic search","episodic","thinking","unified","Orama"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:59:30.332Z","content_hash":"e83f302cf326563e","content":"The UserPromptSubmit hook implements a unified search strategy:\n1. Searches both episodic and thinking memories based on configuration flags\n2. Uses Orama vector store + Ollama embeddings for semantic similarity\n3. Filters by minimum similarity threshold (default 0.5)\n4. Respects token budgets for each memory type\n5. Skips internal prompts containing `[LOCAL_RECALL_INTERNAL]`\n6. Outputs combined results to stdout\n\nEach memory type has independent configuration for enabled/disabled, max tokens, and min similarity.","timestamp":"2025-12-21T19:27:11.957Z"}
{"action":"add","id":"510c51ab-5ea4-4927-b66a-f3fc987b09c3","subject":"Session startup loads all memories at once, not as delta","keywords":["session start","hook","memory loading","full reload","delta"],"applies_to":"global","occurred_at":"2025-12-21T18:25:49.095Z","content_hash":"48f55156225b456c","content":"The SessionStart hook in `src/hooks/session-start.ts` performs a **full reload** of memories on each session, not a delta. It creates a fresh `MemoryManager` instance, loads all memories, sorts by `occurred_at` descending, and injects the 5 most recent memories into context. No incremental/delta loading mechanism exists.","timestamp":"2025-12-21T19:27:11.959Z"}
{"action":"add","id":"36b63dfb-7990-48d4-8f0a-d2e37e96d75a","subject":"Plugin version location and format","keywords":["version bump","plugin.json","package.json","versioning"],"applies_to":"global","occurred_at":"2025-12-21T19:19:51.719Z","content_hash":"f050a55c4b9bf47b","content":"Plugin version is maintained in two locations and must be kept in sync:\n1. `package.json` - Main package version\n2. `dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json` - Plugin manifest version\n\nBoth must be updated together when bumping versions. Current version tracking pattern: `0.1.1` â†’ `0.1.2`","timestamp":"2025-12-21T19:27:11.960Z"}
{"action":"add","id":"43488c77-a31e-4c4d-b9c3-c19658d2c898","subject":"Memory-extractor processes transcript code blocks with markdown stripping","keywords":["memory-extractor","code-blocks","markdown","transcript-processing","text-cleaning"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:58:55.753Z","content_hash":"3f90dabe009a5563","content":"The `stripMarkdownCodeBlocks()` method in memory-extractor.ts is used to clean transcript text by removing markdown code blocks. This is a utility function that processes text during transcript analysis for memory extraction, indicating that transcripts may contain markdown-formatted code blocks that need to be handled carefully when extracting memories.","timestamp":"2025-12-21T19:27:11.960Z"}
{"action":"add","id":"fe423bd8-fad1-44d6-a268-1a59be58d547","subject":"Session guarding requires [LOCAL_RECALL_INTERNAL] prefix on memory extraction prompts","keywords":["session guarding","memory extraction","internal prompt","recursion prevention","user prompt submit hook"],"applies_to":"global","occurred_at":"2025-12-21T18:29:11.578Z","content_hash":"4f73fd3e76a00614","content":"The UserPromptSubmit hook filters prompts with `[LOCAL_RECALL_INTERNAL]` prefix to prevent recursive processing of internal memory extraction prompts. The memory extraction prompt in `buildMemoryExtractionPrompt()` must include this prefix, otherwise the MCP daemon's `claude -p` calls for memory extraction will trigger the hook and create unwanted recursion. The guard is checked at line 161 of `user-prompt-submit.ts`.","timestamp":"2025-12-21T19:27:11.960Z"}
{"action":"add","id":"b4d577ba-30b4-4bcc-b945-df0fd670d951","subject":".gitignore configuration for local-recall project should exclude cache and index files","keywords":["gitignore","local-recall","episodic-memory","thinking-memory","index files"],"applies_to":"file:/Users/joe/Code/Syntessera/local-recall/.gitignore","occurred_at":"2025-12-03T12:59:07.634Z","content_hash":"d7357c0085c846bc","content":"The .gitignore in the local-recall project should include:\n- `local_cache/` - Ollama model cache and dependencies\n- `orama-episodic-index.json` - Generated vector index (auto-created)\n- `orama-thinking-index.json` - Generated vector index (auto-created)\n- `recall.log` - Debug log file\n\nThese are all auto-generated files that should not be version-controlled.","timestamp":"2025-12-21T19:27:11.961Z"}
{"action":"add","id":"03d8e35f-fcff-4f42-affe-047b677e965e","subject":"Memory types enabled by default in configuration","keywords":["episodicEnabled","thinkingEnabled","default configuration","types.ts","memory settings"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:25:33.738Z","content_hash":"ef86394602e625a0","content":"Both episodicEnabled and thinkingEnabled are set to true by default in src/core/types.ts (lines 118-121). This means all memory types are active by default when the package is used, requiring no additional configuration for users to benefit from both episodic and thinking memories.","timestamp":"2025-12-21T19:27:11.961Z"}
{"action":"add","id":"7473fdd8-91aa-4ebf-a0f4-fb200473edc0","subject":"MCP server distribution requires git-tracked scripts for Claude Code plugins","keywords":["mcp-server","plugin","distribution","github","git-tracked","local-recall-plugin"],"applies_to":"global","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"3dea25443c37f037","content":"Claude Code fetches plugins from GitHub repositories. The MCP server startup failure was caused by `local-recall-plugin/scripts/` being in .gitignore, so the plugin directory was missing required startup scripts. Solution: Remove plugin script directories from .gitignore and commit them to git so they're available when Claude Code clones the repository.\n\nKey insight: For npm packages distributed via GitHub, any runtime files (scripts, configs, etc.) must be git-tracked - .gitignore exclusions apply during npm install from git URLs.","timestamp":"2025-12-21T19:27:11.964Z"}
{"action":"add","id":"dcead7bf-d6fe-42d5-be97-fd7c3f11f357","subject":"No existing mutex or concurrency tests in the test suite","keywords":["testing","mutex","concurrency","test coverage","test gaps"],"applies_to":"global","occurred_at":"2025-12-21T19:17:36.210Z","content_hash":"37ab7d48e7459540","content":"A search of the test suite revealed there are currently no dedicated tests for mutex errors or concurrent access patterns (no files matching tests/**/*mutex* or tests/**/*concurrent*). This is a test coverage gap that should be addressed, especially given the known mutex issue with sqlite-vec initialization in the MCP server.","timestamp":"2025-12-21T19:27:11.964Z"}
{"action":"add","id":"be29c020-eb55-4110-8b70-017407588fbe","subject":"Hooks must not use daemon HTTP client - import and use vector stores directly","keywords":["hooks","user-prompt-submit","session-start","direct-import","vector-search"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"2333bdd461338ac5","content":"Updated hooks to:\n\n1. Import VectorStore and ThinkingVectorStore directly\n2. Call `initialize()` before use to load index with file-based locking\n3. Call `search()` for vector similarity queries\n4. No HTTP requests - file-based locks handle cross-process synchronization\n\nSessionStart hook simplified further - only reads recent memories from filesystem using MemoryManager (no search needed). Both hooks benefit from automatic lock management without daemon complexity.","timestamp":"2025-12-21T19:27:11.965Z"}
{"action":"add","id":"0d1c8bf4-418a-4b54-81e6-b7f523a79af1","subject":"Logging level affects visibility of transcript collection process","keywords":["logging","transcript","debug level","recall.log"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:26:32.435Z","content_hash":"4eec214e78bce69e","content":"Transcript discovery logs are at INFO level (e.g., 'Searching for Claude project transcripts...' at line 53 of dist/core/transcript-collector.js). If recall.log only shows older DEBUG-level messages, it indicates an old MCP server process is still running and needs to be killed. Check recall.log for duplicate entries which confirm multiple servers writing to the same log.","timestamp":"2025-12-21T19:27:11.965Z"}
{"action":"add","id":"5e6bf107-e532-4232-88fa-de9412ab4a62","subject":"Shared gitignore utility function consolidates duplicate code","keywords":["gitignore","utility","deduplication","shared-function"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T18:14:34.568Z","content_hash":"02768b32652a1e27","content":"Both `src/core/memory.ts` and `src/core/index.ts` had identical gitignore creation logic. This was consolidated into a shared utility function `ensureGitignore(baseDir)` in `src/utils/gitignore.ts`. Both files now import and call this function instead of duplicating the implementation. This reduces code duplication and makes future gitignore changes easier to maintain.","timestamp":"2025-12-21T19:27:11.965Z"}
{"action":"add","id":"fa7e82fa-23b1-4f40-972f-8e3fc9a7ed61","subject":"Transcript collector filters synthetic transcripts before copying to avoid unnecessary I/O","keywords":["transcript-collector","synthetic transcripts","sync process","cleanup","optimization"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:23:07.179Z","content_hash":"0cd1775876a99d55","content":"The `syncTranscripts()` method in transcript-collector.ts was updated to check for synthetic transcripts **before** copying them from Claude's cache. Previously, synthetic files could be copied and then cleaned up, wasting I/O.\n\nNew flow (line ~239):\n1. `cleanupTranscripts()` removes any existing synthetic files from `local-recall/transcripts/`\n2. For each source transcript in Claude's cache, calls `isSyntheticFile(transcript.sourcePath)` to check if it's synthetic\n3. Skips copying if synthetic (with debug log)\n4. Only copies genuine transcripts\n\nThis optimization prevents unnecessary file copying operations for transcripts that would be immediately deleted.","timestamp":"2025-12-21T19:27:11.966Z"}
{"action":"add","id":"a0b8e536-dce6-4555-a6c1-3217faba3782","subject":"Claude stores project transcripts in ~/.claude/projects/<project-hash>/transcripts/","keywords":["claude-cache","transcripts","path","project-hash"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T19:02:53.332Z","content_hash":"82af2847612c3948","content":"Claude Code stores project transcripts in `~/.claude/projects/<project-hash>/transcripts/` where the project hash is derived from the project's file path. The transcript collector uses multiple strategies to find these:\n\n1. Primary: Direct path calculation using the project path\n2. Fallback: Scan all directories in ~/.claude/projects and check each for transcript-like content\n3. Last resort: Check for directories ending with specific path patterns\n\nThis hierarchical approach helps locate transcripts even when the exact path calculation may not match Claude's actual hashing algorithm.","timestamp":"2025-12-21T19:27:11.966Z"}
{"action":"add","id":"8fb57d6f-d0ef-41c4-9462-3387ac9d3fc7","subject":"Plugin hooks require JSON format with hookSpecificOutput for context injection","keywords":["hooks","plugin","json output","context injection","sessionstart","claude code integration"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T17:42:21.784Z","content_hash":"173b1517d66a6aa5","content":"Plugin-layer hooks (SessionStart:Callback, UserPromptSubmit:Callback) must output JSON to stdout with structure: `{ hookSpecificOutput: { additionalContext: \"context text\" } }`. Plain `console.log()` output is not injected into Claude's context. This is critical for the session-start and user-prompt-submit hooks to work properly with Claude Code's hook system.","timestamp":"2025-12-21T19:27:11.966Z"}
{"action":"add","id":"0be5e1fb-9225-41d0-8c44-230c64880bfb","subject":"Thinking memory extraction processes Claude's reasoning blocks paired with outputs","keywords":["thinking-memory","extraction","reasoning","output-pairing","parallel-processing"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:18:39.469Z","content_hash":"6001562a1158bcfb","content":"Thinking memories capture Claude's internal reasoning (thinking blocks) paired with corresponding text outputs. The extraction process:\n\n- Processes transcripts to identify `<thinking>` tags and their corresponding outputs\n- Creates memory pairs: thought + output\n- Skips tool-only responses (those without text outputs)\n- Uses parallel processing (20 concurrent extractors) for performance\n- Tracks processed transcripts to avoid reprocessing\n\nThinking memories provide examples of \"how I reasoned â†’ what I produced\" for future sessions, improving contextual decisions.","timestamp":"2025-12-21T19:27:11.967Z"}
{"action":"add","id":"b3250b67-2ca4-4476-8c2f-bf39cf93640a","subject":"Orama vector store uses cosine distance similarity scoring with recency tie-breaker","keywords":["orama","similarity-scoring","cosine-distance","ranking"],"applies_to":"area:vector-store","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"1e97141a2c077c79","content":"Search results use cosine distance similarity scoring:\n- Score range: 0.0 (no match) to 1.0 (identical)\n- Scores rounded to 2 decimal places (e.g., 0.65)\n- Results sorted by score descending\n- Recency tie-breaker: When scores are equal, more recent memories (by `occurred_at`) are ranked first","timestamp":"2025-12-21T19:27:11.967Z"}
{"action":"add","id":"03bb8711-6540-46fe-879c-cff454ddbce4","subject":"Database concurrency issue: hooks and daemon competing for SQLite access","keywords":["concurrency","sqlite","database","mutex","hooks","daemon","lock"],"applies_to":"global","occurred_at":"2025-12-03T09:48:06.256Z","content_hash":"29e42bc3fec08e67","content":"The MCP server daemon and Claude Code hooks (UserPromptSubmit, Stop) were simultaneously accessing the same `memory.sqlite` file, causing mutex lock failures. The `sqlite-vec` extension had issues with concurrent write access.\n\n**Root cause**: Both daemon and hooks opened separate database connections without proper concurrency controls.\n\n**Solution implemented**:\n- Created `src/utils/database.ts` with centralized SQLite management\n- Added 30-second busy timeout to allow SQLite to wait for locks instead of failing immediately\n- Enabled WAL (Write-Ahead Logging) mode for concurrent readers and writers\n- Hooks now open database in **read-only mode** to completely avoid write locks\n- Added retry logic with exponential backoff (up to 3 retries)\n\n**Key insight**: Read-only mode eliminates concurrency issues for search-only operations (hooks) while allowing writes from daemon.","timestamp":"2025-12-21T19:27:11.968Z"}
{"action":"add","id":"4f1217b5-971c-45fd-949b-a9244f1876f3","subject":"Memory extraction tests updated to work with new condensed format","keywords":["tests","memory extraction","prompt","condenser"],"applies_to":"file:tests/unit/prompts/memory-extraction.test.ts","occurred_at":"2025-12-21T19:25:23.828Z","content_hash":"cf85ac1511b6d46b","content":"Updated existing memory extraction tests to work with the condensed transcript format. The tests verify that:\n\n- Memory extraction guidelines are included in prompts\n- JSON schema for memory objects is present\n- Condenser output can be successfully processed by extraction prompts\n- All memory fields (subject, keywords, applies_to, content) are properly formatted\n\nThese tests ensure backward compatibility while validating the new condensed transcript integration.","timestamp":"2025-12-21T19:27:11.968Z"}
{"action":"add","id":"fe0a1111-eb1b-4c66-8b89-59201f499927","subject":"Logger requires single string argument, not multiple parameters","keywords":["logger","api","string-concat","error-handling"],"applies_to":"file:src/utils/logger.ts","occurred_at":"2025-12-21T18:21:17.810Z","content_hash":"fbe7363790a5caca","content":"The logger utility in logger.ts expects a single string argument for debug/error/warn/info calls. When logging structured data, concatenate strings with template literals or use `JSON.stringify()` rather than passing multiple arguments.\n\nIncorrect: `logger.error('error:', error, 'data:', data)`\nCorrect: `logger.error(`error: ${JSON.stringify(error)}`)","timestamp":"2025-12-21T19:27:11.968Z"}
{"action":"add","id":"50530c22-7722-4306-b002-e6b143c24322","subject":"Claude project discovery uses path-to-dashes naming convention in ~/.claude/projects","keywords":["claude projects","transcript collector","path convention","project discovery","dashes"],"applies_to":"file:src/core/transcript-collector.ts","occurred_at":"2025-12-21T18:25:22.045Z","content_hash":"60c0facdd4692c87","content":"Claude stores projects in ~/.claude/projects using a naming convention where the full path has slashes replaced with dashes. For example, /Users/joe/Code/Syntessera/local-recall becomes -Users-joe-Code-Syntessera-local-recall. The TranscriptCollector must prioritize this naming convention when searching for Claude project directories. Transcripts are stored directly in the project folder, not in a transcripts/ subfolder.","timestamp":"2025-12-21T19:27:11.969Z"}
{"action":"add","id":"e49c758a-0c60-44f1-b89b-fcf07eecb4e3","subject":"Next priorities for Local Recall include CLI, deduplication, pruning, and better extraction","keywords":["local-recall","roadmap","priorities","cli","deduplication","memory-decay"],"applies_to":"global","occurred_at":"2025-12-21T18:23:32.479Z","content_hash":"313f3bb163563f2a","content":"Potential next work items for Local Recall:\n1. Build CLI with init, search, list, create commands\n2. Memory deduplication to detect and merge similar memories\n3. Memory decay/pruning to automatically archive stale memories\n4. Smarter retrieval based on current files in context\n5. Improve stop hook analysis for better automatic memory extraction\n6. Live testing by installing the plugin in a real project\n\nThese represent the natural next steps after the core foundation is complete.","timestamp":"2025-12-21T19:27:11.970Z"}
{"action":"add","id":"7d3e92a2-9ace-4898-8dca-9e94208f3636","subject":"Transcript collector validates UUID filenames across multiple methods","keywords":["transcript-collector","uuid-regex","filename-validation","architectural-decision"],"applies_to":"area:transcript-collection","occurred_at":"2025-12-21T19:21:01.282Z","content_hash":"862037d574102cd5","content":"The transcript collector now enforces UUID filename validation as a core filtering mechanism. This is a defensive pattern that ensures robustness when processing transcripts:\n\n- **Pattern**: `UUID_REGEX = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}\\.jsonl$/i`\n- **Helper function**: `isUuidFilename(filename: string): boolean`\n- **Applied consistently** across all transcript discovery and processing methods to maintain data integrity\n- **Prevents issues** with stray or misconfigured files being treated as valid transcripts","timestamp":"2025-12-21T19:27:11.971Z"}
{"action":"add","id":"36c92d1e-8216-452b-b64a-0282aaee58d5","subject":"Vector store search results are sorted by distance (similarity), with recency as secondary tie-breaker","keywords":["vector store","search","similarity","scoring","occurred_at","recency"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:25:49.095Z","content_hash":"fe11651e98e452ca","content":"In `src/core/vector-store.ts:200-270`, search results are primarily sorted by distance/similarity (lower distance = higher similarity), not by `occurred_at`. Similarity scores are calculated as `1 - (distance / 2)` and rounded to 2 decimal places (e.g., 0.65). When multiple results have equal rounded scores, they are sorted by `occurred_at` descending (newest first) as a tie-breaker for recency.","timestamp":"2025-12-21T19:27:11.971Z"}
{"action":"add","id":"a751ef98-2a73-4bda-a89b-0abe1478afed","subject":"sqlite-vec mutex lock error occurs with concurrent process initialization","keywords":["sqlite-vec","mutex-lock","concurrency","initialization","error-handling"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T18:17:33.752Z","content_hash":"6cb03f4fc7151120","content":"When multiple processes try to call `sqlite-vec.load(db)` simultaneously, a C++ runtime mutex lock error occurs. This happens because sqlite-vec initializes native extensions that require exclusive access during loading. The solution uses a file-based lock mechanism with a temporary `.lock` file to serialize access to sqlite-vec initialization across concurrent processes. Locks are automatically cleaned up if they become stale (older than 30 seconds), preventing deadlocks from abandoned lock files.","timestamp":"2025-12-21T19:27:11.972Z"}
{"action":"add","id":"a672b169-5beb-4bb8-8fdd-fdede50d7742","subject":"ONNX runtime mutex errors prevent concurrent hook execution in fastembed","keywords":["onnx","mutex","concurrency","fastembed","embedding","hooks","race-condition"],"applies_to":"global","occurred_at":"2025-12-21T18:24:57.085Z","content_hash":"d5965851d4cee9e7","content":"The project experienced mutex errors when running multiple Claude instances concurrently. The root cause is NOT sqlite-vec (which was replaced with Orama), but rather **ONNX runtime** (used by fastembed for embeddings). When multiple processes initialize the ONNX model concurrently (e.g., in user-prompt-submit hooks), the ONNX runtime's internal mutex causes crashes. The `proper-lockfile` file-based locking doesn't prevent ONNX's kernel-level mutex issues. This is a fundamental limitation of ONNX - multiple processes can't safely initialize it simultaneously.","timestamp":"2025-12-21T19:27:11.972Z"}
{"action":"add","id":"6987c32a-959b-4d81-91f6-b6b5d56bddb6","subject":"JSONL storage location should be within episodic-memory and thinking-memory folders","keywords":["jsonl","storage","location","migration","file structure"],"applies_to":"global","occurred_at":"2025-12-21T19:13:54.006Z","content_hash":"1b1fffee3163436c","content":"Current implementation stores JSONL files at root level (local-recall/episodic-000001.jsonl), but the expected design places them within their respective folders (local-recall/episodic-memory/episodic-000001.jsonl and local-recall/thinking-memory/thinking-000001.jsonl). This keeps all related files (markdown during transition, JSONL, and embeddings) organized together by type.","timestamp":"2025-12-21T19:27:11.973Z"}
{"action":"add","id":"f4d5b5f2-a314-4031-8d08-ce3d81729b5c","subject":"Multiple Claude Code instances may leave stale MCP server processes","keywords":["mcp server","multiple instances","process management","stale processes","recall.log"],"applies_to":"global","occurred_at":"2025-12-12T10:14:38.028Z","content_hash":"ee7939bf7b50728f","content":"When multiple Claude Code instances are running, old MCP server processes may remain running even after code changes. This causes duplicate log entries in recall.log (each line appears twice) and means transcript collection uses outdated code.\n\n**Detection**: Check recall.log for duplicate entries or mismatched log messages compared to source code.\n\n**Resolution**: Kill old MCP server processes and restart Claude Code instances, or rebuild and redeploy the bundled server.js to the plugin cache.","timestamp":"2025-12-21T19:27:11.973Z"}
{"action":"add","id":"59b26f6e-46f0-435c-9a33-507c7a979b2a","subject":"Memory extraction prompt structure and JSON schema","keywords":["memory format","yaml frontmatter","json schema","memory extraction","keywords"],"applies_to":"file:src/prompts/memory-extraction.ts","occurred_at":"2025-12-21T18:29:11.578Z","content_hash":"313ea8cf2a09e21e","content":"Memory extraction prompt output format:\n- Returns JSON object with `memories` array\n- Each memory has: `subject` (max 200 chars), `keywords` (1-10 lowercase), `applies_to` (scope), `content` (markdown)\n- Prefix: `[LOCAL_RECALL_INTERNAL]` prevents hook recursion\n- Must return ONLY valid JSON with no markdown formatting, code blocks, or explanation\n- Scope values: `global`, `file:<path>`, or `area:<name>`","timestamp":"2025-12-21T19:27:11.974Z"}
{"action":"add","id":"8414b291-9ee8-43ff-81d0-123e2f9b3aeb","subject":"Memory schema updated with occurred_at and content_hash fields","keywords":["memory-schema","types","frontmatter"],"applies_to":"file:src/core/types.ts","occurred_at":"2025-12-21T18:22:28.112Z","content_hash":"ded8599556a79ea2","content":"Updated `CreateMemoryInput` and memory metadata schema:\n\n- Added `occurred_at` (ISO-8601 timestamp): When the original conversation happened\n- Added `content_hash` (16-char SHA-256): For deduplication\n- Removed `updated_at` field (memories are immutable)\n- Removed `timeWindow` from config schema\n\nDedup key: `occurred_at` + `content_hash` ensures same memory isn't created twice.","timestamp":"2025-12-21T19:27:11.974Z"}
{"action":"add","id":"a492deff-28bd-4589-af99-2336fcab6c91","subject":"Refactor stop.ts to use transcript.ts parsing utilities","keywords":["stop.ts","transcript.ts","parsing","duplication","refactoring","architecture"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:19:37.035Z","content_hash":"4dfb5166c921f12a","content":"stop.ts had duplicate parsing logic that was broken and inefficient. The fix was to move all transcript parsing into transcript.ts's parseTranscriptForMemories() function which takes raw JSONL content and returns memory suggestions. stop.ts now only reads the file, calls parseTranscriptForMemories(), and saves results via MemoryManager. This eliminates code duplication and allows reusing transcript parsing anywhere in the codebase.","timestamp":"2025-12-21T19:27:11.975Z"}
{"action":"add","id":"ed1413da-42a1-4f8b-9099-2da765eb0feb","subject":"Plugin versioning and metadata management in local-recall","keywords":["version","0.1.3","metadata","plugin","discoverability"],"applies_to":"file:dev-marketplace/local-recall-plugin/","occurred_at":"2025-12-21T18:30:11.718Z","content_hash":"a0b98c94cb081b19","content":"Version 0.1.3 introduced improved MCP tool descriptions with usage guidance and updated plugin metadata. This change was made to enhance tool discoverability and help users understand how to use memory operations effectively. Version bumps should be coordinated with plugin metadata updates.","timestamp":"2025-12-21T19:27:11.975Z"}
{"action":"add","id":"3ede2185-a050-4533-bf3a-6b280d36af0c","subject":"Separate flags needed for episodic and thinking processing to allow parallel daemon execution","keywords":["daemon","flags","episodic","thinking","concurrent","mcp-server"],"applies_to":"file:src/mcp-server/server.ts","occurred_at":"2025-12-21T19:23:44.640Z","content_hash":"882909efe6edcd71","content":"The MCP server daemon maintains separate processing flags:\n- `isEpisodicProcessing` (boolean, default: false) - prevents concurrent episodic memory extraction runs\n- `isThinkingProcessing` (boolean, default: false) - prevents concurrent thinking memory extraction runs\n\nBoth can be true simultaneously, allowing episodic and thinking extraction to run in parallel without blocking each other. This prevents duplicate processing while maximizing throughput of the daemon loop that runs every 5 minutes.","timestamp":"2025-12-21T19:27:11.975Z"}
{"action":"add","id":"f53f90ba-dc67-4262-bb48-6d5b8939bcbb","subject":"Local Recall project architecture uses YAML frontmatter with markdown for memory storage","keywords":["memory format","yaml frontmatter","markdown","storage structure"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"6968cf5df8ba1cef","content":"Memory files use YAML frontmatter for metadata (id, subject, keywords, applies_to, occurred_at, content_hash) followed by markdown content. Each memory is atomic (one concept per file). Files are stored in local-recall/episodic-memory/ and local-recall/thinking-memory/ directories and are version-controlled in git.","timestamp":"2025-12-21T19:27:11.976Z"}
{"action":"add","id":"60c1042e-0914-46e8-8229-f2d047a9c5f8","subject":"Memory extraction should save all thinking but only multiline answers","keywords":["memory","extraction","thinking","answers","filtering"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T18:18:08.509Z","content_hash":"c09ca94177c101f2","content":"Updated `analyzeForMemories` function to:\n- Save **all thinking** (even single-line) as separate memories\n- Save **only multiline answers** (content with 2+ lines)\n- Use first sentence as subject for both types (extracted via `generateSubject`)\n\nThis distinction helps preserve Claude's reasoning while avoiding noise from brief single-line responses.","timestamp":"2025-12-21T19:27:11.976Z"}
{"action":"add","id":"8d89ee6b-fd85-4fc9-b6ac-3438c021fa3e","subject":"Memory extractor successfully uses Haiku model for 20x cost reduction","keywords":["memory-extractor","haiku","model-selection","cost-optimization","performance"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:15:24.090Z","content_hash":"8f604ebb5b2f6aca","content":"The memory extractor was successfully switched from using the default Claude model to Haiku for structured memory extraction tasks. Testing confirmed that Haiku correctly extracts memories with valid YAML frontmatter and markdown content structure. This change provides approximately 20x cost reduction and faster processing while maintaining full compatibility with the existing memory extraction pipeline. The `callClaudeCLI` method at line 80-81 uses `--model haiku` to invoke Haiku explicitly.","timestamp":"2025-12-21T19:27:11.977Z"}
{"action":"add","id":"0eddefc3-a27c-4d12-b89a-79071a47870f","subject":"Internal prompt detection in hooks prevents memory extraction feedback loops","keywords":["internal-prompt","LOCAL_RECALL_INTERNAL","memory-extraction","transcript-processing"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:32:04.567Z","content_hash":"48005a3cf05831e4","content":"The UserPromptSubmit hook skips any prompt containing `[LOCAL_RECALL_INTERNAL]` marker. This prevents feedback loops when the MCP daemon calls `claude -p` to extract memories from transcripts. The marker is added programmatically by the transcript processing code to distinguish between user prompts and internal extraction calls.","timestamp":"2025-12-21T19:27:11.977Z"}
{"action":"add","id":"40fbba51-8894-40fd-a2a1-0f48d4558323","subject":"Hook configuration in .claude/settings.json uses command-based execution","keywords":["hooks","settings","configuration","command","timeout","claude code"],"applies_to":"global","occurred_at":"2025-12-21T17:42:21.784Z","content_hash":"166d74c32a1cfe6c","content":"Hooks are configured in `.claude/settings.json` with structure: `{ \"hooks\": { \"SessionStart\": [{ \"hooks\": [{ \"type\": \"command\", \"command\": \"node ./dist/hooks/session-start.js\", \"timeout\": 30 }] }] } }`. Hook processes receive JSON via stdin and must output to stdout within the timeout period (in seconds).","timestamp":"2025-12-21T19:27:11.978Z"}
{"action":"add","id":"2e17a6b2-0233-42be-aaf7-d1ae8abc70fd","subject":"local-recall plugin successfully installed and requires Claude Code restart","keywords":["plugin","installation","local-recall","restart","setup"],"applies_to":"global","occurred_at":"2025-12-21T19:03:02.326Z","content_hash":"0ec18568a81fdb37","content":"The local-recall plugin has been successfully installed via the /plugin command. Claude Code needs to be restarted to load the newly installed plugin and make it available for use.","timestamp":"2025-12-21T19:27:11.978Z"}
{"action":"add","id":"fcc68ae1-e2f7-436c-a0c6-5476f18df1a7","subject":"Local Recall changed to save all messages without filtering","keywords":["transcript","memory extraction","analysis","filtering","patterns"],"applies_to":"global","occurred_at":"2025-12-21T19:01:46.971Z","content_hash":"305b2bc1b5b774cd","content":"The user requested removing all trigger patterns (like 'remember this', 'save this for later') and instead save all messages without any filtering.\n\nChanges made:\n- Removed `USER_TRIGGER_PATTERNS` regex from `src/utils/transcript.ts` that matched user-triggered phrases\n- Removed `AUTO_DETECT_PATTERNS` heuristics that detected architecture decisions, bugfixes, discoveries, and conventions\n- Simplified `analyzeForMemories()` function to iterate through all messages and save each one\n- Messages are formatted with role prefix (`**user**:` or `**assistant**:`)\n- Empty messages are still skipped for cleanliness\n\nThis is a major behavioral change - the system now captures all conversation content rather than using selective filtering based on keywords or patterns.","timestamp":"2025-12-21T19:27:11.979Z"}
{"action":"add","id":"cd127f26-0763-421a-811f-0c3a2e9995aa","subject":"Session started with local-recall codebase analysis","keywords":["local-recall","memory-system","jsonl-migration","vector-search"],"applies_to":"global","occurred_at":"2025-12-21T19:22:42.847Z","content_hash":"b5c604e4514ad753","content":"The local-recall project is a markdown-powered memory system for AI coding assistants. Recent work involved migrating memory storage from individual files to JSONL format with multi-file support (episodic-000001.jsonl, thinking-000001.jsonl). The system uses Orama for vector search with Ollama embeddings (nomic-embed-text model, 768 dimensions).","timestamp":"2025-12-21T19:27:11.979Z"}
{"action":"add","id":"29136041-86f3-4e6d-a812-3b6a2d7bb8bc","subject":"Vector store migrated from JSON (Orama) to SQLite with vec extension","keywords":["vector-store","sqlite","orama-deprecated","migration","index"],"applies_to":"global","occurred_at":"2025-12-21T18:26:56.199Z","content_hash":"1b9b7635d0f448bd","content":"The project has migrated from Orama-based JSON indexes (`orama-episodic-index.json`, `orama-thinking-index.json`) to SQLite with the `vec` extension for vector storage. The implementation is in `src/core/vector-store.ts`.\n\nKey changes:\n- Vectors are stored in SQLite `memory_embeddings` table with `vec` extension\n- Old documentation references to `orama-*-index.json` files are outdated\n- The vector store interface (`VectorStore`) remains unchanged but implementation is now SQLite-based\n- Search uses SQL vector operations (`embedding MATCH ?`) instead of Orama's JavaScript search","timestamp":"2025-12-21T19:27:11.979Z"}
{"action":"add","id":"05000f10-7b8e-4649-a70e-4d906080b764","subject":"MCP server runs from dev-marketplace subdirectory, not root","keywords":["mcp server","configuration","location","dev-marketplace","plugin"],"applies_to":"global","occurred_at":"2025-12-21T18:28:38.979Z","content_hash":"decf16c4245a219b","content":"The MCP server is currently running from `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js` with config at `dev-marketplace/local-recall-plugin/.mcp.json`.\n\nThis indicates:\n- The main project root doesn't have a `scripts/` directory yet\n- The plugin subdirectory contains a separate build/distribution\n- `npm run build` in the root may not be building the hooks/MCP server yet\n\nWhen checking MCP server status, verify both the root and `dev-marketplace/local-recall-plugin/` locations.","timestamp":"2025-12-21T19:27:11.979Z"}
{"action":"add","id":"dc6505f0-26d9-4687-a959-8cc6728185eb","subject":"Synthetic transcripts must be excluded from all processing pipelines","keywords":["synthetic","filtering","isSyntheticTranscript","data-quality","processing"],"applies_to":"area:memory-extraction","occurred_at":"2025-12-03T09:47:02.103Z","content_hash":"c7a4f924df5adc0c","content":"Added `isSyntheticTranscript()` method to TranscriptCollector (line 317-331) that checks the first 10KB of a transcript for the `\"<synthetic>\"` marker. This method is called in both `thinking-extractor.ts:140-149` and `memory-extractor.ts:441-450` to skip synthetic files early before any processing occurs.\n\nSynthetic files are generated by memory extraction tests and should never be included in thinking or episodic memory extraction. They pollute the memory database with false data.","timestamp":"2025-12-21T19:27:11.980Z"}
{"action":"add","id":"dd042e99-9137-4d2b-b8e8-bcd9b8f13452","subject":"Fix AbortError in user-prompt-submit hook from unhandled spawn timeout","keywords":["user-prompt-submit","spawn","timeout","AbortError","error handling","child process","promise"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T19:20:20.014Z","content_hash":"ddb547ea281a0a60","content":"## Problem\nThe `callClaudeForKeywords()` function in user-prompt-submit.ts was throwing unhandled AbortError when the spawn timeout (line 41) killed the child process. Node.js aborts child processes when timeout expires, but this abort wasn't being caught properly.\n\n## Root Causes\n1. `spawn()` has a `timeout` option that kills the process and throws `AbortError` - this error wasn't wrapped in try-catch\n2. Duplicate `child.on('close', ...)` event handlers (lines 60 and 120) causing race conditions\n3. No synchronization to ensure promise resolves only once\n\n## Solution Applied\n1. Removed `timeout` option from `spawn()` call\n2. Added `safeResolve()` wrapper that prevents multiple resolutions via a flag\n3. Removed duplicate close handler - consolidated into single listener\n4. Added early-exit guard in close handler to prevent duplicate processing\n\n## Key Learning\nNode.js child_process spawn's built-in timeout is problematic because it aborts the process asynchronously. Better to implement manual timeout handling or remove timeout entirely if process naturally completes.","timestamp":"2025-12-21T19:27:11.980Z"}
{"action":"add","id":"63e2536f-a694-4c22-b290-11522960508d","subject":"SessionStart hook strategy: read 5 most recent memories directly from files","keywords":["session-start-hook","memory-injection","context-priming","recent-memories"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"09339b010f7ac212","content":"The SessionStart hook (triggered when Claude Code session begins) implements an efficient strategy:\n1. Does NOT use semantic search or embeddings\n2. Reads the 5 most recent memories directly from disk, sorted by `occurred_at` timestamp\n3. Injects memory content into Claude's context as reference material\n\nThis avoids startup latency from embedding generation while ensuring Claude is aware of recent context. The memories are injected as-is (markdown format) to provide immediate awareness of recent work and decisions.","timestamp":"2025-12-21T19:27:11.981Z"}
{"action":"add","id":"5851e7cb-51ab-4505-8bc2-62a816eb0c11","subject":"SessionStart hook successfully executes and injects memories into context","keywords":["hooks","sessionstart","working","memory","injection","context"],"applies_to":"global","occurred_at":"2025-12-21T19:20:51.697Z","content_hash":"25061aa032869ae7","content":"The SessionStart hook is working correctly - it fires when a Claude Code session begins and successfully loads relevant memories. This can be verified by the 'SessionStart:Callback hook success' message in system reminders. The hook reads recent memory files and injects them into Claude's context.","timestamp":"2025-12-21T19:27:11.981Z"}
{"action":"add","id":"1c0b2258-3ca1-4efe-9f19-92b11de9e895","subject":"Memory extraction moved from Stop hook to MCP server daemon for reliability","keywords":["stop-hook","mcp-server","daemon","transcript-processing","memory-extraction"],"applies_to":"global","occurred_at":"2025-12-21T19:17:41.738Z","content_hash":"14cd670916bd0965","content":"The Stop hook is currently disabled. Memory extraction is now handled by the MCP server daemon which:\n- Processes transcripts asynchronously every 5 minutes\n- Detects changes using content hashes\n- Deletes and recreates memories when transcripts change\n- Runs in the background without blocking Claude's operation\n\nThis approach is more reliable than the synchronous Stop hook as it doesn't block session termination.","timestamp":"2025-12-21T19:27:11.981Z"}
{"action":"add","id":"58323059-bb2c-407f-be72-d947348ba5fb","subject":"Implemented deduplication in thinking-extractor to prevent duplicate thinking/text blocks","keywords":["thinking-extractor","deduplication","streaming artifacts","set deduplication"],"applies_to":"file:src/core/thinking-extractor.ts","occurred_at":"2025-12-21T18:29:32.427Z","content_hash":"978676ae51867fae","content":"Added deduplication using Set to filter out streaming duplicates at lines 146-148. Changed from directly joining `aggregated.thinkingParts` and `aggregated.textParts` to creating unique sets first: `const uniqueThinking = [...new Set(aggregated.thinkingParts)];`. This prevents memories from containing redundant repeated content caused by duplicate JSONL entries in transcripts.","timestamp":"2025-12-21T19:27:11.981Z"}
{"action":"add","id":"4869035c-f117-48fe-aecb-a4bbf228a748","subject":"Memory deduplication uses occurred_at timestamp and content_hash SHA-256 prefix","keywords":["deduplication","content-hash","occurred-at","duplicate-detection"],"applies_to":"area:memory-manager","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"d5c00f5ee8eb6473","content":"The memory manager has a `findDuplicate(occurredAt, contentHash)` function that detects existing duplicate memories. Deduplication uses:\n- `occurred_at`: ISO-8601 timestamp of when event occurred (for sorting and grouping)\n- `content_hash`: SHA-256 prefix (16 chars) of memory content\n\nWhen creating a memory, it returns the existing memory if a duplicate is found rather than creating a new one (idempotent behavior).","timestamp":"2025-12-21T19:27:11.982Z"}
{"action":"add","id":"743247f5-c1bc-4577-bc20-53a2d15801c3","subject":"Project currently has pending decisions on feature priorities and next build direction","keywords":["feature planning","roadmap","cli commands","deduplication","decay pruning"],"applies_to":"global","occurred_at":"2025-12-21T19:17:52.600Z","content_hash":"033460d2201ab49d","content":"Key decision points for next phase: Build CLI (init, search, list, create commands), implement memory deduplication and merge logic, add memory decay/pruning for stale memories, improve context-aware retrieval based on current files, enhance stop hook analysis, or live test in a real project. All are potentially valuable next steps.","timestamp":"2025-12-21T19:27:11.982Z"}
{"action":"add","id":"2336d3b5-b5e5-4a76-b526-6ad541b21537","subject":"Skills added for memory management: check-memories and proactive-recall","keywords":["skills","memory","check-memories","proactive-recall","memory management"],"applies_to":"global","occurred_at":"2025-12-21T19:24:22.148Z","content_hash":"c11d967e0babb66a","content":"Two new skills were added to improve memory management:\n1. **check-memories** - Allows checking stored memories\n2. **proactive-recall** - Enables proactive memory retrieval\n\nThese skills improve Claude Code's ability to leverage Local Recall's memory system during coding sessions. They should be invoked when users need to access or recall contextual information from previous sessions.","timestamp":"2025-12-21T19:27:11.983Z"}
{"action":"add","id":"4b814ff6-f64b-4157-b7e5-182d855b4a72","subject":"Memory extraction parallelism configured with semaphore pattern","keywords":["memory-extractor","parallelism","concurrency","semaphore","transcript-processing"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T19:01:31.770Z","content_hash":"60dd4b5a70feea84","content":"# Parallel Transcript Processing Implementation\n\n## Configuration\nThe `MemoryExtractor.processAllTranscripts()` method was updated to support concurrent processing of transcripts using a semaphore pattern. The `ExtractorOptions` interface now includes a `concurrency` option (default: 10).\n\n## Implementation Details\n- Uses a semaphore pattern with `acquire()` and `release()` to control concurrency\n- All transcript processing promises are spawned immediately with `Promise.all()`\n- The semaphore's `acquire()` call blocks each promise until a processing slot becomes available\n- As each transcript completes (via `processTranscript()`), it calls `release()` to free a slot\n- This approach is more efficient than batching because it keeps all available slots filled continuously\n- Supports up to 10 concurrent extractors by default\n\n## Rationale\nSequential processing (original implementation) was bottlenecked with a simple for loop. The semaphore pattern provides better resource utilization while maintaining controlled parallelism - all slots stay filled until all transcripts are processed, improving throughput.","timestamp":"2025-12-21T19:27:11.983Z"}
{"action":"add","id":"34d2c706-f235-4e70-b7a2-5c7218133ccf","subject":"Episodic memory processing controlled by configuration flag with default disabled","keywords":["configuration","episodic","daemon","feature flag","disabled"],"applies_to":"global","occurred_at":"2025-12-21T19:04:16.673Z","content_hash":"6dfeacff6a1a71d8","content":"## Episodic Memory Processing Configuration\n\nEpisodic memory transcript processing in the MCP daemon is controlled by a configuration flag.\n\n### Configuration\n- **Flag**: `episodicEnabled` (env var: `LOCAL_RECALL_EPISODIC_ENABLED`)\n- **Default**: `false` (disabled)\n- **Location**: `src/mcp-server/server.ts` - processEpisodicMemories function\n\n### Behavior\nThe MCP daemon loop respects this configuration:\n- If `episodicEnabled === false`: Episodic processing is skipped\n- If `episodicEnabled === true`: Runs episodic memory extraction from transcripts every 5 minutes\n- Thinking memory processing runs independently (controlled by `thinkingEnabled`)\n\n### Note\nEpisodic memory tools (`episodic_create`, `episodic_get`, `episodic_search`) remain available via MCP regardless of the daemon processing flag. The configuration only affects automatic transcript processing.","timestamp":"2025-12-21T19:27:11.983Z"}
{"action":"add","id":"e33469c3-7a50-43f5-ad15-cb1039768a82","subject":"Local Recall project structure and core architecture","keywords":["architecture","project-structure","memory-system","claude-code-integration"],"applies_to":"global","occurred_at":"2025-12-21T19:26:26.190Z","content_hash":"370bc7fe4039ff86","content":"Local Recall is a markdown-powered memory system for Claude Code and MCP clients. Core architecture:\n\n**Components:**\n- `src/core/memory.ts` - Memory CRUD operations for markdown files\n- `src/core/search.ts` - Semantic search using vector embeddings\n- `src/hooks/` - Claude Code hooks (SessionStart, Stop)\n- `src/mcp-server/` - MCP server exposing memory tools\n- `src/utils/transcript.ts` - Transcript parsing and analysis\n\n**Memory Storage:**\nMemories stored as markdown files with YAML frontmatter in `local-recall/episodic-memory/`. Each memory has: id, subject, keywords, applies_to (global/file/area), occurred_at timestamp, content_hash for deduplication.\n\n**Integration Points:**\n- SessionStart hook: Loads 5 most recent memories on session start\n- Stop hook: Parses transcripts and extracts memories asynchronously\n- MCP server: Exposes memory tools for any MCP-compatible client\n\n**Key Implementation Detail:**\nUses Orama (pure JavaScript vector store) with Ollama embeddings. No external databases or complex dependencies.","timestamp":"2025-12-21T19:27:11.983Z"}
{"action":"add","id":"d451b3f3-c60d-4059-aa84-b45727d88577","subject":"MCP server runs from plugin subdirectory, not main root","keywords":["mcp-server","configuration","location","plugin-directory"],"applies_to":"global","occurred_at":"2025-12-21T18:28:33.686Z","content_hash":"9c87a4605a9d71f0","content":"The MCP server is configured and running from `dev-marketplace/local-recall-plugin/scripts/mcp-server/server.js`, not from the main project root. The main project root doesn't have a built `scripts/` directory structure yet.\n\nThe MCP server config is located at `dev-marketplace/local-recall-plugin/.mcp.json`. When working on the main project, remember the actual running instance is in the plugin subdirectory.","timestamp":"2025-12-21T19:27:11.984Z"}
{"action":"add","id":"f75ac885-7ebc-4ded-95ed-778d297ca440","subject":"Configuration options for episodic and thinking memory retrieval","keywords":["configuration","episodic","thinking","similarity-threshold","token-budget"],"applies_to":"global","occurred_at":"2025-12-21T18:57:37.986Z","content_hash":"2bf5add11480880e","content":"Both episodic and thinking memories have independent configuration: episodicMaxTokens (default 1000), episodicMinSimilarity (default 0.5), thinkingMaxTokens (default 1000), thinkingMinSimilarity (default 0.5). These can be set via environment variables or .local-recall.json. The similarity threshold filters results by cosine distance (0.0-1.0), and token budget limits context injection.","timestamp":"2025-12-21T19:27:11.984Z"}
{"action":"add","id":"7444d490-cd38-4bc6-b10b-5a453868264b","subject":"Episodic memories default configuration changed to enabled","keywords":["episodic","default","enabled","configuration","types.ts"],"applies_to":"global","occurred_at":"2025-12-21T19:02:31.930Z","content_hash":"99ab2d0f477d98bf","content":"Changed the default value of `episodicEnabled` from `false` to `true` in src/core/types.ts:118. This means episodic memory retrieval is now enabled by default when Local Recall is used. The corresponding documentation in CLAUDE.md was also updated to reflect this change.","timestamp":"2025-12-21T19:27:11.984Z"}
{"action":"add","id":"4b1d6f13-79ba-44d5-a5e0-7fb53faff4ac","subject":"Environment variables control episodic vs thinking memory systems independently","keywords":["environment variables","episodic memory","thinking memory","configuration","feature flags"],"applies_to":"global","occurred_at":"2025-12-21T18:29:50.448Z","content_hash":"b790ea43e4814bf0","content":"Two environment variables were added to control memory systems independently:\n\n- `LOCAL_RECALL_EPISODIC_ENABLED` (default: `false`) - Controls episodic memory search, session-start retrieval, and extraction\n- `LOCAL_RECALL_THINKING_ENABLED` (default: `true`) - Controls thinking memory search and extraction\n\nThese were implemented as configuration options parsed from environment variables in `src/utils/config.ts:56-61` and added to the `Config` interface in `src/core/types.ts:118-119`. The flags are then used in all relevant hooks (`user-prompt-submit.ts`, `user-prompt-submit-thinking.ts`, `session-start.ts`) and the MCP server (`src/mcp-server/server.ts`) to conditionally enable/disable memory operations.\n\nThis allows users to run the system with episodic memory disabled (default) and thinking memory enabled (default), or customize per their preferences.","timestamp":"2025-12-21T19:27:11.985Z"}
{"action":"add","id":"d8d352c5-0c23-4b16-b9c3-12f38d69288e","subject":"Episodic memory is disabled by default in configuration","keywords":["episodic memory","default configuration","disabled","env vars","LOCAL_RECALL_EPISODIC_ENABLED"],"applies_to":"global","occurred_at":"2025-12-21T18:25:49.022Z","content_hash":"0f061135ea5a85e0","content":"Changed the default value of `episodicEnabled` from `true` to `false` in the configuration schema. This means episodic memory retrieval is now disabled by default and users must explicitly enable it by setting `LOCAL_RECALL_EPISODIC_ENABLED=true` environment variable or adding `\"episodicEnabled\": true` to `.local-recall.json` config file.\n\nThe schema definition is located in `src/core/types.ts` line 118 where the Zod schema uses `.default(false)` for the `episodicEnabled` field.\n\nThis change was also documented in CLAUDE.md in the configuration table.","timestamp":"2025-12-21T19:27:11.985Z"}
{"action":"add","id":"725f2202-3480-4df4-bf9e-dc24a99e4bf2","subject":"Episodic and thinking memories use separate Orama indexes with independent configuration","keywords":["episodic-memory","thinking-memory","orama","vector-store","index","configuration"],"applies_to":"global","occurred_at":"2025-12-21T18:25:24.918Z","content_hash":"bdacbf67a3519abb","content":"Local Recall maintains two separate vector indexes:\n\n1. **Episodic memories**: `orama-episodic-index.json`\n   - Configuration: `episodicEnabled`, `episodicMaxTokens`, `episodicMinSimilarity`\n   - Stores general project knowledge and context\n\n2. **Thinking memories**: `orama-thinking-index.json`\n   - Configuration: `thinkingEnabled`, `thinkingMaxTokens`, `thinkingMinSimilarity`\n   - Stores Claude's reasoning paired with outputs\n\nBoth indexes use Orama (pure JavaScript) for semantic search with cosine distance scoring. Each can be enabled/disabled independently through configuration, allowing fine-grained control over which memory types are retrieved.\n\n**Important**: When resetting memories, both indexes should be cleared and rebuilt from transcripts.","timestamp":"2025-12-21T19:27:11.986Z"}
{"action":"add","id":"5a4a5b57-7f36-41e3-a61c-d2d0438af817","subject":"Hook process isolation and concurrent access patterns in local-recall","keywords":["concurrency","mutex","hooks","process isolation","file locking"],"applies_to":"global","occurred_at":"2025-12-21T19:16:20.911Z","content_hash":"f0200aaa79f9a9de","content":"## Architecture Constraint\nHooks run as separate processes triggered by Claude Code events. When multiple hooks execute concurrently (e.g., SessionStart + UserPromptSubmit), they can have mutual exclusion issues with shared resources.\n\n## Current Issues\n1. **sqlite-vec is not thread/process safe**: Native C++ module with internal mutex that fails under concurrent access\n2. **File locking alone insufficient**: Even with file-based locking in place, C++ native modules can crash\n\n## Best Practice\nHooks should be lightweight and stateless:\n- Use HTTP daemon for all database operations\n- Avoid loading native C++ modules (sqlite-vec, etc.) in hooks\n- Keep hooks as thin wrappers that communicate with a central daemon\n- Let the daemon handle all database concurrency internally","timestamp":"2025-12-21T19:27:11.986Z"}
{"action":"add","id":"269586d3-e27d-4d49-9f65-a7d1af47e440","subject":"Thinking memories capture Claude's reasoning paired with output for learning by example","keywords":["thinking-memories","reasoning","output-pairing","learning-examples"],"applies_to":"global","occurred_at":"2025-12-21T18:21:10.507Z","content_hash":"1b89a07b7b3c218a","content":"Thinking memories store thought+output pairs extracted from Claude's internal reasoning blocks. Format:\n- `## Thought` section contains internal reasoning\n- `## Output` section contains the text response that followed\n\nThinking memories are retrieved based on semantic similarity (minimum threshold default 80%) and token budget (default 1000). They provide concrete examples of 'how I reasoned â†’ what I produced' for similar tasks in future sessions.","timestamp":"2025-12-21T19:27:11.987Z"}
{"action":"add","id":"17f67f31-529c-48b2-87c7-e47719f039af","subject":"Memory extraction does not filter or summarize content","keywords":["memory extraction","no filtering","no summarization","raw content","preservation"],"applies_to":"global","occurred_at":"2025-12-21T18:13:49.919Z","content_hash":"8bc487586214b0e7","content":"Local Recall extracts and stores memories exactly as they appear in transcripts without summarization or content filtering. The only filtering rules are: (1) skip user messages, (2) skip single-line agent messages. This preserves the full context and reasoning for future reference.","timestamp":"2025-12-21T19:27:11.987Z"}
{"action":"add","id":"42f15a1a-90a3-496c-950d-158af9b1a3e9","subject":"Session start loads all memories, not delta - creates fresh MemoryManager each session","keywords":["session-start","memory-loading","initialization","performance","delta"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:24:20.066Z","content_hash":"5a4159f807401f92","content":"On session startup, the system performs a **full reload** of all memories rather than a delta/incremental load. Each session creates a fresh `MemoryManager` instance and loads all memories from disk via `listMemories()`. The 5 most recent memories (sorted by `occurred_at` descending) are selected and injected into the session context.\n\nThis is a full reload approach, not incremental - all memory files are read from disk on each session start.","timestamp":"2025-12-21T19:27:11.988Z"}
{"action":"add","id":"306e4157-149e-4d89-abd7-e4894ec12cf1","subject":"Hook architecture receives JSON input and outputs memory content via stdout","keywords":["hooks","claude code","json input","stdout output","session start","user prompt submit"],"applies_to":"global","occurred_at":"2025-12-21T19:17:45.599Z","content_hash":"eeddbc5306537de4","content":"Claude Code hooks (SessionStart, UserPromptSubmit) are configured as shell commands that receive JSON input via stdin containing session_id, transcript_path, and cwd. Hooks search memories using Orama and output results to stdout, which are automatically injected into Claude's context. The UserPromptSubmit hook is unified to handle both episodic and thinking memories based on configuration.","timestamp":"2025-12-21T19:27:11.988Z"}
{"action":"add","id":"bda2f5f5-5868-4c75-85f5-0613bdb57150","subject":"Readonly mode for vector stores in hooks to avoid concurrent writes","keywords":["readonly","hooks","vector-store","search","concurrency"],"applies_to":"file:src/core/vector-store.ts file:src/core/thinking-vector-store.ts","occurred_at":"2025-12-03T09:48:06.256Z","content_hash":"34a63415b26d2224","content":"Vector stores (`VectorStore` and `ThinkingVectorStore`) now support a `readonly` option that opens the SQLite database in read-only mode. This is used by hooks (UserPromptSubmit, SessionStart) which only perform searches.\n\n**Implementation**:\n- Added `VectorStoreOptions` interface with `readonly` boolean property\n- `getVectorStore()` and `getThinkingVectorStore()` now accept options parameter\n- Hooks call `getVectorStore({ basePath, readonly: true })` to avoid write locks\n- Daemon/main process uses default writable mode for add/sync operations\n\n**Benefit**: Completely eliminates mutex contention between hooks and daemon since hooks can't acquire write locks.","timestamp":"2025-12-21T19:27:11.988Z"}
{"action":"add","id":"d73f04a3-ebc0-4295-9f35-fa5c56b62384","subject":"Transcript processing concurrency changed from 20 to 5","keywords":["concurrency","performance","transcript-processing","memory-extractor"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-03T09:51:05.046Z","content_hash":"d0044234fadc52c4","content":"The maximum concurrent transcript processors was reduced from 20 to 5. This is configured at line 148 in `memory-extractor.ts` in the `MAX_CONCURRENT_PROCESSORS` constant (or as part of the concurrency configuration in the extractor initialization). This change reduces system load during transcript processing, which is important for machines with limited resources or when processing large batches of transcripts.","timestamp":"2025-12-21T19:27:11.989Z"}
{"action":"add","id":"a818e498-cb42-42cb-baa5-711b91835e3a","subject":"Thinking memory extraction daemon was not running - needs separate parallel call","keywords":["thinking-extractor","daemon","mcp-server","parallel","episodic","memory-extraction"],"applies_to":"global","occurred_at":"2025-12-21T19:23:44.640Z","content_hash":"b021463c0243787f","content":"The thinking memory extraction was implemented but never actually called by the MCP server daemon. The daemon loop only called `runTranscriptProcessing()` for episodic memories. To fix this, thinking extraction now runs in parallel with episodic extraction using separate flags:\n\n- `isEpisodicProcessing` flag prevents concurrent episodic runs\n- `isThinkingProcessing` flag prevents concurrent thinking runs\n- Both can run simultaneously without blocking each other\n\nThis is invoked in the daemon loop via `runThinkingExtraction()` with proper error handling and logging.","timestamp":"2025-12-21T19:27:11.989Z"}
{"action":"add","id":"91767426-ffe8-4b00-94e3-6b0ded23e2f8","subject":"ONNX runtime mutex errors prevent concurrent hook execution","keywords":["onnx","mutex","concurrency","fastembed","embedding","hooks","threading"],"applies_to":"global","occurred_at":"2025-12-21T18:26:49.611Z","content_hash":"cd1cd249075d8edd","content":"The mutex errors observed during concurrent hook execution are caused by ONNX runtime (used by fastembed), not sqlite-vec. When multiple processes try to load the ONNX embedding model simultaneously, they encounter system-level mutex conflicts. This prevents hooks from being safely executed by multiple Claude instances running concurrently.\n\nRoot cause: `user-prompt-submit.ts` directly instantiates `SearchEngine`/`ThinkingSearchEngine`, which load the embedding model via fastembed. The `proper-lockfile` file-based locking doesn't prevent ONNX's internal mutex issues.\n\nThis is a fundamental limitation of ONNX runtime's concurrency model, not a Local Recall-specific issue. The workaround requires either: (1) using a shared embedding daemon like Ollama, or (2) switching to a pure-JavaScript embedding library without native dependencies.","timestamp":"2025-12-21T19:27:11.990Z"}
{"action":"add","id":"ee1865aa-8c7d-4fca-a82f-ca0250072e08","subject":"Plugin manifest location and structure","keywords":["plugin.json","manifest","plugin metadata","dev-marketplace"],"applies_to":"file:dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json","occurred_at":"2025-12-21T19:20:03.546Z","content_hash":"bd67ac40a6643f0a","content":"The plugin manifest file is located at dev-marketplace/local-recall-plugin/.claude-plugin/plugin.json. This file contains the plugin version and metadata. It must be kept in sync with package.json when releasing new versions.","timestamp":"2025-12-21T19:27:11.991Z"}
{"action":"add","id":"b6990ac1-1418-4710-802d-aa30047394f8","subject":"Mutex errors caused by concurrent sqlite-vec operations across processes","keywords":["sqlite-vec","mutex","concurrent","database","locking","file-based"],"applies_to":"global","occurred_at":"2025-12-21T19:11:29.598Z","content_hash":"59b04848435d8e22","content":"The mutex errors ('mutex lock failed: Invalid argument') were caused by concurrent database operations attempting to use sqlite-vec simultaneously. The issue manifested when:\n\n1. Multiple processes (hooks) opened separate database connections\n2. Each loaded sqlite-vec into their connection\n3. Concurrent operations caused sqlite-vec's internal mutexes to become corrupted\n\nThe original file lock only protected the `sqliteVec.load()` call, not the subsequent vector operations. Solution: implemented cross-process file-based locking in `withDbMutex()` to serialize ALL database operations, preventing concurrent access at the SQLite level.","timestamp":"2025-12-21T19:27:11.991Z"}
{"action":"add","id":"d423c890-91e4-4e56-8c9f-73d2dd84ce4c","subject":"ensureGitignore() should always write the file, not just create if missing","keywords":["gitignore","auto-generated","sqlite","memory-storage"],"applies_to":"file:src/utils/gitignore.ts","occurred_at":"2025-12-21T19:15:38.757Z","content_hash":"5a26f0de759f351e","content":"The ensureGitignore() function only created the .gitignore file if it didn't exist. This meant existing installations wouldn't get updates when new ignore patterns are needed (like sqlite database files). Changed to always write/update the file since it's auto-generated. This ensures all users get the correct patterns.","timestamp":"2025-12-21T19:27:11.992Z"}
{"action":"add","id":"d48cb556-bd20-405c-ba08-e7e3f16958ca","subject":"Memory types enabled by default in configuration","keywords":["episodicEnabled","thinkingEnabled","default configuration","memory types"],"applies_to":"global","occurred_at":"2025-12-21T19:19:51.719Z","content_hash":"a61365e990d71676","content":"Both `episodicEnabled` and `thinkingEnabled` are set to `true` by default in `src/core/types.ts:118-121`. This means both episodic and thinking memories are active by default without requiring explicit configuration.","timestamp":"2025-12-21T19:27:11.992Z"}
{"action":"add","id":"746f78a9-8a17-4ba7-b47c-3f4fa531c991","subject":"Memory extraction uses Zod schema validation with flexible response format handling","keywords":["zod","validation","schema","json-parsing","error-handling"],"applies_to":"file:src/core/memory-extractor.ts","occurred_at":"2025-12-21T18:23:45.023Z","content_hash":"47d88f37087f5898","content":"The parseClaudeResponse method uses Zod for schema validation of memory extraction responses. The schema validates both the overall response structure and individual memory objects. The function must handle various response formats from Claude - the most reliable approach is to first parse the JSON, then normalize the structure before validation. This catches edge cases where the model deviates from the expected format.","timestamp":"2025-12-21T19:27:11.993Z"}
{"action":"add","id":"4e9ce61f-a618-4a5f-bf53-069c3e9961e3","subject":"UserPromptSubmit hook needs recursion guard using [LOCAL_RECALL_INTERNAL] token","keywords":["recursion guard","hook","internal prompts","extraction","mcp config"],"applies_to":"file:src/hooks/user-prompt-submit.ts","occurred_at":"2025-12-21T18:25:22.045Z","content_hash":"f46b153db5aa7c50","content":"When the UserPromptSubmit hook calls `claude -p` for extraction, it triggers another UserPromptSubmit hook recursion. Solution: prefix internal extraction prompts with [LOCAL_RECALL_INTERNAL] token and skip any prompts starting with this token. Also pass --strict-mcp-config to disable MCP servers during internal extraction calls to prevent cascading recursion.","timestamp":"2025-12-21T19:27:11.993Z"}
{"action":"add","id":"e532eec7-df10-49f1-9177-c8db65ba3719","subject":"Plugin hook scripts must have .js extension, not .ts, after compilation","keywords":["plugin","hooks","compilation","typescript","javascript","file-extension"],"applies_to":"area:local-recall-plugin","occurred_at":"2025-12-21T18:25:24.918Z","content_hash":"5f4b623b4983bdbe","content":"Hook scripts in the plugin need to reference the compiled JavaScript files (.js extension), not the TypeScript source files.\n\nThe build process compiles `.ts` files to `.js` and places them in the `dist/` folder. When referencing these from plugin configuration or startup scripts, always use the `.js` extension:\n- âœ“ `node ./dist/hooks/session-start.js`\n- âœ— `node ./src/hooks/session-start.ts`\n\nThis applies to all hook references in plugin initialization code.","timestamp":"2025-12-21T19:27:11.994Z"}
{"action":"add","id":"ed57aea9-12e6-4ac1-a4c5-d3c8018af0a4","subject":"Test suite uses vitest with watch mode by default","keywords":["vitest","tests","npm","watch-mode","package.json"],"applies_to":"file:package.json","occurred_at":"2025-12-03T09:48:06.256Z","content_hash":"dcc5efea8674a8d5","content":"The npm test script originally ran vitest in watch mode (interactive). Changed to `vitest run` to complete tests in CI/CD contexts.\n\n**All 289 tests pass** after concurrency refactoring, indicating the solution is backward-compatible and doesn't break existing functionality.","timestamp":"2025-12-21T19:27:11.994Z"}
{"action":"add","id":"fb1ef0c4-927f-4699-ad6b-5fef741ffbaa","subject":"Memory content hashing uses SHA-256 truncated to 16 characters","keywords":["content-hash","deduplication","hashing","implementation"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T18:20:31.269Z","content_hash":"8cfb5a7119c79778","content":"## Content Hash Implementation\n\n### Algorithm\n- Uses SHA-256 hashing of the memory content\n- Hash is truncated to 16 characters (using `substring(0, 16)`)\n- Stored in `content_hash` field in memory frontmatter\n\n### Purpose\n- Primary deduplication mechanism (combined with `occurred_at`)\n- Allows detecting exact duplicate content\n- 16-character hash provides good collision resistance for practical use\n\n### Method\n`computeContentHash(content: string): string` in memory.ts computes this hash","timestamp":"2025-12-21T19:27:12.005Z"}
{"action":"add","id":"866ba1db-b7a8-472b-b7fc-c2efbab191b8","subject":"Vector store uses SQLite with vector search, not JSON index files","keywords":["vector-store","sqlite","migration","embeddings","search"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T19:19:15.418Z","content_hash":"ab59b853fb2e3549","content":"The vector store was migrated from Orama JSON index files (orama-episodic-index.json) to SQLite. The current implementation in src/core/vector-store.ts uses a relational database with two tables: `memories` (metadata) and `memory_embeddings` (vector data).\n\nData flows into SQLite through three pathways:\n1. **On memory creation**: MemoryManager.createMemory() writes markdown file, then immediately calls vectorStore.add() to insert embedding\n2. **On vector store initialization**: VectorStore.initialize() syncs all existing memory files into database\n3. **MCP server daemon**: Calls vectorStore.sync(memories) to keep database current with file changes","timestamp":"2025-12-21T19:27:12.006Z"}
{"action":"add","id":"e446204b-516f-44f3-ba85-19368bde6ce3","subject":"Plugin structure and build artifacts in dev-marketplace","keywords":["plugin structure","dev-marketplace","build output","skills directory"],"applies_to":"file:dev-marketplace/local-recall-plugin","occurred_at":"2025-12-21T19:23:20.420Z","content_hash":"de92917ab4912976","content":"The local-recall plugin is organized in `dev-marketplace/local-recall-plugin/` with a `skills/` subdirectory containing skill definitions. The plugin maintains metadata and configuration files alongside skill definitions. Build and distribution happens through the dev-marketplace structure rather than the main src/ directory.","timestamp":"2025-12-21T19:27:12.006Z"}
{"action":"add","id":"a83cd1fd-f413-4572-85a9-d328f9732a2b","subject":"Memory deduplication uses occurred_at timestamp and content_hash, no full compaction exists","keywords":["deduplication","memory-management","duplicate-prevention","compaction","memory.ts","findDuplicate"],"applies_to":"file:src/core/memory.ts","occurred_at":"2025-12-21T19:17:14.934Z","content_hash":"b5993b32570efbbc","content":"Memory deduplication in Local Recall uses a **findDuplicate** method that checks for existing memories with matching `occurred_at` timestamp AND `content_hash` before creation.\n\nKey findings:\n- **No full memory compaction** - Memories are not automatically merged, consolidated, or pruned\n- **Duplicate prevention only** - If a memory with the same timestamp and content hash exists, the existing memory is returned instead of creating a duplicate\n- **Configuration exists** - `maxMemories` config option is defined in `src/utils/config.ts` (default 1000) but appears to not be actively used for pruning\n- **Idempotent creation** - Memory creation is designed to be idempotent - creating the same memory multiple times returns the existing one\n\nThis means over time, the memory store can grow unbounded if `maxMemories` limit is not actively enforced.","timestamp":"2025-12-21T19:27:12.007Z"}
{"action":"add","id":"5a4fa728-9b1a-4c82-bca5-6421ee50bdeb","subject":"Complete markdown to JSONL migration required for both episodic and thinking memories","keywords":["migration","markdown","jsonl","episodic-memory","thinking-memory","cleanup"],"applies_to":"global","occurred_at":"2025-12-21T19:13:46.767Z","content_hash":"7da139bfac2dcfcf","content":"A comprehensive migration needs to be completed:\n\n**Current state:**\n- 779 episodic memory markdown files still exist\n- 2132 thinking memory markdown files still exist\n- JSONL files in root contain few entries (partial data)\n\n**Expected final state:**\n1. All markdown files read and migrated to numbered JSONL files\n2. Markdown files deleted after successful migration\n3. JSONL files moved to their respective folders (episodic-memory/ and thinking-memory/)\n4. Embeddings generated and stored in JSONL records\n5. Orama indexes rebuilt from JSONL data\n\nThe migration should verify data integrity and handle duplicates during consolidation.","timestamp":"2025-12-21T19:27:12.007Z"}
{"action":"add","id":"f7e1ec96-4f19-481a-bae9-caf4e04a2f40","subject":"Improved logging with PID and timing information for database operations","keywords":["logging","debugging","pid","performance monitoring","lock acquisition"],"applies_to":"file:src/utils/database.ts","occurred_at":"2025-12-21T18:20:26.357Z","content_hash":"1d40421e0edabd0c","content":"# Enhanced Database Logging\n\n## Changes Made\n1. **PID Logging**: Every log entry includes `[PID:xxxx]` to identify which process is executing\n2. **Lock Acquisition Details**: Shows:\n   - Attempt count when acquiring file locks\n   - Elapsed time for lock acquisition\n   - Named pipe path being locked\n3. **sqlite-vec Load Timing**: Separate timing for:\n   - Vector store load time\n   - Total initialization time\n   - Connection status\n4. **Error Stack Traces**: Full stack traces logged on failures for better debugging\n\n## Purpose\nThese improvements enable debugging of concurrent access issues and identifying which processes are accessing the database and when.","timestamp":"2025-12-21T19:27:12.008Z"}
{"action":"add","id":"4eb797b3-8097-487e-8a05-579b45a6da9c","subject":"Ollama embedding model uses nomic-embed-text with 768 dimensions","keywords":["ollama","embeddings","nomic-embed-text","768 dimensions","model"],"applies_to":"global","occurred_at":"2025-12-21T18:59:36.143Z","content_hash":"80048043ccc546d1","content":"Local Recall uses Ollama for generating embeddings with the `nomic-embed-text` model, which produces 768-dimensional vectors (approximately 274MB model size). This must be explicitly pulled before use: `ollama pull nomic-embed-text`. The embedding base URL and model name are configurable via `OLLAMA_BASE_URL` and `OLLAMA_EMBED_MODEL` environment variables.","timestamp":"2025-12-21T19:27:12.009Z"}
{"action":"add","id":"d73cf980-032b-44d5-ac4a-15f0fbbb0e8c","subject":"Memory extraction filters single-line content by design","keywords":["memory filtering","multiline content","single-line filtering","thinking memories","memory criteria"],"applies_to":"file:src/utils/transcript.ts","occurred_at":"2025-12-21T19:20:20.675Z","content_hash":"3f340160187149e5","content":"The memory extraction logic in `analyzeForMemories()` at `src/utils/transcript.ts:294-342` intentionally has different filtering rules:\n\n- **Thinking blocks**: Saved even if single-line (all thinking is preserved)\n- **Content/answers**: Only saved if multiline (single-line responses are filtered out)\n\nThis design ensures that multiline, substantive responses become memories while brief single-line messages don't clutter the memory system. The filtering check `if (lines.length >= 2)` at line 329 is intentional.","timestamp":"2025-12-21T19:27:12.010Z"}
{"action":"add","id":"acab812d-c248-4c7c-bb61-493a081fb68d","subject":"MCP server distribution requires git-tracked scripts for Claude Code plugins","keywords":["mcp-server","plugin","distribution","github","git-tracked","local-recall-plugin"],"applies_to":"global","occurred_at":"2025-12-21T18:25:24.918Z","content_hash":"fa152efc31541990","content":"Claude Code fetches plugins from GitHub repositories. The MCP server startup failure was caused by `local-recall-plugin/scripts/` being in .gitignore, so the startup scripts were missing when Claude Code tried to load the plugin.\n\n**Solution**: Remove `local-recall-plugin/scripts/` from .gitignore so that hook scripts are tracked in git. This allows Claude Code to find and execute:\n- `local-recall-plugin/scripts/hooks/session-start.js`\n- `local-recall-plugin/scripts/hooks/user-prompt-submit.js`\n- `local-recall-plugin/scripts/hooks/stop.js`\n- `local-recall-plugin/scripts/mcp-server/server.js`\n\n**Key insight**: Any executable script that needs to be distributed as part of a GitHub-hosted plugin must be tracked in git, not ignored.","timestamp":"2025-12-21T19:27:12.011Z"}
{"action":"add","id":"80295540-1738-4774-8613-a26cd22aa5da","subject":"Thinking memories capture thought-output pairs from transcripts for reusable reasoning patterns","keywords":["thinking-memory","thought","output","transcript","reasoning","extraction","claude"],"applies_to":"area:thinking-memory","occurred_at":"2025-12-21T19:02:32.602Z","content_hash":"01d9a2df5ce48f40","content":"Thinking memories store Claude's internal reasoning paired with the corresponding output, creating reusable examples of \"how I thought â†’ what I produced\".\n\nFormat:\n- `## Thought` section - Claude's internal reasoning/thinking block\n- `## Output` section - The text response that followed the thinking\n\nExtractions use 20 parallel workers to process thinking blocks from transcripts. Only thought-output pairs are stored (tool-only responses are skipped). This provides concrete examples of reasoning patterns that can be retrieved and applied to similar future tasks.","timestamp":"2025-12-21T19:27:12.011Z"}
{"action":"add","id":"180dfec4-9933-4a73-8577-beff3f65bc88","subject":"Stop hook handles transcript parsing and memory extraction from Claude transcripts","keywords":["stop","transcript","parsing","memory extraction","memories"],"applies_to":"file:src/hooks/stop.ts","occurred_at":"2025-12-21T19:21:19.454Z","content_hash":"28542d157fffcec1","content":"The stop hook is responsible for parsing transcripts and extracting memories from Claude Code sessions. It processes transcript data and creates memory files based on the conversation content.","timestamp":"2025-12-21T19:27:12.012Z"}
{"action":"add","id":"8a6f6a3c-05e9-4a4e-9c90-96ff71e6c13b","subject":"Memory extractor handles recursive callback loop through session guarding","keywords":["recursion","callback-loop","session-guard","internal-prompts"],"applies_to":"global","occurred_at":"2025-12-21T18:29:15.440Z","content_hash":"7d85d40c0e43ee36","content":"Memory extraction creates a callback loop: MCP daemon calls `claude -p` with a memory extraction prompt â†’ UserPromptSubmit hook fires â†’ hook searches memories â†’ potentially creates new memories. To prevent infinite loops, the hook must filter out internal prompts using the `[LOCAL_RECALL_INTERNAL]` prefix. This guards the system from processing its own internal operations as user-initiated semantic searches.","timestamp":"2025-12-21T19:27:12.012Z"}
{"action":"add","id":"c1a23a5d-ed0b-466e-b051-b341f8bfb9be","subject":"Local Recall marketplace.json version must match package.json for plugin updates","keywords":["marketplace.json","version","plugin","0.1.9","plugin distribution"],"applies_to":"file:.claude-plugin/marketplace.json","occurred_at":"2025-12-21T19:10:16.829Z","content_hash":"2222396522748bab","content":"The marketplace.json file at `.claude-plugin/marketplace.json` controls the version displayed in the Claude Code marketplace. When updating Local Recall, ensure marketplace.json version matches package.json version (currently 0.1.9). If not updated together, users will see stale version information when checking for plugin updates in Claude Code.","timestamp":"2025-12-21T19:27:12.013Z"}
{"action":"add","id":"a1e2ecd7-a3a1-4272-8ba3-5f2e0685131b","subject":"SessionStart hook reads only 5 most recent episodic memories from files","keywords":["sessionstart","episodic memory","recency","file system","memory injection"],"applies_to":"file:src/hooks/session-start.ts","occurred_at":"2025-12-21T18:16:18.307Z","content_hash":"32ee2483e9743dec","content":"## Implementation Details\nThe SessionStart hook does NOT use vector search - it directly reads memory files:\n1. Reads all episodic memory files from `local-recall/episodic-memory/`\n2. Parses YAML frontmatter to extract `occurred_at` timestamp\n3. Sorts by `occurred_at` in descending order (most recent first)\n4. Selects only the first 5 memories\n5. Outputs memory content directly to stdout for context injection\n\n## Why This Design\n- Avoids vector embedding overhead on session start\n- Provides recent context without semantic search\n- Simple and fast - no Ollama dependency for this hook\n- Recency-based ordering ensures latest relevant context\n\n## Configuration\nMax context memories configured via `LOCAL_RECALL_MAX_CONTEXT` env var (default: 10 in code)","timestamp":"2025-12-21T19:27:12.013Z"}
{"action":"add","id":"bd2468ec-19e5-4de0-832d-da882a8a17c3","subject":"Memory file format uses YAML frontmatter with specific required fields","keywords":["markdown","yaml","frontmatter","memory-format","metadata","id","subject"],"applies_to":"global","occurred_at":"2025-12-21T19:22:52.588Z","content_hash":"e80a8ea1206fdda1","content":"Each memory file uses YAML frontmatter (triple dashes) with these required fields:\n- `id`: UUID for unique identification\n- `subject`: One-line brief description\n- `keywords`: Array of searchable terms\n- `applies_to`: Scope (global, file:<path>, or area:<name>)\n- `occurred_at`: ISO-8601 timestamp for deduplication and sorting\n- `content_hash`: SHA-256 prefix (16 chars) for duplicate detection\n\nThe actual memory content follows the frontmatter in markdown format.","timestamp":"2025-12-21T19:27:12.013Z"}
{"action":"add","id":"3af50791-56bb-48f7-b486-093218744975","subject":"Similarity scores rounded to 2 decimal places with recency as tie-breaker","keywords":["scoring","similarity","distance","rounding","ranking","occurred_at"],"applies_to":"file:src/core/vector-store.ts","occurred_at":"2025-12-21T18:24:38.922Z","content_hash":"700cf4333c369a71","content":"Vector search results use **cosine distance** similarity scoring with the following behavior:\n\n1. **Score Range**: 0.0 (no match) to 1.0 (identical)\n2. **Rounding**: All scores are rounded to 2 decimal places using `Math.round((1 - distance / 2) * 100) / 100`\n   - Example: 0.6524... becomes 0.65\n3. **Recency Tie-breaker**: When multiple results have equal similarity scores, they are sorted by `occurred_at` descending (newest first)\n4. **Sort Order**: Results are first sorted by distance, then by `occurred_at` for ties\n\nThis ensures consistent, readable scores and prioritizes more recent memories when similarity is equivalent.","timestamp":"2025-12-21T19:27:12.014Z"}
{"action":"add","id":"674b0f22-4bb6-457a-8491-257ce360d37a","subject":"No existing mutex/concurrency tests in the test suite","keywords":["testing","mutex","concurrent","test-coverage","gap"],"applies_to":"global","occurred_at":"2025-12-21T19:17:32.370Z","content_hash":"99074da8401b4501","content":"Current testing does not include specific tests for mutex errors or concurrent process scenarios. Searches for 'mutex' in code and 'mutex' or 'concurrent' in tests returned no existing test files, indicating a gap in test coverage for concurrent access patterns.","timestamp":"2025-12-21T19:27:12.014Z"}
