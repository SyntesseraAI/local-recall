---
id: 3d22ce00-9583-42e7-9c5b-6605e65a82b6
subject: >-
  Memory extraction from transcripts should use Haiku model for keyword
  extraction
keywords:
  - memory-extraction
  - haiku
  - keyword-extraction
  - transcripts
  - embedding
  - performance
applies_to: global
occurred_at: '2025-12-02T06:27:58.195Z'
content_hash: 91356dccc2bd64f0
---
# Using Haiku for Memory Extraction

The project currently uses Claude Haiku for keyword extraction from user prompts and transcripts. This is appropriate because:

## Why Haiku Works Well

- **Fast**: Haiku is significantly faster than larger models, critical for real-time hook execution
- **Cost-effective**: Lower API costs for repetitive keyword extraction tasks
- **Sufficient capability**: Keyword and concept extraction doesn't require Sonnet-level reasoning
- **Reliable**: Haiku is capable enough for structured keyword output

## Current Implementation

The user-prompt-submit hook calls `claude -p --model haiku` to extract keywords from user prompts before searching the memory index. This pattern works well and should be maintained.

## Alternative: Embedding-Based Search

The project has experimental embedding support (BGE-small-en-v1.5 model) which could eventually replace keyword-based search with semantic similarity. However, keyword extraction via Haiku remains the current approach.
