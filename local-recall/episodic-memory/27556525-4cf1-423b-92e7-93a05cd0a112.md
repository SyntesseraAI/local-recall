---
id: 27556525-4cf1-423b-92e7-93a05cd0a112
subject: >-
  Memory extraction from transcripts uses LLM to identify valuable information
  for future sessions
keywords:
  - memory-extraction
  - transcript-processing
  - llm
  - prompts
  - semantic-understanding
  - future-context
applies_to: 'area:memory-extraction'
occurred_at: '2025-12-02T16:48:32.597Z'
content_hash: e0123be80b50726d
---
# Memory Extraction from Transcripts

The Local Recall system uses an LLM (Claude) to analyze session transcripts and extract valuable memories that will help future AI assistants working on the codebase.

## Key Concept

Not all information from transcripts should be stored as memories. The extraction process is selective and intelligent:

- **Include**: Architectural decisions, bug fixes, code patterns, configuration quirks, learned conventions, component relationships
- **Exclude**: Generic programming knowledge, temporary debugging, obvious information, sensitive data, ephemeral details

## Process Flow

1. Transcript is condensed into a summary format
2. LLM analyzes the condensed transcript
3. Memories are extracted with:
   - Clear subject line
   - Relevant keywords for searchability
   - Appropriate scope (global, file-specific, or area-specific)
   - Detailed content explaining the memory

## Memory Scope

- **global** - Applies to entire codebase (architecture, conventions, preferences)
- **file:<path>** - Specific to a particular file
- **area:<name>** - Related to a component or functional area

## Stored Format

Extracted memories are saved as markdown files with YAML frontmatter containing metadata. These files are version-controlled and searchable via semantic embeddings.
