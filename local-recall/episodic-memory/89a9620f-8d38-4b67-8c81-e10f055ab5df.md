---
id: 89a9620f-8d38-4b67-8c81-e10f055ab5df
subject: Embedding model implementation plan - using fastembed library
keywords:
  - embeddings
  - semantic-search
  - fastembed
  - bge-small
  - vector-store
  - similarity
applies_to: global
occurred_at: '2025-12-02T06:22:10.259Z'
content_hash: b9f31489dfb9e2c6
---
# Embedding Model Implementation Plan

## Architecture Decision

Local Recall uses **fastembed** (Python library via subprocess) with the **BGE-small-en-v1.5** model for semantic search capabilities.

## Rationale

1. **Lightweight** - Model is ~133MB (small enough for local use)
2. **Good quality** - BGE models are strong performers on semantic similarity tasks
3. **Fast** - fastembed uses ONNX runtime for CPU inference
4. **No external dependencies** - Runs locally, no API calls needed
5. **Language agnostic** - Python library can be called from Node.js via subprocess

## Implementation Files

- `src/core/embedding.ts` - TypeScript wrapper for embedding generation
- `src/core/vector-store.ts` - Vector storage and similarity search

## Model Details

- **Model name**: `fast-bge-small-en-v1.5`
- **Cache location**: `local_cache/` (auto-downloaded on first use)
- **First run**: May take 30-60 seconds for model download (only once)
- **Subsequent runs**: Fast, loads from cache

## Integration Points

Embeddings will enable:
1. Semantic search on memory content (not just keywords)
2. Better memory deduplication based on semantic similarity
3. Improved memory retrieval accuracy beyond fuzzy keyword matching

See CLAUDE.md for embedding model troubleshooting guide.
