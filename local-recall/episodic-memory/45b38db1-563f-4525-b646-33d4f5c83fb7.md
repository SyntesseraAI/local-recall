---
id: 45b38db1-563f-4525-b646-33d4f5c83fb7
subject: Transcript condensing strategy for memory extraction - reducing token usage
keywords:
  - transcript
  - condensing
  - memory-extraction
  - token-efficiency
  - claude-api
  - compression
applies_to: 'area:transcript-collector'
occurred_at: '2025-12-01T16:22:27.530Z'
content_hash: 62234c5d3e3d47e5
---
# Transcript Condensing for Memory Extraction

## Problem

Raw transcripts from Claude sessions are very long and would consume excessive tokens when sent to the Claude API for memory extraction.

## Solution

Implement transcript condensing before sending to Claude for memory extraction:

1. **Parse JSONL format**: Read transcript files line by line
2. **Compress content**: Extract essential information (user prompts, assistant responses, tool invocations)
3. **Remove noise**: Filter out verbose logging, repetitive tool outputs
4. **Preserve key info**: Keep important tool results and user context

## Implementation Considerations

- Use streaming or chunking to handle large transcripts efficiently
- Maintain enough detail to extract meaningful memories
- Respect token limits of the Claude API
- Include tool invocations (Tool: Name) and their outcomes (Result: OK/ERROR)

## Context

This is implemented in the `transcript-collector.ts` module, which is responsible for:
- Reading raw transcripts from Claude's cache
- Condensing them to reduce token usage
- Sending condensed transcripts to Claude for memory extraction
- Storing the extracted memories in the episodic-memory directory
