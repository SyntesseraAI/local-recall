---
id: 0500c0b9-a971-4934-beca-0d4aba3be647
subject: >-
  Local Recall embedding implementation requires two new core modules:
  embedding.ts and vector-store.ts
keywords:
  - embedding
  - vector-store
  - semantic-search
  - bg–µ-small
  - fastembed
  - implementation
  - core-modules
applies_to: global
occurred_at: '2025-12-02T07:10:34.190Z'
content_hash: aa2e3207207c9000
---
# Embedding and Vector Store Implementation

Local Recall needs to implement semantic search capabilities using embeddings. This requires two new core modules in `src/core/`:

## 1. embedding.ts Module

Handles embedding generation using fastembed library with BGE-small-en-v1.5 model:
- Lazy loads the embedding model on first use
- Caches model instance for reuse
- Provides synchronous `embed(text: string)` function returning Float32Array
- Model downloads automatically to `local_cache/` (~133MB)
- Should handle model initialization errors gracefully

## 2. vector-store.ts Module

Implements vector storage and similarity search:
- Stores embeddings alongside memory records
- Provides `addEmbedding(memoryId: string, embedding: Float32Array)` to store
- Provides `search(queryEmbedding: Float32Array, topK: number)` for similarity search
- Uses cosine similarity for ranking results
- Integrates with existing memory CRUD operations

## Integration Points

- Memory files need a new `embedding` field for storing vector data
- Search module (`search.ts`) should incorporate semantic search alongside keyword search
- User-prompt-submit hook should use embeddings for better context retrieval
- Memory creation should automatically generate and store embeddings

## Model Details

- Model: BGE-small-en-v1.5 (from sentence-transformers)
- Embedding dimension: 384
- First run: 30-60 seconds for model download (one-time)
- Subsequent runs: Load from cache in `local_cache/`

These modules are essential for improving memory retrieval quality beyond keyword matching.
