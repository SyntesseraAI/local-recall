---
id: 956b8361-c753-4576-98eb-21abed1498c4
subject: >-
  Local Recall uses fastembed BGE-small-en-v1.5 model for semantic search with
  lazy loading
keywords:
  - embedding
  - semantic
  - search
  - fastembed
  - bge
  - model
  - lazy-loading
  - cache
applies_to: 'file:src/core/embedding.ts'
occurred_at: '2025-12-02T07:54:12.441Z'
content_hash: 37d1c2b75b451f46
---
# Embedding Model Configuration

## Model Details

Local Recall uses:
- **Library**: fastembed (Rust-based, fast inference)
- **Model**: BGE-small-en-v1.5
- **Size**: ~133MB
- **Cache Location**: `local_cache/fast-bge-small-en-v1.5/`

## Lazy Loading Behavior

- Model is downloaded and cached on first use
- Subsequent runs load from cache (fast)
- Initial startup may take 30-60 seconds due to download
- Model is shared across all embedding operations

## Common Issues

**Tokenizer file not found error**:
- Usually indicates corrupted/incomplete cache
- Solution: Delete `local_cache/fast-bge-small-en-v1.5*` and let it re-download

## Implementation Pattern

When implementing embedding functionality:
1. Load model once and reuse for multiple embeddings
2. Handle first-run latency gracefully
3. Implement proper error handling for model loading
4. Consider caching embeddings to avoid recomputation
