---
id: ec6759fc-90d0-43a3-844e-fa90f6238d88
subject: Memory extraction workflow and transcript processing pipeline
keywords:
  - memory-extraction
  - transcript
  - processing
  - pipeline
  - daemon
  - mcp-server
  - condenser
  - extractor
applies_to: global
occurred_at: '2025-12-02T16:31:24.435Z'
content_hash: 1679b819e3ba6119
---
# Memory Extraction Workflow

## Current Architecture

The memory extraction uses a multi-stage pipeline:

1. **Transcript Collection** (`transcript-collector.ts`)
   - Reads JSONL files from `~/.claude/projects/<project>/transcripts/`
   - Parses raw transcript data

2. **Transcript Condensing** (`transcript-condenser.ts`)
   - Transforms raw transcripts into a condensed format
   - Reduces verbosity while preserving important information
   - Output format: events with `[User]`, `[Assistant]`, `[Tool]` markers

3. **Memory Extraction** (`memory-extractor.ts`)
   - Uses Claude to analyze condensed transcripts
   - Generates structured memories with metadata
   - Creates YAML frontmatter with: id, subject, keywords, applies_to, occurred_at, content_hash

4. **MCP Server Daemon**
   - Runs asynchronously every 5 minutes
   - Processes new/changed transcripts
   - Tracks processed transcripts with content hashes (no update behavior - recreates on changes)
   - Stores memories as markdown files in `local-recall/episodic-memory/`

## Why This Design

- Async processing prevents blocking user sessions
- Condensing reduces token usage for Claude's analysis
- Hashing enables change detection without re-processing unchanged transcripts
- Decouples transcript collection from memory creation

## Current Status

The Stop hook is currently disabled. Memory extraction is handled entirely by the MCP daemon.
