---
id: 0da8cd75-266f-41b1-af5a-ef372583d48d
subject: >-
  Transcript condensing reduces token usage by ~90% while preserving memory
  extraction value
keywords:
  - transcript-condensing
  - token-efficiency
  - memory-extraction
  - summarization
applies_to: global
occurred_at: '2025-12-01T21:43:03.972Z'
content_hash: d1d1cee6f628722e
---
# Transcript Condensing for Memory Extraction

Implement transcript condensing as a preprocessing step before memory extraction.

## Approach

1. **Condense Format**: Convert full transcript events into compact format:
   - `[User] question/request`
   - `[Assistant] brief response/action`
   - `[Tool: Name]` only tool names (not full parameters)
   - `[Result: OK/ERROR]` outcome only

2. **Token Savings**: ~90% reduction in tokens needed for memory extraction
   - Full transcripts: 10,000+ tokens
   - Condensed transcripts: ~1,000 tokens

3. **Preserved Information**: Condensing retains sufficient context for:
   - Problem identification and solutions
   - Architectural decisions
   - Code changes and their rationale
   - Patterns and conventions discovered

4. **Implementation**: Process transcripts through a condenser before passing to memory extraction model
