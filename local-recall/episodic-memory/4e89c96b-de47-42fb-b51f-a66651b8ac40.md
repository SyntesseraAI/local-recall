---
id: 4e89c96b-de47-42fb-b51f-a66651b8ac40
subject: Transcript processing flow includes condensing before memory extraction
keywords:
  - transcript-condensing
  - memory-extraction-flow
  - processing-pipeline
applies_to: global
occurred_at: '2025-12-01T16:34:56.394Z'
content_hash: b474ea13b30d7791
---
Based on the codebase structure, there's a two-step transcript processing pipeline:

1. **Transcript Condensing** - Raw transcripts from Claude's cache are condensed (likely removing redundant content, shortening long outputs)
2. **Memory Extraction** - The condensed transcript is then sent to Claude Haiku for memory extraction via the `memory-extractor` module

This ensures that the AI model receives a concise, relevant version of the transcript rather than the full raw output, improving extraction quality and reducing token usage.
