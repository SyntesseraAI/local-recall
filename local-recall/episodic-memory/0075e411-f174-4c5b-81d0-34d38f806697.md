---
id: 0075e411-f174-4c5b-81d0-34d38f806697
subject: Migrated embedding service from fastembed to Ollama
keywords:
  - ollama
  - fastembed
  - embedding
  - migration
  - nomic-embed-text
  - vector-search
applies_to: global
occurred_at: '2025-12-03T11:46:02.915Z'
content_hash: 5493e9917b0a1ac0
---
# Embedding Service Migration: fastembed → Ollama

Replaced fastembed (ONNX-based BGE-small-en-v1.5) with Ollama HTTP API for embeddings.

## Key Changes

- **Model**: `nomic-embed-text` (768 dimensions) replaces BGE-small-en-v1.5 (384 dimensions)
- **Architecture**: HTTP API calls to local Ollama server instead of in-process ONNX runtime
- **Concurrency**: Ollama handles concurrent requests properly - no more mutex errors

## Removed Dependencies

- `fastembed` - ONNX embedding library
- `proper-lockfile` - Only needed for ONNX mutex workarounds
- `local_cache/` directory - No longer needed (Ollama manages model storage)

## Configuration

- `OLLAMA_BASE_URL` - Server URL (default: `http://localhost:11434`)
- `OLLAMA_EMBED_MODEL` - Model name (default: `nomic-embed-text`)

## Migration Required

Users must rebuild vector indexes after this change due to dimension change (384 → 768):

```bash
rm local-recall/orama-episodic-index.json
rm local-recall/orama-thinking-index.json
ollama pull nomic-embed-text
```
