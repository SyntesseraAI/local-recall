---
id: 8d7eec24-c884-45d8-9537-8fad9bf794c2
subject: Transcript condensing for memory extraction using Claude API
keywords:
  - transcript
  - condensing
  - memory-extraction
  - claude-api
  - context-window
  - compression
applies_to: 'area:memory-extraction'
occurred_at: '2025-12-01T23:01:35.684Z'
content_hash: f64f52210090009a
---
# Transcript Condensing for Memory Extraction

## Problem

Raw transcripts can be very large, causing context window issues when sending to Claude for memory extraction. Particularly problematic with long coding sessions.

## Solution

Implement transcript condensing before sending to Claude:

1. **Use Claude to condense**: Send transcript through Claude Haiku first to create a condensed summary
2. **Preserve key moments**: Focus on important decisions, changes, and learnings
3. **Reduce size**: Aim to reduce transcript to 20-30% of original size while preserving actionable information
4. **Then extract memories**: Use condensed version for memory extraction

## Implementation

Add condensing step in the memory extraction pipeline (likely in `src/core/memory-extractor.ts`):
- Read raw transcript
- Call Claude to condense (use Haiku for speed/cost)
- Extract memories from condensed transcript
- Store both original and condensed versions for reference

## Benefits

- Reduces token usage for memory extraction
- Prevents context window exhaustion with large transcripts
- Still captures all actionable information
- Improves quality of extracted memories by reducing noise
