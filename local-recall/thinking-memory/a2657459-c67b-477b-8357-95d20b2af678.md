---
id: a2657459-c67b-477b-8357-95d20b2af678
subject: >-
  The code uses `http://localhost:11434` (the correct Ollama port). But the
  error shows...
applies_to: global
occurred_at: '2025-12-20T22:33:12.263Z'
content_hash: 5f8f896683f6dbf6
---
## Thought

The code uses `http://localhost:11434` (the correct Ollama port). But the error shows `http://127.0.0.1:49889/embedding`. 

Wait - I notice the error says `/embedding` but our code uses `/api/embed`. The error message path is different. This suggests the error is coming from INSIDE Ollama itself, not from our code calling Ollama.

Looking at the error more closely:
```
Ollama embed failed: 500 - {"error":"do embedding request: Post \"http://127.0.0.1:49889/embedding\": EOF"}
```

This is Ollama's internal error - Ollama is trying to POST to `http://127.0.0.1:49889/embedding` which is likely its internal embedding server/model process. The 49889 is probably a dynamically allocated port for Ollama's internal model communication.

This is a transient Ollama internal error - the model process might have crashed or restarted. It's not something we can fix in our code. The retry mechanism should eventually succeed.

Let me explain this to the user.

## Output

The code correctly uses `localhost:11434`. The error is **internal to Ollama** - that `49889` port is Ollama's internal model subprocess communication:

```
Ollama embed failed: 500 - {"error":"do embedding request: Post \"http://127.0.0.1:49889/embedding\": EOF"}
```

The path `/embedding` (not `/api/embed`) is Ollama's internal route. This means Ollama itself is having issues communicating with its model process. 

Possible causes:
1. **Model subprocess crashed/restarted** - Ollama spawns internal processes for models
2. **Memory pressure** - macOS may have killed the model process
3. **Ollama update** - Sometimes updates require restart

Try restarting Ollama:

```bash
# Kill and restart Ollama
pkill ollama
ollama serve &
```

Or if using the app, restart the Ollama application.

`★ Insight ─────────────────────────────────────`
**Ollama's architecture:** When you call Ollama's API, it forwards requests to internal model runners on ephemeral ports. The `49889` in the error is a dynamically allocated port for the `nomic-embed-text` model subprocess. When you see "EOF" errors on these internal ports, it means the model process died mid-request - usually due to resource pressure or the model being unloaded.
`─────────────────────────────────────────────────`
