---
id: a6757514-19a0-436b-b81f-71ee7aba8eca
subject: >-
  The user is asking about alternatives to ONNX/fastembed for local vector
  embeddings that might not...
applies_to: global
occurred_at: '2025-12-03T11:22:04.300Z'
content_hash: ba353b50968cb130
---
## Thought

The user is asking about alternatives to ONNX/fastembed for local vector embeddings that might not have the mutex issues.

Let me think about options:

1. **Transformers.js** - Pure JavaScript/WebAssembly implementation of transformers. Uses ONNX runtime under the hood via onnxruntime-web, but it's designed for browser/Node.js and might handle concurrency differently.

2. **@xenova/transformers** - The main transformers.js library. It does use ONNX runtime but in a different way.

3. **Universal Sentence Encoder (TensorFlow.js)** - @tensorflow-models/universal-sentence-encoder. TensorFlow.js based, might not have the same mutex issues.

4. **OpenAI-like local servers** - Running a separate embedding server (like llama.cpp with embedding support, or text-embeddings-inference) that handles concurrency properly.

5. **sqlite-vss with different backend** - But that's still native code.

6. **Simple hash-based or TF-IDF embeddings** - Not as good quality but pure JavaScript.

7. **Voyage AI, Cohere, OpenAI APIs** - Remote APIs, would require internet and API keys.

Let me search for what's available and their characteristics regarding concurrency.

The key issue is that ONNX runtime (used by fastembed) has internal mutexes that fail when multiple processes try to load it. We need either:
- A library that doesn't use ONNX runtime
- A library that handles multi-process scenarios better
- A library that uses ONNX runtime but in a way that doesn't have mutex issues

Transformers.js (@xenova/transformers) uses onnxruntime-node under the hood for Node.js, so it might have the same issues. Let me check if there are other options.

Actually, I should do a web search to find current alternatives and their characteristics.

## Output

Let me search for alternatives:
