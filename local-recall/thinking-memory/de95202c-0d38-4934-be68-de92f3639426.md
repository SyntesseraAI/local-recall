---
id: de95202c-0d38-4934-be68-de92f3639426
subject: >-
  The user doesn't want the HTTP daemon approach because it would mean only one
  Claude instance could...
applies_to: global
occurred_at: '2025-12-03T11:21:39.313Z'
content_hash: 3f781bf2fdf71513
---
## Thought

The user doesn't want the HTTP daemon approach because it would mean only one Claude instance could run at a time (since the daemon would be a singleton owning the embedding model).

The core problem is that ONNX runtime (fastembed) has internal mutex issues when multiple processes load it concurrently. The file-based locking with proper-lockfile isn't working because the ONNX mutex errors happen at a lower level.

Possible alternatives:

1. **Use a different embedding library** that doesn't have mutex issues - maybe one that's pure JavaScript or handles concurrency better

2. **Pre-compute embeddings** - don't generate embeddings at query time in hooks. Instead:
   - Store embeddings in the Orama index (already happening)
   - At query time, use text-based search or a simpler similarity approach that doesn't require loading the model

3. **Use a remote embedding API** - like OpenAI embeddings or a local server

4. **Transformers.js** - This is a pure JavaScript/WASM implementation that might not have the same mutex issues

5. **Disable vector search in hooks** - Fall back to keyword/text search when called from hooks, only use vector search from the MCP server (which is a singleton anyway)

Let me think about the simplest fix. The user wants to run multiple Claude instances, each with their own hooks running. The problem is the embedding model loading.

Option 5 seems most practical - the hooks could do simpler text-based search (keywords, subject matching) instead of vector search. The MCP server (which runs as a singleton per Claude instance) can still do vector search when explicitly called.

Actually, wait - each Claude instance has its own MCP server, so vector search via MCP tools should work fine. The issue is specifically the hooks running concurrently.

Let me check if there's a way to do search without embeddings - maybe using Orama's text search capabilities instead of vector search for the hooks.

## Output

Good point. Each Claude instance needs its own hooks, and they'd all conflict on a shared daemon.

**Alternative approaches:**

1. **Text-based search in hooks** - Use Orama's text search (no embeddings) instead of vector search for hooks. MCP tools can still use vectors.

2. **Different embedding library** - `transformers.js` is pure WASM, might not have mutex issues

3. **Disable hook search entirely** - Only search via MCP tools (each Claude instance has its own MCP server)

4. **Pre-computed embeddings only** - Hooks search the existing Orama index without generating new query embeddings (requires a different search approach)

Which direction do you prefer? Option 1 (text search in hooks) would be the quickest to implement and still provide useful results.
