---
id: 65304c47-d411-4c6f-bcf2-926532fd0c7b
subject: >-
  The user wants to optimize the memory extraction process by reducing the
  amount of content passed...
applies_to: global
occurred_at: '2025-12-01T09:45:08.570Z'
content_hash: e3adb3a0a34e1ffb
---
The user wants to optimize the memory extraction process by reducing the amount of content passed to the extractor. They want to use the transcript types to parse JSONL files and extract only the minimum necessary content for memory creation.

Let me understand the current flow:
1. Transcripts are JSONL files with various entry types
2. Currently, they're passing full transcript content to Claude for memory extraction
3. They want to reduce token usage by extracting only relevant content

Looking at the types, the key information for memory extraction would be:
- User messages (what the user asked/discussed)
- Assistant text responses (what was decided/done)
- Tool uses and their results (what actions were taken)
- Thinking content might be useful for understanding reasoning

Let me first look at the current extraction implementation to understand how it works.
