---
id: f7310f00-b7c1-4044-a835-45aa88424987
subject: >-
  Now I have a complete picture of the vector approach. Let me summarize it
  clearly for the user. Key...
applies_to: global
occurred_at: '2025-12-02T12:40:11.309Z'
content_hash: 7c154dbc6813be76
---
## Thought

Now I have a complete picture of the vector approach. Let me summarize it clearly for the user.

Key components:
1. **Embedding Model**: BGE-small-en-v1.5 via fastembed, produces 384-dimensional vectors
2. **Storage**: SQLite with sqlite-vec extension
3. **What gets embedded**: Subject + Content combined (`${memory.subject}\n\n${memory.content}`)
4. **When**: When a memory is added to the vector store
5. **Search**: Uses `queryEmbed` for the search query (different from `passageEmbed` for documents - this is an asymmetric embedding approach where queries and passages are embedded differently)
6. **Similarity**: Cosine distance, converted to a 0-1 similarity score

The distinction between `passageEmbed` and `queryEmbed` is important - BGE is an asymmetric embedding model where queries and documents are embedded differently for better retrieval.

## Output

## Vector Approach Summary

### Model
- **BGE-small-en-v1.5** via `fastembed` library
- **384 dimensions** per embedding
- Asymmetric embedding model (queries and passages are embedded differently)

### What Gets Embedded

**For memories (documents):**
```typescript
const textForEmbedding = `${memory.subject}\n\n${memory.content}`;
const embedding = await this.embeddingService.embed(textForEmbedding);
```
Uses `passageEmbed()` under the hood - optimized for documents.

**For search queries:**
```typescript
const queryEmbedding = await this.embeddingService.embedQuery(query);
```
Uses `queryEmbed()` - optimized for short search queries.

### When Embeddings Are Generated

1. **On memory creation** - When `VectorStore.add(memory)` is called, the subject+content is embedded and stored alongside the memory metadata
2. **On sync** - When `VectorStore.sync()` runs, any missing memories get their embeddings generated
3. **On search** - The user's query is embedded at search time for comparison

### Storage

- **SQLite** with `sqlite-vec` extension
- Two tables:
  - `memories` - metadata (id, subject, keywords, scope, content, etc.)
  - `memory_embeddings` - virtual table with vector embeddings

### Similarity Scoring

```typescript
// sqlite-vec returns cosine distance (0 = identical, 2 = opposite)
score = Math.round((1 - row.distance / 2) * 100) / 100
```
- Score range: **0.0 to 1.0** (higher = more similar)
- Tie-breaker: When scores are equal, more recent memories are ranked first

### Why This Approach

1. **Asymmetric embedding** - BGE treats queries and documents differently, improving retrieval accuracy for short queries against longer documents
2. **Local execution** - No API calls needed, fast after initial model load
3. **Semantic search** - Finds conceptually similar content even without keyword matches
4. **Efficient storage** - SQLite + sqlite-vec is lightweight and doesn't require a separate vector database
